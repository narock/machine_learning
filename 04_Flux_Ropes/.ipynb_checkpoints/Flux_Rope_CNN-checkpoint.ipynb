{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import everything we'll need"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "\n",
    "import math\n",
    "    \n",
    "import time\n",
    "import random\n",
    "import numpy as np\n",
    "from os import listdir\n",
    "from os.path import isfile, join\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import os\n",
    "import gc\n",
    "\n",
    "from pathlib import Path\n",
    "\n",
    "import keras\n",
    "from keras.utils import Sequence\n",
    "from keras.callbacks.callbacks import History\n",
    "from keras.models import Sequential, Model, Input\n",
    "from keras.layers import Dense, Dropout, Flatten \n",
    "from keras.layers import Conv1D, Conv2D, MaxPooling2D\n",
    "from keras.layers.convolutional import MaxPooling1D\n",
    "from keras import backend as K\n",
    "\n",
    "import tensorflow as tf\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics import mean_squared_error"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Used once during setup. Not needed for every run"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Function to create course grained fluxrope samples over domain. Used to generate our initial training set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created 2000 fluxropes\n"
     ]
    }
   ],
   "source": [
    "outDir = Path(\"/home/narock/data/fluxropes/\")\n",
    "\n",
    "N = 500.\n",
    "C1 = 1.0\n",
    "\n",
    "bRange = np.arange(5, 50, 10)\n",
    "phiRange = np.arange(0, 360, 30)\n",
    "thetaRange = np.arange(-90, 90, 30)\n",
    "y0Range = np.arange(-100, 100, 25)\n",
    "\n",
    "count = 0\n",
    "\n",
    "for bmag in bRange:\n",
    "    for phi in phiRange:\n",
    "        for theta in thetaRange:\n",
    "            for y0R in y0Range:\n",
    "    \n",
    "                # model doesn't work for (phi,theta) (0,0) and (180,0)\n",
    "                if ( (phi != 0 and theta != 0) and (phi != 180 and theta != 0) ):\n",
    "                \n",
    "                    HH = random.choice([-1, 1])\n",
    "                    time, B, BxGSE, ByGSE, BzGSE = model_fluxrope(N, bmag, HH, C1, phi, theta, y0R)\n",
    "                \n",
    "                    BxGSE, ByGSE, BzGSE = normalizeVector(BxGSE, ByGSE, BzGSE, B)\n",
    "                \n",
    "                    b_scaled = str( round( scale(bmag,5,50), 5 ) ).strip()\n",
    "                    phi_scaled = str( round( scale(phi,0,360), 5 ) ).strip()\n",
    "                    theta_scaled = str( round( scale(theta,-90,90), 5 ) ).strip()\n",
    "                    y0R_scaled = str( round( scale(y0R,-100,100), 5 ) ).strip()\n",
    "                    \n",
    "                    # change handedness from -1 or 1 to 0 or 1 to align with \n",
    "                    # neural network sigmoid function\n",
    "                    if (HH == -1):\n",
    "                        HH = 0\n",
    "                    HH = str(HH).strip()\n",
    "    \n",
    "                    label = b_scaled + \"_\" + phi_scaled + \"_\" + theta_scaled + \"_\" + y0R_scaled + \"_\" + HH\n",
    "                    file = \"fluxrope_\" + label + \".txt\"\n",
    "                    fname = outDir / file\n",
    "                    if not os.path.exists(fname):\n",
    "                        f = open( fname, \"w\" )\n",
    "                        f.write(\"bx,by,bz\" + \"\\n\")\n",
    "                    else:\n",
    "                        print(\"File already exists:\", fname)\n",
    "                    for i in range(len(BxGSE)):\n",
    "                        line = str(BxGSE[i]).strip() + \",\" + str(ByGSE[i]).strip() + \",\" + str(BzGSE[i]).strip() + \"\\n\"\n",
    "                        f.write(line)\n",
    "                    f.close()\n",
    "                    count += 1\n",
    "\n",
    "print(\"Created\", count, \"fluxropes\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Some helper functions - scaling, unscaling, vector normalization, and adding noise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def unscale(value, mn, mx):\n",
    "    return (value * (mx-mn)) + mn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def unscaleArray(array, mn, mx):\n",
    "    n = len(array)\n",
    "    u = np.zeros(n)\n",
    "    for i in range(n):\n",
    "        u[i] = unscale(array[i],mn,mx)\n",
    "    return u"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scale(value, mn, mx):\n",
    "    newValue = (value - mn)/(mx - mn) \n",
    "    return newValue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalizeVector(x,y,z,magnitude):\n",
    "    return x/magnitude, y/magnitude, z/magnitude"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def addNoise(vector):\n",
    "    noise = np.random.normal(0.25, 1, len(vector))\n",
    "    return vector+noise"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test-Train-Validation split function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def trainTestValidationSplit( dataX, dataY ):\n",
    "    # 70/15/15 train/test split\n",
    "    n = math.ceil(.7*dataX.shape[0])\n",
    "    xTrain = dataX[0:n,:,:]\n",
    "    yTrain = dataY[0:n]\n",
    "    restX = dataX[n:,:,:]\n",
    "    restY = dataY[n:]\n",
    "    n = math.ceil(.5*restX.shape[0])\n",
    "    xTest = restX[0:n,:,:]\n",
    "    yTest = restY[0:n]\n",
    "    xVal = restX[n:,:,:]\n",
    "    yVal = restY[n:]\n",
    "    return xTrain, yTrain, xTest, yTest, xVal, yVal"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Function to do bayesian predictions and compute how well we did"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 688,
   "metadata": {},
   "outputs": [],
   "source": [
    "def modelPredictionsActiveLearning(model, x, y, batch_size):\n",
    "    \n",
    "    T = 20\n",
    "    d = 4\n",
    "    n = len(x)\n",
    "\n",
    "    mc_predictions = np.zeros(shape=(T,n,d))\n",
    "    mc_ensemble_pred = np.zeros(shape=(n,d))\n",
    "    bce = np.zeros(shape=(T,n))\n",
    " \n",
    "    trace = []\n",
    "    determinant = []\n",
    "    \n",
    "    le = LabelEncoder()\n",
    "    le.fit(y[:,3])\n",
    "    y_enc = le.transform(y[:,3])\n",
    "    \n",
    "    print(\"Evaluating model with testing data...\")\n",
    "    loss = model.evaluate(x, {\"regression\": y[:,0:3], \"handedness\": y_enc}, \n",
    "                          batch_size=batch_size, verbose=1)\n",
    "    mseLoss = loss[1]\n",
    "    bceLoss = loss[2]\n",
    "    \n",
    "    print(\"Getting distribution of predictions and covariance matrix...\")\n",
    "    startTime = time.time()\n",
    "    for i in range(T):\n",
    "        \n",
    "        print(\"     \",i+1,\"of\",T)\n",
    "        \n",
    "        predictions = model.predict(x, batch_size=batch_size)\n",
    "        mc_predictions[i,:,0:3] = predictions[0]    \n",
    "        p = np.reshape( predictions[1], predictions[1].shape[0] )\n",
    "        \n",
    "        # binary cross entropy\n",
    "        ## binary cross entropy is not defined at 0 or 1\n",
    "        p[ p == 0. ] = 0.00001\n",
    "        p[ p == 1. ] = 0.99999\n",
    "        b = -(y[:,3]*np.log(p)+(1-y[:,3])*np.log(1-p))\n",
    "        \n",
    "        if ( np.isnan(b).any() ):\n",
    "            import pdb\n",
    "            pdb.set_trace()\n",
    "        \n",
    "        bce[i,:] = b\n",
    "        mc_predictions[i,:,3] = p\n",
    "                \n",
    "    #for i in range(n):\n",
    "    #    x = np.vstack( (mc_predictions[:,i,0],mc_predictions[:,i,1],mc_predictions[:,i,2],mc_predictions[:,i,3]) )\n",
    "    #    c = np.cov( x )\n",
    "    #    trace.append( np.trace(c) )\n",
    "    #    determinant.append( np.linalg.det(c) )\n",
    "    \n",
    "    print(\"Computing ensemble means...\")\n",
    "    mc_ensemble_pred = np.mean( mc_predictions, axis=0 )\n",
    "    \n",
    "    stopTime = time.time()\n",
    "    duration = stopTime - startTime\n",
    "    \n",
    "    # Evaluate the ensemble model\n",
    "    print(\"Computing mean squared error...\")\n",
    "    for i in range(n):\n",
    "        if ( mc_ensemble_pred[i,3] < 0.5 ):\n",
    "            mc_ensemble_pred[i,3] = 0.\n",
    "        else:\n",
    "            mc_ensemble_pred[i,3] = 1.\n",
    "    ensemble_loss = mean_squared_error(mc_ensemble_pred, y)\n",
    "\n",
    "    return duration, mseLoss, bceLoss, ensemble_loss, bce, mc_ensemble_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 560,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.12783337150988489\n"
     ]
    }
   ],
   "source": [
    "p = 0.12\n",
    "y = 0.\n",
    "bce = -(y*np.log(p)+(1-y)*np.log(1-p))\n",
    "print(bce)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 602,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tqdm\n",
    "import pdb\n",
    "\n",
    "def modelPredictionsGeneral(model, testFiles, batch_size=500):\n",
    "    \n",
    "    T = 20\n",
    "    d = 4\n",
    "    \n",
    "    print(\"Getting distribution of predictions...\")\n",
    "    for i in tqdm.tqdm(range(T)):\n",
    "        \n",
    "        counter = 0\n",
    "        print(\"     \",i+1,\"of\",T)\n",
    "        \n",
    "        for file in testFiles:\n",
    "\n",
    "            xTest, yTest = readNPZ(file)\n",
    "            predictions = model.predict(xTest, verbose=0, batch_size=batch_size)\n",
    "            #pdb.set_trace()\n",
    "            for ii in range(len(predictions)):\n",
    "                if ( predictions[1][ii] < 0.5 ):\n",
    "                    predictions[1][ii] = 0.\n",
    "                else:\n",
    "                    predictions[1][ii] = 1.\n",
    "                    \n",
    "            p = np.hstack( (predictions[0], predictions[1]) )\n",
    "\n",
    "            if (counter == 0):\n",
    "                yAll = yTest\n",
    "                allPredictions = p\n",
    "            else:\n",
    "                yAll = np.concatenate( (yAll, yTest) )\n",
    "                allPredictions = np.concatenate( (allPredictions, p) )\n",
    "            \n",
    "            counter += 1\n",
    "\n",
    "        if (i == 0):\n",
    "            loss = mean_squared_error(allPredictions, yAll)\n",
    "            ensemblePredictions = np.reshape(allPredictions, (1, allPredictions.shape[0], allPredictions.shape[1]))\n",
    "        else:\n",
    "            t = np.reshape( allPredictions, (1,allPredictions.shape[0], allPredictions.shape[1]))\n",
    "            ensemblePredictions = np.vstack( (ensemblePredictions,t) )\n",
    "                                                  \n",
    "    # Evaluate the ensemble model\n",
    "    print(\"Computing ensemble predictions...\")\n",
    "    ensemblePredictions = np.mean( ensemblePredictions, axis = 0 )\n",
    "    ensemble_loss = mean_squared_error(ensemblePredictions, yAll)\n",
    "\n",
    "    return loss, ensemble_loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The heliophysics fluxrope model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_fluxrope(N, By0, HH, C1, phi, theta, y0R):\n",
    "\n",
    "    ## Neural Network uses 0 or 1\n",
    "    ## Fluxrope model uses -1 or 1\n",
    "    if (HH == 0):\n",
    "        HH = -1.\n",
    "        \n",
    "    #N=50              # number of points\n",
    "    AU = 1.5e11\n",
    "    #By0 = 15          # nT \n",
    "    R = 0.07          # AU\n",
    "    time_hrs = 12.    # hrs\n",
    "    tau = 1.\n",
    "    us = 450.         # km/s\n",
    "\n",
    "    philong = (phi-90.)*np.pi/180. \n",
    "    if philong < 0.:\n",
    "        philong = philong + 2.*np.pi\n",
    "    thetalat = theta*np.pi/180.\n",
    "    \n",
    "    y0 = y0R*R/100.\n",
    "    \n",
    "    tt = np.arange(0, time_hrs*60.*60., (60.*60.*time_hrs/N))\n",
    "    ts = tt[-1]\n",
    "\n",
    "    bb = np.sin(philong)*np.sin(thetalat)\n",
    "    aa = np.cos(philong)*np.sqrt(1.-(np.sin(philong)*np.cos(thetalat))**2)\n",
    "    xc = (500.*ts*us/AU)-y0*bb/aa\n",
    "    \n",
    "    num = y0*np.sqrt(1.-(np.sin(philong)*np.cos(thetalat))**2)\n",
    "    dem = np.cos(thetalat)*np.cos(philong)\n",
    "    z0 = num / dem\n",
    "\n",
    "    term1 = xc*np.cos(philong)\n",
    "    term2 = xc*np.sin(philong)\n",
    "    term3 = np.sin(thetalat)+z0*np.cos(thetalat)\n",
    "    RR = np.sqrt( term1**2 + (term2 * term3)**2 )\n",
    "    \n",
    "    Xsat = ((1e3*us*tt/AU)-xc)\n",
    "\n",
    "    term1 = Xsat*np.cos(philong)\n",
    "    term2 = Xsat*np.sin(thetalat)\n",
    "    rNM = np.sqrt( term1**2 + (term2*np.sin(philong)-z0*np.cos(thetalat))**2 )\n",
    "    a1 = np.sin(philong)*np.sin(thetalat)*Xsat - z0*np.cos(thetalat)\n",
    "    a2 = np.cos(philong)*Xsat\n",
    "    PHIsat = np.arctan2(a1,a2)\n",
    "\n",
    "    By = By0*(tau-(rNM/RR)**2)#/bmax\n",
    "    Bpol = -HH*(By0/C1)*(rNM/RR)#/bmax\n",
    "\n",
    "    BxL = -Bpol*np.sin(PHIsat)\n",
    "    ByL = By\n",
    "    BzL = Bpol*np.cos(PHIsat)\n",
    "    bbnm = np.sqrt(Bpol**2+By**2)\n",
    "\n",
    "    BxGSE = BxL*np.cos(philong) - ByL*np.sin(philong)*np.cos(thetalat) + BzL*np.sin(philong)*np.sin(thetalat)\n",
    "    ByGSE = BxL*np.sin(philong) + ByL*np.cos(philong)*np.cos(thetalat) - BzL*np.cos(philong)*np.sin(thetalat)\n",
    "    BzGSE = ByL*np.sin(thetalat) + BzL*np.cos(thetalat)\n",
    "\n",
    "    BxGSE = addNoise(BxGSE)\n",
    "    ByGSE = addNoise(ByGSE)\n",
    "    BzGSE = addNoise(BzGSE)\n",
    "    \n",
    "    BB = np.sqrt(BxGSE**2 + ByGSE**2 + BzGSE**2)\n",
    "    \n",
    "    return tt, BB, BxGSE, ByGSE, BzGSE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Function to read the fine grained samples to see how well our model generalizes to the whole domain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 536,
   "metadata": {},
   "outputs": [],
   "source": [
    "def readNPZ(file):\n",
    "    \n",
    "    npzfile = np.load(file)\n",
    "    return npzfile['x'], npzfile['y']\n",
    "\n",
    "    return dataX, dataY"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Definition of our 1-D CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# define model\n",
    "    \n",
    "def get_model(d1=0.25, d2=0.5, act=\"relu\"):\n",
    "    inp = Input(input_shape)\n",
    "    x = Conv1D(32, kernel_size=5, activation=act, padding=\"same\")(inp)\n",
    "    x = Conv1D(64, kernel_size=5, activation=act, padding=\"same\")(x)\n",
    "    x = MaxPooling1D(pool_size=2)(x)\n",
    "    x = Dropout(d1)(x, training=True)\n",
    "    x = Flatten()(x)\n",
    "    x = Dense(128, activation=act)(x)\n",
    "    x = Dropout(d2)(x, training=True)\n",
    "    out1 = Dense(3, name=\"regression\")(x)\n",
    "    out2 = Dense(1, name=\"handedness\", activation='sigmoid')(x)\n",
    "\n",
    "    losses = {'regression': 'mse',\n",
    "              'handedness': 'binary_crossentropy'}\n",
    "    \n",
    "    lossWeights = {\"regression\": 1.0, \"handedness\": 10.0}\n",
    "    \n",
    "    model = Model(inputs=inp, outputs=[out1,out2])\n",
    "\n",
    "    model.compile(loss=losses, loss_weights=lossWeights, optimizer='adam')\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Function to read our initial course grained sample from disk into memory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2000 fluxrope models found\n",
      "Loading data...\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "could not convert string to float: 'bx'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-19-2be80efcb9bc>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     57\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mline\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mopenFile\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     58\u001b[0m             \u001b[0mparts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mline\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\",\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 59\u001b[0;31m             \u001b[0mbx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparts\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     60\u001b[0m             \u001b[0mby\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparts\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     61\u001b[0m             \u001b[0mbz\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparts\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: could not convert string to float: 'bx'"
     ]
    }
   ],
   "source": [
    "N = 500 # number of time steps in the sequence (flux rope model)\n",
    "\n",
    "from pathlib import Path\n",
    "inDir = Path(\"/home/narock/data/fluxropes/\")\n",
    "\n",
    "# how many model output files?\n",
    "count = 0\n",
    "files = []\n",
    "for f in listdir(inDir): \n",
    "    ff = join(inDir, f)\n",
    "    if isfile(ff):\n",
    "        count += 1\n",
    "        files.append(f)\n",
    "print(count, \"fluxrope models found\")\n",
    "random.shuffle(files)\n",
    "\n",
    "# the input to the CNN has shape [samples, timesteps, features]\n",
    "dataX = np.zeros(shape=(count, N, 3))\n",
    "dataY = np.zeros(shape=(count, 5))\n",
    "\n",
    "# variables for status updates\n",
    "twentyFive = math.ceil(.25 * count)\n",
    "fifty = math.ceil(.5 * count)\n",
    "seventyFive = math.ceil(.75 * count)\n",
    "\n",
    "# read the data files\n",
    "index = 0\n",
    "print(\"Loading data...\")\n",
    "for f in files:\n",
    "\n",
    "        # where are we?\n",
    "        if ( index == twentyFive ): print(\"  25% done\")\n",
    "        if ( index == fifty ): print(\"  50% done\")\n",
    "        if ( index == seventyFive ): print(\"  75% done\")\n",
    "\n",
    "        # extract the output value from the file name\n",
    "        parts = f.split(\"_\")\n",
    "        bmag = float(parts[1])\n",
    "        phi = float(parts[2])\n",
    "        theta = float(parts[3])\n",
    "        y0R = float(parts[4])\n",
    "        HH = parts[5].split(\".\")\n",
    "        HH = float(HH[0])\n",
    "        \n",
    "        # normalize the output value\n",
    "        dataY[index, 0] = bmag\n",
    "        dataY[index, 1] = phi\n",
    "        dataY[index, 2] = theta\n",
    "        dataY[index, 3] = y0R\n",
    "        dataY[index, 4] = HH\n",
    "\n",
    "        # read the data\n",
    "        bx = []\n",
    "        by = []\n",
    "        bz = []\n",
    "        lineNumber = 0\n",
    "        openFile = open(join(dir,f), \"r\")\n",
    "        for line in openFile:\n",
    "            if (lineNumber != 0): # first line is a header\n",
    "                parts = line.split(\",\")\n",
    "                bx.append(float(parts[0]))\n",
    "                by.append(float(parts[1]))\n",
    "                bz.append(float(parts[2]))\n",
    "            lineNumber += 1\n",
    "        openFile.close()\n",
    "        \n",
    "        dataX[index, :, 0] = bx\n",
    "        dataX[index, :, 1] = by\n",
    "        dataX[index, :, 2] = bz\n",
    "\n",
    "        index += 1\n",
    "\n",
    "print(\"  100% done\")\n",
    "input_shape = (500, 3)\n",
    "xTrain, yTrain, xTest, yTest, xVal, yVal = trainTestValidationSplit( dataX, dataY )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Some tests to make sure everything got created/read correctly"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.) Make sure the training data is the correct type and verify the dimensions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 677,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(392, 500, 3)\n",
      "(84, 500, 3)\n",
      "(84, 500, 3)\n",
      "\n",
      "(392, 4)\n",
      "(84, 4)\n",
      "(84, 4)\n"
     ]
    }
   ],
   "source": [
    "xTrain = xTrain.astype('float32')\n",
    "yTrain = yTrain.astype('float32')\n",
    "\n",
    "print(xTrain.shape)\n",
    "print(xTest.shape)\n",
    "print(xVal.shape)\n",
    "print()\n",
    "print(yTrain.shape)\n",
    "print(yTest.shape)\n",
    "print(yVal.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.) Double checking the type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "numpy.float32"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(yTrain[0,3])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.) Making sure there aren't any NAN values that would mess up training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.isnan(xTrain).any()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.) Visualize the x component of the first vector to make sure everything looks as expected"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7f57f179a438>]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(xTrain[0,:,0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create our CNN and output its layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 690,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_2\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_2 (InputLayer)            (None, 500, 3)       0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_3 (Conv1D)               (None, 500, 32)      512         input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_4 (Conv1D)               (None, 500, 64)      10304       conv1d_3[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_2 (MaxPooling1D)  (None, 250, 64)      0           conv1d_4[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dropout_3 (Dropout)             (None, 250, 64)      0           max_pooling1d_2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "flatten_2 (Flatten)             (None, 16000)        0           dropout_3[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_2 (Dense)                 (None, 128)          2048128     flatten_2[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dropout_4 (Dropout)             (None, 128)          0           dense_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "regression (Dense)              (None, 3)            387         dropout_4[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "handedness (Dense)              (None, 1)            129         dropout_4[0][0]                  \n",
      "==================================================================================================\n",
      "Total params: 2,059,460\n",
      "Trainable params: 2,059,460\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "mc_model = get_model(act=\"relu\")\n",
    "mc_model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### This is required for my GPU: GeForce RTX 2060\n",
    "### Without this config, tensorflow cannot properly allocate GPU memory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 691,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = tf.ConfigProto()\n",
    "config.gpu_options.allow_growth = True\n",
    "config.gpu_options.per_process_gpu_memory_fraction = 0.90\n",
    "session = tf.Session(config=config)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initialize some lists we'll use during testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 692,
   "metadata": {},
   "outputs": [],
   "source": [
    "mses = []\n",
    "ensemble_mses = []\n",
    "training_times = []"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Stop training when the validation loss doesn't decrease for 4 consecutive epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 693,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 392 samples, validate on 84 samples\n",
      "Epoch 1/150\n",
      "392/392 [==============================] - 0s 602us/step - loss: 2.6689 - regression_loss: 1.5154 - handedness_loss: 0.7179 - val_loss: 0.9923 - val_regression_loss: 0.2910 - val_handedness_loss: 0.7013\n",
      "Epoch 2/150\n",
      "392/392 [==============================] - 0s 87us/step - loss: 0.9736 - regression_loss: 0.3006 - handedness_loss: 0.6766 - val_loss: 0.9727 - val_regression_loss: 0.2859 - val_handedness_loss: 0.6869\n",
      "Epoch 3/150\n",
      "392/392 [==============================] - 0s 88us/step - loss: 0.9528 - regression_loss: 0.2763 - handedness_loss: 0.6691 - val_loss: 0.9561 - val_regression_loss: 0.2774 - val_handedness_loss: 0.6787\n",
      "Epoch 4/150\n",
      "392/392 [==============================] - 0s 90us/step - loss: 0.9455 - regression_loss: 0.2593 - handedness_loss: 0.6534 - val_loss: 0.9579 - val_regression_loss: 0.2714 - val_handedness_loss: 0.6865\n",
      "Epoch 5/150\n",
      "392/392 [==============================] - 0s 95us/step - loss: 0.9382 - regression_loss: 0.2596 - handedness_loss: 0.6418 - val_loss: 0.9483 - val_regression_loss: 0.2668 - val_handedness_loss: 0.6815\n",
      "Epoch 6/150\n",
      "392/392 [==============================] - 0s 97us/step - loss: 0.9275 - regression_loss: 0.2557 - handedness_loss: 0.6447 - val_loss: 0.9396 - val_regression_loss: 0.2609 - val_handedness_loss: 0.6787\n",
      "Epoch 7/150\n",
      "392/392 [==============================] - 0s 94us/step - loss: 0.9199 - regression_loss: 0.2739 - handedness_loss: 0.6468 - val_loss: 0.9407 - val_regression_loss: 0.2654 - val_handedness_loss: 0.6753\n",
      "Epoch 8/150\n",
      "392/392 [==============================] - 0s 95us/step - loss: 0.9091 - regression_loss: 0.2596 - handedness_loss: 0.6599 - val_loss: 0.9281 - val_regression_loss: 0.2571 - val_handedness_loss: 0.6710\n",
      "Epoch 9/150\n",
      "392/392 [==============================] - 0s 90us/step - loss: 0.9029 - regression_loss: 0.2669 - handedness_loss: 0.6464 - val_loss: 0.9135 - val_regression_loss: 0.2490 - val_handedness_loss: 0.6644\n",
      "Epoch 10/150\n",
      "392/392 [==============================] - 0s 91us/step - loss: 0.8857 - regression_loss: 0.2516 - handedness_loss: 0.6394 - val_loss: 0.9085 - val_regression_loss: 0.2416 - val_handedness_loss: 0.6669\n",
      "Epoch 11/150\n",
      "392/392 [==============================] - 0s 91us/step - loss: 0.8821 - regression_loss: 0.2305 - handedness_loss: 0.6365 - val_loss: 0.8998 - val_regression_loss: 0.2396 - val_handedness_loss: 0.6602\n",
      "Epoch 12/150\n",
      "392/392 [==============================] - 0s 95us/step - loss: 0.8612 - regression_loss: 0.2450 - handedness_loss: 0.6380 - val_loss: 0.8735 - val_regression_loss: 0.2359 - val_handedness_loss: 0.6376\n",
      "Epoch 13/150\n",
      "392/392 [==============================] - 0s 94us/step - loss: 0.8615 - regression_loss: 0.2370 - handedness_loss: 0.6135 - val_loss: 0.8660 - val_regression_loss: 0.2291 - val_handedness_loss: 0.6369\n",
      "Epoch 14/150\n",
      "392/392 [==============================] - 0s 105us/step - loss: 0.8487 - regression_loss: 0.2314 - handedness_loss: 0.6072 - val_loss: 0.8463 - val_regression_loss: 0.2266 - val_handedness_loss: 0.6196\n",
      "Epoch 15/150\n",
      "392/392 [==============================] - 0s 99us/step - loss: 0.8428 - regression_loss: 0.2141 - handedness_loss: 0.6420 - val_loss: 0.8760 - val_regression_loss: 0.2242 - val_handedness_loss: 0.6518\n",
      "Epoch 16/150\n",
      "392/392 [==============================] - 0s 99us/step - loss: 0.8249 - regression_loss: 0.2137 - handedness_loss: 0.5751 - val_loss: 0.8181 - val_regression_loss: 0.2072 - val_handedness_loss: 0.6109\n",
      "Epoch 17/150\n",
      "392/392 [==============================] - 0s 95us/step - loss: 0.8238 - regression_loss: 0.2326 - handedness_loss: 0.6065 - val_loss: 0.8684 - val_regression_loss: 0.2000 - val_handedness_loss: 0.6684\n",
      "Epoch 18/150\n",
      "392/392 [==============================] - 0s 103us/step - loss: 0.7986 - regression_loss: 0.2296 - handedness_loss: 0.6470 - val_loss: 0.8539 - val_regression_loss: 0.1873 - val_handedness_loss: 0.6666\n",
      "Epoch 19/150\n",
      "392/392 [==============================] - 0s 97us/step - loss: 0.7973 - regression_loss: 0.2116 - handedness_loss: 0.5851 - val_loss: 0.8516 - val_regression_loss: 0.1986 - val_handedness_loss: 0.6530\n",
      "Epoch 20/150\n",
      "392/392 [==============================] - 0s 99us/step - loss: 0.7687 - regression_loss: 0.1883 - handedness_loss: 0.5751 - val_loss: 0.8152 - val_regression_loss: 0.1757 - val_handedness_loss: 0.6395\n"
     ]
    }
   ],
   "source": [
    "startTime = time.time()\n",
    "\n",
    "callbacks_list = [\n",
    "    keras.callbacks.EarlyStopping(monitor='val_regression_loss', patience=4),\n",
    "    keras.callbacks.EarlyStopping(monitor='val_handedness_loss', patience=4)\n",
    "]\n",
    "\n",
    "le = LabelEncoder()\n",
    "le.fit(yTrain[:,3])\n",
    "y_train_enc = le.transform(yTrain[:,3])\n",
    "y_val_enc = le.transform(yVal[:,3])\n",
    "\n",
    "h_mc = mc_model.fit(xTrain, {\"regression\": yTrain[:,0:3], \"handedness\": y_train_enc}, \n",
    "                    epochs=150, batch_size=128, verbose=1, \n",
    "                    callbacks=callbacks_list,\n",
    "                    validation_data=(xVal,{\"regression\": yVal[:,0:3], \"handedness\": y_val_enc}) )\n",
    "\n",
    "epochs = len(h_mc.history['loss'])\n",
    "\n",
    "stopTime = time.time()\n",
    "duration = stopTime-startTime\n",
    "training_times.append(duration)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 334,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = mc_model.predict(xTrain, batch_size=3072)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 365,
   "metadata": {},
   "outputs": [],
   "source": [
    "t = np.reshape( predictions[1], predictions[1].shape[0] )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 377,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-19.55987   12.455739   1.042935]\n",
      "[0.]\n",
      "(392, 3)\n",
      "(392, 1)\n"
     ]
    }
   ],
   "source": [
    "print(predictions[0][35])\n",
    "print(predictions[1][35])\n",
    "print(predictions[0].shape)\n",
    "print(predictions[1].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 380,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(392, 4)"
      ]
     },
     "execution_count": 380,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p = np.hstack( (predictions[0], predictions[1]) )\n",
    "p.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualize our two losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 694,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0, 0.5)"
      ]
     },
     "execution_count": 694,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(h_mc.history['regression_loss'], label=\"Loss\")\n",
    "plt.plot(h_mc.history['val_regression_loss'], marker='o', label=\"Validation\")\n",
    "plt.xlim(0,epochs)\n",
    "plt.title('Regression')\n",
    "plt.legend()\n",
    "plt.ylim(0,0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 695,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x7fe5e0497eb8>"
      ]
     },
     "execution_count": 695,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(h_mc.history['handedness_loss'], label=\"Loss\")\n",
    "plt.plot(h_mc.history['val_handedness_loss'], marker='o', label=\"Validation\")\n",
    "plt.xlim(0,epochs)\n",
    "plt.title('Handedness')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### How well did we do?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 696,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating model with testing data...\n",
      "84/84 [==============================] - 0s 35us/step\n",
      "Getting distribution of predictions and covariance matrix...\n",
      "      1 of 20\n",
      "      2 of 20\n",
      "      3 of 20\n",
      "      4 of 20\n",
      "      5 of 20\n",
      "      6 of 20\n",
      "      7 of 20\n",
      "      8 of 20\n",
      "      9 of 20\n",
      "      10 of 20\n",
      "      11 of 20\n",
      "      12 of 20\n",
      "      13 of 20\n",
      "      14 of 20\n",
      "      15 of 20\n",
      "      16 of 20\n",
      "      17 of 20\n",
      "      18 of 20\n",
      "      19 of 20\n",
      "      20 of 20\n",
      "Computing ensemble means...\n",
      "Computing mean squared error...\n"
     ]
    }
   ],
   "source": [
    "batch_size = 3072\n",
    "duration, mseLoss, bceLoss, ensemble_loss, bce, mc_ensemble_pred = modelPredictionsActiveLearning(mc_model,\n",
    "                                                                                                  xTest, yTest, \n",
    "                                                                                                  batch_size)\n",
    "\n",
    "training_times.append(duration)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 576,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])"
      ]
     },
     "execution_count": 576,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mc_ensemble_pred[0:10,3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 577,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0., 0., 0., 0., 1., 0., 1., 1., 1., 1.])"
      ]
     },
     "execution_count": 577,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "yTest[0:10,3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 584,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.2385656237602234 0.6964489221572876 0.32515070002904833\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(array([ 0.,  0.,  0.,  0.,  0., 84.,  0.,  0.,  0.,  0.]),\n",
       " array([-0.5, -0.4, -0.3, -0.2, -0.1,  0. ,  0.1,  0.2,  0.3,  0.4,  0.5]),\n",
       " <a list of 10 Patch objects>)"
      ]
     },
     "execution_count": 584,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(mseLoss, bceLoss, ensemble_loss)\n",
    "plt.hist(mc_ensemble_pred[:,3])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compare against fine-grained sample to see how well our model generalizes to the entire domain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 697,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test files: 405\n"
     ]
    }
   ],
   "source": [
    "testDir = '/home/narock/data/fluxropes_testing_npz/'\n",
    "testFiles = [join(testDir,f) for f in listdir(testDir) if isfile(join(testDir, f))]\n",
    "random.shuffle(testFiles)\n",
    "\n",
    "print(\"Test files:\", len(testFiles))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Functions to generalize the active learning \n",
    "#### one to get the physics model parameters we're uncertain about \n",
    "#### and one to execute the physics model for those parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 453,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pick values using gaussian centered at uncertain values\n",
    "def nextBatch(yTest, aquisition, batchSize, p, phiStepSize, thetaStepSize, y0RStepSize):\n",
    "    \n",
    "    batch = np.zeros(shape=(batchSize,4)) - 999.9\n",
    "    \n",
    "    # probability of random sampling (exploration) starts off the same \n",
    "    # as the probability of most sure aquisition\n",
    "    #aquisition = [np.max(aquisition)] + aquisition\n",
    "        \n",
    "    # create a softmax probability distribution\n",
    "    aquisition = np.array(aquisition) \n",
    "    num = np.exp(aquisition) \n",
    "    den = np.sum(num)\n",
    "    sigma = num / den\n",
    "        \n",
    "    # use probabilites to choose batchSize actions to follow (exploration or exploitation)\n",
    "    choices = np.random.choice( [0,1], batchSize, replace=True, p=[p,1-p])\n",
    "    \n",
    "    phiIndicies = np.arange(0., 360, phiStepSize)\n",
    "    thetaIndicies = np.arange(-90., 90, thetaStepSize)\n",
    "    y0RIndicies = np.arange(-100., 100, y0RStepSize)\n",
    "    \n",
    "    # loop over the choices and take the appropriate action\n",
    "    for i in range(batchSize):\n",
    "    \n",
    "        if (choices[i] == 0): # random exploration\n",
    "    \n",
    "            batch[i,0] = np.random.choice( phiIndicies, 1, replace=True )\n",
    "            batch[i,1] = np.random.choice( thetaIndicies, 1, replace=True )\n",
    "            batch[i,2] = np.random.choice( y0RIndicies, 1, replace=True )\n",
    "            batch[i,3] = np.random.choice([-1, 1], 1, replace=True )\n",
    "        \n",
    "        else:\n",
    "                    \n",
    "            lst = np.arange( len(sigma) )\n",
    "            index = np.random.choice( lst, 1, replace=True, p=sigma )\n",
    "            phi = unscale( yTest[ index, 0 ], 0., 360. )\n",
    "            theta = unscale( yTest[ index, 1 ], -90., 90. )\n",
    "            y0R = unscale( yTest[ index, 2 ], -100., 100. )\n",
    "            HH = yTest[ index, 3 ]\n",
    "\n",
    "            # check boundary conditions\n",
    "            # also check model limitations - model doesn't work for (phi,theta) (0,0) and (180,0)\n",
    "        \n",
    "            for j in range(4):\n",
    "\n",
    "                while ( (batch[i,0] < 0.) or (batch[i,0] > 360.) ): \n",
    "                    batch[i,0] = np.random.normal( phi ) \n",
    "                while ( (batch[i,1] < -90.) or (batch[i,1] > 90.) ):\n",
    "                    batch[i,1] = np.random.normal( theta ) \n",
    "                while ( (batch[i,2] < -100.) or (batch[i,2] > 100.) ):\n",
    "                    batch[i,2] = np.random.normal( y0R ) \n",
    "        \n",
    "                if ( batch[i,0] == 0. and batch[i,1] == 0.):\n",
    "                    batch[i,0] == 5.\n",
    "                    batch[i,1] == 5.\n",
    "                if ( batch[i,0] == 180 and batch[i,1] == 0 ):\n",
    "                    batch[i,0] == 170\n",
    "                    batch[i,1] == 5.\n",
    "        \n",
    "                # use the same handedness we were uncertain about\n",
    "                batch[i,3] = HH\n",
    "                    \n",
    "    return batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 454,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getMoreFluxRopes( batch ):\n",
    "    \n",
    "    # flux rope model parameters\n",
    "    N = 500.\n",
    "    C1 = 1.0\n",
    "\n",
    "    newX = np.zeros(shape=(batch.shape[0], 500, 3))\n",
    "    newY = np.zeros(shape=(batch.shape[0], 4))\n",
    "\n",
    "    # randomize (shuffle) the list\n",
    "    random.shuffle(batch)\n",
    "\n",
    "    # call the fluxrope model to get 1000 more training instances\n",
    "    for i in range( batch.shape[0] ):\n",
    "    \n",
    "        phi = batch[ i, 0 ]\n",
    "        theta = batch[ i, 1 ]\n",
    "        y0R = batch[ i, 2 ]\n",
    "        HH = batch[ i, 3 ]\n",
    "\n",
    "        newY[i, 0] = scale( phi, 0., 360. )\n",
    "        newY[i, 1] = scale( theta, -90., 90. )\n",
    "        newY[i, 2] = scale( y0R, -100., 100. )\n",
    "        newY[i, 3] = HH\n",
    "        \n",
    "        time, B, BxGSE, ByGSE, BzGSE = model_fluxrope(N, HH, C1, phi, theta, y0R)\n",
    "        BxGSE, ByGSE, BzGSE = normalizeVector(BxGSE, ByGSE, BzGSE, B)\n",
    "     \n",
    "        if ( np.isnan(BxGSE).any() ):\n",
    "            print(\"Ignoring (phi,theta): \", phi, theta)\n",
    "        \n",
    "        newX[i,:,0] = BxGSE\n",
    "        newX[i,:,1] = ByGSE\n",
    "        newX[i,:,2] = BzGSE\n",
    "        \n",
    "    return newX, newY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7fe5f8205b00>]"
      ]
     },
     "execution_count": 241,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXQAAAD4CAYAAAD8Zh1EAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy8li6FKAAAgAElEQVR4nO3dd3hUdd7+8fcnBUIoQSAgJKEXKdKM9GqjrBIBUbAtroIFWLurW37r6rOP69oLRVAsqCCwFnRtiNJrUECQFkJJkBJ6J+37+2PGfbKRQIBJzmRyv64rFzNnDpn7OhluTr7ne84x5xwiIlLyhXkdQEREAkOFLiISIlToIiIhQoUuIhIiVOgiIiEiwqs3rlatmqtbt65Xby8iUiItX758j3Mu9lSveVbodevWJTk52au3FxEpkcxsa0GvachFRCREqNBFREKECl1EJESo0EVEQoQKXUQkRJyx0M1sopntNrPVBbxuZvaymaWY2Sozaxv4mCIiciaF2UN/C+h9mtf7AI38X8OBsecfS0REztYZC905NxfYd5pVkoB3nM9ioLKZ1QxUwPy27DnK01+uIzdXl/0VEckrEGPocUBanufp/mW/YmbDzSzZzJIzMjLO6c2+/mknY2dv4k8fr1api4jkUaxnijrnxgPjARITE8+pjYd1rc+BY1mMmb2J8DB4MqkFZhbQnCIiJVEgCn07kJDnebx/WZEwMx7u1YQc53htTiphZvytX3OVuoiUeoEo9BnASDObArQHDjrndgTg+xbIzHi090Xk5jomzNtMmBl/vaaZSl1ESrUzFrqZTQZ6ANXMLB34KxAJ4JwbB3wO9AVSgGPAbUUVNl8u/ti3KTm5MHHBZsLDjD//pqlKXURKrTMWunNuyBled8CIgCU6C2bGX65uSq5zvDHfV+qP9blIpS4ipZJnl88NFPMPt+Q6x/i5vjH1P/RuolIXkVKnxBc6+Er9b/2ak5PrGDfHN/vloatU6iJSuoREoYOv1J9MakGuc4z+bhPhZjxwVROvY4mIFJuQKXSAsDDj79deTG4uvPxtCgD3X9lYe+oiUiqEVKGDr9SfGnAxZr5Sz8p1PNJLwy8iEvpCrtDBV+r/2/9iwsOMsbM3kZPrNPtFREJeSBY6+Er9f65tQUSYMX5uKlk5ufy/q3XykYiErpAtdPAdKH28X3PCw8KYuGAzObmOx69pTliYSl1EQk9IFzr838lHEeG+PfXsXMf/JLVQqYtIyAn5QgdfqT/W5yIiwowxszeRk+N4asDFKnURCSmlotDh/67SGBEexsuzNpKVm8sz17UiXKUuIiGi1BQ6+Er9gSsbE27GC99sICfX8dygVkSE617ZIlLylapC/8W9VzQiItx45qv1ZGbn8tLgNpSJUKmLSMlWaltsRM+G/Pk3Tfli9U6GT0rmRFaO15FERM5LqS10gDu61uepARczZ0MGQ99cypGT2V5HEhE5Z6W60AGGtKvNize0ZtmW/dz8+hIOHsvyOpKIyDkp9YUOkNQ6jjE3teWnnw8xeMJi9hw56XUkEZGzpkL369X8Ql7/bSKb9xzh+tcWsePgca8jiYicFRV6Ht0ax/LO79qz+9BJBo1bxLa9x7yOJCJSaCr0fNrVq8L7w9pz5GQ2g15bSMruw15HEhEpFBX6KbSMr8wHwzuSkwvXv7aY1dsPeh1JROSMVOgFaHJhRabd1ZGoiDCGTFjM8q37vY4kInJahSp0M+ttZuvNLMXMHj3F63XMbJaZrTKz2WYWH/ioxa9etfJMu7sTVcuX4ZY3ljBvY4bXkURECnTGQjezcGA00AdoBgwxs2b5VnsWeMc51xJ4Angq0EG9Ele5HFPv6kjtKtH87q1lfLbqZ68jiYicUmH20NsBKc65VOdcJjAFSMq3TjPgW//j707xeolWvWIUH9zZkdYJlRk1+QcmLdridSQRkV8pTKHHAWl5nqf7l+W1Ehjgf9wfqGhmVc8/XvCIKRfJpNvbc/lF1fnLJ2t48ZsNOOe8jiUi8h+BOij6ENDdzH4AugPbgV9d7crMhptZspklZ2SUvPHoqMhwxt18CQPbxvPiNxt5fMYacnNV6iISHApz+dztQEKe5/H+Zf/hnPsZ/x66mVUABjrnDuT/Rs658cB4gMTExBLZhBHhYTxzXUuqlI9kwrzN7DuWxXODWunyuyLiucIU+jKgkZnVw1fkg4Eb865gZtWAfc65XOAxYGKggwaTsDDjT79pRtUKZfnHF+s4eDyLcTe3JbpMqby8vIgEiTPuVjrnsoGRwFfAWmCqc26NmT1hZv38q/UA1pvZBqAG8PciyhtU7uregH8ObMn8jRncOGEJ+49meh1JREox8+rAXmJioktOTvbkvQPtqzU7GTX5B2pXiWbS7e2oGVPO60giEqLMbLlzLvFUr2ngNwB6Nb+Qt29rx86DJ7hu7CI2ZRzxOpKIlEIq9ADp2KAqU4Z34GR2DteNXahLBYhIsVOhB1CLuBim39WJmHKR3DhhMV+v2el1JBEpRVToAVa3Wnn+dXcnLqpZibveXc6kxVu9jiQipYQKvQhUrVCWycPa07NJdf7y8Wqe/nKdzioVkSKnQi8i0WUieO2WS7ixfW3Gzt7EA1NXkpmd63UsEQlhOhOmCEWEh/H3a1tQKyaKZ7/eQMbhk4y9uS0VoyK9jiYiIUh76EXMzBh5WSOeHdSKxal7uf61xew6dMLrWCISglToxeS6S+KZOPRStu09yoAxC9m4S/cqFZHAUqEXo26NY/ngzo5k5uQycOxClm7e53UkEQkhKvRi1iIuhg/v7kRsxbLc/MYS3QFJRAJGhe6BhCrR/OvuTrSKj2Hk+z8w+rsUTWsUkfOmQvdI5egyvHtHe5Ja1+KZr9bzyPRVmtYoIudF0xY9VDYinBdvaE3dquV5adZG0vcfZ9zNlxATrWmNInL2tIfuMTPj/isb88INrVi+dT/9xy5g696jXscSkRJIhR4k+reJ59072rPvaCb9xywkeYtmwIjI2VGhB5F29arw0T2dfVdrfH0Jn6zYfua/JCLip0IPMvWqlefDuzvROqEy905ZwSuzNmoGjIgUigo9CF1QvgyTbm9H/zZxPDdzAw9OW8nJ7ByvY4lIkNMslyBVNiKc569vRb1q5Xl+5gbS9x/ntZsv4YLyZbyOJiJBSnvoQczM+P3ljXhpcGtWpB0gafQCNugaMCJSABV6CZDUOo4pwztwPCuHAWMWMmvtLq8jiUgQUqGXEG1rX8CMkZ2pWy2aO95JZtycTTpYKiL/pVCFbma9zWy9maWY2aOneL22mX1nZj+Y2Soz6xv4qFIzphzT7uxE34tr8o8v1vHg1JWcyNLBUhHxOWOhm1k4MBroAzQDhphZs3yr/RmY6pxrAwwGxgQ6qPiUKxPOq0Pa8OCVjfnwh+0MHr+Y3bphhohQuD30dkCKcy7VOZcJTAGS8q3jgEr+xzGArglbhMyMUZc3YtzNbVm/8zD9Xl3Aj+kHvY4lIh4rTKHHAWl5nqf7l+X1OHCzmaUDnwOjTvWNzGy4mSWbWXJGRsY5xJW8ereoyfS7OxIeZgx6baGurS5SygXqoOgQ4C3nXDzQF5hkZr/63s658c65ROdcYmxsbIDeunRrXiuGT0Z2pkUt37XVn/96Pbm5OlgqUhoVptC3Awl5nsf7l+V1OzAVwDm3CIgCqgUioJxZtQpleW9Ye65PjOflb1O4+73lHDmZ7XUsESlmhSn0ZUAjM6tnZmXwHfSckW+dbcDlAGbWFF+ha0ylGJWNCOfpgS35y9XNmPnTLvqPXsDmPboMr0hpcsZCd85lAyOBr4C1+GazrDGzJ8ysn3+1B4FhZrYSmAwMdZokXezMjNu71OPd29uz58hJ+r06n2/X6SQkkdLCvOrdxMREl5yc7Ml7lwbp+49x56Tl/LTjEPdf0ZiRPRsSFmZexxKR82Rmy51ziad6TWeKhqj4C3w3or62dRzPz9zAne8u5/CJLK9jiUgRUqGHsKhI3xUb/3pNM75dt5trRy8gZfcRr2OJSBFRoYc4M+O2zr5x9QPHsrh29AJm/qRxdZFQpEIvJTo2qMqMUV2oV608w95J5oWZGzRfXSTEqNBLkbjK5Zh2V0euuySel2ZtZNg7yRzSuLpIyFChlzJRkeE8c11LnkxqzpwNGfR7ZT5rdxzyOpaIBIAKvRQyM27pWJfJwztwLDOH/mMWMH15utexROQ8qdBLsUvrVuHfv+9Km4QLeGjaSh791ypdX12kBFOhl3KxFcsy6fZ23NOjAVOWpTFw7EK27T3mdSwROQcqdCEiPIxHel/E67cmkrbvGFe/Mo9vNLVRpMRRoct/XNGsBp+N6krtqr77lj795Tqyc3K9jiUihaRCl/9Su2o00+/qxJB2CYydvYlb3lhKxuGTXscSkUJQocuvREWG89SAljw7qBXfb9vPb16ex7It+7yOJSJnoEKXAl13STwfj+hMdJlwBo9fzLg5m3R2qUgQU6HLaTWtWYkZo7rQq3kN/vHFOn739jL2HtEQjEgwUqHLGVWKimT0jW158toWLNy0l74vz2NJ6l6vY4lIPip0KRQz45YOdfjonk5El4lgyITFvDJrIzkaghEJGip0OSvNa8Xw6aguXNOqFs/N3MCtE5ew+/AJr2OJCCp0OQcVykbw4g2t+efAlizfup++L81n/sY9XscSKfVU6HJOzIzrL01gxsguXBAdyS0Tl/Dc1+t1IpKIh1Tocl4a16jIJyM7M+iSeF75NoUbJyxhx8HjXscSKZVU6HLeostE8M/rWvHCDa1Y/fNB+r40T7e5E/FAoQrdzHqb2XozSzGzR0/x+gtmtsL/tcHMDgQ+qgS7/m3i+XRUF2pVLsewd5L588c/cjxTl+MVKS5nLHQzCwdGA32AZsAQM2uWdx3n3P3OudbOudbAK8CHRRFWgl+D2Ap8eE8nhnerz7uLt9HvVd0RSaS4FGYPvR2Q4pxLdc5lAlOApNOsPwSYHIhwUjKVjQjnj32bMun2dhw4nkXSqwuYOH8zzmnOukhRKkyhxwFpeZ6n+5f9ipnVAeoB3xbw+nAzSzaz5IyMjLPNKiVM10axfHlvV7o1rsYTn/3E0DeX6cqNIkUo0AdFBwPTnXOnHDh1zo13ziU65xJjY2MD/NYSjKpWKMuEWxN5Mqk5i1P30ueluXy3frfXsURCUmEKfTuQkOd5vH/ZqQxGwy2Szy83pf50VBeqVSjLbW8u42+frtH9S0UCrDCFvgxoZGb1zKwMvtKekX8lM7sIuABYFNiIEioa16jIxyM6M7RTXd5csIVrRy9gw67DXscSCRlnLHTnXDYwEvgKWAtMdc6tMbMnzKxfnlUHA1OcjnzJaURFhvN4v+a8OfRSMg6f5OpX5vPG/M26zrpIAJhX/ZuYmOiSk5M9eW8JDhmHT/LYh6v4Zu1uOjWoyjODWhFXuZzXsUSCmpktd84lnuo1nSkqnomt6Dtg+o8BF7My7QC9X5jLh9+na3qjyDlSoYunzIzB7Wrzxb3daHJhRR6YupJ73vuefUczvY4mUuKo0CUo1K4azQd3duQPvS/im7W76PXiXL5bp+mNImdDhS5BIzzMuLtHAz4Z0YUq0WW47a1l/PGjHzl6MtvraCIlggpdgk6zWpX4ZGRnhnerz+Sl2+j78jyWb93vdSyRoKdCl6AUFem7HszkYR3IznEMGreQp79cx8lsnYwkUhAVugS1DvWr8uV9XbnuknjGzt7E1S/PZ2Wars4scioqdAl6FaMi+ed1rXhz6KUcOpHFgLELeeYr7a2L5KdClxKj50XV+fr+7vRvE8fo7zbR75UF/Jh+0OtYIkFDhS4lSky5SJ4d1IqJQxM5cDyTa8cs4Lmv15OZrZtTi6jQpUS67KIafH1fd65tHccr36bQ79X5rN6uvXUp3VToUmLFREfy3PWteOO3iew7mknS6AU8r711KcVU6FLiXd60BjPv705Sq1q87N9b19i6lEYqdAkJMdGRPH9Da16/9Ze99fk89flajmdqJoyUHip0CSlXNKvBzAe6c8OlCbw2N5XeL81l4aY9XscSKRYqdAk5MeUieWpAS94f1h6AGycs4bEPV3HweJbHyUSKlgpdQlanBtX48t5u3NmtPh8sS+PK5+fw1ZqdXscSKTIqdAlp5cqE81jfpnw8ojNVypfhzknLGfHe92QcPul1NJGAU6FLqdAyvjKfjurCw72aMHPtLq54fg7TktN0dyQJKSp0KTUiw8MY0bMhn/++K41rVODh6au45Y2lbNlz1OtoIgGhQpdSp2H1CnwwvCNPJjVnRdoBrnpxLq9+u1EnJEmJp0KXUikszLilY11mPdidK5vW4NmvN9D35Xks3bzP62gi56xQhW5mvc1svZmlmNmjBaxzvZn9ZGZrzOz9wMYUKRo1KkUx+qa2vDn0Uo5n5nD9a4v4w/RV7NdNqqUEsjMdFDKzcGADcCWQDiwDhjjnfsqzTiNgKnCZc26/mVV3zp32Dr+JiYkuOTn5fPOLBMyxzGxemrWR1+dtJqZcJH/q25QBbeMwM6+jifyHmS13ziWe6rXC7KG3A1Kcc6nOuUxgCpCUb51hwGjn3H6AM5W5SDCKLhPBY32a8tmoLtSpGs2D01Zy0+tLSM044nU0kUIpTKHHAWl5nqf7l+XVGGhsZgvMbLGZ9T7VNzKz4WaWbGbJGRkZ55ZYpIg1rVmJf93Vib/3b8GP2w/S+8V5vPjNBt0hSYJeoA6KRgCNgB7AEGCCmVXOv5JzbrxzLtE5lxgbGxugtxYJvLAw46b2dZj1YHd6tbiQF7/ZSK8X5jJ7vX75lOBVmELfDiTkeR7vX5ZXOjDDOZflnNuMb8y9UWAiininesUoXhnShnd+144wM4a+uYw7JyWTvv+Y19FEfqUwhb4MaGRm9cysDDAYmJFvnY/x7Z1jZtXwDcGkBjCniKe6NY7li/u68nCvJszdsIcrnp/Dq99u1DCMBJUzFrpzLhsYCXwFrAWmOufWmNkTZtbPv9pXwF4z+wn4DnjYObe3qEKLeKFsRDgjejbkmwe707NJdZ79eoOGYSSonHHaYlHRtEUp6eZuyODxGWtI3XOUXs1r8JermxF/QbTXsSTEne+0RRE5BQ3DSLBRoYucBw3DSDBRoYsEQFzlcoy9+ZL/mg0z/J1ktu3VbBgpPip0kQDKOwwzP8U3DPP0l+s4cjLb62hSCqjQRQLsl2GY7x7qwdWtajJ29iZ6Pjubaclp5ObqhhpSdFToIkWkRqUonr++NR/d04m4yuV4ePoqrh2zgOVb93sdTUKUCl2kiLWpfQEf3t2JF25oxa5DJxg4diH3TfmBHQePex1NQowKXaQYhIUZ/dvE8+2DPRh1WUM+X72Ty56dw8uzNnIiS9McJTBU6CLFqHzZCB68qgmzHujOZRdV5/mZG7j8uTl8tupn3bBazpsKXcQDCVWiGX1TW6YM70ClcpGMfP8HbnhtMSvTDngdTUowFbqIhzrUr8pno7rwv/0vJnXPEZJGL+D3k38gbZ/mr8vZ07VcRILEkZPZvDZnExPmpZKbC7d1rss9PRsSUy7S62gSRHQtF5ESoIJ/fP27h3rQr3Utxs9Lpfsz3zFx/mYys3O9jiclgApdJMjUjCnHs4Na8dmoLrSoFcMTn/3ElS/M4Ysfd+jAqZyWCl0kSDWvFcOk29vx1m2XUjYijLvf+57rxi3SiUlSIBW6SBAzM3o0qc7nv+/KPwZczLZ9xxg4diEj3vuerXuPeh1PgowOioqUIEdPZjNhXiqvzUklOzeXm9rXYUTPhsRWLOt1NCkmpzsoqkIXKYF2HzrBC99sZGpyGmUjwrijSz2GdatPxSjNiAl1KnSREJWacYTnZm7g36t2cEF0JCN6NuTmDnWIigz3OpoUERW6SIhblX6AZ75az7yNe6gVE8V9VzZmQJs4IsJ1mCzUaB66SIhrGV+ZSbe357072hNbsSyPTF9F75fm8eXqnZrqWIqo0EVCSOeG1fh4RGfG3dyWXOe4693l9B+zkEWb9nodTYpBoQrdzHqb2XozSzGzR0/x+lAzyzCzFf6vOwIfVUQKw8zo3aImX9/XjacHXsyuQycYMmExt05cyo/pB72OJ0XojGPoZhYObACuBNKBZcAQ59xPedYZCiQ650YW9o01hi5SPE5k5TBp0VZGz07hwLEsrmxWgweubEzTmpW8jibn4HzH0NsBKc65VOdcJjAFSApkQBEpOlGR4QzrVp95j/Tk/isaszh1L31emseI975n467DXseTACpMoccBaXmep/uX5TfQzFaZ2XQzSwhIOhEJmIpRkdx7RSPmP3IZoy5ryOz1u7nqxbncN+UHUjOOeB1PAiBQB0U/Beo651oCM4G3T7WSmQ03s2QzS87IyAjQW4vI2YiJjuTBq5ow7w+XMbxbfb5as4srX5jLQ9NW6jrsJVxhxtA7Ao8753r5nz8G4Jx7qoD1w4F9zrmY031fjaGLBIeMwycZN2cTkxZvJTfXMSgxgVGXNaRW5XJeR5NTON8x9GVAIzOrZ2ZlgMHAjHxvUDPP037A2nMNKyLFK7ZiWf5ydTPmPdKTG9vXZvryNHo8M5u/frKaXYdOeB1PzkKhzhQ1s77Ai0A4MNE593czewJIds7NMLOn8BV5NrAPuNs5t+5031N76CLBafuB47z67UamJacTFmYMuTSBu3o0oGaM9tiDgU79F5Gztm3vMcbMTmH68nTCzLguMZ67uzcgoUq019FKNRW6iJyz9P3HGDdnE1OXpZPrHAPbxnNPzwbUqVre62ilkgpdRM7bjoPHeW1OKpOXbiM715HUuhYjejakQWwFr6OVKip0EQmY3YdOMH5uKu8u2Upmdi5Xt6zFqMsa0qhGRa+jlQoqdBEJuD1HTvL6vM28s2gLx7Ny6NPiQkb2bESzWrqkQFFSoYtIkdl3NJOJ8zfz9sItHD6ZzWUXVeeeHg1IrFvF62ghSYUuIkXu4LEs3lm0hTcXbmHf0UwurXsB9/RoSI8msZiZ1/FChgpdRIrNscxsPliWxoS5qfx88ARNa1bi7h4N6NviQt1BKQBU6CJS7LJycvlkxc+Mm7OJlN1HqFM1muHd6jOwbbzueXoeVOgi4pncXMfMtbsYM3sTK9MOEFuxLHd0qceN7WtTMSrS63gljgpdRDznnGPRpr2Mmb2J+Sl7qBQVwa0d6/LbTnWJrVjW63glhgpdRILKqvQDjJ29iS/X7CQyPIwBbeK4o2s9GlbXXPYzUaGLSFBKzTjCG/M3M315Oiezc7n8ouoM61af9vWqaGZMAVToIhLU9h45ybuLt/HOoi3sPZpJy/gYhnWtTx/NjPkVFbqIlAgnsnL48PvtvD4vldQ9R4mrXI7bu9Tj+ksTqFA2wut4QUGFLiIlSm6uY9a63UyYm8rSLfuoFBXBTR3qMLRTXWpUivI6nqdU6CJSYv2wbT+vz9vMF6t3EB5mXNOyFrd1rsfF8ae9y2XIUqGLSIm3be8xJi7YzLTkNI5m5pBY5wJu61yPXs1rlKpxdhW6iISMQyeymJacztsLt7Bt3zFqxURxS8e6DGmXQOXoMl7HK3IqdBEJOTm5jllrd/Hmgi0sSt1LVGQYA9rGc1unuiF9bXYVuoiEtLU7DvHWgi18tGI7mdm5dG1Ujds616VH4+qEhYXWfHYVuoiUCvuOZjJ5qW8++65DJ6lXrTxDO9Vl4CXxITPtUYUuIqVKVk4uX6zeycT5m1mRdoCKZSMYeEk8N3eoQ8PqJfseqCp0ESm1fti2n7cXbuHzH3eSmZNLpwZVuaVDHa5oVoPIEjg75rwL3cx6Ay8B4cDrzrl/FLDeQGA6cKlz7rRtrUIXkeK058hJpian8d7ibWw/cJwalcpyY7s6DG6XUKJOVjqvQjezcGADcCWQDiwDhjjnfsq3XkXg30AZYKQKXUSCUU6u47t1u5m0eCtzNmQQEWb0an4hN3eoQ4f6wX9RsNMVemGOErQDUpxzqf5vNgVIAn7Kt96TwNPAw+eRVUSkSIWHGVc0q8EVzWqwZc9R3l+6janJafz7xx00rF6BWzrUYUDbuBJ5843CDCDFAWl5nqf7l/2HmbUFEpxz/z7dNzKz4WaWbGbJGRkZZx1WRCSQ6lYrzx/7NmXxY5fzzHUtKV8mnL/OWEP7/53Fnz76kbU7Dnkd8ayc9zweMwsDngeGnmld59x4YDz4hlzO971FRAIhKjKcQYkJDEpMYGXaASYt3sr05em8t2QbrRMqc2O72lzdqibRZYJ76mNhxtA7Ao8753r5nz8G4Jx7yv88BtgEHPH/lQuBfUC/042jawxdRILZ/qOZfPjDdiYv3UbK7iNUKBtBUutaDGlXmxZx3l0Y7HwPikbgOyh6ObAd30HRG51zawpYfzbwkA6KikgocM6RvHU/k5du49+rdnAyO5eL42IY3C6Bfq1qFftYeyCmLfYFXsQ3bXGic+7vZvYEkOycm5Fv3dmo0EUkBB08lsXHK3x77et2Hia6TDjXtKzFkPa1aRUfUywzZHRikYhIADnnWJF2gClL05ix8meOZ+Vw0YUVubF9bZJaxxFTruj22lXoIiJF5PCJLGas/JnJS7exevshoiLD6HtxTa5PTCiSm12r0EVEisGP6QeZvGwbn674mcMns6lTNZpBl8Qz8JJ4asaUC8h7qNBFRIrR8cwcvli9g2nJ6SxK3UuYQddGsVyfmMAVzapTNiL8nL+3Cl1ExCNb9x5l+vJ0pi9PZ8fBE1SOjuRv/ZqT1DruzH/5FM731H8RETlHdaqW58GrmnDfFY2Zn7KHqclpxFUOzPBLfip0EZFiEB5mdG8cS/fGsUX2HiXvYsAiInJKKnQRkRChQhcRCREqdBGREKFCFxEJESp0EZEQoUIXEQkRKnQRkRDh2an/ZpYBbD3Hv14N2BPAOIEUrNmU6+wo19kL1myhlquOc+6UZyd5Vujnw8ySC7qWgdeCNZtynR3lOnvBmq005dKQi4hIiFChi4iEiJJa6OO9DnAawZpNuc6Ocp29YM1WanKVyDF0ERH5tZK6hy4iIvmo0EVEQkSJK3Qz621m680sxcwe9TBHgpl9Z2Y/mdkaM7vXv/xxM9tuZiv8X309yE0bWXMAAAQ0SURBVLbFzH70v3+yf1kVM5tpZhv9f15QzJma5NkmK8zskJnd59X2MrOJZrbbzFbnWXbKbWQ+L/s/c6vMrG0x53rGzNb53/sjM6vsX17XzI7n2XbjijlXgT87M3vMv73Wm1mvosp1mmwf5Mm1xcxW+JcXyzY7TT8U7WfMOVdivoBwYBNQHygDrASaeZSlJtDW/7gisAFoBjwOPOTxdtoCVMu37J/Ao/7HjwJPe/xz3AnU8Wp7Ad2AtsDqM20joC/wBWBAB2BJMee6CojwP346T666edfzYHud8mfn/3ewEigL1PP/mw0vzmz5Xn8O+H/Fuc1O0w9F+hkraXvo7YAU51yqcy4TmAIkeRHEObfDOfe9//FhYC1wbnd9LR5JwNv+x28D13qY5XJgk3PuXM8UPm/OubnAvnyLC9pGScA7zmcxUNnMahZXLufc1865bP/TxUB8Ubz32eY6jSRginPupHNuM5CC799usWczMwOuByYX1fsXkKmgfijSz1hJK/Q4IC3P83SCoETNrC7QBljiXzTS/2vTxOIe2vBzwNdmttzMhvuX1XDO7fA/3gnU8CDXLwbz3//AvN5evyhoGwXT5+53+PbkflHPzH4wszlm1tWDPKf62QXT9uoK7HLObcyzrFi3Wb5+KNLPWEkr9KBjZhWAfwH3OecOAWOBBkBrYAe+X/eKWxfnXFugDzDCzLrlfdH5fsfzZL6qmZUB+gHT/IuCYXv9ipfbqCBm9icgG3jPv2gHUNs51wZ4AHjfzCoVY6Sg/NnlM4T/3nko1m12in74j6L4jJW0Qt8OJOR5Hu9f5gkzi8T3w3rPOfchgHNul3MuxzmXC0ygCH/VLIhzbrv/z93AR/4Mu375Fc7/5+7izuXXB/jeObfLn9Hz7ZVHQdvI88+dmQ0FrgZu8hcB/iGNvf7Hy/GNVTcurkyn+dl5vr0AzCwCGAB88Muy4txmp+oHivgzVtIKfRnQyMzq+ff0BgMzvAjiH5t7A1jrnHs+z/K84179gdX5/24R5ypvZhV/eYzvgNpqfNvpt/7Vfgt8Upy58vivPSavt1c+BW2jGcCt/pkIHYCDeX5tLnJm1ht4BOjnnDuWZ3msmYX7H9cHGgGpxZiroJ/dDGCwmZU1s3r+XEuLK1ceVwDrnHPpvyworm1WUD9Q1J+xoj7aG+gvfEeDN+D7n/VPHubogu/XpVXACv9XX2AS8KN/+QygZjHnqo9vhsFKYM0v2wioCswCNgLfAFU82Gblgb1ATJ5lnmwvfP+p7ACy8I1X3l7QNsI382C0/zP3I5BYzLlS8I2v/vI5G+dfd6D/Z7wC+B64pphzFfizA/7k317rgT7F/bP0L38LuCvfusWyzU7TD0X6GdOp/yIiIaKkDbmIiEgBVOgiIiFChS4iEiJU6CIiIUKFLiISIlToIiIhQoUuIhIi/j/ciJ2iBWPsbwAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "x = np.linspace(0,1,num=n)\n",
    "p = np.exp(-1*x)\n",
    "plt.plot(p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 698,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp1 = []\n",
    "temp2 = []\n",
    "temp3 = []"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Start the Active Learning!!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Trace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 404,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "  0%|          | 0/20 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Getting distribution of predictions...\n",
      "      1 of 20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "  5%|▌         | 1/20 [00:18<05:43, 18.08s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      2 of 20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 10%|█         | 2/20 [00:36<05:24, 18.05s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      3 of 20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 15%|█▌        | 3/20 [00:54<05:06, 18.05s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      4 of 20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 20%|██        | 4/20 [01:12<04:49, 18.08s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      5 of 20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 25%|██▌       | 5/20 [01:30<04:31, 18.08s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      6 of 20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 30%|███       | 6/20 [01:48<04:13, 18.14s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      7 of 20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 35%|███▌      | 7/20 [02:06<03:55, 18.13s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      8 of 20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 40%|████      | 8/20 [02:24<03:37, 18.10s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      9 of 20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 45%|████▌     | 9/20 [02:42<03:19, 18.10s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      10 of 20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 50%|█████     | 10/20 [03:01<03:01, 18.11s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      11 of 20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 55%|█████▌    | 11/20 [03:19<02:42, 18.11s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      12 of 20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 60%|██████    | 12/20 [03:37<02:24, 18.11s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      13 of 20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 65%|██████▌   | 13/20 [03:55<02:06, 18.12s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      14 of 20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 70%|███████   | 14/20 [04:13<01:48, 18.16s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      15 of 20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 75%|███████▌  | 15/20 [04:31<01:30, 18.14s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      16 of 20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 80%|████████  | 16/20 [04:49<01:12, 18.12s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      17 of 20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 85%|████████▌ | 17/20 [05:07<00:54, 18.15s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      18 of 20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 90%|█████████ | 18/20 [05:26<00:36, 18.16s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      19 of 20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 95%|█████████▌| 19/20 [05:44<00:18, 18.12s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      20 of 20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "100%|██████████| 20/20 [06:02<00:00, 18.11s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing ensemble predictions...\n",
      "MSE: 0.497\n",
      "MC-ensemble MSE: 0.477\n",
      "Iteration 0\n",
      "Train on 492 samples, validate on 84 samples\n",
      "Epoch 1/150\n",
      "492/492 [==============================] - 0s 426us/step - loss: 1.9272 - regression_loss: 1.1604 - handedness_loss: 0.7299 - val_loss: 0.9844 - val_regression_loss: 0.3032 - val_handedness_loss: 0.6811\n",
      "Epoch 2/150\n",
      "492/492 [==============================] - 0s 68us/step - loss: 0.9668 - regression_loss: 0.3072 - handedness_loss: 0.6598 - val_loss: 0.9529 - val_regression_loss: 0.2670 - val_handedness_loss: 0.6860\n",
      "Epoch 3/150\n",
      "492/492 [==============================] - 0s 76us/step - loss: 0.9532 - regression_loss: 0.2806 - handedness_loss: 0.6706 - val_loss: 0.9195 - val_regression_loss: 0.2500 - val_handedness_loss: 0.6695\n",
      "Epoch 4/150\n",
      "492/492 [==============================] - 0s 79us/step - loss: 0.9373 - regression_loss: 0.2687 - handedness_loss: 0.6688 - val_loss: 0.9133 - val_regression_loss: 0.2463 - val_handedness_loss: 0.6670\n",
      "Epoch 5/150\n",
      "492/492 [==============================] - 0s 83us/step - loss: 0.9245 - regression_loss: 0.2638 - handedness_loss: 0.6605 - val_loss: 0.9162 - val_regression_loss: 0.2430 - val_handedness_loss: 0.6732\n",
      "Epoch 6/150\n",
      "492/492 [==============================] - 0s 99us/step - loss: 0.9046 - regression_loss: 0.2601 - handedness_loss: 0.6450 - val_loss: 0.9131 - val_regression_loss: 0.2405 - val_handedness_loss: 0.6727\n",
      "Epoch 7/150\n",
      "492/492 [==============================] - 0s 153us/step - loss: 0.8926 - regression_loss: 0.2556 - handedness_loss: 0.6383 - val_loss: 0.9013 - val_regression_loss: 0.2348 - val_handedness_loss: 0.6665\n",
      "Epoch 8/150\n",
      "492/492 [==============================] - 0s 157us/step - loss: 0.8853 - regression_loss: 0.2474 - handedness_loss: 0.6378 - val_loss: 0.8861 - val_regression_loss: 0.2247 - val_handedness_loss: 0.6614\n",
      "Epoch 9/150\n",
      "492/492 [==============================] - 0s 155us/step - loss: 0.8701 - regression_loss: 0.2411 - handedness_loss: 0.6293 - val_loss: 0.8700 - val_regression_loss: 0.2307 - val_handedness_loss: 0.6394\n",
      "Epoch 10/150\n",
      "492/492 [==============================] - 0s 144us/step - loss: 0.8437 - regression_loss: 0.2322 - handedness_loss: 0.6117 - val_loss: 0.8535 - val_regression_loss: 0.2144 - val_handedness_loss: 0.6391\n",
      "Epoch 11/150\n",
      "492/492 [==============================] - 0s 125us/step - loss: 0.8241 - regression_loss: 0.2228 - handedness_loss: 0.6012 - val_loss: 0.8407 - val_regression_loss: 0.2011 - val_handedness_loss: 0.6396\n",
      "Epoch 12/150\n",
      "492/492 [==============================] - 0s 130us/step - loss: 0.8087 - regression_loss: 0.2254 - handedness_loss: 0.5851 - val_loss: 0.8582 - val_regression_loss: 0.1915 - val_handedness_loss: 0.6667\n",
      "Epoch 13/150\n",
      "492/492 [==============================] - 0s 127us/step - loss: 0.7866 - regression_loss: 0.2152 - handedness_loss: 0.5726 - val_loss: 0.8021 - val_regression_loss: 0.1890 - val_handedness_loss: 0.6131\n",
      "Epoch 14/150\n",
      "492/492 [==============================] - 0s 126us/step - loss: 0.7763 - regression_loss: 0.2097 - handedness_loss: 0.5673 - val_loss: 0.8153 - val_regression_loss: 0.1841 - val_handedness_loss: 0.6312\n",
      "Epoch 15/150\n",
      "492/492 [==============================] - 0s 127us/step - loss: 0.7442 - regression_loss: 0.2004 - handedness_loss: 0.5438 - val_loss: 0.8030 - val_regression_loss: 0.1812 - val_handedness_loss: 0.6218\n",
      "Epoch 16/150\n",
      "492/492 [==============================] - 0s 125us/step - loss: 0.7021 - regression_loss: 0.1914 - handedness_loss: 0.5078 - val_loss: 0.7782 - val_regression_loss: 0.1757 - val_handedness_loss: 0.6024\n",
      "Epoch 17/150\n",
      "492/492 [==============================] - 0s 127us/step - loss: 0.6917 - regression_loss: 0.1911 - handedness_loss: 0.5002 - val_loss: 0.8181 - val_regression_loss: 0.1778 - val_handedness_loss: 0.6403\n",
      "Epoch 18/150\n",
      "492/492 [==============================] - 0s 126us/step - loss: 0.6387 - regression_loss: 0.1815 - handedness_loss: 0.4549 - val_loss: 0.8090 - val_regression_loss: 0.1571 - val_handedness_loss: 0.6519\n",
      "Epoch 19/150\n",
      "492/492 [==============================] - 0s 125us/step - loss: 0.6438 - regression_loss: 0.1727 - handedness_loss: 0.4676 - val_loss: 0.7872 - val_regression_loss: 0.1523 - val_handedness_loss: 0.6349\n",
      "Epoch 20/150\n",
      "492/492 [==============================] - 0s 124us/step - loss: 0.5806 - regression_loss: 0.1711 - handedness_loss: 0.4111 - val_loss: 0.7098 - val_regression_loss: 0.1545 - val_handedness_loss: 0.5553\n",
      "Epoch 21/150\n",
      "492/492 [==============================] - 0s 127us/step - loss: 0.5501 - regression_loss: 0.1678 - handedness_loss: 0.3851 - val_loss: 0.7720 - val_regression_loss: 0.1405 - val_handedness_loss: 0.6315\n",
      "Epoch 22/150\n",
      "492/492 [==============================] - 0s 128us/step - loss: 0.5339 - regression_loss: 0.1608 - handedness_loss: 0.3762 - val_loss: 0.7605 - val_regression_loss: 0.1467 - val_handedness_loss: 0.6138\n",
      "Epoch 23/150\n",
      "492/492 [==============================] - 0s 125us/step - loss: 0.4818 - regression_loss: 0.1554 - handedness_loss: 0.3240 - val_loss: 0.7147 - val_regression_loss: 0.1381 - val_handedness_loss: 0.5767\n",
      "Epoch 24/150\n",
      "492/492 [==============================] - 0s 126us/step - loss: 0.4061 - regression_loss: 0.1562 - handedness_loss: 0.2448 - val_loss: 0.7730 - val_regression_loss: 0.1513 - val_handedness_loss: 0.6218\n",
      "Evaluating model with testing data...\n",
      "84/84 [==============================] - 0s 59us/step\n",
      "Getting distribution of predictions and covariance matrix...\n",
      "      1 of 20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "  0%|          | 0/20 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      2 of 20\n",
      "      3 of 20\n",
      "      4 of 20\n",
      "      5 of 20\n",
      "      6 of 20\n",
      "      7 of 20\n",
      "      8 of 20\n",
      "      9 of 20\n",
      "      10 of 20\n",
      "      11 of 20\n",
      "      12 of 20\n",
      "      13 of 20\n",
      "      14 of 20\n",
      "      15 of 20\n",
      "      16 of 20\n",
      "      17 of 20\n",
      "      18 of 20\n",
      "      19 of 20\n",
      "      20 of 20\n",
      "Computing ensemble means...\n",
      "Computing mean squared error...\n",
      "Getting distribution of predictions...\n",
      "      1 of 20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "  5%|▌         | 1/20 [00:30<09:31, 30.08s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      2 of 20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 10%|█         | 2/20 [01:00<09:03, 30.17s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      3 of 20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 15%|█▌        | 3/20 [01:30<08:31, 30.11s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      4 of 20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 20%|██        | 4/20 [02:00<08:01, 30.09s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      5 of 20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 25%|██▌       | 5/20 [02:30<07:30, 30.06s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      6 of 20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 30%|███       | 6/20 [03:00<07:00, 30.04s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      7 of 20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 35%|███▌      | 7/20 [03:30<06:30, 30.07s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      8 of 20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 40%|████      | 8/20 [04:00<05:59, 29.94s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      9 of 20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 45%|████▌     | 9/20 [04:30<05:29, 29.97s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      10 of 20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 50%|█████     | 10/20 [05:00<05:01, 30.10s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      11 of 20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 55%|█████▌    | 11/20 [05:30<04:31, 30.14s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      12 of 20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 60%|██████    | 12/20 [06:01<04:01, 30.13s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      13 of 20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 65%|██████▌   | 13/20 [06:31<03:30, 30.14s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      14 of 20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 70%|███████   | 14/20 [07:01<03:00, 30.15s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      15 of 20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 75%|███████▌  | 15/20 [07:31<02:30, 30.12s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      16 of 20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 80%|████████  | 16/20 [08:01<02:00, 30.08s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      17 of 20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 85%|████████▌ | 17/20 [08:31<01:30, 30.14s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      18 of 20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 90%|█████████ | 18/20 [09:01<01:00, 30.10s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      19 of 20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 95%|█████████▌| 19/20 [09:31<00:30, 30.08s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      20 of 20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "100%|██████████| 20/20 [10:01<00:00, 30.08s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing ensemble predictions...\n",
      "Iteration 1\n",
      "Train on 632 samples, validate on 114 samples\n",
      "Epoch 1/150\n",
      "632/632 [==============================] - 0s 348us/step - loss: 1.8982 - regression_loss: 1.2272 - handedness_loss: 0.6596 - val_loss: 0.8384 - val_regression_loss: 0.3946 - val_handedness_loss: 0.4438\n",
      "Epoch 2/150\n",
      "632/632 [==============================] - 0s 72us/step - loss: 0.9462 - regression_loss: 0.3148 - handedness_loss: 0.6314 - val_loss: 0.7178 - val_regression_loss: 0.3644 - val_handedness_loss: 0.3534\n",
      "Epoch 3/150\n",
      "632/632 [==============================] - 0s 88us/step - loss: 0.8940 - regression_loss: 0.2979 - handedness_loss: 0.5965 - val_loss: 0.6713 - val_regression_loss: 0.3592 - val_handedness_loss: 0.3121\n",
      "Epoch 4/150\n",
      "632/632 [==============================] - 0s 78us/step - loss: 0.8448 - regression_loss: 0.2920 - handedness_loss: 0.5535 - val_loss: 0.4067 - val_regression_loss: 0.3503 - val_handedness_loss: 0.0564\n",
      "Epoch 5/150\n",
      "632/632 [==============================] - 0s 149us/step - loss: 0.8000 - regression_loss: 0.2798 - handedness_loss: 0.5194 - val_loss: 0.4075 - val_regression_loss: 0.3371 - val_handedness_loss: 0.0703\n",
      "Epoch 6/150\n",
      "632/632 [==============================] - 0s 146us/step - loss: 0.7295 - regression_loss: 0.2619 - handedness_loss: 0.4655 - val_loss: 0.2707 - val_regression_loss: 0.3079 - val_handedness_loss: -0.0371\n",
      "Epoch 7/150\n",
      "632/632 [==============================] - 0s 146us/step - loss: 0.7153 - regression_loss: 0.2663 - handedness_loss: 0.4479 - val_loss: 0.1345 - val_regression_loss: 0.2847 - val_handedness_loss: -0.1501\n",
      "Epoch 8/150\n",
      "632/632 [==============================] - 0s 157us/step - loss: 0.6305 - regression_loss: 0.2353 - handedness_loss: 0.3954 - val_loss: -0.0890 - val_regression_loss: 0.2672 - val_handedness_loss: -0.3562\n",
      "Epoch 9/150\n",
      "632/632 [==============================] - 0s 154us/step - loss: 0.5524 - regression_loss: 0.2164 - handedness_loss: 0.3372 - val_loss: -0.3443 - val_regression_loss: 0.2965 - val_handedness_loss: -0.6408\n",
      "Epoch 10/150\n",
      "632/632 [==============================] - 0s 110us/step - loss: 0.5756 - regression_loss: 0.2650 - handedness_loss: 0.3103 - val_loss: -0.4401 - val_regression_loss: 0.3050 - val_handedness_loss: -0.7451\n",
      "Epoch 11/150\n",
      "632/632 [==============================] - 0s 80us/step - loss: 0.4751 - regression_loss: 0.2323 - handedness_loss: 0.2438 - val_loss: -0.7599 - val_regression_loss: 0.2772 - val_handedness_loss: -1.0370\n",
      "Epoch 12/150\n",
      "632/632 [==============================] - 0s 85us/step - loss: 0.3697 - regression_loss: 0.2229 - handedness_loss: 0.1456 - val_loss: -0.7198 - val_regression_loss: 0.3588 - val_handedness_loss: -1.0786\n",
      "Evaluating model with testing data...\n",
      "114/114 [==============================] - 0s 33us/step\n",
      "Getting distribution of predictions and covariance matrix...\n",
      "      1 of 20\n",
      "      2 of 20\n",
      "      3 of 20\n",
      "      4 of 20\n",
      "      5 of 20\n",
      "      6 of 20\n",
      "      7 of 20\n",
      "      8 of 20\n",
      "      9 of 20\n",
      "      10 of 20\n",
      "      11 of 20\n",
      "      12 of 20\n",
      "      13 of 20\n",
      "      14 of 20\n",
      "      15 of 20\n",
      "      16 of 20\n",
      "      17 of 20\n",
      "      18 of 20\n",
      "      19 of 20\n",
      "      20 of 20\n",
      "Computing ensemble means...\n",
      "Computing mean squared error...\n",
      "Iteration 2\n",
      "Train on 772 samples, validate on 144 samples\n",
      "Epoch 1/150\n",
      "772/772 [==============================] - 0s 301us/step - loss: 1.7785 - regression_loss: 0.9707 - handedness_loss: 0.7042 - val_loss: 0.9533 - val_regression_loss: 0.3260 - val_handedness_loss: 0.6153\n",
      "Epoch 2/150\n",
      "772/772 [==============================] - 0s 76us/step - loss: 0.9323 - regression_loss: 0.2984 - handedness_loss: 0.6583 - val_loss: 0.8885 - val_regression_loss: 0.3081 - val_handedness_loss: 0.6212\n",
      "Epoch 3/150\n",
      "772/772 [==============================] - 0s 129us/step - loss: 0.8814 - regression_loss: 0.3089 - handedness_loss: 0.6309 - val_loss: 0.7649 - val_regression_loss: 0.2796 - val_handedness_loss: 0.4441\n",
      "Epoch 4/150\n",
      "772/772 [==============================] - 0s 136us/step - loss: 0.8210 - regression_loss: 0.2591 - handedness_loss: 0.5611 - val_loss: 0.6098 - val_regression_loss: 0.2716 - val_handedness_loss: 0.3722\n",
      "Epoch 5/150\n",
      "772/772 [==============================] - 0s 134us/step - loss: 0.7635 - regression_loss: 0.2252 - handedness_loss: 0.5200 - val_loss: 0.4390 - val_regression_loss: 0.2106 - val_handedness_loss: 0.1721\n",
      "Epoch 6/150\n",
      "772/772 [==============================] - 0s 148us/step - loss: 0.7049 - regression_loss: 0.2482 - handedness_loss: 0.5211 - val_loss: 0.3683 - val_regression_loss: 0.2254 - val_handedness_loss: 0.0949\n",
      "Epoch 7/150\n",
      "772/772 [==============================] - 0s 169us/step - loss: 0.6782 - regression_loss: 0.2668 - handedness_loss: 0.5142 - val_loss: 0.2914 - val_regression_loss: 0.2077 - val_handedness_loss: 0.1511\n",
      "Epoch 8/150\n",
      "772/772 [==============================] - 0s 121us/step - loss: 0.6456 - regression_loss: 0.1907 - handedness_loss: 0.4500 - val_loss: 0.4793 - val_regression_loss: 0.1721 - val_handedness_loss: 0.2273\n",
      "Epoch 9/150\n",
      "772/772 [==============================] - 0s 105us/step - loss: 0.6251 - regression_loss: 0.1898 - handedness_loss: 0.4439 - val_loss: 0.0580 - val_regression_loss: 0.1718 - val_handedness_loss: -0.1275\n",
      "Epoch 10/150\n",
      "772/772 [==============================] - 0s 93us/step - loss: 0.4875 - regression_loss: 0.2011 - handedness_loss: 0.3011 - val_loss: -0.2167 - val_regression_loss: 0.1867 - val_handedness_loss: -0.4390\n",
      "Epoch 11/150\n",
      "772/772 [==============================] - 0s 93us/step - loss: 0.4829 - regression_loss: 0.2796 - handedness_loss: 0.4098 - val_loss: -0.3620 - val_regression_loss: 0.1969 - val_handedness_loss: -0.4591\n",
      "Epoch 12/150\n",
      "772/772 [==============================] - 0s 156us/step - loss: 0.4332 - regression_loss: 0.2267 - handedness_loss: 0.2270 - val_loss: -0.0128 - val_regression_loss: 0.1908 - val_handedness_loss: -0.2048\n",
      "Epoch 13/150\n",
      "772/772 [==============================] - 0s 132us/step - loss: 0.3933 - regression_loss: 0.1930 - handedness_loss: 0.2757 - val_loss: -0.4915 - val_regression_loss: 0.1770 - val_handedness_loss: -0.6296\n",
      "Evaluating model with testing data...\n",
      "144/144 [==============================] - 0s 41us/step\n",
      "Getting distribution of predictions and covariance matrix...\n",
      "      1 of 20\n",
      "      2 of 20\n",
      "      3 of 20\n",
      "      4 of 20\n",
      "      5 of 20\n",
      "      6 of 20\n",
      "      7 of 20\n",
      "      8 of 20\n",
      "      9 of 20\n",
      "      10 of 20\n",
      "      11 of 20\n",
      "      12 of 20\n",
      "      13 of 20\n",
      "      14 of 20\n",
      "      15 of 20\n",
      "      16 of 20\n",
      "      17 of 20\n",
      "      18 of 20\n",
      "      19 of 20\n",
      "      20 of 20\n",
      "Computing ensemble means...\n",
      "Computing mean squared error...\n",
      "Iteration 3\n",
      "Train on 912 samples, validate on 174 samples\n",
      "Epoch 1/150\n",
      "912/912 [==============================] - 0s 264us/step - loss: 2.0905 - regression_loss: 1.3114 - handedness_loss: 0.6610 - val_loss: 0.9552 - val_regression_loss: 0.3399 - val_handedness_loss: 0.6338\n",
      "Epoch 2/150\n",
      "912/912 [==============================] - 0s 69us/step - loss: 0.9341 - regression_loss: 0.3042 - handedness_loss: 0.6226 - val_loss: 0.9115 - val_regression_loss: 0.3415 - val_handedness_loss: 0.5771\n",
      "Epoch 3/150\n",
      "912/912 [==============================] - 0s 77us/step - loss: 0.8772 - regression_loss: 0.2870 - handedness_loss: 0.5821 - val_loss: 0.8368 - val_regression_loss: 0.3191 - val_handedness_loss: 0.5360\n",
      "Epoch 4/150\n",
      "912/912 [==============================] - 0s 117us/step - loss: 0.8221 - regression_loss: 0.2888 - handedness_loss: 0.4930 - val_loss: 0.7254 - val_regression_loss: 0.3112 - val_handedness_loss: 0.4316\n",
      "Epoch 5/150\n",
      "912/912 [==============================] - 0s 107us/step - loss: 0.7801 - regression_loss: 0.2874 - handedness_loss: 0.4855 - val_loss: 0.6398 - val_regression_loss: 0.3564 - val_handedness_loss: 0.2863\n",
      "Epoch 6/150\n",
      "912/912 [==============================] - 0s 112us/step - loss: 0.7077 - regression_loss: 0.2812 - handedness_loss: 0.4232 - val_loss: 0.5617 - val_regression_loss: 0.2814 - val_handedness_loss: 0.2791\n",
      "Epoch 7/150\n",
      "912/912 [==============================] - 0s 115us/step - loss: 0.6407 - regression_loss: 0.2724 - handedness_loss: 0.3554 - val_loss: 0.4721 - val_regression_loss: 0.2988 - val_handedness_loss: 0.1592\n",
      "Epoch 8/150\n",
      "912/912 [==============================] - 0s 133us/step - loss: 0.6004 - regression_loss: 0.2581 - handedness_loss: 0.3441 - val_loss: 0.3086 - val_regression_loss: 0.2694 - val_handedness_loss: 0.0381\n",
      "Epoch 9/150\n",
      "912/912 [==============================] - 0s 144us/step - loss: 0.5508 - regression_loss: 0.2828 - handedness_loss: 0.2628 - val_loss: 0.2392 - val_regression_loss: 0.2851 - val_handedness_loss: -0.0889\n",
      "Epoch 10/150\n",
      "912/912 [==============================] - 0s 137us/step - loss: 0.4667 - regression_loss: 0.2616 - handedness_loss: 0.1813 - val_loss: 0.1280 - val_regression_loss: 0.2637 - val_handedness_loss: -0.1197\n",
      "Epoch 11/150\n",
      "912/912 [==============================] - 0s 128us/step - loss: 0.3924 - regression_loss: 0.2998 - handedness_loss: 0.0482 - val_loss: 0.0802 - val_regression_loss: 0.2813 - val_handedness_loss: -0.1750\n",
      "Epoch 12/150\n",
      "912/912 [==============================] - 0s 126us/step - loss: 0.3146 - regression_loss: 0.3205 - handedness_loss: 0.0357 - val_loss: -0.0139 - val_regression_loss: 0.2997 - val_handedness_loss: -0.2972\n",
      "Epoch 13/150\n",
      "912/912 [==============================] - 0s 131us/step - loss: 0.2200 - regression_loss: 0.2608 - handedness_loss: -0.1070 - val_loss: -0.4540 - val_regression_loss: 0.3257 - val_handedness_loss: -0.7126\n",
      "Epoch 14/150\n",
      "912/912 [==============================] - 0s 127us/step - loss: 0.1057 - regression_loss: 0.3135 - handedness_loss: -0.2667 - val_loss: -0.8100 - val_regression_loss: 0.4037 - val_handedness_loss: -1.1951\n",
      "Evaluating model with testing data...\n",
      "174/174 [==============================] - 0s 39us/step\n",
      "Getting distribution of predictions and covariance matrix...\n",
      "      1 of 20\n",
      "      2 of 20\n",
      "      3 of 20\n",
      "      4 of 20\n",
      "      5 of 20\n",
      "      6 of 20\n",
      "      7 of 20\n",
      "      8 of 20\n",
      "      9 of 20\n",
      "      10 of 20\n",
      "      11 of 20\n",
      "      12 of 20\n",
      "      13 of 20\n",
      "      14 of 20\n",
      "      15 of 20\n",
      "      16 of 20\n",
      "      17 of 20\n",
      "      18 of 20\n",
      "      19 of 20\n",
      "      20 of 20\n",
      "Computing ensemble means...\n",
      "Computing mean squared error...\n",
      "Iteration 4\n",
      "Train on 1052 samples, validate on 204 samples\n",
      "Epoch 1/150\n",
      "1052/1052 [==============================] - 0s 258us/step - loss: 1.5278 - regression_loss: 0.8479 - handedness_loss: 0.6427 - val_loss: 0.9609 - val_regression_loss: 0.3586 - val_handedness_loss: 0.5878\n",
      "Epoch 2/150\n",
      "1052/1052 [==============================] - 0s 81us/step - loss: 0.9405 - regression_loss: 0.3068 - handedness_loss: 0.6266 - val_loss: 0.8143 - val_regression_loss: 0.2945 - val_handedness_loss: 0.4953\n",
      "Epoch 3/150\n",
      "1052/1052 [==============================] - 0s 118us/step - loss: 0.8484 - regression_loss: 0.2794 - handedness_loss: 0.5716 - val_loss: 0.6799 - val_regression_loss: 0.2651 - val_handedness_loss: 0.3855\n",
      "Epoch 4/150\n",
      "1052/1052 [==============================] - 0s 98us/step - loss: 0.7858 - regression_loss: 0.2496 - handedness_loss: 0.5354 - val_loss: 0.5182 - val_regression_loss: 0.2506 - val_handedness_loss: 0.1458\n",
      "Epoch 5/150\n",
      "1052/1052 [==============================] - 0s 131us/step - loss: 0.7080 - regression_loss: 0.2499 - handedness_loss: 0.4371 - val_loss: 0.4158 - val_regression_loss: 0.2544 - val_handedness_loss: 0.0979\n",
      "Epoch 6/150\n",
      "1052/1052 [==============================] - 0s 123us/step - loss: 0.6326 - regression_loss: 0.2400 - handedness_loss: 0.4076 - val_loss: 0.1999 - val_regression_loss: 0.2503 - val_handedness_loss: -0.1204\n",
      "Epoch 7/150\n",
      "1052/1052 [==============================] - 0s 142us/step - loss: 0.5438 - regression_loss: 0.2396 - handedness_loss: 0.2849 - val_loss: 0.0233 - val_regression_loss: 0.2999 - val_handedness_loss: -0.3648\n",
      "Epoch 8/150\n",
      "1052/1052 [==============================] - 0s 143us/step - loss: 0.3783 - regression_loss: 0.2780 - handedness_loss: 0.0468 - val_loss: -0.2177 - val_regression_loss: 0.3130 - val_handedness_loss: -0.6737\n",
      "Epoch 9/150\n",
      "1052/1052 [==============================] - 0s 146us/step - loss: 0.3209 - regression_loss: 0.3055 - handedness_loss: 0.0472 - val_loss: -0.6181 - val_regression_loss: 0.3398 - val_handedness_loss: -1.1323\n",
      "Epoch 10/150\n",
      "1052/1052 [==============================] - 0s 145us/step - loss: -0.0574 - regression_loss: 0.3722 - handedness_loss: -0.4556 - val_loss: -1.2137 - val_regression_loss: 0.5198 - val_handedness_loss: -1.9103\n",
      "Evaluating model with testing data...\n",
      "204/204 [==============================] - 0s 42us/step\n",
      "Getting distribution of predictions and covariance matrix...\n",
      "      1 of 20\n",
      "      2 of 20\n",
      "      3 of 20\n",
      "      4 of 20\n",
      "      5 of 20\n",
      "      6 of 20\n",
      "      7 of 20\n",
      "      8 of 20\n",
      "      9 of 20\n",
      "      10 of 20\n",
      "      11 of 20\n",
      "      12 of 20\n",
      "      13 of 20\n",
      "      14 of 20\n",
      "      15 of 20\n",
      "      16 of 20\n",
      "      17 of 20\n",
      "      18 of 20\n",
      "      19 of 20\n",
      "      20 of 20\n",
      "Computing ensemble means...\n",
      "Computing mean squared error...\n",
      "Iteration 5\n",
      "Train on 1192 samples, validate on 234 samples\n",
      "Epoch 1/150\n",
      "1192/1192 [==============================] - 0s 224us/step - loss: 1.4010 - regression_loss: 0.7762 - handedness_loss: 0.5885 - val_loss: 0.7951 - val_regression_loss: 0.3691 - val_handedness_loss: 0.4251\n",
      "Epoch 2/150\n",
      "1192/1192 [==============================] - 0s 75us/step - loss: 0.8610 - regression_loss: 0.3126 - handedness_loss: 0.5534 - val_loss: 0.4281 - val_regression_loss: 0.3590 - val_handedness_loss: 0.0625\n",
      "Epoch 3/150\n",
      "1192/1192 [==============================] - 0s 128us/step - loss: 0.7165 - regression_loss: 0.3036 - handedness_loss: 0.4227 - val_loss: 0.0556 - val_regression_loss: 0.4094 - val_handedness_loss: -0.3710\n",
      "Epoch 4/150\n",
      "1192/1192 [==============================] - 0s 101us/step - loss: 0.6156 - regression_loss: 0.3136 - handedness_loss: 0.2960 - val_loss: -0.1992 - val_regression_loss: 0.3945 - val_handedness_loss: -0.6214\n",
      "Epoch 5/150\n",
      "1192/1192 [==============================] - 0s 111us/step - loss: 0.4682 - regression_loss: 0.3261 - handedness_loss: 0.0676 - val_loss: -0.6446 - val_regression_loss: 0.5361 - val_handedness_loss: -1.2040\n",
      "Epoch 6/150\n",
      "1192/1192 [==============================] - 0s 132us/step - loss: 0.2537 - regression_loss: 0.4447 - handedness_loss: -0.1521 - val_loss: -1.1959 - val_regression_loss: 0.5695 - val_handedness_loss: -1.8083\n",
      "Evaluating model with testing data...\n",
      "234/234 [==============================] - 0s 40us/step\n",
      "Getting distribution of predictions and covariance matrix...\n",
      "      1 of 20\n",
      "      2 of 20\n",
      "      3 of 20\n",
      "      4 of 20\n",
      "      5 of 20\n",
      "      6 of 20\n",
      "      7 of 20\n",
      "      8 of 20\n",
      "      9 of 20\n",
      "      10 of 20\n",
      "      11 of 20\n",
      "      12 of 20\n",
      "      13 of 20\n",
      "      14 of 20\n",
      "      15 of 20\n",
      "      16 of 20\n",
      "      17 of 20\n",
      "      18 of 20\n",
      "      19 of 20\n",
      "      20 of 20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "  0%|          | 0/20 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing ensemble means...\n",
      "Computing mean squared error...\n",
      "Getting distribution of predictions...\n",
      "      1 of 20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "  5%|▌         | 1/20 [00:29<09:27, 29.84s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      2 of 20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 10%|█         | 2/20 [00:59<08:56, 29.83s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      3 of 20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 15%|█▌        | 3/20 [01:29<08:27, 29.85s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      4 of 20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 20%|██        | 4/20 [01:59<07:58, 29.93s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      5 of 20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 25%|██▌       | 5/20 [02:29<07:29, 29.99s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      6 of 20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 30%|███       | 6/20 [02:59<07:00, 30.03s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      7 of 20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 35%|███▌      | 7/20 [03:29<06:30, 30.01s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      8 of 20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 40%|████      | 8/20 [03:59<06:00, 30.03s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      9 of 20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 45%|████▌     | 9/20 [04:29<05:30, 30.03s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      10 of 20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 50%|█████     | 10/20 [05:00<05:00, 30.10s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      11 of 20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 55%|█████▌    | 11/20 [05:30<04:30, 30.05s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      12 of 20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 60%|██████    | 12/20 [06:00<04:00, 30.00s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      13 of 20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 65%|██████▌   | 13/20 [06:30<03:30, 30.03s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      14 of 20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 70%|███████   | 14/20 [07:00<03:00, 30.02s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      15 of 20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 75%|███████▌  | 15/20 [07:30<02:30, 30.06s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      16 of 20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 80%|████████  | 16/20 [08:00<02:00, 30.06s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      17 of 20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 85%|████████▌ | 17/20 [08:30<01:30, 30.05s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      18 of 20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 90%|█████████ | 18/20 [09:00<01:00, 30.06s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      19 of 20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 95%|█████████▌| 19/20 [09:30<00:30, 30.04s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      20 of 20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "100%|██████████| 20/20 [10:00<00:00, 30.01s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing ensemble predictions...\n",
      "Iteration 6\n",
      "Train on 1332 samples, validate on 264 samples\n",
      "Epoch 1/150\n",
      "1332/1332 [==============================] - 0s 224us/step - loss: 1.3592 - regression_loss: 0.7212 - handedness_loss: 0.6168 - val_loss: 0.7217 - val_regression_loss: 0.3693 - val_handedness_loss: 0.2428\n",
      "Epoch 2/150\n",
      "1332/1332 [==============================] - 0s 92us/step - loss: 0.8540 - regression_loss: 0.3545 - handedness_loss: 0.4955 - val_loss: 0.3659 - val_regression_loss: 0.3853 - val_handedness_loss: -0.0282\n",
      "Epoch 3/150\n",
      "1332/1332 [==============================] - 0s 152us/step - loss: 0.6874 - regression_loss: 0.3195 - handedness_loss: 0.3467 - val_loss: -0.1110 - val_regression_loss: 0.2963 - val_handedness_loss: -0.6111\n",
      "Epoch 4/150\n",
      "1332/1332 [==============================] - 0s 155us/step - loss: 0.4961 - regression_loss: 0.3208 - handedness_loss: 0.1532 - val_loss: -0.4656 - val_regression_loss: 0.3310 - val_handedness_loss: -0.8934\n",
      "Epoch 5/150\n",
      "1332/1332 [==============================] - 0s 153us/step - loss: 0.3707 - regression_loss: 0.3210 - handedness_loss: 0.0315 - val_loss: -0.9038 - val_regression_loss: 0.4358 - val_handedness_loss: -1.1584\n",
      "Epoch 6/150\n",
      "1332/1332 [==============================] - 0s 153us/step - loss: 0.1705 - regression_loss: 0.4079 - handedness_loss: -0.2138 - val_loss: -1.5048 - val_regression_loss: 0.5040 - val_handedness_loss: -1.5138\n",
      "Epoch 7/150\n",
      "1332/1332 [==============================] - 0s 152us/step - loss: -0.1993 - regression_loss: 0.5380 - handedness_loss: -0.6715 - val_loss: -2.7610 - val_regression_loss: 0.6133 - val_handedness_loss: -3.8030\n",
      "Evaluating model with testing data...\n",
      "264/264 [==============================] - 0s 38us/step\n",
      "Getting distribution of predictions and covariance matrix...\n",
      "      1 of 20\n",
      "      2 of 20\n",
      "      3 of 20\n",
      "      4 of 20\n",
      "      5 of 20\n",
      "      6 of 20\n",
      "      7 of 20\n",
      "      8 of 20\n",
      "      9 of 20\n",
      "      10 of 20\n",
      "      11 of 20\n",
      "      12 of 20\n",
      "      13 of 20\n",
      "      14 of 20\n",
      "      15 of 20\n",
      "      16 of 20\n",
      "      17 of 20\n",
      "      18 of 20\n",
      "      19 of 20\n",
      "      20 of 20\n",
      "Computing ensemble means...\n",
      "Computing mean squared error...\n",
      "Iteration 7\n",
      "Train on 1472 samples, validate on 294 samples\n",
      "Epoch 1/150\n",
      "1472/1472 [==============================] - 0s 200us/step - loss: 1.1928 - regression_loss: 0.6869 - handedness_loss: 0.4886 - val_loss: 0.5443 - val_regression_loss: 0.3159 - val_handedness_loss: 0.2522\n",
      "Epoch 2/150\n",
      "1472/1472 [==============================] - 0s 81us/step - loss: 0.6358 - regression_loss: 0.2838 - handedness_loss: 0.3401 - val_loss: 0.0325 - val_regression_loss: 0.3442 - val_handedness_loss: -0.2809\n",
      "Epoch 3/150\n",
      "1472/1472 [==============================] - 0s 154us/step - loss: 0.4140 - regression_loss: 0.3107 - handedness_loss: 0.0898 - val_loss: -0.2629 - val_regression_loss: 0.3150 - val_handedness_loss: -0.4665\n",
      "Epoch 4/150\n",
      "1472/1472 [==============================] - 0s 114us/step - loss: 0.1378 - regression_loss: 0.3440 - handedness_loss: -0.2136 - val_loss: -0.9896 - val_regression_loss: 0.3790 - val_handedness_loss: -1.2183\n",
      "Epoch 5/150\n",
      "1472/1472 [==============================] - 0s 123us/step - loss: -0.2505 - regression_loss: 0.5177 - handedness_loss: -0.7647 - val_loss: -2.1963 - val_regression_loss: 0.6960 - val_handedness_loss: -2.6036\n",
      "Epoch 6/150\n",
      "1472/1472 [==============================] - 0s 133us/step - loss: -0.8056 - regression_loss: 0.6930 - handedness_loss: -1.6213 - val_loss: -3.8749 - val_regression_loss: 1.2322 - val_handedness_loss: -4.8880\n",
      "Epoch 7/150\n",
      "1472/1472 [==============================] - 0s 134us/step - loss: -1.8922 - regression_loss: 1.3271 - handedness_loss: -3.3740 - val_loss: -5.7690 - val_regression_loss: 1.2384 - val_handedness_loss: -6.4511\n",
      "Evaluating model with testing data...\n",
      "294/294 [==============================] - 0s 36us/step\n",
      "Getting distribution of predictions and covariance matrix...\n",
      "      1 of 20\n",
      "      2 of 20\n",
      "      3 of 20\n",
      "      4 of 20\n",
      "      5 of 20\n",
      "      6 of 20\n",
      "      7 of 20\n",
      "      8 of 20\n",
      "      9 of 20\n",
      "      10 of 20\n",
      "      11 of 20\n",
      "      12 of 20\n",
      "      13 of 20\n",
      "      14 of 20\n",
      "      15 of 20\n",
      "      16 of 20\n",
      "      17 of 20\n",
      "      18 of 20\n",
      "      19 of 20\n",
      "      20 of 20\n",
      "Computing ensemble means...\n",
      "Computing mean squared error...\n",
      "Iteration 8\n",
      "Train on 1612 samples, validate on 324 samples\n",
      "Epoch 1/150\n",
      "1612/1612 [==============================] - 0s 180us/step - loss: 1.6148 - regression_loss: 1.1188 - handedness_loss: 0.4733 - val_loss: 0.6580 - val_regression_loss: 0.3490 - val_handedness_loss: 0.3235\n",
      "Epoch 2/150\n",
      "1612/1612 [==============================] - 0s 74us/step - loss: 0.6808 - regression_loss: 0.3230 - handedness_loss: 0.3579 - val_loss: 0.0022 - val_regression_loss: 0.3194 - val_handedness_loss: -0.2824\n",
      "Epoch 3/150\n",
      "1612/1612 [==============================] - 0s 112us/step - loss: 0.3782 - regression_loss: 0.3135 - handedness_loss: 0.0552 - val_loss: -0.6264 - val_regression_loss: 0.3475 - val_handedness_loss: -0.8671\n",
      "Epoch 4/150\n",
      "1612/1612 [==============================] - 0s 110us/step - loss: 0.1133 - regression_loss: 0.4173 - handedness_loss: -0.3047 - val_loss: -0.6685 - val_regression_loss: 0.3831 - val_handedness_loss: -0.9365\n",
      "Epoch 5/150\n",
      "1612/1612 [==============================] - 0s 106us/step - loss: -0.3321 - regression_loss: 0.4720 - handedness_loss: -0.8185 - val_loss: -1.9786 - val_regression_loss: 0.8025 - val_handedness_loss: -2.5490\n",
      "Epoch 6/150\n",
      "1612/1612 [==============================] - 0s 131us/step - loss: -1.1961 - regression_loss: 0.8362 - handedness_loss: -2.0334 - val_loss: -3.4716 - val_regression_loss: 1.4462 - val_handedness_loss: -4.4945\n",
      "Evaluating model with testing data...\n",
      "324/324 [==============================] - 0s 34us/step\n",
      "Getting distribution of predictions and covariance matrix...\n",
      "      1 of 20\n",
      "      2 of 20\n",
      "      3 of 20\n",
      "      4 of 20\n",
      "      5 of 20\n",
      "      6 of 20\n",
      "      7 of 20\n",
      "      8 of 20\n",
      "      9 of 20\n",
      "      10 of 20\n",
      "      11 of 20\n",
      "      12 of 20\n",
      "      13 of 20\n",
      "      14 of 20\n",
      "      15 of 20\n",
      "      16 of 20\n",
      "      17 of 20\n",
      "      18 of 20\n",
      "      19 of 20\n",
      "      20 of 20\n",
      "Computing ensemble means...\n",
      "Computing mean squared error...\n",
      "Iteration 9\n",
      "Train on 1752 samples, validate on 354 samples\n",
      "Epoch 1/150\n",
      "1752/1752 [==============================] - 0s 170us/step - loss: 1.5739 - regression_loss: 1.0342 - handedness_loss: 0.5227 - val_loss: 0.7254 - val_regression_loss: 0.3215 - val_handedness_loss: 0.4064\n",
      "Epoch 2/150\n",
      "1752/1752 [==============================] - 0s 78us/step - loss: 0.7788 - regression_loss: 0.3285 - handedness_loss: 0.4483 - val_loss: 0.2199 - val_regression_loss: 0.3413 - val_handedness_loss: -0.1159\n",
      "Epoch 3/150\n",
      "1752/1752 [==============================] - 0s 108us/step - loss: 0.5735 - regression_loss: 0.3146 - handedness_loss: 0.2545 - val_loss: -0.1772 - val_regression_loss: 0.3613 - val_handedness_loss: -0.5536\n",
      "Epoch 4/150\n",
      "1752/1752 [==============================] - 0s 98us/step - loss: 0.2878 - regression_loss: 0.3528 - handedness_loss: -0.0690 - val_loss: -0.8993 - val_regression_loss: 0.3637 - val_handedness_loss: -1.2778\n",
      "Epoch 5/150\n",
      "1752/1752 [==============================] - 0s 138us/step - loss: -0.1667 - regression_loss: 0.4168 - handedness_loss: -0.5688 - val_loss: -2.2662 - val_regression_loss: 0.6644 - val_handedness_loss: -2.9706\n",
      "Evaluating model with testing data...\n",
      "354/354 [==============================] - 0s 31us/step\n",
      "Getting distribution of predictions and covariance matrix...\n",
      "      1 of 20\n",
      "      2 of 20\n",
      "      3 of 20\n",
      "      4 of 20\n",
      "      5 of 20\n",
      "      6 of 20\n",
      "      7 of 20\n",
      "      8 of 20\n",
      "      9 of 20\n",
      "      10 of 20\n",
      "      11 of 20\n",
      "      12 of 20\n",
      "      13 of 20\n",
      "      14 of 20\n",
      "      15 of 20\n",
      "      16 of 20\n",
      "      17 of 20\n",
      "      18 of 20\n",
      "      19 of 20\n",
      "      20 of 20\n",
      "Computing ensemble means...\n",
      "Computing mean squared error...\n",
      "Iteration 10\n",
      "Train on 1892 samples, validate on 384 samples\n",
      "Epoch 1/150\n",
      "1892/1892 [==============================] - 0s 184us/step - loss: 1.3016 - regression_loss: 0.8253 - handedness_loss: 0.4646 - val_loss: 0.3016 - val_regression_loss: 0.2472 - val_handedness_loss: 0.0544\n",
      "Epoch 2/150\n",
      "1892/1892 [==============================] - 0s 86us/step - loss: 0.5112 - regression_loss: 0.2278 - handedness_loss: 0.2806 - val_loss: -0.3172 - val_regression_loss: 0.2353 - val_handedness_loss: -0.5525\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3/150\n",
      "1892/1892 [==============================] - 0s 116us/step - loss: 0.1896 - regression_loss: 0.2331 - handedness_loss: -0.0446 - val_loss: -0.9782 - val_regression_loss: 0.2626 - val_handedness_loss: -1.2407\n",
      "Epoch 4/150\n",
      "1892/1892 [==============================] - 0s 142us/step - loss: -0.5018 - regression_loss: 0.3601 - handedness_loss: -0.8763 - val_loss: -2.9430 - val_regression_loss: 0.7034 - val_handedness_loss: -3.6463\n",
      "Epoch 5/150\n",
      "1892/1892 [==============================] - 0s 141us/step - loss: -2.1488 - regression_loss: 0.7937 - handedness_loss: -2.9866 - val_loss: -7.5431 - val_regression_loss: 1.4848 - val_handedness_loss: -9.0279\n",
      "Epoch 6/150\n",
      "1892/1892 [==============================] - 0s 105us/step - loss: -6.2349 - regression_loss: 1.5887 - handedness_loss: -7.9133 - val_loss: -20.0984 - val_regression_loss: 3.2066 - val_handedness_loss: -23.3050\n",
      "Evaluating model with testing data...\n",
      "384/384 [==============================] - 0s 24us/step\n",
      "Getting distribution of predictions and covariance matrix...\n",
      "      1 of 20\n",
      "      2 of 20\n",
      "      3 of 20\n",
      "      4 of 20\n",
      "      5 of 20\n",
      "      6 of 20\n",
      "      7 of 20\n",
      "      8 of 20\n",
      "      9 of 20\n",
      "      10 of 20\n",
      "      11 of 20\n",
      "      12 of 20\n",
      "      13 of 20\n",
      "      14 of 20\n",
      "      15 of 20\n",
      "      16 of 20\n",
      "      17 of 20\n",
      "      18 "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "  0%|          | 0/20 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "of 20\n",
      "      19 of 20\n",
      "      20 of 20\n",
      "Computing ensemble means...\n",
      "Computing mean squared error...\n",
      "Getting distribution of predictions...\n",
      "      1 of 20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "  5%|▌         | 1/20 [00:29<09:29, 29.99s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      2 of 20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 10%|█         | 2/20 [00:59<08:59, 30.00s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      3 of 20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 15%|█▌        | 3/20 [01:30<08:29, 30.00s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      4 of 20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 20%|██        | 4/20 [02:00<08:00, 30.05s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      5 of 20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 25%|██▌       | 5/20 [02:30<07:30, 30.05s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      6 of 20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 30%|███       | 6/20 [03:00<07:01, 30.09s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      7 of 20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 35%|███▌      | 7/20 [03:30<06:30, 30.05s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      8 of 20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 40%|████      | 8/20 [04:00<06:01, 30.15s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      9 of 20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 45%|████▌     | 9/20 [04:30<05:31, 30.13s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      10 of 20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 50%|█████     | 10/20 [05:01<05:01, 30.16s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      11 of 20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 55%|█████▌    | 11/20 [05:30<04:30, 30.07s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      12 of 20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 60%|██████    | 12/20 [06:00<04:00, 30.06s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      13 of 20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 65%|██████▌   | 13/20 [06:32<03:33, 30.48s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      14 of 20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 70%|███████   | 14/20 [07:03<03:04, 30.76s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      15 of 20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 75%|███████▌  | 15/20 [07:35<02:35, 31.06s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      16 of 20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 80%|████████  | 16/20 [08:07<02:04, 31.19s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      17 of 20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 85%|████████▌ | 17/20 [08:37<01:32, 30.96s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      18 of 20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 90%|█████████ | 18/20 [09:07<01:01, 30.76s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      19 of 20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 95%|█████████▌| 19/20 [09:37<00:30, 30.57s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      20 of 20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "100%|██████████| 20/20 [10:08<00:00, 30.40s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing ensemble predictions...\n",
      "Iteration 11\n",
      "Train on 2032 samples, validate on 414 samples\n",
      "Epoch 1/150\n",
      "2032/2032 [==============================] - 0s 193us/step - loss: 1.4512 - regression_loss: 0.9669 - handedness_loss: 0.4787 - val_loss: 0.6012 - val_regression_loss: 0.2637 - val_handedness_loss: 0.3471\n",
      "Epoch 2/150\n",
      "2032/2032 [==============================] - 0s 111us/step - loss: 0.6109 - regression_loss: 0.2333 - handedness_loss: 0.3772 - val_loss: -0.1990 - val_regression_loss: 0.2453 - val_handedness_loss: -0.4134\n",
      "Epoch 3/150\n",
      "2032/2032 [==============================] - 0s 150us/step - loss: 0.2868 - regression_loss: 0.2444 - handedness_loss: 0.0404 - val_loss: -0.9249 - val_regression_loss: 0.3867 - val_handedness_loss: -1.2643\n",
      "Epoch 4/150\n",
      "2032/2032 [==============================] - 0s 118us/step - loss: -0.1711 - regression_loss: 0.4468 - handedness_loss: -0.6112 - val_loss: -2.1554 - val_regression_loss: 0.6574 - val_handedness_loss: -2.7943\n",
      "Epoch 5/150\n",
      "2032/2032 [==============================] - 0s 151us/step - loss: -1.0538 - regression_loss: 0.6075 - handedness_loss: -1.6673 - val_loss: -5.3253 - val_regression_loss: 1.3966 - val_handedness_loss: -6.8605\n",
      "Epoch 6/150\n",
      "2032/2032 [==============================] - 0s 137us/step - loss: -3.9900 - regression_loss: 1.6051 - handedness_loss: -5.5959 - val_loss: -17.7106 - val_regression_loss: 3.7888 - val_handedness_loss: -23.1119\n",
      "Evaluating model with testing data...\n",
      "414/414 [==============================] - 0s 32us/step\n",
      "Getting distribution of predictions and covariance matrix...\n",
      "      1 of 20\n",
      "      2 of 20\n",
      "      3 of 20\n",
      "      4 of 20\n",
      "      5 of 20\n",
      "      6 of 20\n",
      "      7 of 20\n",
      "      8 of 20\n",
      "      9 of 20\n",
      "      10 of 20\n",
      "      11 of 20\n",
      "      12 of 20\n",
      "      13 of 20\n",
      "      14 of 20\n",
      "      15 of 20\n",
      "      16 of 20\n",
      "      17 of 20\n",
      "      18 of 20\n",
      "      19 of 20\n",
      "      20 of 20\n",
      "Computing ensemble means...\n",
      "Computing mean squared error...\n",
      "Iteration 12\n",
      "Train on 2172 samples, validate on 444 samples\n",
      "Epoch 1/150\n",
      "2172/2172 [==============================] - 0s 180us/step - loss: 0.8398 - regression_loss: 0.4953 - handedness_loss: 0.3441 - val_loss: -0.1542 - val_regression_loss: 0.1998 - val_handedness_loss: -0.3414\n",
      "Epoch 2/150\n",
      "2172/2172 [==============================] - 0s 88us/step - loss: 0.2469 - regression_loss: 0.2297 - handedness_loss: 0.0170 - val_loss: -0.9367 - val_regression_loss: 0.3157 - val_handedness_loss: -1.1743\n",
      "Epoch 3/150\n",
      "2172/2172 [==============================] - 0s 114us/step - loss: -0.4139 - regression_loss: 0.4330 - handedness_loss: -0.8494 - val_loss: -3.0797 - val_regression_loss: 0.6501 - val_handedness_loss: -3.5772\n",
      "Epoch 4/150\n",
      "2172/2172 [==============================] - 0s 119us/step - loss: -1.8236 - regression_loss: 1.1115 - handedness_loss: -2.9377 - val_loss: -7.8755 - val_regression_loss: 2.1949 - val_handedness_loss: -9.5743\n",
      "Epoch 5/150\n",
      "2172/2172 [==============================] - 0s 145us/step - loss: -6.2503 - regression_loss: 2.5030 - handedness_loss: -8.7668 - val_loss: -23.7175 - val_regression_loss: 5.7942 - val_handedness_loss: -28.0514\n",
      "Evaluating model with testing data...\n",
      "444/444 [==============================] - 0s 31us/step\n",
      "Getting distribution of predictions and covariance matrix...\n",
      "      1 of 20\n",
      "      2 of 20\n",
      "      3 of 20\n",
      "      4 of 20\n",
      "      5 of 20\n",
      "      6 of 20\n",
      "      7 of 20\n",
      "      8 of 20\n",
      "      9 of 20\n",
      "      10 of 20\n",
      "      11 of 20\n",
      "      12 of 20\n",
      "      13 of 20\n",
      "      14 of 20\n",
      "      15 of 20\n",
      "      16 of 20\n",
      "      17 of 20\n",
      "      18 of 20\n",
      "      19 of 20\n",
      "      20 of 20\n",
      "Computing ensemble means...\n",
      "Computing mean squared error...\n",
      "Iteration 13\n",
      "Train on 2312 samples, validate on 474 samples\n",
      "Epoch 1/150\n",
      "2312/2312 [==============================] - 0s 181us/step - loss: 1.1871 - regression_loss: 0.8180 - handedness_loss: 0.3238 - val_loss: -0.2045 - val_regression_loss: 0.2170 - val_handedness_loss: -0.3969\n",
      "Epoch 2/150\n",
      "2312/2312 [==============================] - 0s 103us/step - loss: 0.2064 - regression_loss: 0.3380 - handedness_loss: -0.1460 - val_loss: -1.4404 - val_regression_loss: 0.4905 - val_handedness_loss: -1.8587\n",
      "Epoch 3/150\n",
      "2312/2312 [==============================] - 0s 113us/step - loss: -0.3131 - regression_loss: 0.5319 - handedness_loss: -0.6935 - val_loss: -3.1907 - val_regression_loss: 0.7969 - val_handedness_loss: -3.8734\n",
      "Epoch 4/150\n",
      "2312/2312 [==============================] - 0s 97us/step - loss: -1.1041 - regression_loss: 0.8152 - handedness_loss: -2.0438 - val_loss: -6.2439 - val_regression_loss: 2.0190 - val_handedness_loss: -7.9676\n",
      "Epoch 5/150\n",
      "2312/2312 [==============================] - 0s 108us/step - loss: -3.3702 - regression_loss: 1.9256 - handedness_loss: -5.6839 - val_loss: -14.7712 - val_regression_loss: 5.6701 - val_handedness_loss: -19.8314\n",
      "Evaluating model with testing data...\n",
      "474/474 [==============================] - 0s 24us/step\n",
      "Getting distribution of predictions and covariance matrix...\n",
      "      1 of 20\n",
      "      2 of 20\n",
      "      3 of 20\n",
      "      4 of 20\n",
      "      5 of 20\n",
      "      6 of 20\n",
      "      7 of 20\n",
      "      8 of 20\n",
      "      9 of 20\n",
      "      10 of 20\n",
      "      11 of 20\n",
      "      12 of 20\n",
      "      13 of 20\n",
      "      14 of 20\n",
      "      15 of 20\n",
      "      16 of 20\n",
      "      17 of 20\n",
      "      18 of 20\n",
      "      19 of 20\n",
      "      20 of 20\n",
      "Computing ensemble means...\n",
      "Computing mean squared error...\n",
      "Iteration 14\n",
      "Train on 2452 samples, validate on 504 samples\n",
      "Epoch 1/150\n",
      "2452/2452 [==============================] - 0s 173us/step - loss: 0.9769 - regression_loss: 0.5761 - handedness_loss: 0.3590 - val_loss: -0.0966 - val_regression_loss: 0.2869 - val_handedness_loss: -0.3796\n",
      "Epoch 2/150\n",
      "2452/2452 [==============================] - 0s 104us/step - loss: 0.3229 - regression_loss: 0.2793 - handedness_loss: -0.0046 - val_loss: -0.7527 - val_regression_loss: 0.3379 - val_handedness_loss: -1.0814\n",
      "Epoch 3/150\n",
      "2452/2452 [==============================] - 0s 100us/step - loss: -0.1703 - regression_loss: 0.4439 - handedness_loss: -0.5469 - val_loss: -1.8682 - val_regression_loss: 0.7399 - val_handedness_loss: -2.5911\n",
      "Epoch 4/150\n",
      "2452/2452 [==============================] - 0s 83us/step - loss: -0.9608 - regression_loss: 0.8448 - handedness_loss: -1.8606 - val_loss: -4.0827 - val_regression_loss: 1.0835 - val_handedness_loss: -5.1370\n",
      "Epoch 5/150\n",
      "2452/2452 [==============================] - 0s 94us/step - loss: -3.7879 - regression_loss: 1.6014 - handedness_loss: -5.1995 - val_loss: -15.7052 - val_regression_loss: 3.4229 - val_handedness_loss: -19.0152\n",
      "Evaluating model with testing data...\n",
      "504/504 [==============================] - 0s 31us/step\n",
      "Getting distribution of predictions and covariance matrix...\n",
      "      1 of 20\n",
      "      2 of 20\n",
      "      3 of 20\n",
      "      4 of 20\n",
      "      5 of 20\n",
      "      6 of 20\n",
      "      7 of 20\n",
      "      8 of 20\n",
      "      9 of 20\n",
      "      10 of 20\n",
      "      11 of 20\n",
      "      12 of 20\n",
      "      13 of 20\n",
      "      14 of 20\n",
      "      15 of 20\n",
      "      16 of 20\n",
      "      17 of 20\n",
      "      18 of 20\n",
      "      19 of 20\n",
      "      20 of 20\n",
      "Computing ensemble means...\n",
      "Computing mean squared error...\n",
      "Iteration 15\n",
      "Train on 2592 samples, validate on 534 samples\n",
      "Epoch 1/150\n",
      "2592/2592 [==============================] - 0s 148us/step - loss: 1.0274 - regression_loss: 0.7452 - handedness_loss: 0.2529 - val_loss: -0.2413 - val_regression_loss: 0.3302 - val_handedness_loss: -0.5695\n",
      "Epoch 2/150\n",
      "2592/2592 [==============================] - 0s 96us/step - loss: -0.0461 - regression_loss: 0.4356 - handedness_loss: -0.4525 - val_loss: -1.6925 - val_regression_loss: 0.8370 - val_handedness_loss: -2.3921\n",
      "Epoch 3/150\n",
      "2592/2592 [==============================] - 0s 116us/step - loss: -1.3336 - regression_loss: 0.8802 - handedness_loss: -2.2444 - val_loss: -5.1656 - val_regression_loss: 2.5411 - val_handedness_loss: -7.5097\n",
      "Epoch 4/150\n",
      "2592/2592 [==============================] - 0s 109us/step - loss: -5.0079 - regression_loss: 2.7005 - handedness_loss: -7.4119 - val_loss: -17.7660 - val_regression_loss: 6.6586 - val_handedness_loss: -24.8402\n",
      "Epoch 5/150\n",
      "2592/2592 [==============================] - 0s 125us/step - loss: -20.2784 - regression_loss: 6.4602 - handedness_loss: -27.5500 - val_loss: -81.7877 - val_regression_loss: 9.3014 - val_handedness_loss: -87.9337\n",
      "Evaluating model with testing data...\n",
      "534/534 [==============================] - 0s 31us/step\n",
      "Getting distribution of predictions and covariance matrix...\n",
      "      1 of 20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      2 of 20\n",
      "      3 of 20\n",
      "      4 of 20\n",
      "      5 of 20\n",
      "      6 of 20\n",
      "      7 of 20\n",
      "      8 of 20\n",
      "      9 of 20\n",
      "      10 of 20\n",
      "      11 of 20\n",
      "      12 of 20\n",
      "      13 of 20\n",
      "      14 of 20\n",
      "      15 of 20\n",
      "      16 of 20\n",
      "      17 of 20\n",
      "      18 of 20\n",
      "      19 of 20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "  0%|          | 0/20 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      20 of 20\n",
      "Computing ensemble means...\n",
      "Computing mean squared error...\n",
      "Getting distribution of predictions...\n",
      "      1 of 20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "  5%|▌         | 1/20 [00:29<09:29, 29.97s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      2 of 20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 10%|█         | 2/20 [01:00<09:00, 30.05s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      3 of 20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 15%|█▌        | 3/20 [01:30<08:31, 30.08s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      4 of 20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 20%|██        | 4/20 [02:00<08:01, 30.12s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      5 of 20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 25%|██▌       | 5/20 [02:30<07:31, 30.10s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      6 of 20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 30%|███       | 6/20 [03:01<07:04, 30.32s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      7 of 20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 35%|███▌      | 7/20 [03:31<06:32, 30.18s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      8 of 20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 40%|████      | 8/20 [04:01<06:02, 30.20s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      9 of 20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 45%|████▌     | 9/20 [04:31<05:32, 30.22s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      10 of 20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 50%|█████     | 10/20 [05:01<05:01, 30.14s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      11 of 20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 55%|█████▌    | 11/20 [05:31<04:30, 30.03s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      12 of 20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 60%|██████    | 12/20 [06:01<04:00, 30.07s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      13 of 20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 65%|██████▌   | 13/20 [06:31<03:30, 30.10s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      14 of 20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 70%|███████   | 14/20 [07:01<03:00, 30.06s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      15 of 20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 75%|███████▌  | 15/20 [07:31<02:30, 30.01s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      16 of 20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 80%|████████  | 16/20 [08:01<02:00, 30.02s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      17 of 20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 85%|████████▌ | 17/20 [08:31<01:30, 30.07s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      18 of 20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 90%|█████████ | 18/20 [09:02<01:00, 30.09s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      19 of 20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 95%|█████████▌| 19/20 [09:31<00:29, 29.95s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      20 of 20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "100%|██████████| 20/20 [10:02<00:00, 30.11s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing ensemble predictions...\n",
      "Iteration 16\n",
      "Train on 2732 samples, validate on 564 samples\n",
      "Epoch 1/150\n",
      "2732/2732 [==============================] - 0s 180us/step - loss: 0.7665 - regression_loss: 0.6651 - handedness_loss: 0.0419 - val_loss: -0.9353 - val_regression_loss: 0.5422 - val_handedness_loss: -1.5605\n",
      "Epoch 2/150\n",
      "2732/2732 [==============================] - 0s 140us/step - loss: -0.5454 - regression_loss: 0.7028 - handedness_loss: -1.2617 - val_loss: -3.2534 - val_regression_loss: 1.3833 - val_handedness_loss: -4.8552\n",
      "Epoch 3/150\n",
      "2732/2732 [==============================] - 0s 145us/step - loss: -2.4186 - regression_loss: 1.7075 - handedness_loss: -4.2008 - val_loss: -8.2700 - val_regression_loss: 3.2075 - val_handedness_loss: -11.8754\n",
      "Epoch 4/150\n",
      "2732/2732 [==============================] - 0s 145us/step - loss: -8.4078 - regression_loss: 4.3542 - handedness_loss: -12.6017 - val_loss: -29.8999 - val_regression_loss: 9.9047 - val_handedness_loss: -40.7860\n",
      "Epoch 5/150\n",
      "2732/2732 [==============================] - 0s 138us/step - loss: -36.3130 - regression_loss: 12.0578 - handedness_loss: -51.4564 - val_loss: -147.7317 - val_regression_loss: 28.8768 - val_handedness_loss: -183.9739\n",
      "Evaluating model with testing data...\n",
      "564/564 [==============================] - 0s 27us/step\n",
      "Getting distribution of predictions and covariance matrix...\n",
      "      1 of 20\n",
      "      2 of 20\n",
      "      3 of 20\n",
      "      4 of 20\n",
      "      5 of 20\n",
      "      6 of 20\n",
      "      7 of 20\n",
      "      8 of 20\n",
      "      9 of 20\n",
      "      10 of 20\n",
      "      11 of 20\n",
      "      12 of 20\n",
      "      13 of 20\n",
      "      14 of 20\n",
      "      15 of 20\n",
      "      16 of 20\n",
      "      17 of 20\n",
      "      18 of 20\n",
      "      19 of 20\n",
      "      20 of 20\n",
      "Computing ensemble means...\n",
      "Computing mean squared error...\n",
      "Iteration 17\n",
      "Train on 2872 samples, validate on 594 samples\n",
      "Epoch 1/150\n",
      "2872/2872 [==============================] - 0s 166us/step - loss: 0.2120 - regression_loss: 0.3728 - handedness_loss: -0.1772 - val_loss: -2.5796 - val_regression_loss: 0.9694 - val_handedness_loss: -3.4609\n",
      "Epoch 2/150\n",
      "2872/2872 [==============================] - 0s 118us/step - loss: -2.2747 - regression_loss: 1.5067 - handedness_loss: -3.7213 - val_loss: -11.1704 - val_regression_loss: 3.7713 - val_handedness_loss: -14.7720\n",
      "Epoch 3/150\n",
      "2872/2872 [==============================] - 0s 143us/step - loss: -11.6540 - regression_loss: 5.4314 - handedness_loss: -17.3097 - val_loss: -44.2667 - val_regression_loss: 12.6061 - val_handedness_loss: -55.8635\n",
      "Epoch 4/150\n",
      "2872/2872 [==============================] - 0s 143us/step - loss: -59.1859 - regression_loss: 12.5504 - handedness_loss: -72.1516 - val_loss: -266.4712 - val_regression_loss: 17.2669 - val_handedness_loss: -278.7531\n",
      "Epoch 5/150\n",
      "2872/2872 [==============================] - 0s 144us/step - loss: -317.1944 - regression_loss: 18.6499 - handedness_loss: -357.5226 - val_loss: -1466.4891 - val_regression_loss: 25.3436 - val_handedness_loss: -1465.5657\n",
      "Evaluating model with testing data...\n",
      "594/594 [==============================] - 0s 28us/step\n",
      "Getting distribution of predictions and covariance matrix...\n",
      "      1 of 20\n",
      "      2 of 20\n",
      "      3 of 20\n",
      "      4 of 20\n",
      "      5 of 20\n",
      "      6 of 20\n",
      "      7 of 20\n",
      "      8 of 20\n",
      "      9 of 20\n",
      "      10 of 20\n",
      "      11 of 20\n",
      "      12 of 20\n",
      "      13 of 20\n",
      "      14 of 20\n",
      "      15 of 20\n",
      "      16 of 20\n",
      "      17 of 20\n",
      "      18 of 20\n",
      "      19 of 20\n",
      "      20 of 20\n",
      "Computing ensemble means...\n",
      "Computing mean squared error...\n",
      "Iteration 18\n",
      "Train on 3012 samples, validate on 624 samples\n",
      "Epoch 1/150\n",
      "3012/3012 [==============================] - 0s 165us/step - loss: 0.4399 - regression_loss: 0.3989 - handedness_loss: 0.0327 - val_loss: -0.6147 - val_regression_loss: 0.4508 - val_handedness_loss: -1.0310\n",
      "Epoch 2/150\n",
      "3012/3012 [==============================] - 0s 108us/step - loss: -0.5063 - regression_loss: 0.6088 - handedness_loss: -1.1218 - val_loss: -2.4695 - val_regression_loss: 1.2636 - val_handedness_loss: -3.6584\n",
      "Epoch 3/150\n",
      "3012/3012 [==============================] - 0s 119us/step - loss: -3.0462 - regression_loss: 2.1216 - handedness_loss: -5.3364 - val_loss: -8.5811 - val_regression_loss: 5.6941 - val_handedness_loss: -14.0322\n",
      "Epoch 4/150\n",
      "3012/3012 [==============================] - 0s 137us/step - loss: -10.8214 - regression_loss: 5.8583 - handedness_loss: -16.8584 - val_loss: -32.4213 - val_regression_loss: 12.2099 - val_handedness_loss: -44.1152\n",
      "Epoch 5/150\n",
      "3012/3012 [==============================] - 0s 145us/step - loss: -50.8229 - regression_loss: 15.0134 - handedness_loss: -65.2820 - val_loss: -159.1966 - val_regression_loss: 32.3289 - val_handedness_loss: -187.8372\n",
      "Evaluating model with testing data...\n",
      "624/624 [==============================] - 0s 30us/step\n",
      "Getting distribution of predictions and covariance matrix...\n",
      "      1 of 20\n",
      "      2 of 20\n",
      "      3 of 20\n",
      "      4 of 20\n",
      "      5 of 20\n",
      "      6 of 20\n",
      "      7 of 20\n",
      "      8 of 20\n",
      "      9 of 20\n",
      "      10 of 20\n",
      "      11 of 20\n",
      "      12 of 20\n",
      "      13 of 20\n",
      "      14 of 20\n",
      "      15 of 20\n",
      "      16 of 20\n",
      "      17 of 20\n",
      "      18 of 20\n",
      "      19 of 20\n",
      "      20 of 20\n",
      "Computing ensemble means...\n",
      "Computing mean squared error...\n",
      "Iteration 19\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/narock/.local/lib/python3.6/site-packages/ipykernel_launcher.py:12: RuntimeWarning: overflow encountered in exp\n",
      "  if sys.path[0] == '':\n",
      "/home/narock/.local/lib/python3.6/site-packages/ipykernel_launcher.py:14: RuntimeWarning: invalid value encountered in true_divide\n",
      "  \n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "probabilities contain NaN",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-404-36545eda896e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     43\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     44\u001b[0m     \u001b[0;31m# get the next set of data - trace\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 45\u001b[0;31m     \u001b[0mbatch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnextBatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0myTest\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrace\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatchSize\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mp\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mphiStepSize\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mthetaStepSize\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my0RStepSize\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     46\u001b[0m     \u001b[0mnewX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnewY\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetMoreFluxRopes\u001b[0m\u001b[0;34m(\u001b[0m \u001b[0mbatch\u001b[0m \u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     47\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-369-37f683c0a456>\u001b[0m in \u001b[0;36mnextBatch\u001b[0;34m(yTest, aquisition, batchSize, p, phiStepSize, thetaStepSize, y0RStepSize)\u001b[0m\n\u001b[1;32m     34\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     35\u001b[0m             \u001b[0mlst\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marange\u001b[0m\u001b[0;34m(\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msigma\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 36\u001b[0;31m             \u001b[0mindex\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchoice\u001b[0m\u001b[0;34m(\u001b[0m \u001b[0mlst\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreplace\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mp\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msigma\u001b[0m \u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     37\u001b[0m             \u001b[0mphi\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0munscale\u001b[0m\u001b[0;34m(\u001b[0m \u001b[0myTest\u001b[0m\u001b[0;34m[\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m \u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0.\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m360.\u001b[0m \u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     38\u001b[0m             \u001b[0mtheta\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0munscale\u001b[0m\u001b[0;34m(\u001b[0m \u001b[0myTest\u001b[0m\u001b[0;34m[\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m \u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m90.\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m90.\u001b[0m \u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mmtrand.pyx\u001b[0m in \u001b[0;36mmtrand.RandomState.choice\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: probabilities contain NaN"
     ]
    }
   ],
   "source": [
    "# how well does the first go generalize?\n",
    "loss, ensemble_loss = modelPredictionsGeneral(mc_model, testFiles)\n",
    "print(\"MSE: {:.3}\".format(loss))\n",
    "print(\"MC-ensemble MSE: {:.3}\".format(ensemble_loss))\n",
    "\n",
    "# keep track of the losses in our three lists\n",
    "mses.append(loss)\n",
    "ensemble_mses.append(ensemble_loss)\n",
    "\n",
    "# number of iterations\n",
    "n = 200\n",
    "\n",
    "# when to check how well we generalize\n",
    "check = np.arange(0,n,5)\n",
    "check = np.append(check,n)\n",
    "\n",
    "# exploration vs. exploitation probability\n",
    "x = np.linspace(0,1,num=n)\n",
    "#p = np.exp(-2.75*x)\n",
    "p = np.exp(-1.*x)\n",
    "\n",
    "for i in range(n):\n",
    "\n",
    "    print(\"Iteration\", i)\n",
    "    \n",
    "    # how many instances to get in our next batch\n",
    "    batchSize = 100\n",
    "    phiStepSize = 1.\n",
    "    thetaStepSize = 1.\n",
    "    y0RStepSize = 1.\n",
    "    \n",
    "    #####################\n",
    "    ### Trace\n",
    "    #####################\n",
    "        \n",
    "    startTime = time.time()\n",
    "    \n",
    "    # clear the previous model and session\n",
    "    keras.backend.clear_session()\n",
    "    gc.collect()\n",
    "    del h_mc\n",
    "    del mc_model\n",
    "    \n",
    "    # get the next set of data - trace\n",
    "    batch = nextBatch(yTest, trace, batchSize, p[i], phiStepSize, thetaStepSize, y0RStepSize)\n",
    "    newX, newY = getMoreFluxRopes( batch )\n",
    "    \n",
    "    # train the next batch\n",
    "    mc_model = get_model(act=\"relu\")\n",
    "    xTrain, yTrain, xTest, yTest, xVal, yVal = trainTestValidationSplit( dataX,dataY )\n",
    "    xTrain = np.concatenate( (xTrain, newX) )\n",
    "    yTrain = np.concatenate( (yTrain, newY) )\n",
    "    #h_mc = mc_model.fit(xTrain, yTrain, \n",
    "    #                epochs=150, batch_size=128, verbose=1, \n",
    "    #                callbacks=callbacks_list,\n",
    "    #                validation_data=(xVal, yVal))\n",
    "    h_mc = mc_model.fit(xTrain, {\"regression\": yTrain[:,0:3], \"handedness\": yTrain[:,3]}, \n",
    "                     epochs=150, batch_size=128, verbose=1, \n",
    "                     callbacks=callbacks_list,\n",
    "                     validation_data=(xVal,{\"regression\": yVal[:,0:3], \"handedness\": yVal[:,3]}) )\n",
    "    \n",
    "    \n",
    "    dataX = np.concatenate( (xTrain, xTest, xVal, newX) )\n",
    "    dataY = np.concatenate( (yTrain, yTest, yVal, newY) )\n",
    "    \n",
    "    stopTime = time.time()\n",
    "\n",
    "    duration = stopTime-startTime\n",
    "    training_times.append(duration)\n",
    "    \n",
    "    # how well did we do?\n",
    "    duration, loss, ensemble_loss, mc_ensemble_pred, trace, det = modelPredictionsActiveLearning(mc_model, \n",
    "                                                                                                 xTest, \n",
    "                                                                                                 yTest,\n",
    "                                                                                                 batch_size=3072)\n",
    "    temp1.append(loss)\n",
    "    temp2.append(ensemble_loss)\n",
    "    training_times.append(duration)\n",
    "    \n",
    "    # are we generalizing better?\n",
    "    if ( i in check ):\n",
    "        loss, ensemble_loss = modelPredictionsGeneral(mc_model, testFiles, batch_size=64)\n",
    "        mses.append(loss)\n",
    "        ensemble_mses.append(ensemble_loss)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 255,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# write results to a file\n",
    "xa = np.arange(41)\n",
    "plt.plot(xa*5, ensemble_mses, color='red')\n",
    "plt.plot(xa*5, mses)\n",
    "plt.ylabel('MSE')\n",
    "plt.xlabel('Iteration')\n",
    "plt.title('Trace')\n",
    "\n",
    "file = open(\"/home/narock/data/fluxropes_results/trace_100_-1.txt\", \"w\")\n",
    "for i in range( len(mses) ):\n",
    "    line = str(mses[i]) + ',' + str(ensemble_mses[i]) + '\\n'\n",
    "    file.write(line)\n",
    "file.close()\n",
    "\n",
    "file = open(\"/home/narock/data/fluxropes_results/trace_times_100_-1.txt\", \"w\")\n",
    "for i in range( len(training_times) ):\n",
    "    line =  str(training_times[i]) + '\\n'\n",
    "    file.write(line)\n",
    "file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 256,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11146.843316078186\n",
      "0.0748917736970528\n"
     ]
    }
   ],
   "source": [
    "print( np.sum(training_times) )\n",
    "print( ensemble_mses[-1] )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 272,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "40560"
      ]
     },
     "execution_count": 272,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(dataX)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 276,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating model with testing data...\n",
      "40560/40560 [==============================] - 1s 20us/step\n",
      "Getting distribution of predictions and covariance matrix...\n",
      "      1 of 20\n",
      "      2 of 20\n",
      "      3 of 20\n",
      "      4 of 20\n",
      "      5 of 20\n",
      "      6 of 20\n",
      "      7 of 20\n",
      "      8 of 20\n",
      "      9 of 20\n",
      "      10 of 20\n",
      "      11 of 20\n",
      "      12 of 20\n",
      "      13 of 20\n",
      "      14 of 20\n",
      "      15 of 20\n",
      "      16 of 20\n",
      "      17 of 20\n",
      "      18 of 20\n",
      "      19 of 20\n",
      "      20 of 20\n"
     ]
    }
   ],
   "source": [
    "T = 20\n",
    "d = 4\n",
    "n = len(dataX)\n",
    "\n",
    "mc_predictions = np.zeros(shape=(T,n,d))\n",
    "mc_ensemble_pred = np.zeros(shape=(n,d))\n",
    " \n",
    "trace = []\n",
    "determinant = []\n",
    "    \n",
    "print(\"Evaluating model with testing data...\")\n",
    "loss = mc_model.evaluate(dataX, dataY, batch_size=3072, verbose=1)\n",
    "    \n",
    "count = 1\n",
    "print(\"Getting distribution of predictions and covariance matrix...\")\n",
    "for i in range(T):\n",
    "    print(\"     \",count,\"of\",T)\n",
    "    predictions = mc_model.predict(dataX, batch_size=3072)\n",
    "    mc_predictions[i,:,:] = predictions\n",
    "    count += 1\n",
    "\n",
    "phiVar = []\n",
    "thetaVar = []\n",
    "y0RVar = []\n",
    "hVar = []\n",
    "for i in range(n):\n",
    "    x = np.vstack( (mc_predictions[:,i,0],mc_predictions[:,i,1],mc_predictions[:,i,2],mc_predictions[:,i,3]) )\n",
    "    c = np.cov( x )\n",
    "    var = np.diagonal(c)\n",
    "    phiVar.append(var[0])\n",
    "    thetaVar.append(var[1])\n",
    "    y0RVar.append(var[2])\n",
    "    hVar.append(var[3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 282,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([1.4798e+04, 1.5234e+04, 6.6950e+03, 2.6240e+03, 8.7400e+02,\n",
       "        2.6200e+02, 5.3000e+01, 1.1000e+01, 8.0000e+00, 1.0000e+00]),\n",
       " array([1.28218484e-03, 2.16675395e+00, 4.33222571e+00, 6.49769747e+00,\n",
       "        8.66316924e+00, 1.08286410e+01, 1.29941128e+01, 1.51595845e+01,\n",
       "        1.73250563e+01, 1.94905280e+01, 2.16559998e+01]),\n",
       " <a list of 10 Patch objects>)"
      ]
     },
     "execution_count": 282,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.hist(unscaleArray(phiVar,0,360))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 279,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([8.8510e+03, 1.8568e+04, 9.6740e+03, 2.6660e+03, 6.1900e+02,\n",
       "        1.3900e+02, 2.9000e+01, 1.0000e+01, 1.0000e+00, 3.0000e+00]),\n",
       " array([-89.99978699, -88.08137711, -86.16296723, -84.24455735,\n",
       "        -82.32614747, -80.40773759, -78.48932771, -76.57091783,\n",
       "        -74.65250795, -72.73409807, -70.81568819]),\n",
       " <a list of 10 Patch objects>)"
      ]
     },
     "execution_count": 279,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.hist(unscaleArray(thetaVar,-90,90))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 280,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([1.1448e+04, 1.5268e+04, 7.5000e+03, 3.4910e+03, 1.7510e+03,\n",
       "        7.2000e+02, 2.6600e+02, 9.3000e+01, 2.0000e+01, 3.0000e+00]),\n",
       " array([-99.99998241, -99.98170768, -99.96343295, -99.94515822,\n",
       "        -99.92688349, -99.90860876, -99.89033403, -99.87205929,\n",
       "        -99.85378456, -99.83550983, -99.8172351 ]),\n",
       " <a list of 10 Patch objects>)"
      ]
     },
     "execution_count": 280,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.hist(unscaleArray(y0RVar,-100,100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 281,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([4.3300e+03, 1.3869e+04, 1.3781e+04, 6.2700e+03, 1.7980e+03,\n",
       "        3.9800e+02, 9.1000e+01, 1.5000e+01, 7.0000e+00, 1.0000e+00]),\n",
       " array([-0.99964149, -0.84435841, -0.68907532, -0.53379224, -0.37850915,\n",
       "        -0.22322606, -0.06794298,  0.08734011,  0.24262319,  0.39790628,\n",
       "         0.55318936]),\n",
       " <a list of 10 Patch objects>)"
      ]
     },
     "execution_count": 281,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.hist(unscaleArray(hVar,-1,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 259,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7fe614264e80>]"
      ]
     },
     "execution_count": 259,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(temp1)\n",
    "plt.plot(temp2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 269,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7fe5c40b7f28>]"
      ]
     },
     "execution_count": 269,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import scipy.signal\n",
    "plt.plot(temp2, color='orange')\n",
    "yhat = scipy.signal.savgol_filter(temp2, 11, 3)\n",
    "plt.plot(yhat)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Determinant"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|          | 0/20 [00:00<?, ?it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Getting distribution of predictions...\n",
      "      1 of 20\n",
      "1600/1600 [==============================] - 0s 31us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  5%|▌         | 1/20 [00:17<05:38, 17.81s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      2 of 20\n",
      "1600/1600 [==============================] - 0s 17us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 10%|█         | 2/20 [00:35<05:19, 17.74s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      3 of 20\n",
      "1600/1600 [==============================] - 0s 19us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 15%|█▌        | 3/20 [00:53<05:03, 17.84s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      4 of 20\n",
      "1600/1600 [==============================] - 0s 18us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 20%|██        | 4/20 [01:11<04:48, 18.02s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      5 of 20\n",
      "1600/1600 [==============================] - 0s 19us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 25%|██▌       | 5/20 [01:30<04:32, 18.16s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      6 of 20\n",
      "1600/1600 [==============================] - 0s 19us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 30%|███       | 6/20 [01:49<04:16, 18.30s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      7 of 20\n",
      "1600/1600 [==============================] - 0s 18us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 35%|███▌      | 7/20 [02:06<03:55, 18.15s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      8 of 20\n",
      "1600/1600 [==============================] - 0s 19us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 40%|████      | 8/20 [02:24<03:36, 18.03s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      9 of 20\n",
      "1600/1600 [==============================] - 0s 19us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 45%|████▌     | 9/20 [02:42<03:17, 17.96s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      10 of 20\n",
      "1600/1600 [==============================] - 0s 19us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 50%|█████     | 10/20 [03:00<02:58, 17.87s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      11 of 20\n",
      "1600/1600 [==============================] - 0s 19us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 55%|█████▌    | 11/20 [03:17<02:40, 17.80s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      12 of 20\n",
      "1600/1600 [==============================] - 0s 18us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 60%|██████    | 12/20 [03:35<02:22, 17.79s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      13 of 20\n",
      "1600/1600 [==============================] - 0s 19us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 65%|██████▌   | 13/20 [03:53<02:04, 17.76s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      14 of 20\n",
      "1600/1600 [==============================] - 0s 19us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 70%|███████   | 14/20 [04:10<01:46, 17.75s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      15 of 20\n",
      "1600/1600 [==============================] - 0s 19us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 75%|███████▌  | 15/20 [04:28<01:28, 17.80s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      16 of 20\n",
      "1600/1600 [==============================] - 0s 19us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 80%|████████  | 16/20 [04:46<01:11, 17.80s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      17 of 20\n",
      "1600/1600 [==============================] - 0s 19us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 85%|████████▌ | 17/20 [05:04<00:53, 17.78s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      18 of 20\n",
      "1600/1600 [==============================] - 0s 18us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 90%|█████████ | 18/20 [05:21<00:35, 17.75s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      19 of 20\n",
      "1600/1600 [==============================] - 0s 19us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 95%|█████████▌| 19/20 [05:39<00:17, 17.73s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      20 of 20\n",
      "1600/1600 [==============================] - 0s 18us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 20/20 [05:57<00:00, 17.87s/it]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing ensemble predictions...\n",
      "MSE: 0.295\n",
      "MC-ensemble MSE: 0.246\n",
      "Iteration 0\n",
      "Train on 492 samples, validate on 84 samples\n",
      "Epoch 1/150\n",
      "492/492 [==============================] - 0s 331us/step - loss: 1.7487 - val_loss: 0.4642\n",
      "Epoch 2/150\n",
      "492/492 [==============================] - 0s 64us/step - loss: 0.4685 - val_loss: 0.3913\n",
      "Epoch 3/150\n",
      "492/492 [==============================] - 0s 68us/step - loss: 0.4605 - val_loss: 0.3831\n",
      "Epoch 4/150\n",
      "492/492 [==============================] - 0s 76us/step - loss: 0.4440 - val_loss: 0.3836\n",
      "Epoch 5/150\n",
      "492/492 [==============================] - 0s 102us/step - loss: 0.4358 - val_loss: 0.3815\n",
      "Epoch 6/150\n",
      "492/492 [==============================] - 0s 118us/step - loss: 0.4225 - val_loss: 0.3666\n",
      "Epoch 7/150\n",
      "492/492 [==============================] - 0s 111us/step - loss: 0.4113 - val_loss: 0.3660\n",
      "Epoch 8/150\n",
      "492/492 [==============================] - 0s 114us/step - loss: 0.4037 - val_loss: 0.3627\n",
      "Epoch 9/150\n",
      "492/492 [==============================] - 0s 113us/step - loss: 0.3963 - val_loss: 0.3662\n",
      "Epoch 10/150\n",
      "492/492 [==============================] - 0s 112us/step - loss: 0.3845 - val_loss: 0.3543\n",
      "Epoch 11/150\n",
      "492/492 [==============================] - 0s 112us/step - loss: 0.3819 - val_loss: 0.3591\n",
      "Epoch 12/150\n",
      "492/492 [==============================] - 0s 92us/step - loss: 0.3637 - val_loss: 0.3230\n",
      "Epoch 13/150\n",
      "492/492 [==============================] - 0s 110us/step - loss: 0.3416 - val_loss: 0.3411\n",
      "Epoch 14/150\n",
      "492/492 [==============================] - 0s 111us/step - loss: 0.3473 - val_loss: 0.3078\n",
      "Epoch 15/150\n",
      "492/492 [==============================] - 0s 110us/step - loss: 0.3339 - val_loss: 0.3145\n",
      "Epoch 16/150\n",
      "492/492 [==============================] - 0s 109us/step - loss: 0.3226 - val_loss: 0.3237\n",
      "Epoch 17/150\n",
      "492/492 [==============================] - 0s 111us/step - loss: 0.3237 - val_loss: 0.3396\n",
      "Epoch 18/150\n",
      "492/492 [==============================] - 0s 108us/step - loss: 0.3019 - val_loss: 0.3082\n",
      "Evaluating model with testing data...\n",
      "84/84 [==============================] - 0s 59us/step\n",
      "Getting distribution of predictions and covariance matrix...\n",
      "      1 of 20\n",
      "      2 of 20\n",
      "      3 of 20\n",
      "      4 of 20\n",
      "      5 of 20\n",
      "      6 of 20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|          | 0/20 [00:00<?, ?it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      7 of 20\n",
      "      8 of 20\n",
      "      9 of 20\n",
      "      10 of 20\n",
      "      11 of 20\n",
      "      12 of 20\n",
      "      13 of 20\n",
      "      14 of 20\n",
      "      15 of 20\n",
      "      16 of 20\n",
      "      17 of 20\n",
      "      18 of 20\n",
      "      19 of 20\n",
      "      20 of 20\n",
      "Computing ensemble means...\n",
      "Computing mean squared error...\n",
      "Getting distribution of predictions...\n",
      "      1 of 20\n",
      "1600/1600 [==============================] - 0s 27us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  5%|▌         | 1/20 [00:29<09:20, 29.52s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      2 of 20\n",
      "1600/1600 [==============================] - 0s 29us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 10%|█         | 2/20 [00:59<08:52, 29.60s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      3 of 20\n",
      "1600/1600 [==============================] - 0s 29us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 15%|█▌        | 3/20 [01:28<08:21, 29.53s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      4 of 20\n",
      "1600/1600 [==============================] - 0s 33us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 20%|██        | 4/20 [01:58<07:52, 29.56s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      5 of 20\n",
      "1600/1600 [==============================] - 0s 29us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 25%|██▌       | 5/20 [02:27<07:22, 29.49s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      6 of 20\n",
      "1600/1600 [==============================] - 0s 30us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 30%|███       | 6/20 [02:56<06:51, 29.41s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      7 of 20\n",
      "1600/1600 [==============================] - 0s 30us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 35%|███▌      | 7/20 [03:26<06:24, 29.56s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      8 of 20\n",
      "1600/1600 [==============================] - 0s 29us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 40%|████      | 8/20 [03:56<05:54, 29.53s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      9 of 20\n",
      "1600/1600 [==============================] - 0s 29us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 45%|████▌     | 9/20 [04:26<05:25, 29.61s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      10 of 20\n",
      "1600/1600 [==============================] - 0s 29us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 50%|█████     | 10/20 [04:55<04:56, 29.63s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      11 of 20\n",
      "1600/1600 [==============================] - 0s 28us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 55%|█████▌    | 11/20 [05:25<04:26, 29.59s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      12 of 20\n",
      "1600/1600 [==============================] - 0s 30us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 60%|██████    | 12/20 [05:54<03:56, 29.59s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      13 of 20\n",
      "1600/1600 [==============================] - 0s 28us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 65%|██████▌   | 13/20 [06:24<03:27, 29.58s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      14 of 20\n",
      "1600/1600 [==============================] - 0s 29us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 70%|███████   | 14/20 [06:53<02:57, 29.52s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      15 of 20\n",
      "1600/1600 [==============================] - 0s 29us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 75%|███████▌  | 15/20 [07:23<02:27, 29.59s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      16 of 20\n",
      "1600/1600 [==============================] - 0s 28us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 80%|████████  | 16/20 [07:53<01:58, 29.64s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      17 of 20\n",
      "1600/1600 [==============================] - 0s 29us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 85%|████████▌ | 17/20 [08:22<01:28, 29.65s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      18 of 20\n",
      "1600/1600 [==============================] - 0s 29us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 90%|█████████ | 18/20 [08:52<00:59, 29.60s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      19 of 20\n",
      "1600/1600 [==============================] - 0s 29us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 95%|█████████▌| 19/20 [09:22<00:29, 29.67s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      20 of 20\n",
      "1600/1600 [==============================] - 0s 30us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 20/20 [09:51<00:00, 29.59s/it]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing ensemble predictions...\n",
      "Iteration 1\n",
      "Train on 632 samples, validate on 114 samples\n",
      "Epoch 1/150\n",
      "632/632 [==============================] - 0s 273us/step - loss: 1.5823 - val_loss: 0.4923\n",
      "Epoch 2/150\n",
      "632/632 [==============================] - 0s 66us/step - loss: 0.4412 - val_loss: 0.4422\n",
      "Epoch 3/150\n",
      "632/632 [==============================] - 0s 78us/step - loss: 0.3901 - val_loss: 0.4145\n",
      "Epoch 4/150\n",
      "632/632 [==============================] - 0s 120us/step - loss: 0.3627 - val_loss: 0.3941\n",
      "Epoch 5/150\n",
      "632/632 [==============================] - 0s 117us/step - loss: 0.3546 - val_loss: 0.3525\n",
      "Epoch 6/150\n",
      "632/632 [==============================] - 0s 119us/step - loss: 0.3377 - val_loss: 0.3560\n",
      "Epoch 7/150\n",
      "632/632 [==============================] - 0s 117us/step - loss: 0.3155 - val_loss: 0.3389\n",
      "Epoch 8/150\n",
      "632/632 [==============================] - 0s 116us/step - loss: 0.3158 - val_loss: 0.3088\n",
      "Epoch 9/150\n",
      "632/632 [==============================] - 0s 117us/step - loss: 0.3039 - val_loss: 0.3217\n",
      "Epoch 10/150\n",
      "632/632 [==============================] - 0s 115us/step - loss: 0.2966 - val_loss: 0.2916\n",
      "Epoch 11/150\n",
      "632/632 [==============================] - 0s 116us/step - loss: 0.2789 - val_loss: 0.2917\n",
      "Epoch 12/150\n",
      "632/632 [==============================] - 0s 116us/step - loss: 0.2671 - val_loss: 0.2946\n",
      "Epoch 13/150\n",
      "632/632 [==============================] - 0s 117us/step - loss: 0.2601 - val_loss: 0.2888\n",
      "Epoch 14/150\n",
      "632/632 [==============================] - 0s 116us/step - loss: 0.2669 - val_loss: 0.2628\n",
      "Epoch 15/150\n",
      "632/632 [==============================] - 0s 108us/step - loss: 0.2560 - val_loss: 0.2644\n",
      "Epoch 16/150\n",
      "632/632 [==============================] - 0s 115us/step - loss: 0.2516 - val_loss: 0.2655\n",
      "Epoch 17/150\n",
      "632/632 [==============================] - 0s 117us/step - loss: 0.2505 - val_loss: 0.2638\n",
      "Epoch 18/150\n",
      "632/632 [==============================] - 0s 116us/step - loss: 0.2333 - val_loss: 0.2543\n",
      "Epoch 19/150\n",
      "632/632 [==============================] - 0s 117us/step - loss: 0.2372 - val_loss: 0.2710\n",
      "Epoch 20/150\n",
      "632/632 [==============================] - 0s 105us/step - loss: 0.2242 - val_loss: 0.2365\n",
      "Epoch 21/150\n",
      "632/632 [==============================] - 0s 81us/step - loss: 0.2271 - val_loss: 0.2371\n",
      "Epoch 22/150\n",
      "632/632 [==============================] - 0s 110us/step - loss: 0.2207 - val_loss: 0.2445\n",
      "Epoch 23/150\n",
      "632/632 [==============================] - 0s 108us/step - loss: 0.2224 - val_loss: 0.2133\n",
      "Epoch 24/150\n",
      "632/632 [==============================] - 0s 101us/step - loss: 0.2175 - val_loss: 0.2122\n",
      "Epoch 25/150\n",
      "632/632 [==============================] - 0s 116us/step - loss: 0.2202 - val_loss: 0.2270\n",
      "Epoch 26/150\n",
      "632/632 [==============================] - 0s 102us/step - loss: 0.2162 - val_loss: 0.2097\n",
      "Epoch 27/150\n",
      "632/632 [==============================] - 0s 83us/step - loss: 0.2134 - val_loss: 0.2036\n",
      "Epoch 28/150\n",
      "632/632 [==============================] - 0s 82us/step - loss: 0.2152 - val_loss: 0.2007\n",
      "Epoch 29/150\n",
      "632/632 [==============================] - 0s 104us/step - loss: 0.2156 - val_loss: 0.1999\n",
      "Epoch 30/150\n",
      "632/632 [==============================] - 0s 104us/step - loss: 0.2011 - val_loss: 0.1944\n",
      "Epoch 31/150\n",
      "632/632 [==============================] - 0s 111us/step - loss: 0.1978 - val_loss: 0.1857\n",
      "Epoch 32/150\n",
      "632/632 [==============================] - 0s 95us/step - loss: 0.1956 - val_loss: 0.2076\n",
      "Epoch 33/150\n",
      "632/632 [==============================] - 0s 97us/step - loss: 0.1941 - val_loss: 0.1792\n",
      "Epoch 34/150\n",
      "632/632 [==============================] - 0s 116us/step - loss: 0.2022 - val_loss: 0.2226\n",
      "Epoch 35/150\n",
      "632/632 [==============================] - 0s 107us/step - loss: 0.1951 - val_loss: 0.2100\n",
      "Epoch 36/150\n",
      "632/632 [==============================] - 0s 109us/step - loss: 0.1899 - val_loss: 0.1919\n",
      "Epoch 37/150\n",
      "632/632 [==============================] - 0s 109us/step - loss: 0.1830 - val_loss: 0.1824\n",
      "Evaluating model with testing data...\n",
      "114/114 [==============================] - 0s 50us/step\n",
      "Getting distribution of predictions and covariance matrix...\n",
      "      1 of 20\n",
      "      2 of 20\n",
      "      3 of 20\n",
      "      4 of 20\n",
      "      5 of 20\n",
      "      6 of 20\n",
      "      7 of 20\n",
      "      8 of 20\n",
      "      9 of 20\n",
      "      10 of 20\n",
      "      11 of 20\n",
      "      12 of 20\n",
      "      13 of 20\n",
      "      14 of 20\n",
      "      15 of 20\n",
      "      16 of 20\n",
      "      17 of 20\n",
      "      18 of 20\n",
      "      19 of 20\n",
      "      20 of 20\n",
      "Computing ensemble means...\n",
      "Computing mean squared error...\n",
      "Iteration 2\n",
      "Train on 772 samples, validate on 144 samples\n",
      "Epoch 1/150\n",
      "772/772 [==============================] - 0s 233us/step - loss: 2.6282 - val_loss: 0.5891\n",
      "Epoch 2/150\n",
      "772/772 [==============================] - 0s 67us/step - loss: 0.5546 - val_loss: 0.4441\n",
      "Epoch 3/150\n",
      "772/772 [==============================] - 0s 87us/step - loss: 0.4597 - val_loss: 0.4403\n",
      "Epoch 4/150\n",
      "772/772 [==============================] - 0s 116us/step - loss: 0.4451 - val_loss: 0.4291\n",
      "Epoch 5/150\n",
      "772/772 [==============================] - 0s 106us/step - loss: 0.4364 - val_loss: 0.4178\n",
      "Epoch 6/150\n",
      "772/772 [==============================] - 0s 135us/step - loss: 0.4285 - val_loss: 0.4059\n",
      "Epoch 7/150\n",
      "772/772 [==============================] - 0s 88us/step - loss: 0.4205 - val_loss: 0.4013\n",
      "Epoch 8/150\n",
      "772/772 [==============================] - 0s 88us/step - loss: 0.4098 - val_loss: 0.3965\n",
      "Epoch 9/150\n",
      "772/772 [==============================] - 0s 120us/step - loss: 0.4094 - val_loss: 0.3879\n",
      "Epoch 10/150\n",
      "772/772 [==============================] - 0s 89us/step - loss: 0.4021 - val_loss: 0.3869\n",
      "Epoch 11/150\n",
      "772/772 [==============================] - 0s 93us/step - loss: 0.3905 - val_loss: 0.3702\n",
      "Epoch 12/150\n",
      "772/772 [==============================] - 0s 103us/step - loss: 0.3805 - val_loss: 0.3623\n",
      "Epoch 13/150\n",
      "772/772 [==============================] - 0s 113us/step - loss: 0.3704 - val_loss: 0.3465\n",
      "Epoch 14/150\n",
      "772/772 [==============================] - 0s 99us/step - loss: 0.3662 - val_loss: 0.3441\n",
      "Epoch 15/150\n",
      "772/772 [==============================] - 0s 91us/step - loss: 0.3542 - val_loss: 0.3439\n",
      "Epoch 16/150\n",
      "772/772 [==============================] - 0s 119us/step - loss: 0.3462 - val_loss: 0.3290\n",
      "Epoch 17/150\n",
      "772/772 [==============================] - 0s 90us/step - loss: 0.3375 - val_loss: 0.3232\n",
      "Epoch 18/150\n",
      "772/772 [==============================] - 0s 110us/step - loss: 0.3291 - val_loss: 0.3137\n",
      "Epoch 19/150\n",
      "772/772 [==============================] - 0s 106us/step - loss: 0.3249 - val_loss: 0.3064\n",
      "Epoch 20/150\n",
      "772/772 [==============================] - 0s 102us/step - loss: 0.3140 - val_loss: 0.2952\n",
      "Epoch 21/150\n",
      "772/772 [==============================] - 0s 95us/step - loss: 0.3071 - val_loss: 0.2916\n",
      "Epoch 22/150\n",
      "772/772 [==============================] - 0s 108us/step - loss: 0.3092 - val_loss: 0.3000\n",
      "Epoch 23/150\n",
      "772/772 [==============================] - 0s 95us/step - loss: 0.3021 - val_loss: 0.2978\n",
      "Epoch 24/150\n",
      "772/772 [==============================] - 0s 101us/step - loss: 0.2949 - val_loss: 0.2823\n",
      "Epoch 25/150\n",
      "772/772 [==============================] - 0s 104us/step - loss: 0.2876 - val_loss: 0.2838\n",
      "Epoch 26/150\n",
      "772/772 [==============================] - 0s 98us/step - loss: 0.2860 - val_loss: 0.2715\n",
      "Epoch 27/150\n",
      "772/772 [==============================] - 0s 104us/step - loss: 0.2878 - val_loss: 0.2583\n",
      "Epoch 28/150\n",
      "772/772 [==============================] - 0s 90us/step - loss: 0.2768 - val_loss: 0.2528\n",
      "Epoch 29/150\n",
      "772/772 [==============================] - 0s 92us/step - loss: 0.2814 - val_loss: 0.2678\n",
      "Epoch 30/150\n",
      "772/772 [==============================] - 0s 102us/step - loss: 0.2740 - val_loss: 0.2516\n",
      "Epoch 31/150\n",
      "772/772 [==============================] - 0s 86us/step - loss: 0.2752 - val_loss: 0.2698\n",
      "Epoch 32/150\n",
      "772/772 [==============================] - 0s 112us/step - loss: 0.2748 - val_loss: 0.2730\n",
      "Epoch 33/150\n",
      "772/772 [==============================] - 0s 90us/step - loss: 0.2690 - val_loss: 0.2690\n",
      "Epoch 34/150\n",
      "772/772 [==============================] - 0s 84us/step - loss: 0.2667 - val_loss: 0.2508\n",
      "Epoch 35/150\n",
      "772/772 [==============================] - 0s 122us/step - loss: 0.2660 - val_loss: 0.2391\n",
      "Epoch 36/150\n",
      "772/772 [==============================] - 0s 91us/step - loss: 0.2756 - val_loss: 0.2445\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 37/150\n",
      "772/772 [==============================] - 0s 83us/step - loss: 0.2612 - val_loss: 0.2454\n",
      "Epoch 38/150\n",
      "772/772 [==============================] - 0s 132us/step - loss: 0.2604 - val_loss: 0.2503\n",
      "Epoch 39/150\n",
      "772/772 [==============================] - 0s 134us/step - loss: 0.2582 - val_loss: 0.2336\n",
      "Epoch 40/150\n",
      "772/772 [==============================] - 0s 133us/step - loss: 0.2493 - val_loss: 0.2371\n",
      "Epoch 41/150\n",
      "772/772 [==============================] - 0s 119us/step - loss: 0.2593 - val_loss: 0.2381\n",
      "Epoch 42/150\n",
      "772/772 [==============================] - 0s 131us/step - loss: 0.2542 - val_loss: 0.2518\n",
      "Epoch 43/150\n",
      "772/772 [==============================] - 0s 118us/step - loss: 0.2573 - val_loss: 0.2475\n",
      "Evaluating model with testing data...\n",
      "144/144 [==============================] - 0s 40us/step\n",
      "Getting distribution of predictions and covariance matrix...\n",
      "      1 of 20\n",
      "      2 of 20\n",
      "      3 of 20\n",
      "      4 of 20\n",
      "      5 of 20\n",
      "      6 of 20\n",
      "      7 of 20\n",
      "      8 of 20\n",
      "      9 of 20\n",
      "      10 of 20\n",
      "      11 of 20\n",
      "      12 of 20\n",
      "      13 of 20\n",
      "      14 of 20\n",
      "      15 of 20\n",
      "      16 of 20\n",
      "      17 of 20\n",
      "      18 of 20\n",
      "      19 of 20\n",
      "      20 of 20\n",
      "Computing ensemble means...\n",
      "Computing mean squared error...\n",
      "Iteration 3\n",
      "Train on 912 samples, validate on 174 samples\n",
      "Epoch 1/150\n",
      "912/912 [==============================] - 0s 208us/step - loss: 1.5059 - val_loss: 0.4533\n",
      "Epoch 2/150\n",
      "912/912 [==============================] - 0s 66us/step - loss: 0.4476 - val_loss: 0.4539\n",
      "Epoch 3/150\n",
      "912/912 [==============================] - 0s 118us/step - loss: 0.4388 - val_loss: 0.4450\n",
      "Epoch 4/150\n",
      "912/912 [==============================] - 0s 128us/step - loss: 0.4221 - val_loss: 0.4168\n",
      "Epoch 5/150\n",
      "912/912 [==============================] - 0s 127us/step - loss: 0.4155 - val_loss: 0.4244\n",
      "Epoch 6/150\n",
      "912/912 [==============================] - 0s 130us/step - loss: 0.4019 - val_loss: 0.4027\n",
      "Epoch 7/150\n",
      "912/912 [==============================] - 0s 127us/step - loss: 0.3926 - val_loss: 0.3898\n",
      "Epoch 8/150\n",
      "912/912 [==============================] - 0s 128us/step - loss: 0.3770 - val_loss: 0.3807\n",
      "Epoch 9/150\n",
      "912/912 [==============================] - 0s 128us/step - loss: 0.3647 - val_loss: 0.3651\n",
      "Epoch 10/150\n",
      "912/912 [==============================] - 0s 129us/step - loss: 0.3512 - val_loss: 0.3515\n",
      "Epoch 11/150\n",
      "912/912 [==============================] - 0s 128us/step - loss: 0.3372 - val_loss: 0.3499\n",
      "Epoch 12/150\n",
      "912/912 [==============================] - 0s 127us/step - loss: 0.3275 - val_loss: 0.3344\n",
      "Epoch 13/150\n",
      "912/912 [==============================] - 0s 128us/step - loss: 0.3279 - val_loss: 0.3313\n",
      "Epoch 14/150\n",
      "912/912 [==============================] - 0s 127us/step - loss: 0.3121 - val_loss: 0.3376\n",
      "Epoch 15/150\n",
      "912/912 [==============================] - 0s 128us/step - loss: 0.3112 - val_loss: 0.3397\n",
      "Epoch 16/150\n",
      "912/912 [==============================] - 0s 129us/step - loss: 0.3026 - val_loss: 0.3076\n",
      "Epoch 17/150\n",
      "912/912 [==============================] - 0s 128us/step - loss: 0.2993 - val_loss: 0.2854\n",
      "Epoch 18/150\n",
      "912/912 [==============================] - 0s 129us/step - loss: 0.2895 - val_loss: 0.2967\n",
      "Epoch 19/150\n",
      "912/912 [==============================] - 0s 130us/step - loss: 0.2908 - val_loss: 0.2961\n",
      "Epoch 20/150\n",
      "912/912 [==============================] - 0s 128us/step - loss: 0.2803 - val_loss: 0.2768\n",
      "Epoch 21/150\n",
      "912/912 [==============================] - 0s 128us/step - loss: 0.2826 - val_loss: 0.2628\n",
      "Epoch 22/150\n",
      "912/912 [==============================] - 0s 128us/step - loss: 0.2694 - val_loss: 0.2700\n",
      "Epoch 23/150\n",
      "912/912 [==============================] - 0s 128us/step - loss: 0.2648 - val_loss: 0.2574\n",
      "Epoch 24/150\n",
      "912/912 [==============================] - 0s 128us/step - loss: 0.2590 - val_loss: 0.2449\n",
      "Epoch 25/150\n",
      "912/912 [==============================] - 0s 129us/step - loss: 0.2575 - val_loss: 0.2503\n",
      "Epoch 26/150\n",
      "912/912 [==============================] - 0s 128us/step - loss: 0.2616 - val_loss: 0.2597\n",
      "Epoch 27/150\n",
      "912/912 [==============================] - 0s 130us/step - loss: 0.2601 - val_loss: 0.2340\n",
      "Epoch 28/150\n",
      "912/912 [==============================] - 0s 101us/step - loss: 0.2404 - val_loss: 0.2508\n",
      "Epoch 29/150\n",
      "912/912 [==============================] - 0s 111us/step - loss: 0.2504 - val_loss: 0.2300\n",
      "Epoch 30/150\n",
      "912/912 [==============================] - 0s 101us/step - loss: 0.2488 - val_loss: 0.2416\n",
      "Epoch 31/150\n",
      "912/912 [==============================] - 0s 89us/step - loss: 0.2450 - val_loss: 0.2252\n",
      "Epoch 32/150\n",
      "912/912 [==============================] - 0s 111us/step - loss: 0.2369 - val_loss: 0.2186\n",
      "Epoch 33/150\n",
      "912/912 [==============================] - 0s 128us/step - loss: 0.2500 - val_loss: 0.2413\n",
      "Epoch 34/150\n",
      "912/912 [==============================] - 0s 111us/step - loss: 0.2301 - val_loss: 0.2378\n",
      "Epoch 35/150\n",
      "912/912 [==============================] - 0s 104us/step - loss: 0.2251 - val_loss: 0.2057\n",
      "Epoch 36/150\n",
      "912/912 [==============================] - 0s 104us/step - loss: 0.2311 - val_loss: 0.2243\n",
      "Epoch 37/150\n",
      "912/912 [==============================] - 0s 105us/step - loss: 0.2238 - val_loss: 0.2154\n",
      "Epoch 38/150\n",
      "912/912 [==============================] - 0s 103us/step - loss: 0.2295 - val_loss: 0.2238\n",
      "Epoch 39/150\n",
      "912/912 [==============================] - 0s 116us/step - loss: 0.2274 - val_loss: 0.2325\n",
      "Evaluating model with testing data...\n",
      "174/174 [==============================] - 0s 42us/step\n",
      "Getting distribution of predictions and covariance matrix...\n",
      "      1 of 20\n",
      "      2 of 20\n",
      "      3 of 20\n",
      "      4 of 20\n",
      "      5 of 20\n",
      "      6 of 20\n",
      "      7 of 20\n",
      "      8 of 20\n",
      "      9 of 20\n",
      "      10 of 20\n",
      "      11 of 20\n",
      "      12 of 20\n",
      "      13 of 20\n",
      "      14 of 20\n",
      "      15 of 20\n",
      "      16 of 20\n",
      "      17 of 20\n",
      "      18 of 20\n",
      "      19 of 20\n",
      "      20 of 20\n",
      "Computing ensemble means...\n",
      "Computing mean squared error...\n",
      "Iteration 4\n",
      "Train on 1052 samples, validate on 204 samples\n",
      "Epoch 1/150\n",
      "1052/1052 [==============================] - 0s 188us/step - loss: 1.0399 - val_loss: 0.4741\n",
      "Epoch 2/150\n",
      "1052/1052 [==============================] - 0s 65us/step - loss: 0.4443 - val_loss: 0.4560\n",
      "Epoch 3/150\n",
      "1052/1052 [==============================] - 0s 80us/step - loss: 0.4235 - val_loss: 0.4413\n",
      "Epoch 4/150\n",
      "1052/1052 [==============================] - 0s 67us/step - loss: 0.3998 - val_loss: 0.4056\n",
      "Epoch 5/150\n",
      "1052/1052 [==============================] - 0s 102us/step - loss: 0.3772 - val_loss: 0.4016\n",
      "Epoch 6/150\n",
      "1052/1052 [==============================] - 0s 114us/step - loss: 0.3536 - val_loss: 0.3453\n",
      "Epoch 7/150\n",
      "1052/1052 [==============================] - 0s 98us/step - loss: 0.3320 - val_loss: 0.3369\n",
      "Epoch 8/150\n",
      "1052/1052 [==============================] - 0s 88us/step - loss: 0.3106 - val_loss: 0.3192\n",
      "Epoch 9/150\n",
      "1052/1052 [==============================] - 0s 100us/step - loss: 0.3025 - val_loss: 0.3219\n",
      "Epoch 10/150\n",
      "1052/1052 [==============================] - 0s 99us/step - loss: 0.2882 - val_loss: 0.3096\n",
      "Epoch 11/150\n",
      "1052/1052 [==============================] - 0s 93us/step - loss: 0.2809 - val_loss: 0.2918\n",
      "Epoch 12/150\n",
      "1052/1052 [==============================] - 0s 80us/step - loss: 0.2727 - val_loss: 0.2729\n",
      "Epoch 13/150\n",
      "1052/1052 [==============================] - 0s 103us/step - loss: 0.2554 - val_loss: 0.2692\n",
      "Epoch 14/150\n",
      "1052/1052 [==============================] - 0s 124us/step - loss: 0.2535 - val_loss: 0.2725\n",
      "Epoch 15/150\n",
      "1052/1052 [==============================] - 0s 124us/step - loss: 0.2624 - val_loss: 0.2498\n",
      "Epoch 16/150\n",
      "1052/1052 [==============================] - 0s 124us/step - loss: 0.2443 - val_loss: 0.2549\n",
      "Epoch 17/150\n",
      "1052/1052 [==============================] - 0s 124us/step - loss: 0.2479 - val_loss: 0.2435\n",
      "Epoch 18/150\n",
      "1052/1052 [==============================] - 0s 124us/step - loss: 0.2418 - val_loss: 0.2360\n",
      "Epoch 19/150\n",
      "1052/1052 [==============================] - 0s 108us/step - loss: 0.2348 - val_loss: 0.2358\n",
      "Epoch 20/150\n",
      "1052/1052 [==============================] - 0s 100us/step - loss: 0.2309 - val_loss: 0.2441\n",
      "Epoch 21/150\n",
      "1052/1052 [==============================] - 0s 92us/step - loss: 0.2316 - val_loss: 0.2168\n",
      "Epoch 22/150\n",
      "1052/1052 [==============================] - 0s 81us/step - loss: 0.2256 - val_loss: 0.2141\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 23/150\n",
      "1052/1052 [==============================] - 0s 100us/step - loss: 0.2263 - val_loss: 0.2320\n",
      "Epoch 24/150\n",
      "1052/1052 [==============================] - 0s 118us/step - loss: 0.2088 - val_loss: 0.2187\n",
      "Epoch 25/150\n",
      "1052/1052 [==============================] - 0s 123us/step - loss: 0.2111 - val_loss: 0.2161\n",
      "Epoch 26/150\n",
      "1052/1052 [==============================] - 0s 124us/step - loss: 0.2131 - val_loss: 0.2254\n",
      "Evaluating model with testing data...\n",
      "204/204 [==============================] - 0s 37us/step\n",
      "Getting distribution of predictions and covariance matrix...\n",
      "      1 of 20\n",
      "      2 of 20\n",
      "      3 of 20\n",
      "      4 of 20\n",
      "      5 of 20\n",
      "      6 of 20\n",
      "      7 of 20\n",
      "      8 of 20\n",
      "      9 of 20\n",
      "      10 of 20\n",
      "      11 of 20\n",
      "      12 of 20\n",
      "      13 of 20\n",
      "      14 of 20\n",
      "      15 of 20\n",
      "      16 of 20\n",
      "      17 of 20\n",
      "      18 of 20\n",
      "      19 of 20\n",
      "      20 of 20\n",
      "Computing ensemble means...\n",
      "Computing mean squared error...\n",
      "Iteration 5\n",
      "Train on 1192 samples, validate on 234 samples\n",
      "Epoch 1/150\n",
      "1192/1192 [==============================] - 0s 175us/step - loss: 0.9230 - val_loss: 0.5043\n",
      "Epoch 2/150\n",
      "1192/1192 [==============================] - 0s 67us/step - loss: 0.4687 - val_loss: 0.4962\n",
      "Epoch 3/150\n",
      "1192/1192 [==============================] - 0s 81us/step - loss: 0.4585 - val_loss: 0.4863\n",
      "Epoch 4/150\n",
      "1192/1192 [==============================] - 0s 110us/step - loss: 0.4497 - val_loss: 0.4745\n",
      "Epoch 5/150\n",
      "1192/1192 [==============================] - 0s 122us/step - loss: 0.4347 - val_loss: 0.4457\n",
      "Epoch 6/150\n",
      "1192/1192 [==============================] - 0s 124us/step - loss: 0.4227 - val_loss: 0.4363\n",
      "Epoch 7/150\n",
      "1192/1192 [==============================] - 0s 120us/step - loss: 0.4116 - val_loss: 0.4216\n",
      "Epoch 8/150\n",
      "1192/1192 [==============================] - 0s 123us/step - loss: 0.3997 - val_loss: 0.4046\n",
      "Epoch 9/150\n",
      "1192/1192 [==============================] - 0s 123us/step - loss: 0.3893 - val_loss: 0.3990\n",
      "Epoch 10/150\n",
      "1192/1192 [==============================] - 0s 122us/step - loss: 0.3786 - val_loss: 0.3826\n",
      "Epoch 11/150\n",
      "1192/1192 [==============================] - 0s 122us/step - loss: 0.3708 - val_loss: 0.3663\n",
      "Epoch 12/150\n",
      "1192/1192 [==============================] - 0s 121us/step - loss: 0.3544 - val_loss: 0.3569\n",
      "Epoch 13/150\n",
      "1192/1192 [==============================] - 0s 121us/step - loss: 0.3505 - val_loss: 0.3619\n",
      "Epoch 14/150\n",
      "1192/1192 [==============================] - 0s 121us/step - loss: 0.3402 - val_loss: 0.3505\n",
      "Epoch 15/150\n",
      "1192/1192 [==============================] - 0s 121us/step - loss: 0.3399 - val_loss: 0.3607\n",
      "Epoch 16/150\n",
      "1192/1192 [==============================] - 0s 122us/step - loss: 0.3307 - val_loss: 0.3327\n",
      "Epoch 17/150\n",
      "1192/1192 [==============================] - 0s 123us/step - loss: 0.3313 - val_loss: 0.3223\n",
      "Epoch 18/150\n",
      "1192/1192 [==============================] - 0s 121us/step - loss: 0.3192 - val_loss: 0.3209\n",
      "Epoch 19/150\n",
      "1192/1192 [==============================] - 0s 123us/step - loss: 0.3216 - val_loss: 0.3050\n",
      "Epoch 20/150\n",
      "1192/1192 [==============================] - 0s 123us/step - loss: 0.3127 - val_loss: 0.3053\n",
      "Epoch 21/150\n",
      "1192/1192 [==============================] - 0s 105us/step - loss: 0.3117 - val_loss: 0.2922\n",
      "Epoch 22/150\n",
      "1192/1192 [==============================] - 0s 99us/step - loss: 0.3028 - val_loss: 0.2892\n",
      "Epoch 23/150\n",
      "1192/1192 [==============================] - 0s 114us/step - loss: 0.3074 - val_loss: 0.2845\n",
      "Epoch 24/150\n",
      "1192/1192 [==============================] - 0s 107us/step - loss: 0.2998 - val_loss: 0.2777\n",
      "Epoch 25/150\n",
      "1192/1192 [==============================] - 0s 94us/step - loss: 0.2934 - val_loss: 0.2742\n",
      "Epoch 26/150\n",
      "1192/1192 [==============================] - 0s 106us/step - loss: 0.2900 - val_loss: 0.2782\n",
      "Epoch 27/150\n",
      "1192/1192 [==============================] - 0s 114us/step - loss: 0.2847 - val_loss: 0.2682\n",
      "Epoch 28/150\n",
      "1192/1192 [==============================] - 0s 94us/step - loss: 0.2841 - val_loss: 0.2698\n",
      "Epoch 29/150\n",
      "1192/1192 [==============================] - 0s 107us/step - loss: 0.2884 - val_loss: 0.2751\n",
      "Epoch 30/150\n",
      "1192/1192 [==============================] - 0s 115us/step - loss: 0.2815 - val_loss: 0.2648\n",
      "Epoch 31/150\n",
      "1192/1192 [==============================] - 0s 97us/step - loss: 0.2778 - val_loss: 0.2689\n",
      "Epoch 32/150\n",
      "1192/1192 [==============================] - 0s 114us/step - loss: 0.2771 - val_loss: 0.2652\n",
      "Epoch 33/150\n",
      "1192/1192 [==============================] - 0s 104us/step - loss: 0.2778 - val_loss: 0.2682\n",
      "Epoch 34/150\n",
      "1192/1192 [==============================] - 0s 109us/step - loss: 0.2717 - val_loss: 0.2607\n",
      "Epoch 35/150\n",
      "1192/1192 [==============================] - 0s 101us/step - loss: 0.2712 - val_loss: 0.2472\n",
      "Epoch 36/150\n",
      "1192/1192 [==============================] - 0s 108us/step - loss: 0.2670 - val_loss: 0.2601\n",
      "Epoch 37/150\n",
      "1192/1192 [==============================] - 0s 104us/step - loss: 0.2619 - val_loss: 0.2350\n",
      "Epoch 38/150\n",
      "1192/1192 [==============================] - 0s 103us/step - loss: 0.2672 - val_loss: 0.2576\n",
      "Epoch 39/150\n",
      "1192/1192 [==============================] - 0s 96us/step - loss: 0.2550 - val_loss: 0.2305\n",
      "Epoch 40/150\n",
      "1192/1192 [==============================] - 0s 101us/step - loss: 0.2650 - val_loss: 0.2319\n",
      "Epoch 41/150\n",
      "1192/1192 [==============================] - 0s 94us/step - loss: 0.2576 - val_loss: 0.2363\n",
      "Epoch 42/150\n",
      "1192/1192 [==============================] - 0s 98us/step - loss: 0.2598 - val_loss: 0.2259\n",
      "Epoch 43/150\n",
      "1192/1192 [==============================] - 0s 122us/step - loss: 0.2476 - val_loss: 0.2290\n",
      "Epoch 44/150\n",
      "1192/1192 [==============================] - 0s 121us/step - loss: 0.2517 - val_loss: 0.2339\n",
      "Epoch 45/150\n",
      "1192/1192 [==============================] - 0s 121us/step - loss: 0.2509 - val_loss: 0.2492\n",
      "Epoch 46/150\n",
      "1192/1192 [==============================] - 0s 121us/step - loss: 0.2502 - val_loss: 0.2118\n",
      "Epoch 47/150\n",
      "1192/1192 [==============================] - 0s 122us/step - loss: 0.2437 - val_loss: 0.2357\n",
      "Epoch 48/150\n",
      "1192/1192 [==============================] - 0s 122us/step - loss: 0.2430 - val_loss: 0.2267\n",
      "Epoch 49/150\n",
      "1192/1192 [==============================] - 0s 121us/step - loss: 0.2435 - val_loss: 0.2405\n",
      "Epoch 50/150\n",
      "1192/1192 [==============================] - 0s 121us/step - loss: 0.2480 - val_loss: 0.2319\n",
      "Evaluating model with testing data...\n",
      "234/234 [==============================] - 0s 35us/step\n",
      "Getting distribution of predictions and covariance matrix...\n",
      "      1 of 20\n",
      "      2 of 20\n",
      "      3 of 20\n",
      "      4 of 20\n",
      "      5 of 20\n",
      "      6 of 20\n",
      "      7 of 20\n",
      "      8 of 20\n",
      "      9 of 20\n",
      "      10 of 20\n",
      "      11 of 20\n",
      "      12 of 20\n",
      "      13 of 20\n",
      "      14 of 20\n",
      "      15 of 20\n",
      "      16 of 20\n",
      "      17 of 20\n",
      "      18 of 20\n",
      "      19 of 20\n",
      "      20 of 20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|          | 0/20 [00:00<?, ?it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing ensemble means...\n",
      "Computing mean squared error...\n",
      "Getting distribution of predictions...\n",
      "      1 of 20\n",
      "1600/1600 [==============================] - 0s 27us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  5%|▌         | 1/20 [00:29<09:21, 29.54s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      2 of 20\n",
      "1600/1600 [==============================] - 0s 29us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 10%|█         | 2/20 [00:59<08:51, 29.52s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      3 of 20\n",
      "1600/1600 [==============================] - 0s 33us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 15%|█▌        | 3/20 [01:28<08:21, 29.50s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      4 of 20\n",
      "1600/1600 [==============================] - 0s 31us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 20%|██        | 4/20 [01:57<07:51, 29.46s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      5 of 20\n",
      "1600/1600 [==============================] - 0s 29us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 25%|██▌       | 5/20 [02:27<07:23, 29.59s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      6 of 20\n",
      "1600/1600 [==============================] - 0s 30us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 30%|███       | 6/20 [02:57<06:53, 29.55s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      7 of 20\n",
      "1600/1600 [==============================] - 0s 57us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 35%|███▌      | 7/20 [03:26<06:24, 29.61s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      8 of 20\n",
      "1600/1600 [==============================] - 0s 29us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 40%|████      | 8/20 [03:56<05:55, 29.63s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      9 of 20\n",
      "1600/1600 [==============================] - 0s 28us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 45%|████▌     | 9/20 [04:26<05:25, 29.60s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      10 of 20\n",
      "1600/1600 [==============================] - 0s 29us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 50%|█████     | 10/20 [04:55<04:55, 29.58s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      11 of 20\n",
      "1600/1600 [==============================] - 0s 29us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 55%|█████▌    | 11/20 [05:25<04:25, 29.51s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      12 of 20\n",
      "1600/1600 [==============================] - 0s 29us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 60%|██████    | 12/20 [05:54<03:56, 29.60s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      13 of 20\n",
      "1600/1600 [==============================] - 0s 43us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 65%|██████▌   | 13/20 [06:24<03:27, 29.59s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      14 of 20\n",
      "1600/1600 [==============================] - 0s 29us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 70%|███████   | 14/20 [06:54<02:57, 29.60s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      15 of 20\n",
      "1600/1600 [==============================] - 0s 29us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 75%|███████▌  | 15/20 [07:23<02:27, 29.58s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      16 of 20\n",
      "1600/1600 [==============================] - 0s 30us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 80%|████████  | 16/20 [07:53<01:58, 29.56s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      17 of 20\n",
      "1600/1600 [==============================] - 0s 30us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 85%|████████▌ | 17/20 [08:22<01:28, 29.61s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      18 of 20\n",
      "1600/1600 [==============================] - 0s 29us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 90%|█████████ | 18/20 [08:52<00:59, 29.61s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      19 of 20\n",
      "1600/1600 [==============================] - 0s 29us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 95%|█████████▌| 19/20 [09:22<00:29, 29.62s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      20 of 20\n",
      "1600/1600 [==============================] - 0s 29us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 20/20 [09:51<00:00, 29.59s/it]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing ensemble predictions...\n",
      "Iteration 6\n",
      "Train on 1332 samples, validate on 264 samples\n",
      "Epoch 1/150\n",
      "1332/1332 [==============================] - 0s 172us/step - loss: 1.3833 - val_loss: 0.5119\n",
      "Epoch 2/150\n",
      "1332/1332 [==============================] - 0s 87us/step - loss: 0.4794 - val_loss: 0.5084\n",
      "Epoch 3/150\n",
      "1332/1332 [==============================] - 0s 109us/step - loss: 0.4753 - val_loss: 0.5034\n",
      "Epoch 4/150\n",
      "1332/1332 [==============================] - 0s 124us/step - loss: 0.4688 - val_loss: 0.4973\n",
      "Epoch 5/150\n",
      "1332/1332 [==============================] - 0s 123us/step - loss: 0.4633 - val_loss: 0.4905\n",
      "Epoch 6/150\n",
      "1332/1332 [==============================] - 0s 126us/step - loss: 0.4560 - val_loss: 0.4832\n",
      "Epoch 7/150\n",
      "1332/1332 [==============================] - 0s 123us/step - loss: 0.4479 - val_loss: 0.4770\n",
      "Epoch 8/150\n",
      "1332/1332 [==============================] - 0s 124us/step - loss: 0.4421 - val_loss: 0.4668\n",
      "Epoch 9/150\n",
      "1332/1332 [==============================] - 0s 124us/step - loss: 0.4325 - val_loss: 0.4626\n",
      "Epoch 10/150\n",
      "1332/1332 [==============================] - 0s 126us/step - loss: 0.4265 - val_loss: 0.4538\n",
      "Epoch 11/150\n",
      "1332/1332 [==============================] - 0s 108us/step - loss: 0.4181 - val_loss: 0.4480\n",
      "Epoch 12/150\n",
      "1332/1332 [==============================] - 0s 117us/step - loss: 0.4099 - val_loss: 0.4337\n",
      "Epoch 13/150\n",
      "1332/1332 [==============================] - 0s 124us/step - loss: 0.3999 - val_loss: 0.4238\n",
      "Epoch 14/150\n",
      "1332/1332 [==============================] - 0s 124us/step - loss: 0.3918 - val_loss: 0.4185\n",
      "Epoch 15/150\n",
      "1332/1332 [==============================] - 0s 117us/step - loss: 0.3893 - val_loss: 0.4126\n",
      "Epoch 16/150\n",
      "1332/1332 [==============================] - 0s 123us/step - loss: 0.3835 - val_loss: 0.4036\n",
      "Epoch 17/150\n",
      "1332/1332 [==============================] - 0s 125us/step - loss: 0.3749 - val_loss: 0.4001\n",
      "Epoch 18/150\n",
      "1332/1332 [==============================] - 0s 124us/step - loss: 0.3723 - val_loss: 0.3925\n",
      "Epoch 19/150\n",
      "1332/1332 [==============================] - 0s 115us/step - loss: 0.3649 - val_loss: 0.3987\n",
      "Epoch 20/150\n",
      "1332/1332 [==============================] - 0s 103us/step - loss: 0.3594 - val_loss: 0.3864\n",
      "Epoch 21/150\n",
      "1332/1332 [==============================] - 0s 116us/step - loss: 0.3565 - val_loss: 0.3801\n",
      "Epoch 22/150\n",
      "1332/1332 [==============================] - 0s 121us/step - loss: 0.3529 - val_loss: 0.3741\n",
      "Epoch 23/150\n",
      "1332/1332 [==============================] - 0s 109us/step - loss: 0.3483 - val_loss: 0.3637\n",
      "Epoch 24/150\n",
      "1332/1332 [==============================] - 0s 109us/step - loss: 0.3430 - val_loss: 0.3576\n",
      "Epoch 25/150\n",
      "1332/1332 [==============================] - 0s 112us/step - loss: 0.3397 - val_loss: 0.3662\n",
      "Epoch 26/150\n",
      "1332/1332 [==============================] - 0s 123us/step - loss: 0.3379 - val_loss: 0.3554\n",
      "Epoch 27/150\n",
      "1332/1332 [==============================] - 0s 123us/step - loss: 0.3325 - val_loss: 0.3546\n",
      "Epoch 28/150\n",
      "1332/1332 [==============================] - 0s 123us/step - loss: 0.3308 - val_loss: 0.3438\n",
      "Epoch 29/150\n",
      "1332/1332 [==============================] - 0s 124us/step - loss: 0.3235 - val_loss: 0.3394\n",
      "Epoch 30/150\n",
      "1332/1332 [==============================] - 0s 124us/step - loss: 0.3241 - val_loss: 0.3379\n",
      "Epoch 31/150\n",
      "1332/1332 [==============================] - 0s 122us/step - loss: 0.3201 - val_loss: 0.3286\n",
      "Epoch 32/150\n",
      "1332/1332 [==============================] - 0s 113us/step - loss: 0.3159 - val_loss: 0.3344\n",
      "Epoch 33/150\n",
      "1332/1332 [==============================] - 0s 120us/step - loss: 0.3162 - val_loss: 0.3359\n",
      "Epoch 34/150\n",
      "1332/1332 [==============================] - 0s 101us/step - loss: 0.3160 - val_loss: 0.3303\n",
      "Epoch 35/150\n",
      "1332/1332 [==============================] - 0s 121us/step - loss: 0.3131 - val_loss: 0.3185\n",
      "Epoch 36/150\n",
      "1332/1332 [==============================] - 0s 114us/step - loss: 0.3123 - val_loss: 0.3230\n",
      "Epoch 37/150\n",
      "1332/1332 [==============================] - 0s 106us/step - loss: 0.3066 - val_loss: 0.3222\n",
      "Epoch 38/150\n",
      "1332/1332 [==============================] - 0s 108us/step - loss: 0.3074 - val_loss: 0.3063\n",
      "Epoch 39/150\n",
      "1332/1332 [==============================] - 0s 94us/step - loss: 0.3030 - val_loss: 0.3142\n",
      "Epoch 40/150\n",
      "1332/1332 [==============================] - 0s 99us/step - loss: 0.3027 - val_loss: 0.3129\n",
      "Epoch 41/150\n",
      "1332/1332 [==============================] - 0s 103us/step - loss: 0.3015 - val_loss: 0.3143\n",
      "Epoch 42/150\n",
      "1332/1332 [==============================] - 0s 117us/step - loss: 0.2982 - val_loss: 0.3134\n",
      "Evaluating model with testing data...\n",
      "264/264 [==============================] - 0s 24us/step\n",
      "Getting distribution of predictions and covariance matrix...\n",
      "      1 of 20\n",
      "      2 of 20\n",
      "      3 of 20\n",
      "      4 of 20\n",
      "      5 of 20\n",
      "      6 of 20\n",
      "      7 of 20\n",
      "      8 of 20\n",
      "      9 of 20\n",
      "      10 of 20\n",
      "      11 of 20\n",
      "      12 of 20\n",
      "      13 of 20\n",
      "      14 of 20\n",
      "      15 of 20\n",
      "      16 of 20\n",
      "      17 of 20\n",
      "      18 of 20\n",
      "      19 of 20\n",
      "      20 of 20\n",
      "Computing ensemble means...\n",
      "Computing mean squared error...\n",
      "Iteration 7\n",
      "Train on 1472 samples, validate on 294 samples\n",
      "Epoch 1/150\n",
      "1472/1472 [==============================] - 0s 151us/step - loss: 0.7916 - val_loss: 0.5083\n",
      "Epoch 2/150\n",
      "1472/1472 [==============================] - 0s 78us/step - loss: 0.4622 - val_loss: 0.4964\n",
      "Epoch 3/150\n",
      "1472/1472 [==============================] - 0s 111us/step - loss: 0.4473 - val_loss: 0.4746\n",
      "Epoch 4/150\n",
      "1472/1472 [==============================] - 0s 119us/step - loss: 0.4301 - val_loss: 0.4625\n",
      "Epoch 5/150\n",
      "1472/1472 [==============================] - 0s 86us/step - loss: 0.4114 - val_loss: 0.4288\n",
      "Epoch 6/150\n",
      "1472/1472 [==============================] - 0s 84us/step - loss: 0.3891 - val_loss: 0.3958\n",
      "Epoch 7/150\n",
      "1472/1472 [==============================] - 0s 104us/step - loss: 0.3616 - val_loss: 0.3692\n",
      "Epoch 8/150\n",
      "1472/1472 [==============================] - 0s 93us/step - loss: 0.3419 - val_loss: 0.3514\n",
      "Epoch 9/150\n",
      "1472/1472 [==============================] - 0s 108us/step - loss: 0.3226 - val_loss: 0.3104\n",
      "Epoch 10/150\n",
      "1472/1472 [==============================] - 0s 107us/step - loss: 0.3010 - val_loss: 0.2956\n",
      "Epoch 11/150\n",
      "1472/1472 [==============================] - 0s 97us/step - loss: 0.2932 - val_loss: 0.2873\n",
      "Epoch 12/150\n",
      "1472/1472 [==============================] - 0s 99us/step - loss: 0.2839 - val_loss: 0.2805\n",
      "Epoch 13/150\n",
      "1472/1472 [==============================] - 0s 102us/step - loss: 0.2748 - val_loss: 0.2528\n",
      "Epoch 14/150\n",
      "1472/1472 [==============================] - 0s 108us/step - loss: 0.2618 - val_loss: 0.2811\n",
      "Epoch 15/150\n",
      "1472/1472 [==============================] - 0s 110us/step - loss: 0.2517 - val_loss: 0.2441\n",
      "Epoch 16/150\n",
      "1472/1472 [==============================] - 0s 83us/step - loss: 0.2569 - val_loss: 0.2572\n",
      "Epoch 17/150\n",
      "1472/1472 [==============================] - 0s 96us/step - loss: 0.2472 - val_loss: 0.2563\n",
      "Epoch 18/150\n",
      "1472/1472 [==============================] - 0s 108us/step - loss: 0.2376 - val_loss: 0.2314\n",
      "Epoch 19/150\n",
      "1472/1472 [==============================] - 0s 108us/step - loss: 0.2334 - val_loss: 0.2256\n",
      "Epoch 20/150\n",
      "1472/1472 [==============================] - 0s 108us/step - loss: 0.2360 - val_loss: 0.2307\n",
      "Epoch 21/150\n",
      "1472/1472 [==============================] - 0s 108us/step - loss: 0.2362 - val_loss: 0.2384\n",
      "Epoch 22/150\n",
      "1472/1472 [==============================] - 0s 109us/step - loss: 0.2261 - val_loss: 0.2211\n",
      "Epoch 23/150\n",
      "1472/1472 [==============================] - 0s 101us/step - loss: 0.2244 - val_loss: 0.2219\n",
      "Epoch 24/150\n",
      "1472/1472 [==============================] - 0s 87us/step - loss: 0.2257 - val_loss: 0.2210\n",
      "Epoch 25/150\n",
      "1472/1472 [==============================] - 0s 90us/step - loss: 0.2265 - val_loss: 0.2216\n",
      "Epoch 26/150\n",
      "1472/1472 [==============================] - 0s 93us/step - loss: 0.2242 - val_loss: 0.2241\n",
      "Epoch 27/150\n",
      "1472/1472 [==============================] - 0s 119us/step - loss: 0.2235 - val_loss: 0.2258\n",
      "Epoch 28/150\n",
      "1472/1472 [==============================] - 0s 97us/step - loss: 0.2136 - val_loss: 0.2210\n",
      "Epoch 29/150\n",
      "1472/1472 [==============================] - 0s 97us/step - loss: 0.2164 - val_loss: 0.2123\n",
      "Epoch 30/150\n",
      "1472/1472 [==============================] - 0s 112us/step - loss: 0.2189 - val_loss: 0.2248\n",
      "Epoch 31/150\n",
      "1472/1472 [==============================] - 0s 119us/step - loss: 0.2214 - val_loss: 0.2260\n",
      "Epoch 32/150\n",
      "1472/1472 [==============================] - 0s 119us/step - loss: 0.2126 - val_loss: 0.2065\n",
      "Epoch 33/150\n",
      "1472/1472 [==============================] - 0s 118us/step - loss: 0.2065 - val_loss: 0.2013\n",
      "Epoch 34/150\n",
      "1472/1472 [==============================] - 0s 119us/step - loss: 0.2073 - val_loss: 0.2200\n",
      "Epoch 35/150\n",
      "1472/1472 [==============================] - 0s 119us/step - loss: 0.2076 - val_loss: 0.2070\n",
      "Epoch 36/150\n",
      "1472/1472 [==============================] - 0s 118us/step - loss: 0.2011 - val_loss: 0.2026\n",
      "Epoch 37/150\n",
      "1472/1472 [==============================] - 0s 119us/step - loss: 0.2009 - val_loss: 0.1954\n",
      "Epoch 38/150\n",
      "1472/1472 [==============================] - 0s 118us/step - loss: 0.1968 - val_loss: 0.2071\n",
      "Epoch 39/150\n",
      "1472/1472 [==============================] - 0s 119us/step - loss: 0.1980 - val_loss: 0.1875\n",
      "Epoch 40/150\n",
      "1472/1472 [==============================] - 0s 119us/step - loss: 0.2034 - val_loss: 0.1897\n",
      "Epoch 41/150\n",
      "1472/1472 [==============================] - 0s 119us/step - loss: 0.1989 - val_loss: 0.2032\n",
      "Epoch 42/150\n",
      "1472/1472 [==============================] - 0s 118us/step - loss: 0.1990 - val_loss: 0.2024\n",
      "Epoch 43/150\n",
      "1472/1472 [==============================] - 0s 120us/step - loss: 0.1930 - val_loss: 0.1989\n",
      "Evaluating model with testing data...\n",
      "294/294 [==============================] - 0s 34us/step\n",
      "Getting distribution of predictions and covariance matrix...\n",
      "      1 of 20\n",
      "      2 of 20\n",
      "      3 of 20\n",
      "      4 of 20\n",
      "      5 of 20\n",
      "      6 of 20\n",
      "      7 of 20\n",
      "      8 of 20\n",
      "      9 of 20\n",
      "      10 of 20\n",
      "      11 of 20\n",
      "      12 of 20\n",
      "      13 of 20\n",
      "      14 of 20\n",
      "      15 of 20\n",
      "      16 of 20\n",
      "      17 of 20\n",
      "      18 of 20\n",
      "      19 of 20\n",
      "      20 of 20\n",
      "Computing ensemble means...\n",
      "Computing mean squared error...\n",
      "Iteration 8\n",
      "Train on 1612 samples, validate on 324 samples\n",
      "Epoch 1/150\n",
      "1612/1612 [==============================] - 0s 154us/step - loss: 1.4028 - val_loss: 0.4850\n",
      "Epoch 2/150\n",
      "1612/1612 [==============================] - 0s 72us/step - loss: 0.4528 - val_loss: 0.4648\n",
      "Epoch 3/150\n",
      "1612/1612 [==============================] - 0s 121us/step - loss: 0.4353 - val_loss: 0.4422\n",
      "Epoch 4/150\n",
      "1612/1612 [==============================] - 0s 118us/step - loss: 0.4130 - val_loss: 0.4177\n",
      "Epoch 5/150\n",
      "1612/1612 [==============================] - 0s 94us/step - loss: 0.3873 - val_loss: 0.3924\n",
      "Epoch 6/150\n",
      "1612/1612 [==============================] - 0s 119us/step - loss: 0.3657 - val_loss: 0.3735\n",
      "Epoch 7/150\n",
      "1612/1612 [==============================] - 0s 107us/step - loss: 0.3527 - val_loss: 0.3582\n",
      "Epoch 8/150\n",
      "1612/1612 [==============================] - 0s 118us/step - loss: 0.3324 - val_loss: 0.3320\n",
      "Epoch 9/150\n",
      "1612/1612 [==============================] - 0s 119us/step - loss: 0.3185 - val_loss: 0.3111\n",
      "Epoch 10/150\n",
      "1612/1612 [==============================] - 0s 118us/step - loss: 0.3066 - val_loss: 0.3103\n",
      "Epoch 11/150\n",
      "1612/1612 [==============================] - 0s 118us/step - loss: 0.2991 - val_loss: 0.3065\n",
      "Epoch 12/150\n",
      "1612/1612 [==============================] - 0s 118us/step - loss: 0.2873 - val_loss: 0.2898\n",
      "Epoch 13/150\n",
      "1612/1612 [==============================] - 0s 106us/step - loss: 0.2787 - val_loss: 0.2793\n",
      "Epoch 14/150\n",
      "1612/1612 [==============================] - 0s 117us/step - loss: 0.2703 - val_loss: 0.2762\n",
      "Epoch 15/150\n",
      "1612/1612 [==============================] - 0s 118us/step - loss: 0.2700 - val_loss: 0.2731\n",
      "Epoch 16/150\n",
      "1612/1612 [==============================] - 0s 116us/step - loss: 0.2619 - val_loss: 0.2618\n",
      "Epoch 17/150\n",
      "1612/1612 [==============================] - 0s 118us/step - loss: 0.2635 - val_loss: 0.2518\n",
      "Epoch 18/150\n",
      "1612/1612 [==============================] - 0s 117us/step - loss: 0.2518 - val_loss: 0.2516\n",
      "Epoch 19/150\n",
      "1612/1612 [==============================] - 0s 117us/step - loss: 0.2443 - val_loss: 0.2466\n",
      "Epoch 20/150\n",
      "1612/1612 [==============================] - 0s 117us/step - loss: 0.2522 - val_loss: 0.2519\n",
      "Epoch 21/150\n",
      "1612/1612 [==============================] - 0s 118us/step - loss: 0.2480 - val_loss: 0.2616\n",
      "Epoch 22/150\n",
      "1612/1612 [==============================] - 0s 118us/step - loss: 0.2486 - val_loss: 0.2331\n",
      "Epoch 23/150\n",
      "1612/1612 [==============================] - 0s 125us/step - loss: 0.2420 - val_loss: 0.2336\n",
      "Epoch 24/150\n",
      "1612/1612 [==============================] - 0s 117us/step - loss: 0.2367 - val_loss: 0.2364\n",
      "Epoch 25/150\n",
      "1612/1612 [==============================] - 0s 119us/step - loss: 0.2405 - val_loss: 0.2333\n",
      "Epoch 26/150\n",
      "1612/1612 [==============================] - 0s 118us/step - loss: 0.2273 - val_loss: 0.2269\n",
      "Epoch 27/150\n",
      "1612/1612 [==============================] - 0s 118us/step - loss: 0.2262 - val_loss: 0.2270\n",
      "Epoch 28/150\n",
      "1612/1612 [==============================] - 0s 118us/step - loss: 0.2277 - val_loss: 0.2253\n",
      "Epoch 29/150\n",
      "1612/1612 [==============================] - 0s 119us/step - loss: 0.2248 - val_loss: 0.2163\n",
      "Epoch 30/150\n",
      "1612/1612 [==============================] - 0s 98us/step - loss: 0.2261 - val_loss: 0.2200\n",
      "Epoch 31/150\n",
      "1612/1612 [==============================] - 0s 104us/step - loss: 0.2179 - val_loss: 0.2294\n",
      "Epoch 32/150\n",
      "1612/1612 [==============================] - 0s 117us/step - loss: 0.2244 - val_loss: 0.2210\n",
      "Epoch 33/150\n",
      "1612/1612 [==============================] - 0s 117us/step - loss: 0.2199 - val_loss: 0.2089\n",
      "Epoch 34/150\n",
      "1612/1612 [==============================] - 0s 118us/step - loss: 0.2190 - val_loss: 0.2152\n",
      "Epoch 35/150\n",
      "1612/1612 [==============================] - 0s 119us/step - loss: 0.2195 - val_loss: 0.2259\n",
      "Epoch 36/150\n",
      "1612/1612 [==============================] - 0s 99us/step - loss: 0.2121 - val_loss: 0.2060\n",
      "Epoch 37/150\n",
      "1612/1612 [==============================] - 0s 81us/step - loss: 0.2143 - val_loss: 0.2126\n",
      "Epoch 38/150\n",
      "1612/1612 [==============================] - 0s 117us/step - loss: 0.2163 - val_loss: 0.2159\n",
      "Epoch 39/150\n",
      "1612/1612 [==============================] - 0s 118us/step - loss: 0.2082 - val_loss: 0.2109\n",
      "Epoch 40/150\n",
      "1612/1612 [==============================] - 0s 118us/step - loss: 0.2057 - val_loss: 0.2108\n",
      "Evaluating model with testing data...\n",
      "324/324 [==============================] - 0s 33us/step\n",
      "Getting distribution of predictions and covariance matrix...\n",
      "      1 of 20\n",
      "      2 of 20\n",
      "      3 of 20\n",
      "      4 of 20\n",
      "      5 of 20\n",
      "      6 of 20\n",
      "      7 of 20\n",
      "      8 of 20\n",
      "      9 of 20\n",
      "      10 of 20\n",
      "      11 of 20\n",
      "      12 of 20\n",
      "      13 of 20\n",
      "      14 of 20\n",
      "      15 of 20\n",
      "      16 of 20\n",
      "      17 of 20\n",
      "      18 of 20\n",
      "      19 of 20\n",
      "      20 of 20\n",
      "Computing ensemble means...\n",
      "Computing mean squared error...\n",
      "Iteration 9\n",
      "Train on 1752 samples, validate on 354 samples\n",
      "Epoch 1/150\n",
      "1752/1752 [==============================] - 0s 137us/step - loss: 0.7299 - val_loss: 0.4634\n",
      "Epoch 2/150\n",
      "1752/1752 [==============================] - 0s 68us/step - loss: 0.4457 - val_loss: 0.4419\n",
      "Epoch 3/150\n",
      "1752/1752 [==============================] - 0s 98us/step - loss: 0.4220 - val_loss: 0.3955\n",
      "Epoch 4/150\n",
      "1752/1752 [==============================] - 0s 86us/step - loss: 0.3857 - val_loss: 0.3612\n",
      "Epoch 5/150\n",
      "1752/1752 [==============================] - 0s 98us/step - loss: 0.3555 - val_loss: 0.3234\n",
      "Epoch 6/150\n",
      "1752/1752 [==============================] - 0s 108us/step - loss: 0.3197 - val_loss: 0.3031\n",
      "Epoch 7/150\n",
      "1752/1752 [==============================] - 0s 107us/step - loss: 0.3038 - val_loss: 0.2876\n",
      "Epoch 8/150\n",
      "1752/1752 [==============================] - 0s 113us/step - loss: 0.2912 - val_loss: 0.2578\n",
      "Epoch 9/150\n",
      "1752/1752 [==============================] - 0s 100us/step - loss: 0.2764 - val_loss: 0.2707\n",
      "Epoch 10/150\n",
      "1752/1752 [==============================] - 0s 108us/step - loss: 0.2581 - val_loss: 0.2459\n",
      "Epoch 11/150\n",
      "1752/1752 [==============================] - 0s 117us/step - loss: 0.2529 - val_loss: 0.2407\n",
      "Epoch 12/150\n",
      "1752/1752 [==============================] - 0s 100us/step - loss: 0.2475 - val_loss: 0.2428\n",
      "Epoch 13/150\n",
      "1752/1752 [==============================] - 0s 101us/step - loss: 0.2404 - val_loss: 0.2154\n",
      "Epoch 14/150\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1752/1752 [==============================] - 0s 96us/step - loss: 0.2449 - val_loss: 0.2269\n",
      "Epoch 15/150\n",
      "1752/1752 [==============================] - 0s 117us/step - loss: 0.2374 - val_loss: 0.2195\n",
      "Epoch 16/150\n",
      "1752/1752 [==============================] - 0s 117us/step - loss: 0.2276 - val_loss: 0.2229\n",
      "Epoch 17/150\n",
      "1752/1752 [==============================] - 0s 117us/step - loss: 0.2272 - val_loss: 0.2062\n",
      "Epoch 18/150\n",
      "1752/1752 [==============================] - 0s 118us/step - loss: 0.2202 - val_loss: 0.2035\n",
      "Epoch 19/150\n",
      "1752/1752 [==============================] - 0s 108us/step - loss: 0.2213 - val_loss: 0.2137\n",
      "Epoch 20/150\n",
      "1752/1752 [==============================] - 0s 118us/step - loss: 0.2131 - val_loss: 0.2022\n",
      "Epoch 21/150\n",
      "1752/1752 [==============================] - 0s 118us/step - loss: 0.2141 - val_loss: 0.1983\n",
      "Epoch 22/150\n",
      "1752/1752 [==============================] - 0s 118us/step - loss: 0.2125 - val_loss: 0.2007\n",
      "Epoch 23/150\n",
      "1752/1752 [==============================] - 0s 117us/step - loss: 0.2015 - val_loss: 0.2004\n",
      "Epoch 24/150\n",
      "1752/1752 [==============================] - 0s 118us/step - loss: 0.2057 - val_loss: 0.2048\n",
      "Epoch 25/150\n",
      "1752/1752 [==============================] - 0s 117us/step - loss: 0.2016 - val_loss: 0.1949\n",
      "Epoch 26/150\n",
      "1752/1752 [==============================] - 0s 118us/step - loss: 0.2019 - val_loss: 0.1756\n",
      "Epoch 27/150\n",
      "1752/1752 [==============================] - 0s 117us/step - loss: 0.2006 - val_loss: 0.1928\n",
      "Epoch 28/150\n",
      "1752/1752 [==============================] - 0s 117us/step - loss: 0.2026 - val_loss: 0.1879\n",
      "Epoch 29/150\n",
      "1752/1752 [==============================] - 0s 118us/step - loss: 0.1980 - val_loss: 0.1825\n",
      "Epoch 30/150\n",
      "1752/1752 [==============================] - 0s 117us/step - loss: 0.1937 - val_loss: 0.1865\n",
      "Evaluating model with testing data...\n",
      "354/354 [==============================] - 0s 30us/step\n",
      "Getting distribution of predictions and covariance matrix...\n",
      "      1 of 20\n",
      "      2 of 20\n",
      "      3 of 20\n",
      "      4 of 20\n",
      "      5 of 20\n",
      "      6 of 20\n",
      "      7 of 20\n",
      "      8 of 20\n",
      "      9 of 20\n",
      "      10 of 20\n",
      "      11 of 20\n",
      "      12 of 20\n",
      "      13 of 20\n",
      "      14 of 20\n",
      "      15 of 20\n",
      "      16 of 20\n",
      "      17 of 20\n",
      "      18 of 20\n",
      "      19 of 20\n",
      "      20 of 20\n",
      "Computing ensemble means...\n",
      "Computing mean squared error...\n",
      "Iteration 10\n",
      "Train on 1892 samples, validate on 384 samples\n",
      "Epoch 1/150\n",
      "1892/1892 [==============================] - 0s 136us/step - loss: 1.2555 - val_loss: 0.4787\n",
      "Epoch 2/150\n",
      "1892/1892 [==============================] - 0s 68us/step - loss: 0.4650 - val_loss: 0.4657\n",
      "Epoch 3/150\n",
      "1892/1892 [==============================] - 0s 111us/step - loss: 0.4505 - val_loss: 0.4534\n",
      "Epoch 4/150\n",
      "1892/1892 [==============================] - 0s 113us/step - loss: 0.4349 - val_loss: 0.4311\n",
      "Epoch 5/150\n",
      "1892/1892 [==============================] - 0s 105us/step - loss: 0.4083 - val_loss: 0.4026\n",
      "Epoch 6/150\n",
      "1892/1892 [==============================] - 0s 115us/step - loss: 0.3874 - val_loss: 0.3746\n",
      "Epoch 7/150\n",
      "1892/1892 [==============================] - 0s 117us/step - loss: 0.3699 - val_loss: 0.3661\n",
      "Epoch 8/150\n",
      "1892/1892 [==============================] - 0s 117us/step - loss: 0.3519 - val_loss: 0.3419\n",
      "Epoch 9/150\n",
      "1892/1892 [==============================] - 0s 111us/step - loss: 0.3419 - val_loss: 0.3397\n",
      "Epoch 10/150\n",
      "1892/1892 [==============================] - 0s 117us/step - loss: 0.3225 - val_loss: 0.3155\n",
      "Epoch 11/150\n",
      "1892/1892 [==============================] - 0s 94us/step - loss: 0.3187 - val_loss: 0.3158\n",
      "Epoch 12/150\n",
      "1892/1892 [==============================] - 0s 117us/step - loss: 0.3164 - val_loss: 0.3054\n",
      "Epoch 13/150\n",
      "1892/1892 [==============================] - 0s 111us/step - loss: 0.3107 - val_loss: 0.2998\n",
      "Epoch 14/150\n",
      "1892/1892 [==============================] - 0s 111us/step - loss: 0.3016 - val_loss: 0.3014\n",
      "Epoch 15/150\n",
      "1892/1892 [==============================] - 0s 117us/step - loss: 0.2981 - val_loss: 0.2912\n",
      "Epoch 16/150\n",
      "1892/1892 [==============================] - 0s 106us/step - loss: 0.2948 - val_loss: 0.2864\n",
      "Epoch 17/150\n",
      "1892/1892 [==============================] - 0s 86us/step - loss: 0.2920 - val_loss: 0.2815\n",
      "Epoch 18/150\n",
      "1892/1892 [==============================] - 0s 112us/step - loss: 0.2902 - val_loss: 0.2829\n",
      "Epoch 19/150\n",
      "1892/1892 [==============================] - 0s 97us/step - loss: 0.2890 - val_loss: 0.2695\n",
      "Epoch 20/150\n",
      "1892/1892 [==============================] - 0s 106us/step - loss: 0.2847 - val_loss: 0.2668\n",
      "Epoch 21/150\n",
      "1892/1892 [==============================] - 0s 114us/step - loss: 0.2775 - val_loss: 0.2866\n",
      "Epoch 22/150\n",
      "1892/1892 [==============================] - 0s 117us/step - loss: 0.2755 - val_loss: 0.2720\n",
      "Epoch 23/150\n",
      "1892/1892 [==============================] - 0s 117us/step - loss: 0.2699 - val_loss: 0.2590\n",
      "Epoch 24/150\n",
      "1892/1892 [==============================] - 0s 117us/step - loss: 0.2712 - val_loss: 0.2564\n",
      "Epoch 25/150\n",
      "1892/1892 [==============================] - 0s 116us/step - loss: 0.2659 - val_loss: 0.2617\n",
      "Epoch 26/150\n",
      "1892/1892 [==============================] - 0s 116us/step - loss: 0.2675 - val_loss: 0.2506\n",
      "Epoch 27/150\n",
      "1892/1892 [==============================] - 0s 96us/step - loss: 0.2682 - val_loss: 0.2573\n",
      "Epoch 28/150\n",
      "1892/1892 [==============================] - 0s 110us/step - loss: 0.2626 - val_loss: 0.2533\n",
      "Epoch 29/150\n",
      "1892/1892 [==============================] - 0s 106us/step - loss: 0.2577 - val_loss: 0.2451\n",
      "Epoch 30/150\n",
      "1892/1892 [==============================] - 0s 116us/step - loss: 0.2555 - val_loss: 0.2583\n",
      "Epoch 31/150\n",
      "1892/1892 [==============================] - 0s 103us/step - loss: 0.2530 - val_loss: 0.2343\n",
      "Epoch 32/150\n",
      "1892/1892 [==============================] - 0s 118us/step - loss: 0.2531 - val_loss: 0.2411\n",
      "Epoch 33/150\n",
      "1892/1892 [==============================] - 0s 117us/step - loss: 0.2483 - val_loss: 0.2365\n",
      "Epoch 34/150\n",
      "1892/1892 [==============================] - 0s 104us/step - loss: 0.2452 - val_loss: 0.2354\n",
      "Epoch 35/150\n",
      "1892/1892 [==============================] - 0s 96us/step - loss: 0.2478 - val_loss: 0.2372\n",
      "Evaluating model with testing data...\n",
      "384/384 [==============================] - 0s 19us/step\n",
      "Getting distribution of predictions and covariance matrix...\n",
      "      1 of 20\n",
      "      2 of 20\n",
      "      3 of 20\n",
      "      4 of 20\n",
      "      5 of 20\n",
      "      6 of 20\n",
      "      7 of 20\n",
      "      8 of 20\n",
      "      9 of 20\n",
      "      10 of 20\n",
      "      11 of 20\n",
      "      12 of 20\n",
      "      13 of 20\n",
      "      14 of 20\n",
      "      15 of 20\n",
      "      16 of 20\n",
      "      17 of 20\n",
      "      18 of 20\n",
      "      19 of 20\n",
      "      20 of 20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|          | 0/20 [00:00<?, ?it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing ensemble means...\n",
      "Computing mean squared error...\n",
      "Getting distribution of predictions...\n",
      "      1 of 20\n",
      "1600/1600 [==============================] - 0s 28us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  5%|▌         | 1/20 [00:28<09:10, 28.95s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      2 of 20\n",
      "1600/1600 [==============================] - 0s 29us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 10%|█         | 2/20 [00:58<08:44, 29.11s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      3 of 20\n",
      "1600/1600 [==============================] - 0s 28us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 15%|█▌        | 3/20 [01:27<08:16, 29.19s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      4 of 20\n",
      "1600/1600 [==============================] - 0s 29us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 20%|██        | 4/20 [01:57<07:48, 29.29s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      5 of 20\n",
      "1600/1600 [==============================] - 0s 29us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 25%|██▌       | 5/20 [02:26<07:20, 29.35s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      6 of 20\n",
      "1600/1600 [==============================] - 0s 28us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 30%|███       | 6/20 [02:56<06:52, 29.43s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      7 of 20\n",
      "1600/1600 [==============================] - 0s 30us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 35%|███▌      | 7/20 [03:26<06:23, 29.53s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      8 of 20\n",
      "1600/1600 [==============================] - 0s 31us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 40%|████      | 8/20 [03:55<05:53, 29.47s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      9 of 20\n",
      "1600/1600 [==============================] - 0s 29us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 45%|████▌     | 9/20 [04:25<05:24, 29.50s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      10 of 20\n",
      "1600/1600 [==============================] - 0s 30us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 50%|█████     | 10/20 [04:54<04:55, 29.55s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      11 of 20\n",
      "1600/1600 [==============================] - 0s 29us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 55%|█████▌    | 11/20 [05:24<04:25, 29.55s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      12 of 20\n",
      "1600/1600 [==============================] - 0s 29us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 60%|██████    | 12/20 [05:53<03:56, 29.58s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      13 of 20\n",
      "1600/1600 [==============================] - 0s 30us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 65%|██████▌   | 13/20 [06:23<03:27, 29.62s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      14 of 20\n",
      "1600/1600 [==============================] - 0s 29us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 70%|███████   | 14/20 [06:53<02:57, 29.58s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      15 of 20\n",
      "1600/1600 [==============================] - 0s 29us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 75%|███████▌  | 15/20 [07:23<02:28, 29.69s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      16 of 20\n",
      "1600/1600 [==============================] - 0s 29us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 80%|████████  | 16/20 [07:52<01:58, 29.64s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      17 of 20\n",
      "1600/1600 [==============================] - 0s 29us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 85%|████████▌ | 17/20 [08:21<01:28, 29.55s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      18 of 20\n",
      "1600/1600 [==============================] - 0s 30us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 90%|█████████ | 18/20 [08:51<00:59, 29.58s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      19 of 20\n",
      "1600/1600 [==============================] - 0s 29us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 95%|█████████▌| 19/20 [09:21<00:29, 29.60s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      20 of 20\n",
      "1600/1600 [==============================] - 0s 29us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 20/20 [09:51<00:00, 29.55s/it]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing ensemble predictions...\n",
      "Iteration 11\n",
      "Train on 2032 samples, validate on 414 samples\n",
      "Epoch 1/150\n",
      "2032/2032 [==============================] - 0s 134us/step - loss: 0.6876 - val_loss: 0.4724\n",
      "Epoch 2/150\n",
      "2032/2032 [==============================] - 0s 89us/step - loss: 0.4565 - val_loss: 0.4518\n",
      "Epoch 3/150\n",
      "2032/2032 [==============================] - 0s 104us/step - loss: 0.4322 - val_loss: 0.4222\n",
      "Epoch 4/150\n",
      "2032/2032 [==============================] - 0s 117us/step - loss: 0.4040 - val_loss: 0.3970\n",
      "Epoch 5/150\n",
      "2032/2032 [==============================] - 0s 117us/step - loss: 0.3801 - val_loss: 0.3674\n",
      "Epoch 6/150\n",
      "2032/2032 [==============================] - 0s 118us/step - loss: 0.3499 - val_loss: 0.3238\n",
      "Epoch 7/150\n",
      "2032/2032 [==============================] - 0s 117us/step - loss: 0.3199 - val_loss: 0.3014\n",
      "Epoch 8/150\n",
      "2032/2032 [==============================] - 0s 117us/step - loss: 0.2959 - val_loss: 0.2884\n",
      "Epoch 9/150\n",
      "2032/2032 [==============================] - 0s 117us/step - loss: 0.2814 - val_loss: 0.2675\n",
      "Epoch 10/150\n",
      "2032/2032 [==============================] - 0s 118us/step - loss: 0.2676 - val_loss: 0.2446\n",
      "Epoch 11/150\n",
      "2032/2032 [==============================] - 0s 117us/step - loss: 0.2568 - val_loss: 0.2754\n",
      "Epoch 12/150\n",
      "2032/2032 [==============================] - 0s 117us/step - loss: 0.2556 - val_loss: 0.2503\n",
      "Epoch 13/150\n",
      "2032/2032 [==============================] - 0s 117us/step - loss: 0.2427 - val_loss: 0.2327\n",
      "Epoch 14/150\n",
      "2032/2032 [==============================] - 0s 117us/step - loss: 0.2334 - val_loss: 0.2339\n",
      "Epoch 15/150\n",
      "2032/2032 [==============================] - 0s 117us/step - loss: 0.2266 - val_loss: 0.2154\n",
      "Epoch 16/150\n",
      "2032/2032 [==============================] - 0s 118us/step - loss: 0.2273 - val_loss: 0.2173\n",
      "Epoch 17/150\n",
      "2032/2032 [==============================] - 0s 116us/step - loss: 0.2232 - val_loss: 0.2208\n",
      "Epoch 18/150\n",
      "2032/2032 [==============================] - 0s 116us/step - loss: 0.2151 - val_loss: 0.2197\n",
      "Epoch 19/150\n",
      "2032/2032 [==============================] - 0s 99us/step - loss: 0.2158 - val_loss: 0.2243\n",
      "Evaluating model with testing data...\n",
      "414/414 [==============================] - 0s 30us/step\n",
      "Getting distribution of predictions and covariance matrix...\n",
      "      1 of 20\n",
      "      2 of 20\n",
      "      3 of 20\n",
      "      4 of 20\n",
      "      5 of 20\n",
      "      6 of 20\n",
      "      7 of 20\n",
      "      8 of 20\n",
      "      9 of 20\n",
      "      10 of 20\n",
      "      11 of 20\n",
      "      12 of 20\n",
      "      13 of 20\n",
      "      14 of 20\n",
      "      15 of 20\n",
      "      16 of 20\n",
      "      17 of 20\n",
      "      18 of 20\n",
      "      19 of 20\n",
      "      20 of 20\n",
      "Computing ensemble means...\n",
      "Computing mean squared error...\n",
      "Iteration 12\n",
      "Train on 2172 samples, validate on 444 samples\n",
      "Epoch 1/150\n",
      "2172/2172 [==============================] - 0s 126us/step - loss: 0.7327 - val_loss: 0.4700\n",
      "Epoch 2/150\n",
      "2172/2172 [==============================] - 0s 83us/step - loss: 0.4474 - val_loss: 0.4342\n",
      "Epoch 3/150\n",
      "2172/2172 [==============================] - 0s 117us/step - loss: 0.4101 - val_loss: 0.3954\n",
      "Epoch 4/150\n",
      "2172/2172 [==============================] - 0s 116us/step - loss: 0.3668 - val_loss: 0.3461\n",
      "Epoch 5/150\n",
      "2172/2172 [==============================] - 0s 115us/step - loss: 0.3314 - val_loss: 0.3113\n",
      "Epoch 6/150\n",
      "2172/2172 [==============================] - 0s 99us/step - loss: 0.3008 - val_loss: 0.3058\n",
      "Epoch 7/150\n",
      "2172/2172 [==============================] - 0s 107us/step - loss: 0.2877 - val_loss: 0.2938\n",
      "Epoch 8/150\n",
      "2172/2172 [==============================] - 0s 111us/step - loss: 0.2781 - val_loss: 0.2909\n",
      "Epoch 9/150\n",
      "2172/2172 [==============================] - 0s 115us/step - loss: 0.2666 - val_loss: 0.2722\n",
      "Epoch 10/150\n",
      "2172/2172 [==============================] - 0s 116us/step - loss: 0.2600 - val_loss: 0.2539\n",
      "Epoch 11/150\n",
      "2172/2172 [==============================] - 0s 100us/step - loss: 0.2481 - val_loss: 0.2449\n",
      "Epoch 12/150\n",
      "2172/2172 [==============================] - 0s 108us/step - loss: 0.2408 - val_loss: 0.2490\n",
      "Epoch 13/150\n",
      "2172/2172 [==============================] - 0s 104us/step - loss: 0.2302 - val_loss: 0.2299\n",
      "Epoch 14/150\n",
      "2172/2172 [==============================] - 0s 106us/step - loss: 0.2218 - val_loss: 0.2211\n",
      "Epoch 15/150\n",
      "2172/2172 [==============================] - 0s 110us/step - loss: 0.2209 - val_loss: 0.2128\n",
      "Epoch 16/150\n",
      "2172/2172 [==============================] - 0s 115us/step - loss: 0.2145 - val_loss: 0.2159\n",
      "Epoch 17/150\n",
      "2172/2172 [==============================] - 0s 116us/step - loss: 0.2081 - val_loss: 0.2071\n",
      "Epoch 18/150\n",
      "2172/2172 [==============================] - 0s 95us/step - loss: 0.2100 - val_loss: 0.2018\n",
      "Epoch 19/150\n",
      "2172/2172 [==============================] - 0s 103us/step - loss: 0.2028 - val_loss: 0.1979\n",
      "Epoch 20/150\n",
      "2172/2172 [==============================] - 0s 98us/step - loss: 0.2008 - val_loss: 0.2026\n",
      "Epoch 21/150\n",
      "2172/2172 [==============================] - 0s 113us/step - loss: 0.2032 - val_loss: 0.1998\n",
      "Epoch 22/150\n",
      "2172/2172 [==============================] - 0s 104us/step - loss: 0.1950 - val_loss: 0.2019\n",
      "Epoch 23/150\n",
      "2172/2172 [==============================] - 0s 104us/step - loss: 0.1948 - val_loss: 0.1959\n",
      "Epoch 24/150\n",
      "2172/2172 [==============================] - 0s 107us/step - loss: 0.1947 - val_loss: 0.1989\n",
      "Epoch 25/150\n",
      "2172/2172 [==============================] - 0s 115us/step - loss: 0.1869 - val_loss: 0.1824\n",
      "Epoch 26/150\n",
      "2172/2172 [==============================] - 0s 80us/step - loss: 0.1937 - val_loss: 0.1940\n",
      "Epoch 27/150\n",
      "2172/2172 [==============================] - 0s 59us/step - loss: 0.1898 - val_loss: 0.1904\n",
      "Epoch 28/150\n",
      "2172/2172 [==============================] - 0s 59us/step - loss: 0.1856 - val_loss: 0.1886\n",
      "Epoch 29/150\n",
      "2172/2172 [==============================] - 0s 59us/step - loss: 0.1874 - val_loss: 0.1911\n",
      "Evaluating model with testing data...\n",
      "444/444 [==============================] - 0s 18us/step\n",
      "Getting distribution of predictions and covariance matrix...\n",
      "      1 of 20\n",
      "      2 of 20\n",
      "      3 of 20\n",
      "      4 of 20\n",
      "      5 of 20\n",
      "      6 of 20\n",
      "      7 of 20\n",
      "      8 of 20\n",
      "      9 of 20\n",
      "      10 of 20\n",
      "      11 of 20\n",
      "      12 of 20\n",
      "      13 of 20\n",
      "      14 of 20\n",
      "      15 of 20\n",
      "      16 of 20\n",
      "      17 of 20\n",
      "      18 of 20\n",
      "      19 of 20\n",
      "      20 of 20\n",
      "Computing ensemble means...\n",
      "Computing mean squared error...\n",
      "Iteration 13\n",
      "Train on 2312 samples, validate on 474 samples\n",
      "Epoch 1/150\n",
      "2312/2312 [==============================] - 0s 128us/step - loss: 1.1606 - val_loss: 0.4997\n",
      "Epoch 2/150\n",
      "2312/2312 [==============================] - 0s 84us/step - loss: 0.4574 - val_loss: 0.4578\n",
      "Epoch 3/150\n",
      "2312/2312 [==============================] - 0s 88us/step - loss: 0.4236 - val_loss: 0.4296\n",
      "Epoch 4/150\n",
      "2312/2312 [==============================] - 0s 120us/step - loss: 0.3922 - val_loss: 0.3894\n",
      "Epoch 5/150\n",
      "2312/2312 [==============================] - 0s 115us/step - loss: 0.3726 - val_loss: 0.3654\n",
      "Epoch 6/150\n",
      "2312/2312 [==============================] - 0s 101us/step - loss: 0.3464 - val_loss: 0.3436\n",
      "Epoch 7/150\n",
      "2312/2312 [==============================] - 0s 103us/step - loss: 0.3227 - val_loss: 0.3298\n",
      "Epoch 8/150\n",
      "2312/2312 [==============================] - 0s 104us/step - loss: 0.3165 - val_loss: 0.3249\n",
      "Epoch 9/150\n",
      "2312/2312 [==============================] - 0s 89us/step - loss: 0.3009 - val_loss: 0.3087\n",
      "Epoch 10/150\n",
      "2312/2312 [==============================] - 0s 85us/step - loss: 0.2944 - val_loss: 0.2966\n",
      "Epoch 11/150\n",
      "2312/2312 [==============================] - 0s 113us/step - loss: 0.2885 - val_loss: 0.2936\n",
      "Epoch 12/150\n",
      "2312/2312 [==============================] - 0s 94us/step - loss: 0.2873 - val_loss: 0.2846\n",
      "Epoch 13/150\n",
      "2312/2312 [==============================] - 0s 120us/step - loss: 0.2838 - val_loss: 0.2918\n",
      "Epoch 14/150\n",
      "2312/2312 [==============================] - 0s 120us/step - loss: 0.2710 - val_loss: 0.2774\n",
      "Epoch 15/150\n",
      "2312/2312 [==============================] - 0s 103us/step - loss: 0.2640 - val_loss: 0.2642\n",
      "Epoch 16/150\n",
      "2312/2312 [==============================] - 0s 104us/step - loss: 0.2562 - val_loss: 0.2584\n",
      "Epoch 17/150\n",
      "2312/2312 [==============================] - 0s 90us/step - loss: 0.2499 - val_loss: 0.2431\n",
      "Epoch 18/150\n",
      "2312/2312 [==============================] - 0s 107us/step - loss: 0.2422 - val_loss: 0.2530\n",
      "Epoch 19/150\n",
      "2312/2312 [==============================] - 0s 116us/step - loss: 0.2461 - val_loss: 0.2529\n",
      "Epoch 20/150\n",
      "2312/2312 [==============================] - 0s 120us/step - loss: 0.2390 - val_loss: 0.2439\n",
      "Epoch 21/150\n",
      "2312/2312 [==============================] - 0s 120us/step - loss: 0.2385 - val_loss: 0.2474\n",
      "Evaluating model with testing data...\n",
      "474/474 [==============================] - 0s 19us/step\n",
      "Getting distribution of predictions and covariance matrix...\n",
      "      1 of 20\n",
      "      2 of 20\n",
      "      3 of 20\n",
      "      4 of 20\n",
      "      5 of 20\n",
      "      6 of 20\n",
      "      7 of 20\n",
      "      8 of 20\n",
      "      9 of 20\n",
      "      10 of 20\n",
      "      11 of 20\n",
      "      12 of 20\n",
      "      13 of 20\n",
      "      14 of 20\n",
      "      15 of 20\n",
      "      16 of 20\n",
      "      17 of 20\n",
      "      18 of 20\n",
      "      19 of 20\n",
      "      20 of 20\n",
      "Computing ensemble means...\n",
      "Computing mean squared error...\n",
      "Iteration 14\n",
      "Train on 2452 samples, validate on 504 samples\n",
      "Epoch 1/150\n",
      "2452/2452 [==============================] - 0s 125us/step - loss: 0.7126 - val_loss: 0.4722\n",
      "Epoch 2/150\n",
      "2452/2452 [==============================] - 0s 85us/step - loss: 0.4248 - val_loss: 0.4048\n",
      "Epoch 3/150\n",
      "2452/2452 [==============================] - 0s 116us/step - loss: 0.3613 - val_loss: 0.3485\n",
      "Epoch 4/150\n",
      "2452/2452 [==============================] - 0s 118us/step - loss: 0.3161 - val_loss: 0.2944\n",
      "Epoch 5/150\n",
      "2452/2452 [==============================] - 0s 119us/step - loss: 0.2854 - val_loss: 0.2702\n",
      "Epoch 6/150\n",
      "2452/2452 [==============================] - 0s 119us/step - loss: 0.2592 - val_loss: 0.2619\n",
      "Epoch 7/150\n",
      "2452/2452 [==============================] - 0s 119us/step - loss: 0.2456 - val_loss: 0.2474\n",
      "Epoch 8/150\n",
      "2452/2452 [==============================] - 0s 118us/step - loss: 0.2283 - val_loss: 0.2306\n",
      "Epoch 9/150\n",
      "2452/2452 [==============================] - 0s 117us/step - loss: 0.2287 - val_loss: 0.2175\n",
      "Epoch 10/150\n",
      "2452/2452 [==============================] - 0s 117us/step - loss: 0.2126 - val_loss: 0.2136\n",
      "Epoch 11/150\n",
      "2452/2452 [==============================] - 0s 119us/step - loss: 0.2064 - val_loss: 0.2030\n",
      "Epoch 12/150\n",
      "2452/2452 [==============================] - 0s 118us/step - loss: 0.2000 - val_loss: 0.2084\n",
      "Epoch 13/150\n",
      "2452/2452 [==============================] - 0s 120us/step - loss: 0.1975 - val_loss: 0.1838\n",
      "Epoch 14/150\n",
      "2452/2452 [==============================] - 0s 119us/step - loss: 0.1892 - val_loss: 0.1912\n",
      "Epoch 15/150\n",
      "2452/2452 [==============================] - 0s 119us/step - loss: 0.1913 - val_loss: 0.1906\n",
      "Epoch 16/150\n",
      "2452/2452 [==============================] - 0s 105us/step - loss: 0.1796 - val_loss: 0.1823\n",
      "Epoch 17/150\n",
      "2452/2452 [==============================] - 0s 119us/step - loss: 0.1800 - val_loss: 0.1813\n",
      "Epoch 18/150\n",
      "2452/2452 [==============================] - 0s 119us/step - loss: 0.1801 - val_loss: 0.1797\n",
      "Epoch 19/150\n",
      "2452/2452 [==============================] - 0s 107us/step - loss: 0.1849 - val_loss: 0.1699\n",
      "Epoch 20/150\n",
      "2452/2452 [==============================] - 0s 119us/step - loss: 0.1730 - val_loss: 0.1634\n",
      "Epoch 21/150\n",
      "2452/2452 [==============================] - 0s 119us/step - loss: 0.1709 - val_loss: 0.1819\n",
      "Epoch 22/150\n",
      "2452/2452 [==============================] - 0s 106us/step - loss: 0.1681 - val_loss: 0.1752\n",
      "Epoch 23/150\n",
      "2452/2452 [==============================] - 0s 117us/step - loss: 0.1631 - val_loss: 0.1661\n",
      "Epoch 24/150\n",
      "2452/2452 [==============================] - 0s 120us/step - loss: 0.1650 - val_loss: 0.1594\n",
      "Epoch 25/150\n",
      "2452/2452 [==============================] - 0s 112us/step - loss: 0.1620 - val_loss: 0.1557\n",
      "Epoch 26/150\n",
      "2452/2452 [==============================] - 0s 108us/step - loss: 0.1593 - val_loss: 0.1577\n",
      "Epoch 27/150\n",
      "2452/2452 [==============================] - 0s 119us/step - loss: 0.1575 - val_loss: 0.1648\n",
      "Epoch 28/150\n",
      "2452/2452 [==============================] - 0s 119us/step - loss: 0.1529 - val_loss: 0.1544\n",
      "Epoch 29/150\n",
      "2452/2452 [==============================] - 0s 104us/step - loss: 0.1557 - val_loss: 0.1490\n",
      "Epoch 30/150\n",
      "2452/2452 [==============================] - 0s 113us/step - loss: 0.1547 - val_loss: 0.1617\n",
      "Epoch 31/150\n",
      "2452/2452 [==============================] - 0s 113us/step - loss: 0.1529 - val_loss: 0.1610\n",
      "Epoch 32/150\n",
      "2452/2452 [==============================] - 0s 113us/step - loss: 0.1521 - val_loss: 0.1465\n",
      "Epoch 33/150\n",
      "2452/2452 [==============================] - 0s 118us/step - loss: 0.1514 - val_loss: 0.1432\n",
      "Epoch 34/150\n",
      "2452/2452 [==============================] - 0s 105us/step - loss: 0.1476 - val_loss: 0.1512\n",
      "Epoch 35/150\n",
      "2452/2452 [==============================] - 0s 120us/step - loss: 0.1452 - val_loss: 0.1503\n",
      "Epoch 36/150\n",
      "2452/2452 [==============================] - 0s 119us/step - loss: 0.1504 - val_loss: 0.1399\n",
      "Epoch 37/150\n",
      "2452/2452 [==============================] - 0s 107us/step - loss: 0.1468 - val_loss: 0.1474\n",
      "Epoch 38/150\n",
      "2452/2452 [==============================] - 0s 117us/step - loss: 0.1486 - val_loss: 0.1431\n",
      "Epoch 39/150\n",
      "2452/2452 [==============================] - 0s 118us/step - loss: 0.1421 - val_loss: 0.1409\n",
      "Epoch 40/150\n",
      "2452/2452 [==============================] - 0s 93us/step - loss: 0.1470 - val_loss: 0.1360\n",
      "Epoch 41/150\n",
      "2452/2452 [==============================] - 0s 101us/step - loss: 0.1432 - val_loss: 0.1448\n",
      "Epoch 42/150\n",
      "2452/2452 [==============================] - 0s 119us/step - loss: 0.1426 - val_loss: 0.1453\n",
      "Epoch 43/150\n",
      "2452/2452 [==============================] - 0s 119us/step - loss: 0.1390 - val_loss: 0.1453\n",
      "Epoch 44/150\n",
      "2452/2452 [==============================] - 0s 93us/step - loss: 0.1392 - val_loss: 0.1403\n",
      "Evaluating model with testing data...\n",
      "504/504 [==============================] - 0s 28us/step\n",
      "Getting distribution of predictions and covariance matrix...\n",
      "      1 of 20\n",
      "      2 of 20\n",
      "      3 of 20\n",
      "      4 of 20\n",
      "      5 of 20\n",
      "      6 of 20\n",
      "      7 of 20\n",
      "      8 of 20\n",
      "      9 of 20\n",
      "      10 of 20\n",
      "      11 of 20\n",
      "      12 of 20\n",
      "      13 of 20\n",
      "      14 of 20\n",
      "      15 of 20\n",
      "      16 of 20\n",
      "      17 of 20\n",
      "      18 of 20\n",
      "      19 of 20\n",
      "      20 of 20\n",
      "Computing ensemble means...\n",
      "Computing mean squared error...\n",
      "Iteration 15\n",
      "Train on 2592 samples, validate on 534 samples\n",
      "Epoch 1/150\n",
      "2592/2592 [==============================] - 0s 121us/step - loss: 0.7990 - val_loss: 0.4654\n",
      "Epoch 2/150\n",
      "2592/2592 [==============================] - 0s 87us/step - loss: 0.4157 - val_loss: 0.4171\n",
      "Epoch 3/150\n",
      "2592/2592 [==============================] - 0s 98us/step - loss: 0.3721 - val_loss: 0.3672\n",
      "Epoch 4/150\n",
      "2592/2592 [==============================] - 0s 102us/step - loss: 0.3370 - val_loss: 0.3459\n",
      "Epoch 5/150\n",
      "2592/2592 [==============================] - 0s 119us/step - loss: 0.3105 - val_loss: 0.3191\n",
      "Epoch 6/150\n",
      "2592/2592 [==============================] - 0s 119us/step - loss: 0.2958 - val_loss: 0.2964\n",
      "Epoch 7/150\n",
      "2592/2592 [==============================] - 0s 118us/step - loss: 0.2823 - val_loss: 0.3004\n",
      "Epoch 8/150\n",
      "2592/2592 [==============================] - 0s 118us/step - loss: 0.2655 - val_loss: 0.2748\n",
      "Epoch 9/150\n",
      "2592/2592 [==============================] - 0s 107us/step - loss: 0.2614 - val_loss: 0.2665\n",
      "Epoch 10/150\n",
      "2592/2592 [==============================] - 0s 119us/step - loss: 0.2483 - val_loss: 0.2645\n",
      "Epoch 11/150\n",
      "2592/2592 [==============================] - 0s 104us/step - loss: 0.2477 - val_loss: 0.2602\n",
      "Epoch 12/150\n",
      "2592/2592 [==============================] - 0s 106us/step - loss: 0.2419 - val_loss: 0.2419\n",
      "Epoch 13/150\n",
      "2592/2592 [==============================] - 0s 105us/step - loss: 0.2385 - val_loss: 0.2462\n",
      "Epoch 14/150\n",
      "2592/2592 [==============================] - 0s 97us/step - loss: 0.2312 - val_loss: 0.2572\n",
      "Epoch 15/150\n",
      "2592/2592 [==============================] - 0s 101us/step - loss: 0.2259 - val_loss: 0.2374\n",
      "Epoch 16/150\n",
      "2592/2592 [==============================] - 0s 102us/step - loss: 0.2275 - val_loss: 0.2382\n",
      "Epoch 17/150\n",
      "2592/2592 [==============================] - 0s 95us/step - loss: 0.2211 - val_loss: 0.2175\n",
      "Epoch 18/150\n",
      "2592/2592 [==============================] - 0s 115us/step - loss: 0.2155 - val_loss: 0.2175\n",
      "Epoch 19/150\n",
      "2592/2592 [==============================] - 0s 103us/step - loss: 0.1998 - val_loss: 0.2050\n",
      "Epoch 20/150\n",
      "2592/2592 [==============================] - 0s 101us/step - loss: 0.2046 - val_loss: 0.2146\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 21/150\n",
      "2592/2592 [==============================] - 0s 118us/step - loss: 0.2011 - val_loss: 0.2069\n",
      "Epoch 22/150\n",
      "2592/2592 [==============================] - 0s 117us/step - loss: 0.1971 - val_loss: 0.2132\n",
      "Epoch 23/150\n",
      "2592/2592 [==============================] - 0s 118us/step - loss: 0.1941 - val_loss: 0.2020\n",
      "Epoch 24/150\n",
      "2592/2592 [==============================] - 0s 119us/step - loss: 0.1956 - val_loss: 0.1969\n",
      "Epoch 25/150\n",
      "2592/2592 [==============================] - 0s 118us/step - loss: 0.1891 - val_loss: 0.1922\n",
      "Epoch 26/150\n",
      "2592/2592 [==============================] - 0s 118us/step - loss: 0.1875 - val_loss: 0.1992\n",
      "Epoch 27/150\n",
      "2592/2592 [==============================] - 0s 118us/step - loss: 0.1837 - val_loss: 0.1926\n",
      "Epoch 28/150\n",
      "2592/2592 [==============================] - 0s 118us/step - loss: 0.1889 - val_loss: 0.1891\n",
      "Epoch 29/150\n",
      "2592/2592 [==============================] - 0s 117us/step - loss: 0.1853 - val_loss: 0.1850\n",
      "Epoch 30/150\n",
      "2592/2592 [==============================] - 0s 118us/step - loss: 0.1813 - val_loss: 0.1835\n",
      "Epoch 31/150\n",
      "2592/2592 [==============================] - 0s 118us/step - loss: 0.1827 - val_loss: 0.1926\n",
      "Epoch 32/150\n",
      "2592/2592 [==============================] - 0s 118us/step - loss: 0.1815 - val_loss: 0.1771\n",
      "Epoch 33/150\n",
      "2592/2592 [==============================] - 0s 119us/step - loss: 0.1792 - val_loss: 0.1830\n",
      "Epoch 34/150\n",
      "2592/2592 [==============================] - 0s 119us/step - loss: 0.1736 - val_loss: 0.1873\n",
      "Epoch 35/150\n",
      "2592/2592 [==============================] - 0s 117us/step - loss: 0.1716 - val_loss: 0.1703\n",
      "Epoch 36/150\n",
      "2592/2592 [==============================] - 0s 119us/step - loss: 0.1724 - val_loss: 0.1703\n",
      "Epoch 37/150\n",
      "2592/2592 [==============================] - 0s 119us/step - loss: 0.1704 - val_loss: 0.1675\n",
      "Epoch 38/150\n",
      "2592/2592 [==============================] - 0s 118us/step - loss: 0.1678 - val_loss: 0.1675\n",
      "Epoch 39/150\n",
      "2592/2592 [==============================] - 0s 118us/step - loss: 0.1683 - val_loss: 0.1752\n",
      "Epoch 40/150\n",
      "2592/2592 [==============================] - 0s 118us/step - loss: 0.1670 - val_loss: 0.1794\n",
      "Epoch 41/150\n",
      "2592/2592 [==============================] - 0s 118us/step - loss: 0.1674 - val_loss: 0.1720\n",
      "Epoch 42/150\n",
      "2592/2592 [==============================] - 0s 118us/step - loss: 0.1634 - val_loss: 0.1747\n",
      "Evaluating model with testing data...\n",
      "534/534 [==============================] - 0s 27us/step\n",
      "Getting distribution of predictions and covariance matrix...\n",
      "      1 of 20\n",
      "      2 of 20\n",
      "      3 of 20\n",
      "      4 of 20\n",
      "      5 of 20\n",
      "      6 of 20\n",
      "      7 of 20\n",
      "      8 of 20\n",
      "      9 of 20\n",
      "      10 of 20\n",
      "      11 of 20\n",
      "      12 of 20\n",
      "      13 of 20\n",
      "      14 of 20\n",
      "      15 of 20\n",
      "      16 of 20\n",
      "      17 of 20\n",
      "      18 of 20\n",
      "      19 of 20\n",
      "      20 of 20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|          | 0/20 [00:00<?, ?it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing ensemble means...\n",
      "Computing mean squared error...\n",
      "Getting distribution of predictions...\n",
      "      1 of 20\n",
      "1600/1600 [==============================] - 0s 27us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  5%|▌         | 1/20 [00:29<09:16, 29.29s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      2 of 20\n",
      "1600/1600 [==============================] - 0s 29us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 10%|█         | 2/20 [00:59<08:49, 29.43s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      3 of 20\n",
      "1600/1600 [==============================] - 0s 29us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 15%|█▌        | 3/20 [01:28<08:20, 29.43s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      4 of 20\n",
      "1600/1600 [==============================] - 0s 29us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 20%|██        | 4/20 [01:58<07:52, 29.53s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      5 of 20\n",
      "1600/1600 [==============================] - 0s 28us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 25%|██▌       | 5/20 [02:27<07:23, 29.59s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      6 of 20\n",
      "1600/1600 [==============================] - 0s 29us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 30%|███       | 6/20 [02:57<06:54, 29.64s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      7 of 20\n",
      "1600/1600 [==============================] - 0s 29us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 35%|███▌      | 7/20 [03:27<06:24, 29.59s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      8 of 20\n",
      "1600/1600 [==============================] - 0s 28us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 40%|████      | 8/20 [03:56<05:54, 29.57s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      9 of 20\n",
      "1600/1600 [==============================] - 0s 29us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 45%|████▌     | 9/20 [04:26<05:25, 29.60s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      10 of 20\n",
      "1600/1600 [==============================] - 0s 29us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 50%|█████     | 10/20 [04:55<04:55, 29.55s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      11 of 20\n",
      "1600/1600 [==============================] - 0s 30us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 55%|█████▌    | 11/20 [05:25<04:25, 29.50s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      12 of 20\n",
      "1600/1600 [==============================] - 0s 29us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 60%|██████    | 12/20 [05:54<03:55, 29.39s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      13 of 20\n",
      "1600/1600 [==============================] - 0s 29us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 65%|██████▌   | 13/20 [06:24<03:26, 29.49s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      14 of 20\n",
      "1600/1600 [==============================] - 0s 29us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 70%|███████   | 14/20 [06:53<02:57, 29.52s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      15 of 20\n",
      "1600/1600 [==============================] - 0s 29us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 75%|███████▌  | 15/20 [07:23<02:27, 29.53s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      16 of 20\n",
      "1600/1600 [==============================] - 0s 29us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 80%|████████  | 16/20 [07:52<01:57, 29.47s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      17 of 20\n",
      "1600/1600 [==============================] - 0s 29us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 85%|████████▌ | 17/20 [08:21<01:28, 29.44s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      18 of 20\n",
      "1600/1600 [==============================] - 0s 29us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 90%|█████████ | 18/20 [08:51<00:58, 29.49s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      19 of 20\n",
      "1600/1600 [==============================] - 0s 29us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 95%|█████████▌| 19/20 [09:21<00:29, 29.56s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      20 of 20\n",
      "1600/1600 [==============================] - 0s 29us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 20/20 [09:50<00:00, 29.53s/it]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing ensemble predictions...\n",
      "Iteration 16\n",
      "Train on 2732 samples, validate on 564 samples\n",
      "Epoch 1/150\n",
      "2732/2732 [==============================] - 0s 133us/step - loss: 0.6958 - val_loss: 0.4762\n",
      "Epoch 2/150\n",
      "2732/2732 [==============================] - 0s 82us/step - loss: 0.4387 - val_loss: 0.4376\n",
      "Epoch 3/150\n",
      "2732/2732 [==============================] - 0s 119us/step - loss: 0.3896 - val_loss: 0.3714\n",
      "Epoch 4/150\n",
      "2732/2732 [==============================] - 0s 119us/step - loss: 0.3367 - val_loss: 0.3287\n",
      "Epoch 5/150\n",
      "2732/2732 [==============================] - 0s 120us/step - loss: 0.3042 - val_loss: 0.2894\n",
      "Epoch 6/150\n",
      "2732/2732 [==============================] - 0s 120us/step - loss: 0.2730 - val_loss: 0.2664\n",
      "Epoch 7/150\n",
      "2732/2732 [==============================] - 0s 120us/step - loss: 0.2482 - val_loss: 0.2478\n",
      "Epoch 8/150\n",
      "2732/2732 [==============================] - 0s 119us/step - loss: 0.2327 - val_loss: 0.2349\n",
      "Epoch 9/150\n",
      "2732/2732 [==============================] - 0s 120us/step - loss: 0.2207 - val_loss: 0.2270\n",
      "Epoch 10/150\n",
      "2732/2732 [==============================] - 0s 119us/step - loss: 0.2067 - val_loss: 0.2029\n",
      "Epoch 11/150\n",
      "2732/2732 [==============================] - 0s 120us/step - loss: 0.2007 - val_loss: 0.1934\n",
      "Epoch 12/150\n",
      "2732/2732 [==============================] - 0s 120us/step - loss: 0.1930 - val_loss: 0.2074\n",
      "Epoch 13/150\n",
      "2732/2732 [==============================] - 0s 120us/step - loss: 0.1877 - val_loss: 0.1940\n",
      "Epoch 14/150\n",
      "2732/2732 [==============================] - 0s 120us/step - loss: 0.1851 - val_loss: 0.1932\n",
      "Epoch 15/150\n",
      "2732/2732 [==============================] - 0s 116us/step - loss: 0.1830 - val_loss: 0.1921\n",
      "Epoch 16/150\n",
      "2732/2732 [==============================] - 0s 120us/step - loss: 0.1820 - val_loss: 0.1859\n",
      "Epoch 17/150\n",
      "2732/2732 [==============================] - 0s 120us/step - loss: 0.1724 - val_loss: 0.1730\n",
      "Epoch 18/150\n",
      "2732/2732 [==============================] - 0s 120us/step - loss: 0.1727 - val_loss: 0.1705\n",
      "Epoch 19/150\n",
      "2732/2732 [==============================] - 0s 119us/step - loss: 0.1688 - val_loss: 0.1737\n",
      "Epoch 20/150\n",
      "2732/2732 [==============================] - 0s 122us/step - loss: 0.1690 - val_loss: 0.1579\n",
      "Epoch 21/150\n",
      "2732/2732 [==============================] - 0s 119us/step - loss: 0.1611 - val_loss: 0.1660\n",
      "Epoch 22/150\n",
      "2732/2732 [==============================] - 0s 120us/step - loss: 0.1596 - val_loss: 0.1654\n",
      "Epoch 23/150\n",
      "2732/2732 [==============================] - 0s 99us/step - loss: 0.1603 - val_loss: 0.1517\n",
      "Epoch 24/150\n",
      "2732/2732 [==============================] - 0s 120us/step - loss: 0.1576 - val_loss: 0.1481\n",
      "Epoch 25/150\n",
      "2732/2732 [==============================] - 0s 119us/step - loss: 0.1502 - val_loss: 0.1451\n",
      "Epoch 26/150\n",
      "2732/2732 [==============================] - 0s 114us/step - loss: 0.1538 - val_loss: 0.1475\n",
      "Epoch 27/150\n",
      "2732/2732 [==============================] - 0s 120us/step - loss: 0.1479 - val_loss: 0.1510\n",
      "Epoch 28/150\n",
      "2732/2732 [==============================] - 0s 119us/step - loss: 0.1482 - val_loss: 0.1504\n",
      "Epoch 29/150\n",
      "2732/2732 [==============================] - 0s 113us/step - loss: 0.1440 - val_loss: 0.1416\n",
      "Epoch 30/150\n",
      "2732/2732 [==============================] - 0s 119us/step - loss: 0.1422 - val_loss: 0.1486\n",
      "Epoch 31/150\n",
      "2732/2732 [==============================] - 0s 120us/step - loss: 0.1417 - val_loss: 0.1433\n",
      "Epoch 32/150\n",
      "2732/2732 [==============================] - 0s 120us/step - loss: 0.1426 - val_loss: 0.1485\n",
      "Epoch 33/150\n",
      "2732/2732 [==============================] - 0s 119us/step - loss: 0.1456 - val_loss: 0.1413\n",
      "Epoch 34/150\n",
      "2732/2732 [==============================] - 0s 118us/step - loss: 0.1389 - val_loss: 0.1359\n",
      "Epoch 35/150\n",
      "2732/2732 [==============================] - 0s 111us/step - loss: 0.1383 - val_loss: 0.1383\n",
      "Epoch 36/150\n",
      "2732/2732 [==============================] - 0s 120us/step - loss: 0.1349 - val_loss: 0.1461\n",
      "Epoch 37/150\n",
      "2732/2732 [==============================] - 0s 95us/step - loss: 0.1405 - val_loss: 0.1311\n",
      "Epoch 38/150\n",
      "2732/2732 [==============================] - 0s 115us/step - loss: 0.1339 - val_loss: 0.1289\n",
      "Epoch 39/150\n",
      "2732/2732 [==============================] - 0s 120us/step - loss: 0.1318 - val_loss: 0.1359\n",
      "Epoch 40/150\n",
      "2732/2732 [==============================] - 0s 120us/step - loss: 0.1345 - val_loss: 0.1401\n",
      "Epoch 41/150\n",
      "2732/2732 [==============================] - 0s 119us/step - loss: 0.1341 - val_loss: 0.1295\n",
      "Epoch 42/150\n",
      "2732/2732 [==============================] - 0s 119us/step - loss: 0.1338 - val_loss: 0.1325\n",
      "Evaluating model with testing data...\n",
      "564/564 [==============================] - 0s 17us/step\n",
      "Getting distribution of predictions and covariance matrix...\n",
      "      1 of 20\n",
      "      2 of 20\n",
      "      3 of 20\n",
      "      4 of 20\n",
      "      5 of 20\n",
      "      6 of 20\n",
      "      7 of 20\n",
      "      8 of 20\n",
      "      9 of 20\n",
      "      10 of 20\n",
      "      11 of 20\n",
      "      12 of 20\n",
      "      13 of 20\n",
      "      14 of 20\n",
      "      15 of 20\n",
      "      16 of 20\n",
      "      17 of 20\n",
      "      18 of 20\n",
      "      19 of 20\n",
      "      20 of 20\n",
      "Computing ensemble means...\n",
      "Computing mean squared error...\n",
      "Iteration 17\n",
      "Train on 2872 samples, validate on 594 samples\n",
      "Epoch 1/150\n",
      "2872/2872 [==============================] - 0s 125us/step - loss: 0.8061 - val_loss: 0.4690\n",
      "Epoch 2/150\n",
      "2872/2872 [==============================] - 0s 95us/step - loss: 0.4362 - val_loss: 0.4076\n",
      "Epoch 3/150\n",
      "2872/2872 [==============================] - 0s 116us/step - loss: 0.3739 - val_loss: 0.3488\n",
      "Epoch 4/150\n",
      "2872/2872 [==============================] - 0s 116us/step - loss: 0.3374 - val_loss: 0.3206\n",
      "Epoch 5/150\n",
      "2872/2872 [==============================] - 0s 117us/step - loss: 0.3104 - val_loss: 0.3035\n",
      "Epoch 6/150\n",
      "2872/2872 [==============================] - 0s 101us/step - loss: 0.2936 - val_loss: 0.2849\n",
      "Epoch 7/150\n",
      "2872/2872 [==============================] - 0s 115us/step - loss: 0.2806 - val_loss: 0.2745\n",
      "Epoch 8/150\n",
      "2872/2872 [==============================] - 0s 116us/step - loss: 0.2735 - val_loss: 0.2682\n",
      "Epoch 9/150\n",
      "2872/2872 [==============================] - 0s 107us/step - loss: 0.2600 - val_loss: 0.2556\n",
      "Epoch 10/150\n",
      "2872/2872 [==============================] - 0s 116us/step - loss: 0.2544 - val_loss: 0.2625\n",
      "Epoch 11/150\n",
      "2872/2872 [==============================] - 0s 116us/step - loss: 0.2467 - val_loss: 0.2569\n",
      "Epoch 12/150\n",
      "2872/2872 [==============================] - 0s 107us/step - loss: 0.2436 - val_loss: 0.2500\n",
      "Epoch 13/150\n",
      "2872/2872 [==============================] - 0s 117us/step - loss: 0.2430 - val_loss: 0.2412\n",
      "Epoch 14/150\n",
      "2872/2872 [==============================] - 0s 117us/step - loss: 0.2381 - val_loss: 0.2434\n",
      "Epoch 15/150\n",
      "2872/2872 [==============================] - 0s 105us/step - loss: 0.2369 - val_loss: 0.2390\n",
      "Epoch 16/150\n",
      "2872/2872 [==============================] - 0s 101us/step - loss: 0.2300 - val_loss: 0.2269\n",
      "Epoch 17/150\n",
      "2872/2872 [==============================] - 0s 105us/step - loss: 0.2249 - val_loss: 0.2302\n",
      "Epoch 18/150\n",
      "2872/2872 [==============================] - 0s 105us/step - loss: 0.2199 - val_loss: 0.2217\n",
      "Epoch 19/150\n",
      "2872/2872 [==============================] - 0s 107us/step - loss: 0.2205 - val_loss: 0.2294\n",
      "Epoch 20/150\n",
      "2872/2872 [==============================] - 0s 116us/step - loss: 0.2167 - val_loss: 0.2196\n",
      "Epoch 21/150\n",
      "2872/2872 [==============================] - 0s 117us/step - loss: 0.2187 - val_loss: 0.2128\n",
      "Epoch 22/150\n",
      "2872/2872 [==============================] - 0s 117us/step - loss: 0.2095 - val_loss: 0.2201\n",
      "Epoch 23/150\n",
      "2872/2872 [==============================] - 0s 104us/step - loss: 0.2124 - val_loss: 0.2064\n",
      "Epoch 24/150\n",
      "2872/2872 [==============================] - 0s 106us/step - loss: 0.2049 - val_loss: 0.2032\n",
      "Epoch 25/150\n",
      "2872/2872 [==============================] - 0s 98us/step - loss: 0.2029 - val_loss: 0.2030\n",
      "Epoch 26/150\n",
      "2872/2872 [==============================] - 0s 100us/step - loss: 0.2016 - val_loss: 0.2031\n",
      "Epoch 27/150\n",
      "2872/2872 [==============================] - 0s 115us/step - loss: 0.2023 - val_loss: 0.2003\n",
      "Epoch 28/150\n",
      "2872/2872 [==============================] - 0s 117us/step - loss: 0.1950 - val_loss: 0.1953\n",
      "Epoch 29/150\n",
      "2872/2872 [==============================] - 0s 108us/step - loss: 0.1988 - val_loss: 0.2014\n",
      "Epoch 30/150\n",
      "2872/2872 [==============================] - 0s 108us/step - loss: 0.1932 - val_loss: 0.1958\n",
      "Epoch 31/150\n",
      "2872/2872 [==============================] - 0s 116us/step - loss: 0.1944 - val_loss: 0.1893\n",
      "Epoch 32/150\n",
      "2872/2872 [==============================] - 0s 117us/step - loss: 0.1895 - val_loss: 0.1897\n",
      "Epoch 33/150\n",
      "2872/2872 [==============================] - 0s 116us/step - loss: 0.1884 - val_loss: 0.1970\n",
      "Epoch 34/150\n",
      "2872/2872 [==============================] - 0s 117us/step - loss: 0.1889 - val_loss: 0.1851\n",
      "Epoch 35/150\n",
      "2872/2872 [==============================] - 0s 117us/step - loss: 0.1895 - val_loss: 0.1739\n",
      "Epoch 36/150\n",
      "2872/2872 [==============================] - 0s 116us/step - loss: 0.1890 - val_loss: 0.1852\n",
      "Epoch 37/150\n",
      "2872/2872 [==============================] - 0s 116us/step - loss: 0.1832 - val_loss: 0.1950\n",
      "Epoch 38/150\n",
      "2872/2872 [==============================] - 0s 116us/step - loss: 0.1804 - val_loss: 0.1776\n",
      "Epoch 39/150\n",
      "2872/2872 [==============================] - 0s 117us/step - loss: 0.1755 - val_loss: 0.1756\n",
      "Evaluating model with testing data...\n",
      "594/594 [==============================] - 0s 17us/step\n",
      "Getting distribution of predictions and covariance matrix...\n",
      "      1 of 20\n",
      "      2 of 20\n",
      "      3 of 20\n",
      "      4 of 20\n",
      "      5 of 20\n",
      "      6 of 20\n",
      "      7 of 20\n",
      "      8 of 20\n",
      "      9 of 20\n",
      "      10 of 20\n",
      "      11 of 20\n",
      "      12 of 20\n",
      "      13 of 20\n",
      "      14 of 20\n",
      "      15 of 20\n",
      "      16 of 20\n",
      "      17 of 20\n",
      "      18 of 20\n",
      "      19 of 20\n",
      "      20 of 20\n",
      "Computing ensemble means...\n",
      "Computing mean squared error...\n",
      "Iteration 18\n",
      "Train on 3012 samples, validate on 624 samples\n",
      "Epoch 1/150\n",
      "3012/3012 [==============================] - 0s 117us/step - loss: 0.6094 - val_loss: 0.4436\n",
      "Epoch 2/150\n",
      "3012/3012 [==============================] - 0s 86us/step - loss: 0.4107 - val_loss: 0.3837\n",
      "Epoch 3/150\n",
      "3012/3012 [==============================] - 0s 99us/step - loss: 0.3456 - val_loss: 0.3256\n",
      "Epoch 4/150\n",
      "3012/3012 [==============================] - 0s 104us/step - loss: 0.2847 - val_loss: 0.2663\n",
      "Epoch 5/150\n",
      "3012/3012 [==============================] - 0s 109us/step - loss: 0.2514 - val_loss: 0.2423\n",
      "Epoch 6/150\n",
      "3012/3012 [==============================] - 0s 116us/step - loss: 0.2323 - val_loss: 0.2271\n",
      "Epoch 7/150\n",
      "3012/3012 [==============================] - 0s 116us/step - loss: 0.2185 - val_loss: 0.2261\n",
      "Epoch 8/150\n",
      "3012/3012 [==============================] - 0s 115us/step - loss: 0.2068 - val_loss: 0.2051\n",
      "Epoch 9/150\n",
      "3012/3012 [==============================] - 0s 114us/step - loss: 0.1970 - val_loss: 0.1998\n",
      "Epoch 10/150\n",
      "3012/3012 [==============================] - 0s 116us/step - loss: 0.1946 - val_loss: 0.1967\n",
      "Epoch 11/150\n",
      "3012/3012 [==============================] - 0s 116us/step - loss: 0.1882 - val_loss: 0.1865\n",
      "Epoch 12/150\n",
      "3012/3012 [==============================] - 0s 116us/step - loss: 0.1794 - val_loss: 0.1871\n",
      "Epoch 13/150\n",
      "3012/3012 [==============================] - 0s 117us/step - loss: 0.1880 - val_loss: 0.1803\n",
      "Epoch 14/150\n",
      "3012/3012 [==============================] - 0s 116us/step - loss: 0.1774 - val_loss: 0.1714\n",
      "Epoch 15/150\n",
      "3012/3012 [==============================] - 0s 112us/step - loss: 0.1747 - val_loss: 0.1743\n",
      "Epoch 16/150\n",
      "3012/3012 [==============================] - 0s 117us/step - loss: 0.1721 - val_loss: 0.1732\n",
      "Epoch 17/150\n",
      "3012/3012 [==============================] - 0s 113us/step - loss: 0.1695 - val_loss: 0.1646\n",
      "Epoch 18/150\n",
      "3012/3012 [==============================] - 0s 117us/step - loss: 0.1652 - val_loss: 0.1630\n",
      "Epoch 19/150\n",
      "3012/3012 [==============================] - 0s 117us/step - loss: 0.1672 - val_loss: 0.1635\n",
      "Epoch 20/150\n",
      "3012/3012 [==============================] - 0s 110us/step - loss: 0.1575 - val_loss: 0.1575\n",
      "Epoch 21/150\n",
      "3012/3012 [==============================] - 0s 108us/step - loss: 0.1601 - val_loss: 0.1599\n",
      "Epoch 22/150\n",
      "3012/3012 [==============================] - 0s 117us/step - loss: 0.1599 - val_loss: 0.1626\n",
      "Epoch 23/150\n",
      "3012/3012 [==============================] - 0s 102us/step - loss: 0.1595 - val_loss: 0.1541\n",
      "Epoch 24/150\n",
      "3012/3012 [==============================] - 0s 117us/step - loss: 0.1537 - val_loss: 0.1500\n",
      "Epoch 25/150\n",
      "3012/3012 [==============================] - 0s 115us/step - loss: 0.1519 - val_loss: 0.1465\n",
      "Epoch 26/150\n",
      "3012/3012 [==============================] - 0s 101us/step - loss: 0.1493 - val_loss: 0.1480\n",
      "Epoch 27/150\n",
      "3012/3012 [==============================] - 0s 105us/step - loss: 0.1478 - val_loss: 0.1466\n",
      "Epoch 28/150\n",
      "3012/3012 [==============================] - 0s 117us/step - loss: 0.1481 - val_loss: 0.1513\n",
      "Epoch 29/150\n",
      "3012/3012 [==============================] - 0s 117us/step - loss: 0.1412 - val_loss: 0.1422\n",
      "Epoch 30/150\n",
      "3012/3012 [==============================] - 0s 93us/step - loss: 0.1411 - val_loss: 0.1388\n",
      "Epoch 31/150\n",
      "3012/3012 [==============================] - 0s 101us/step - loss: 0.1442 - val_loss: 0.1420\n",
      "Epoch 32/150\n",
      "3012/3012 [==============================] - 0s 112us/step - loss: 0.1435 - val_loss: 0.1372\n",
      "Epoch 33/150\n",
      "3012/3012 [==============================] - 0s 117us/step - loss: 0.1385 - val_loss: 0.1419\n",
      "Epoch 34/150\n",
      "3012/3012 [==============================] - 0s 107us/step - loss: 0.1424 - val_loss: 0.1384\n",
      "Epoch 35/150\n",
      "3012/3012 [==============================] - 0s 117us/step - loss: 0.1384 - val_loss: 0.1295\n",
      "Epoch 36/150\n",
      "3012/3012 [==============================] - 0s 109us/step - loss: 0.1369 - val_loss: 0.1320\n",
      "Epoch 37/150\n",
      "3012/3012 [==============================] - 0s 117us/step - loss: 0.1359 - val_loss: 0.1330\n",
      "Epoch 38/150\n",
      "3012/3012 [==============================] - 0s 106us/step - loss: 0.1345 - val_loss: 0.1392\n",
      "Epoch 39/150\n",
      "3012/3012 [==============================] - 0s 117us/step - loss: 0.1341 - val_loss: 0.1280\n",
      "Epoch 40/150\n",
      "3012/3012 [==============================] - 0s 115us/step - loss: 0.1345 - val_loss: 0.1355\n",
      "Epoch 41/150\n",
      "3012/3012 [==============================] - 0s 94us/step - loss: 0.1358 - val_loss: 0.1206\n",
      "Epoch 42/150\n",
      "3012/3012 [==============================] - 0s 103us/step - loss: 0.1323 - val_loss: 0.1299\n",
      "Epoch 43/150\n",
      "3012/3012 [==============================] - 0s 115us/step - loss: 0.1299 - val_loss: 0.1240\n",
      "Epoch 44/150\n",
      "3012/3012 [==============================] - 0s 109us/step - loss: 0.1277 - val_loss: 0.1301\n",
      "Epoch 45/150\n",
      "3012/3012 [==============================] - 0s 92us/step - loss: 0.1289 - val_loss: 0.1305\n",
      "Evaluating model with testing data...\n",
      "624/624 [==============================] - 0s 17us/step\n",
      "Getting distribution of predictions and covariance matrix...\n",
      "      1 of 20\n",
      "      2 of 20\n",
      "      3 of 20\n",
      "      4 of 20\n",
      "      5 of 20\n",
      "      6 of 20\n",
      "      7 of 20\n",
      "      8 of 20\n",
      "      9 of 20\n",
      "      10 of 20\n",
      "      11 of 20\n",
      "      12 of 20\n",
      "      13 of 20\n",
      "      14 of 20\n",
      "      15 of 20\n",
      "      16 of 20\n",
      "      17 of 20\n",
      "      18 of 20\n",
      "      19 of 20\n",
      "      20 of 20\n",
      "Computing ensemble means...\n",
      "Computing mean squared error...\n",
      "Iteration 19\n",
      "Train on 3152 samples, validate on 654 samples\n",
      "Epoch 1/150\n",
      "3152/3152 [==============================] - 0s 120us/step - loss: 0.7332 - val_loss: 0.4295\n",
      "Epoch 2/150\n",
      "3152/3152 [==============================] - 0s 91us/step - loss: 0.4075 - val_loss: 0.4002\n",
      "Epoch 3/150\n",
      "3152/3152 [==============================] - 0s 92us/step - loss: 0.3805 - val_loss: 0.3596\n",
      "Epoch 4/150\n",
      "3152/3152 [==============================] - 0s 116us/step - loss: 0.3565 - val_loss: 0.3502\n",
      "Epoch 5/150\n",
      "3152/3152 [==============================] - 0s 117us/step - loss: 0.3283 - val_loss: 0.3180\n",
      "Epoch 6/150\n",
      "3152/3152 [==============================] - 0s 107us/step - loss: 0.3003 - val_loss: 0.3086\n",
      "Epoch 7/150\n",
      "3152/3152 [==============================] - 0s 99us/step - loss: 0.2834 - val_loss: 0.2862\n",
      "Epoch 8/150\n",
      "3152/3152 [==============================] - 0s 111us/step - loss: 0.2737 - val_loss: 0.2741\n",
      "Epoch 9/150\n",
      "3152/3152 [==============================] - 0s 109us/step - loss: 0.2620 - val_loss: 0.2554\n",
      "Epoch 10/150\n",
      "3152/3152 [==============================] - 0s 98us/step - loss: 0.2437 - val_loss: 0.2462\n",
      "Epoch 11/150\n",
      "3152/3152 [==============================] - 0s 116us/step - loss: 0.2416 - val_loss: 0.2282\n",
      "Epoch 12/150\n",
      "3152/3152 [==============================] - 0s 102us/step - loss: 0.2347 - val_loss: 0.2242\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 13/150\n",
      "3152/3152 [==============================] - 0s 111us/step - loss: 0.2291 - val_loss: 0.2256\n",
      "Epoch 14/150\n",
      "3152/3152 [==============================] - 0s 117us/step - loss: 0.2202 - val_loss: 0.2069\n",
      "Epoch 15/150\n",
      "3152/3152 [==============================] - 0s 116us/step - loss: 0.2149 - val_loss: 0.2195\n",
      "Epoch 16/150\n",
      "3152/3152 [==============================] - 0s 117us/step - loss: 0.2118 - val_loss: 0.2094\n",
      "Epoch 17/150\n",
      "3152/3152 [==============================] - 0s 117us/step - loss: 0.2080 - val_loss: 0.2126\n",
      "Epoch 18/150\n",
      "3152/3152 [==============================] - 0s 118us/step - loss: 0.2021 - val_loss: 0.2050\n",
      "Epoch 19/150\n",
      "3152/3152 [==============================] - 0s 117us/step - loss: 0.2011 - val_loss: 0.2044\n",
      "Epoch 20/150\n",
      "3152/3152 [==============================] - 0s 118us/step - loss: 0.1996 - val_loss: 0.2039\n",
      "Epoch 21/150\n",
      "3152/3152 [==============================] - 0s 118us/step - loss: 0.1963 - val_loss: 0.2002\n",
      "Epoch 22/150\n",
      "3152/3152 [==============================] - 0s 118us/step - loss: 0.1904 - val_loss: 0.1978\n",
      "Epoch 23/150\n",
      "3152/3152 [==============================] - 0s 118us/step - loss: 0.1864 - val_loss: 0.1816\n",
      "Epoch 24/150\n",
      "3152/3152 [==============================] - 0s 118us/step - loss: 0.1862 - val_loss: 0.1885\n",
      "Epoch 25/150\n",
      "3152/3152 [==============================] - 0s 118us/step - loss: 0.1834 - val_loss: 0.1825\n",
      "Epoch 26/150\n",
      "3152/3152 [==============================] - 0s 117us/step - loss: 0.1832 - val_loss: 0.1762\n",
      "Epoch 27/150\n",
      "3152/3152 [==============================] - 0s 116us/step - loss: 0.1798 - val_loss: 0.1707\n",
      "Epoch 28/150\n",
      "3152/3152 [==============================] - 0s 116us/step - loss: 0.1743 - val_loss: 0.1781\n",
      "Epoch 29/150\n",
      "3152/3152 [==============================] - 0s 116us/step - loss: 0.1774 - val_loss: 0.1705\n",
      "Epoch 30/150\n",
      "3152/3152 [==============================] - 0s 116us/step - loss: 0.1722 - val_loss: 0.1757\n",
      "Epoch 31/150\n",
      "3152/3152 [==============================] - 0s 116us/step - loss: 0.1694 - val_loss: 0.1615\n",
      "Epoch 32/150\n",
      "3152/3152 [==============================] - 0s 116us/step - loss: 0.1715 - val_loss: 0.1612\n",
      "Epoch 33/150\n",
      "3152/3152 [==============================] - 0s 116us/step - loss: 0.1696 - val_loss: 0.1774\n",
      "Epoch 34/150\n",
      "3152/3152 [==============================] - 0s 116us/step - loss: 0.1643 - val_loss: 0.1649\n",
      "Epoch 35/150\n",
      "3152/3152 [==============================] - 0s 116us/step - loss: 0.1633 - val_loss: 0.1654\n",
      "Epoch 36/150\n",
      "3152/3152 [==============================] - 0s 116us/step - loss: 0.1636 - val_loss: 0.1584\n",
      "Epoch 37/150\n",
      "3152/3152 [==============================] - 0s 116us/step - loss: 0.1644 - val_loss: 0.1581\n",
      "Epoch 38/150\n",
      "3152/3152 [==============================] - 0s 116us/step - loss: 0.1625 - val_loss: 0.1575\n",
      "Epoch 39/150\n",
      "3152/3152 [==============================] - 0s 116us/step - loss: 0.1572 - val_loss: 0.1624\n",
      "Epoch 40/150\n",
      "3152/3152 [==============================] - 0s 116us/step - loss: 0.1564 - val_loss: 0.1607\n",
      "Epoch 41/150\n",
      "3152/3152 [==============================] - 0s 117us/step - loss: 0.1542 - val_loss: 0.1542\n",
      "Epoch 42/150\n",
      "3152/3152 [==============================] - 0s 116us/step - loss: 0.1568 - val_loss: 0.1533\n",
      "Epoch 43/150\n",
      "3152/3152 [==============================] - 0s 116us/step - loss: 0.1515 - val_loss: 0.1553\n",
      "Epoch 44/150\n",
      "3152/3152 [==============================] - 0s 116us/step - loss: 0.1503 - val_loss: 0.1532\n",
      "Epoch 45/150\n",
      "3152/3152 [==============================] - 0s 115us/step - loss: 0.1517 - val_loss: 0.1535\n",
      "Epoch 46/150\n",
      "3152/3152 [==============================] - 0s 116us/step - loss: 0.1512 - val_loss: 0.1662\n",
      "Epoch 47/150\n",
      "3152/3152 [==============================] - 0s 116us/step - loss: 0.1532 - val_loss: 0.1495\n",
      "Epoch 48/150\n",
      "3152/3152 [==============================] - 0s 116us/step - loss: 0.1475 - val_loss: 0.1490\n",
      "Epoch 49/150\n",
      "3152/3152 [==============================] - 0s 117us/step - loss: 0.1476 - val_loss: 0.1396\n",
      "Epoch 50/150\n",
      "3152/3152 [==============================] - 0s 116us/step - loss: 0.1457 - val_loss: 0.1419\n",
      "Epoch 51/150\n",
      "3152/3152 [==============================] - 0s 117us/step - loss: 0.1457 - val_loss: 0.1446\n",
      "Epoch 52/150\n",
      "3152/3152 [==============================] - 0s 117us/step - loss: 0.1438 - val_loss: 0.1449\n",
      "Epoch 53/150\n",
      "3152/3152 [==============================] - 0s 117us/step - loss: 0.1447 - val_loss: 0.1489\n",
      "Evaluating model with testing data...\n",
      "654/654 [==============================] - 0s 17us/step\n",
      "Getting distribution of predictions and covariance matrix...\n",
      "      1 of 20\n",
      "      2 of 20\n",
      "      3 of 20\n",
      "      4 of 20\n",
      "      5 of 20\n",
      "      6 of 20\n",
      "      7 of 20\n",
      "      8 of 20\n",
      "      9 of 20\n",
      "      10 of 20\n",
      "      11 of 20\n",
      "      12 of 20\n",
      "      13 of 20\n",
      "      14 of 20\n",
      "      15 of 20\n",
      "      16 of 20\n",
      "      17 of 20\n",
      "      18 of 20\n",
      "      19 of 20\n",
      "      20 of 20\n",
      "Computing ensemble means...\n",
      "Computing mean squared error...\n",
      "Iteration 20\n",
      "Train on 3292 samples, validate on 684 samples\n",
      "Epoch 1/150\n",
      "3292/3292 [==============================] - 0s 132us/step - loss: 0.6729 - val_loss: 0.4753\n",
      "Epoch 2/150\n",
      "3292/3292 [==============================] - 0s 90us/step - loss: 0.4536 - val_loss: 0.4370\n",
      "Epoch 3/150\n",
      "3292/3292 [==============================] - 0s 103us/step - loss: 0.4159 - val_loss: 0.3939\n",
      "Epoch 4/150\n",
      "3292/3292 [==============================] - 0s 95us/step - loss: 0.3679 - val_loss: 0.3466\n",
      "Epoch 5/150\n",
      "3292/3292 [==============================] - 0s 106us/step - loss: 0.3342 - val_loss: 0.3215\n",
      "Epoch 6/150\n",
      "3292/3292 [==============================] - 0s 102us/step - loss: 0.3107 - val_loss: 0.3153\n",
      "Epoch 7/150\n",
      "3292/3292 [==============================] - 0s 115us/step - loss: 0.3039 - val_loss: 0.2983\n",
      "Epoch 8/150\n",
      "3292/3292 [==============================] - 0s 99us/step - loss: 0.2874 - val_loss: 0.2818\n",
      "Epoch 9/150\n",
      "3292/3292 [==============================] - 0s 95us/step - loss: 0.2694 - val_loss: 0.2739\n",
      "Epoch 10/150\n",
      "3292/3292 [==============================] - 0s 108us/step - loss: 0.2632 - val_loss: 0.2619\n",
      "Epoch 11/150\n",
      "3292/3292 [==============================] - 0s 112us/step - loss: 0.2518 - val_loss: 0.2530\n",
      "Epoch 12/150\n",
      "3292/3292 [==============================] - 0s 115us/step - loss: 0.2459 - val_loss: 0.2528\n",
      "Epoch 13/150\n",
      "3292/3292 [==============================] - 0s 116us/step - loss: 0.2423 - val_loss: 0.2382\n",
      "Epoch 14/150\n",
      "3292/3292 [==============================] - 0s 99us/step - loss: 0.2344 - val_loss: 0.2369\n",
      "Epoch 15/150\n",
      "3292/3292 [==============================] - 0s 99us/step - loss: 0.2261 - val_loss: 0.2322\n",
      "Epoch 16/150\n",
      "3292/3292 [==============================] - 0s 116us/step - loss: 0.2185 - val_loss: 0.2056\n",
      "Epoch 17/150\n",
      "3292/3292 [==============================] - 0s 107us/step - loss: 0.2109 - val_loss: 0.2011\n",
      "Epoch 18/150\n",
      "3292/3292 [==============================] - 0s 102us/step - loss: 0.2059 - val_loss: 0.2055\n",
      "Epoch 19/150\n",
      "3292/3292 [==============================] - 0s 117us/step - loss: 0.2019 - val_loss: 0.2057\n",
      "Epoch 20/150\n",
      "3292/3292 [==============================] - 0s 117us/step - loss: 0.1947 - val_loss: 0.1961\n",
      "Epoch 21/150\n",
      "3292/3292 [==============================] - 0s 118us/step - loss: 0.1933 - val_loss: 0.1911\n",
      "Epoch 22/150\n",
      "3292/3292 [==============================] - 0s 110us/step - loss: 0.1911 - val_loss: 0.1990\n",
      "Epoch 23/150\n",
      "3292/3292 [==============================] - 0s 117us/step - loss: 0.1919 - val_loss: 0.1837\n",
      "Epoch 24/150\n",
      "3292/3292 [==============================] - 0s 108us/step - loss: 0.1889 - val_loss: 0.1861\n",
      "Epoch 25/150\n",
      "3292/3292 [==============================] - 0s 117us/step - loss: 0.1811 - val_loss: 0.1825\n",
      "Epoch 26/150\n",
      "3292/3292 [==============================] - 0s 117us/step - loss: 0.1855 - val_loss: 0.1877\n",
      "Epoch 27/150\n",
      "3292/3292 [==============================] - 0s 98us/step - loss: 0.1821 - val_loss: 0.1784\n",
      "Epoch 28/150\n",
      "3292/3292 [==============================] - 0s 111us/step - loss: 0.1796 - val_loss: 0.1809\n",
      "Epoch 29/150\n",
      "3292/3292 [==============================] - 0s 112us/step - loss: 0.1822 - val_loss: 0.1895\n",
      "Epoch 30/150\n",
      "3292/3292 [==============================] - 0s 118us/step - loss: 0.1809 - val_loss: 0.1823\n",
      "Epoch 31/150\n",
      "3292/3292 [==============================] - 0s 117us/step - loss: 0.1768 - val_loss: 0.1687\n",
      "Epoch 32/150\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3292/3292 [==============================] - 0s 117us/step - loss: 0.1738 - val_loss: 0.1800\n",
      "Epoch 33/150\n",
      "3292/3292 [==============================] - 0s 117us/step - loss: 0.1758 - val_loss: 0.1772\n",
      "Epoch 34/150\n",
      "3292/3292 [==============================] - 0s 117us/step - loss: 0.1737 - val_loss: 0.1758\n",
      "Epoch 35/150\n",
      "3292/3292 [==============================] - 0s 117us/step - loss: 0.1725 - val_loss: 0.1818\n",
      "Evaluating model with testing data...\n",
      "684/684 [==============================] - 0s 17us/step\n",
      "Getting distribution of predictions and covariance matrix...\n",
      "      1 of 20\n",
      "      2 of 20\n",
      "      3 of 20\n",
      "      4 of 20\n",
      "      5 of 20\n",
      "      6 of 20\n",
      "      7 of 20\n",
      "      8 of 20\n",
      "      9 of 20\n",
      "      10 of 20\n",
      "      11 of 20\n",
      "      12 of 20\n",
      "      13 of 20\n",
      "      14 of 20\n",
      "      15 of 20\n",
      "      16 of 20\n",
      "      17 of 20\n",
      "      18 of 20\n",
      "      19 of 20\n",
      "      20 of 20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|          | 0/20 [00:00<?, ?it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing ensemble means...\n",
      "Computing mean squared error...\n",
      "Getting distribution of predictions...\n",
      "      1 of 20\n",
      "1600/1600 [==============================] - 0s 28us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  5%|▌         | 1/20 [00:29<09:15, 29.25s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      2 of 20\n",
      "1600/1600 [==============================] - 0s 29us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 10%|█         | 2/20 [00:59<08:49, 29.41s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      3 of 20\n",
      "1600/1600 [==============================] - 0s 29us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 15%|█▌        | 3/20 [01:28<08:19, 29.40s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      4 of 20\n",
      "1600/1600 [==============================] - 0s 30us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 20%|██        | 4/20 [01:58<07:51, 29.49s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      5 of 20\n",
      "1600/1600 [==============================] - 0s 32us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 25%|██▌       | 5/20 [02:27<07:22, 29.50s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      6 of 20\n",
      "1600/1600 [==============================] - 0s 28us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 30%|███       | 6/20 [02:57<06:55, 29.64s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      7 of 20\n",
      "1600/1600 [==============================] - 0s 29us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 35%|███▌      | 7/20 [03:27<06:25, 29.66s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      8 of 20\n",
      "1600/1600 [==============================] - 0s 29us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 40%|████      | 8/20 [03:56<05:55, 29.59s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      9 of 20\n",
      "1600/1600 [==============================] - 0s 30us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 45%|████▌     | 9/20 [04:26<05:25, 29.60s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      10 of 20\n",
      "1600/1600 [==============================] - 0s 30us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 50%|█████     | 10/20 [04:56<04:56, 29.62s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      11 of 20\n",
      "1600/1600 [==============================] - 0s 29us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 55%|█████▌    | 11/20 [05:25<04:26, 29.63s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      12 of 20\n",
      "1600/1600 [==============================] - 0s 29us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 60%|██████    | 12/20 [05:55<03:56, 29.60s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      13 of 20\n",
      "1600/1600 [==============================] - 0s 30us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 65%|██████▌   | 13/20 [06:24<03:27, 29.64s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      14 of 20\n",
      "1600/1600 [==============================] - 0s 30us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 70%|███████   | 14/20 [06:54<02:58, 29.70s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      15 of 20\n",
      "1600/1600 [==============================] - 0s 30us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 75%|███████▌  | 15/20 [07:24<02:28, 29.70s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      16 of 20\n",
      "1600/1600 [==============================] - 0s 29us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 80%|████████  | 16/20 [07:54<01:59, 29.79s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      17 of 20\n",
      "1600/1600 [==============================] - 0s 29us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 85%|████████▌ | 17/20 [08:23<01:28, 29.64s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      18 of 20\n",
      "1600/1600 [==============================] - 0s 29us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 90%|█████████ | 18/20 [08:53<00:59, 29.70s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      19 of 20\n",
      "1600/1600 [==============================] - 0s 30us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 95%|█████████▌| 19/20 [09:23<00:29, 29.76s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      20 of 20\n",
      "1600/1600 [==============================] - 0s 29us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 20/20 [09:53<00:00, 29.66s/it]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing ensemble predictions...\n",
      "Iteration 21\n",
      "Train on 3432 samples, validate on 714 samples\n",
      "Epoch 1/150\n",
      "3432/3432 [==============================] - 0s 118us/step - loss: 0.4817 - val_loss: 0.3626\n",
      "Epoch 2/150\n",
      "3432/3432 [==============================] - 0s 68us/step - loss: 0.3102 - val_loss: 0.2837\n",
      "Epoch 3/150\n",
      "3432/3432 [==============================] - 0s 115us/step - loss: 0.2508 - val_loss: 0.2221\n",
      "Epoch 4/150\n",
      "3432/3432 [==============================] - 0s 115us/step - loss: 0.2121 - val_loss: 0.2121\n",
      "Epoch 5/150\n",
      "3432/3432 [==============================] - 0s 116us/step - loss: 0.1937 - val_loss: 0.1911\n",
      "Epoch 6/150\n",
      "3432/3432 [==============================] - 0s 115us/step - loss: 0.1836 - val_loss: 0.1768\n",
      "Epoch 7/150\n",
      "3432/3432 [==============================] - 0s 115us/step - loss: 0.1695 - val_loss: 0.1684\n",
      "Epoch 8/150\n",
      "3432/3432 [==============================] - 0s 114us/step - loss: 0.1670 - val_loss: 0.1683\n",
      "Epoch 9/150\n",
      "3432/3432 [==============================] - 0s 115us/step - loss: 0.1571 - val_loss: 0.1525\n",
      "Epoch 10/150\n",
      "3432/3432 [==============================] - 0s 79us/step - loss: 0.1575 - val_loss: 0.1496\n",
      "Epoch 11/150\n",
      "3432/3432 [==============================] - 0s 116us/step - loss: 0.1535 - val_loss: 0.1492\n",
      "Epoch 12/150\n",
      "3432/3432 [==============================] - 0s 115us/step - loss: 0.1481 - val_loss: 0.1526\n",
      "Epoch 13/150\n",
      "3432/3432 [==============================] - 0s 109us/step - loss: 0.1446 - val_loss: 0.1437\n",
      "Epoch 14/150\n",
      "3432/3432 [==============================] - 0s 114us/step - loss: 0.1411 - val_loss: 0.1365\n",
      "Epoch 15/150\n",
      "3432/3432 [==============================] - 0s 107us/step - loss: 0.1398 - val_loss: 0.1383\n",
      "Epoch 16/150\n",
      "3432/3432 [==============================] - 0s 114us/step - loss: 0.1364 - val_loss: 0.1322\n",
      "Epoch 17/150\n",
      "3432/3432 [==============================] - 0s 111us/step - loss: 0.1346 - val_loss: 0.1300\n",
      "Epoch 18/150\n",
      "3432/3432 [==============================] - 0s 115us/step - loss: 0.1303 - val_loss: 0.1312\n",
      "Epoch 19/150\n",
      "3432/3432 [==============================] - 0s 115us/step - loss: 0.1289 - val_loss: 0.1242\n",
      "Epoch 20/150\n",
      "3432/3432 [==============================] - 0s 115us/step - loss: 0.1252 - val_loss: 0.1270\n",
      "Epoch 21/150\n",
      "3432/3432 [==============================] - 0s 114us/step - loss: 0.1201 - val_loss: 0.1207\n",
      "Epoch 22/150\n",
      "3432/3432 [==============================] - 0s 107us/step - loss: 0.1236 - val_loss: 0.1219\n",
      "Epoch 23/150\n",
      "3432/3432 [==============================] - 0s 114us/step - loss: 0.1203 - val_loss: 0.1185\n",
      "Epoch 24/150\n",
      "3432/3432 [==============================] - 0s 107us/step - loss: 0.1166 - val_loss: 0.1164\n",
      "Epoch 25/150\n",
      "3432/3432 [==============================] - 0s 114us/step - loss: 0.1136 - val_loss: 0.1174\n",
      "Epoch 26/150\n",
      "3432/3432 [==============================] - 0s 114us/step - loss: 0.1160 - val_loss: 0.1090\n",
      "Epoch 27/150\n",
      "3432/3432 [==============================] - 0s 102us/step - loss: 0.1148 - val_loss: 0.1212\n",
      "Epoch 28/150\n",
      "3432/3432 [==============================] - 0s 114us/step - loss: 0.1106 - val_loss: 0.1129\n",
      "Epoch 29/150\n",
      "3432/3432 [==============================] - 0s 109us/step - loss: 0.1090 - val_loss: 0.1081\n",
      "Epoch 30/150\n",
      "3432/3432 [==============================] - 0s 114us/step - loss: 0.1092 - val_loss: 0.1065\n",
      "Epoch 31/150\n",
      "3432/3432 [==============================] - 0s 114us/step - loss: 0.1089 - val_loss: 0.1105\n",
      "Epoch 32/150\n",
      "3432/3432 [==============================] - 0s 108us/step - loss: 0.1072 - val_loss: 0.1059\n",
      "Epoch 33/150\n",
      "3432/3432 [==============================] - 0s 115us/step - loss: 0.1064 - val_loss: 0.1071\n",
      "Epoch 34/150\n",
      "3432/3432 [==============================] - 0s 114us/step - loss: 0.1038 - val_loss: 0.1047\n",
      "Epoch 35/150\n",
      "3432/3432 [==============================] - 0s 109us/step - loss: 0.1019 - val_loss: 0.0989\n",
      "Epoch 36/150\n",
      "3432/3432 [==============================] - 0s 115us/step - loss: 0.1016 - val_loss: 0.1084\n",
      "Epoch 37/150\n",
      "3432/3432 [==============================] - 0s 115us/step - loss: 0.0998 - val_loss: 0.0949\n",
      "Epoch 38/150\n",
      "3432/3432 [==============================] - 0s 100us/step - loss: 0.0991 - val_loss: 0.1034\n",
      "Epoch 39/150\n",
      "3432/3432 [==============================] - 0s 109us/step - loss: 0.0977 - val_loss: 0.0960\n",
      "Epoch 40/150\n",
      "3432/3432 [==============================] - 0s 95us/step - loss: 0.0947 - val_loss: 0.0925\n",
      "Epoch 41/150\n",
      "3432/3432 [==============================] - 0s 108us/step - loss: 0.0947 - val_loss: 0.0922\n",
      "Epoch 42/150\n",
      "3432/3432 [==============================] - 0s 108us/step - loss: 0.0966 - val_loss: 0.0981\n",
      "Epoch 43/150\n",
      "3432/3432 [==============================] - 0s 100us/step - loss: 0.0947 - val_loss: 0.0937\n",
      "Epoch 44/150\n",
      "3432/3432 [==============================] - 0s 102us/step - loss: 0.0939 - val_loss: 0.0950\n",
      "Epoch 45/150\n",
      "3432/3432 [==============================] - 0s 106us/step - loss: 0.0952 - val_loss: 0.1011\n",
      "Evaluating model with testing data...\n",
      "714/714 [==============================] - 0s 17us/step\n",
      "Getting distribution of predictions and covariance matrix...\n",
      "      1 of 20\n",
      "      2 of 20\n",
      "      3 of 20\n",
      "      4 of 20\n",
      "      5 of 20\n",
      "      6 of 20\n",
      "      7 of 20\n",
      "      8 of 20\n",
      "      9 of 20\n",
      "      10 of 20\n",
      "      11 of 20\n",
      "      12 of 20\n",
      "      13 of 20\n",
      "      14 of 20\n",
      "      15 of 20\n",
      "      16 of 20\n",
      "      17 of 20\n",
      "      18 of 20\n",
      "      19 of 20\n",
      "      20 of 20\n",
      "Computing ensemble means...\n",
      "Computing mean squared error...\n",
      "Iteration 22\n",
      "Train on 3572 samples, validate on 744 samples\n",
      "Epoch 1/150\n",
      "3572/3572 [==============================] - 0s 128us/step - loss: 0.5535 - val_loss: 0.4553\n",
      "Epoch 2/150\n",
      "3572/3572 [==============================] - 0s 76us/step - loss: 0.3907 - val_loss: 0.3429\n",
      "Epoch 3/150\n",
      "3572/3572 [==============================] - 0s 113us/step - loss: 0.3022 - val_loss: 0.2737\n",
      "Epoch 4/150\n",
      "3572/3572 [==============================] - 0s 107us/step - loss: 0.2537 - val_loss: 0.2436\n",
      "Epoch 5/150\n",
      "3572/3572 [==============================] - 0s 102us/step - loss: 0.2277 - val_loss: 0.2240\n",
      "Epoch 6/150\n",
      "3572/3572 [==============================] - 0s 114us/step - loss: 0.2121 - val_loss: 0.2100\n",
      "Epoch 7/150\n",
      "3572/3572 [==============================] - 0s 114us/step - loss: 0.2038 - val_loss: 0.2080\n",
      "Epoch 8/150\n",
      "3572/3572 [==============================] - 0s 102us/step - loss: 0.1937 - val_loss: 0.1837\n",
      "Epoch 9/150\n",
      "3572/3572 [==============================] - 0s 113us/step - loss: 0.1881 - val_loss: 0.1844\n",
      "Epoch 10/150\n",
      "3572/3572 [==============================] - 0s 101us/step - loss: 0.1810 - val_loss: 0.1774\n",
      "Epoch 11/150\n",
      "3572/3572 [==============================] - 0s 108us/step - loss: 0.1800 - val_loss: 0.1883\n",
      "Epoch 12/150\n",
      "3572/3572 [==============================] - 0s 111us/step - loss: 0.1742 - val_loss: 0.1691\n",
      "Epoch 13/150\n",
      "3572/3572 [==============================] - 0s 107us/step - loss: 0.1759 - val_loss: 0.1673\n",
      "Epoch 14/150\n",
      "3572/3572 [==============================] - 0s 110us/step - loss: 0.1650 - val_loss: 0.1691\n",
      "Epoch 15/150\n",
      "3572/3572 [==============================] - 0s 102us/step - loss: 0.1629 - val_loss: 0.1615\n",
      "Epoch 16/150\n",
      "3572/3572 [==============================] - 0s 94us/step - loss: 0.1608 - val_loss: 0.1664\n",
      "Epoch 17/150\n",
      "3572/3572 [==============================] - 0s 112us/step - loss: 0.1570 - val_loss: 0.1563\n",
      "Epoch 18/150\n",
      "3572/3572 [==============================] - 0s 97us/step - loss: 0.1557 - val_loss: 0.1567\n",
      "Epoch 19/150\n",
      "3572/3572 [==============================] - 0s 60us/step - loss: 0.1485 - val_loss: 0.1411\n",
      "Epoch 20/150\n",
      "3572/3572 [==============================] - 0s 59us/step - loss: 0.1479 - val_loss: 0.1485\n",
      "Epoch 21/150\n",
      "3572/3572 [==============================] - 0s 59us/step - loss: 0.1464 - val_loss: 0.1461\n",
      "Epoch 22/150\n",
      "3572/3572 [==============================] - 0s 60us/step - loss: 0.1452 - val_loss: 0.1516\n",
      "Epoch 23/150\n",
      "3572/3572 [==============================] - 0s 59us/step - loss: 0.1464 - val_loss: 0.1404\n",
      "Epoch 24/150\n",
      "3572/3572 [==============================] - 0s 60us/step - loss: 0.1405 - val_loss: 0.1392\n",
      "Epoch 25/150\n",
      "3572/3572 [==============================] - 0s 86us/step - loss: 0.1387 - val_loss: 0.1456\n",
      "Epoch 26/150\n",
      "3572/3572 [==============================] - 0s 96us/step - loss: 0.1378 - val_loss: 0.1441\n",
      "Epoch 27/150\n",
      "3572/3572 [==============================] - 0s 102us/step - loss: 0.1348 - val_loss: 0.1397\n",
      "Epoch 28/150\n",
      "3572/3572 [==============================] - 0s 113us/step - loss: 0.1372 - val_loss: 0.1273\n",
      "Epoch 29/150\n",
      "3572/3572 [==============================] - 0s 114us/step - loss: 0.1332 - val_loss: 0.1339\n",
      "Epoch 30/150\n",
      "3572/3572 [==============================] - 0s 110us/step - loss: 0.1294 - val_loss: 0.1373\n",
      "Epoch 31/150\n",
      "3572/3572 [==============================] - 0s 114us/step - loss: 0.1316 - val_loss: 0.1352\n",
      "Epoch 32/150\n",
      "3572/3572 [==============================] - 0s 113us/step - loss: 0.1306 - val_loss: 0.1301\n",
      "Evaluating model with testing data...\n",
      "744/744 [==============================] - 0s 17us/step\n",
      "Getting distribution of predictions and covariance matrix...\n",
      "      1 of 20\n",
      "      2 of 20\n",
      "      3 of 20\n",
      "      4 of 20\n",
      "      5 of 20\n",
      "      6 of 20\n",
      "      7 of 20\n",
      "      8 of 20\n",
      "      9 of 20\n",
      "      10 of 20\n",
      "      11 of 20\n",
      "      12 of 20\n",
      "      13 of 20\n",
      "      14 of 20\n",
      "      15 of 20\n",
      "      16 of 20\n",
      "      17 of 20\n",
      "      18 of 20\n",
      "      19 of 20\n",
      "      20 of 20\n",
      "Computing ensemble means...\n",
      "Computing mean squared error...\n",
      "Iteration 23\n",
      "Train on 3712 samples, validate on 774 samples\n",
      "Epoch 1/150\n",
      "3712/3712 [==============================] - 0s 108us/step - loss: 0.9491 - val_loss: 0.4890\n",
      "Epoch 2/150\n",
      "3712/3712 [==============================] - 0s 98us/step - loss: 0.4560 - val_loss: 0.4415\n",
      "Epoch 3/150\n",
      "3712/3712 [==============================] - 0s 114us/step - loss: 0.4025 - val_loss: 0.3843\n",
      "Epoch 4/150\n",
      "3712/3712 [==============================] - 0s 115us/step - loss: 0.3488 - val_loss: 0.3472\n",
      "Epoch 5/150\n",
      "3712/3712 [==============================] - 0s 115us/step - loss: 0.3207 - val_loss: 0.3224\n",
      "Epoch 6/150\n",
      "3712/3712 [==============================] - 0s 115us/step - loss: 0.2948 - val_loss: 0.3026\n",
      "Epoch 7/150\n",
      "3712/3712 [==============================] - 0s 115us/step - loss: 0.2829 - val_loss: 0.2780\n",
      "Epoch 8/150\n",
      "3712/3712 [==============================] - 0s 114us/step - loss: 0.2704 - val_loss: 0.2833\n",
      "Epoch 9/150\n",
      "3712/3712 [==============================] - 0s 104us/step - loss: 0.2615 - val_loss: 0.2727\n",
      "Epoch 10/150\n",
      "3712/3712 [==============================] - 0s 115us/step - loss: 0.2500 - val_loss: 0.2544\n",
      "Epoch 11/150\n",
      "3712/3712 [==============================] - 0s 103us/step - loss: 0.2426 - val_loss: 0.2416\n",
      "Epoch 12/150\n",
      "3712/3712 [==============================] - 0s 115us/step - loss: 0.2403 - val_loss: 0.2522\n",
      "Epoch 13/150\n",
      "3712/3712 [==============================] - 0s 107us/step - loss: 0.2316 - val_loss: 0.2382\n",
      "Epoch 14/150\n",
      "3712/3712 [==============================] - 0s 113us/step - loss: 0.2253 - val_loss: 0.2515\n",
      "Epoch 15/150\n",
      "3712/3712 [==============================] - 0s 107us/step - loss: 0.2220 - val_loss: 0.2255\n",
      "Epoch 16/150\n",
      "3712/3712 [==============================] - 0s 114us/step - loss: 0.2220 - val_loss: 0.2167\n",
      "Epoch 17/150\n",
      "3712/3712 [==============================] - 0s 116us/step - loss: 0.2206 - val_loss: 0.2275\n",
      "Epoch 18/150\n",
      "3712/3712 [==============================] - 0s 110us/step - loss: 0.2111 - val_loss: 0.2126\n",
      "Epoch 19/150\n",
      "3712/3712 [==============================] - 0s 110us/step - loss: 0.2104 - val_loss: 0.2094\n",
      "Epoch 20/150\n",
      "3712/3712 [==============================] - 0s 114us/step - loss: 0.2087 - val_loss: 0.2124\n",
      "Epoch 21/150\n",
      "3712/3712 [==============================] - 0s 115us/step - loss: 0.2015 - val_loss: 0.2026\n",
      "Epoch 22/150\n",
      "3712/3712 [==============================] - 0s 99us/step - loss: 0.1939 - val_loss: 0.2057\n",
      "Epoch 23/150\n",
      "3712/3712 [==============================] - 0s 116us/step - loss: 0.2004 - val_loss: 0.2069\n",
      "Epoch 24/150\n",
      "3712/3712 [==============================] - 0s 115us/step - loss: 0.1949 - val_loss: 0.2041\n",
      "Epoch 25/150\n",
      "3712/3712 [==============================] - 0s 103us/step - loss: 0.1982 - val_loss: 0.1927\n",
      "Epoch 26/150\n",
      "3712/3712 [==============================] - 0s 108us/step - loss: 0.1904 - val_loss: 0.2028\n",
      "Epoch 27/150\n",
      "3712/3712 [==============================] - 0s 115us/step - loss: 0.1891 - val_loss: 0.1911\n",
      "Epoch 28/150\n",
      "3712/3712 [==============================] - 0s 105us/step - loss: 0.1883 - val_loss: 0.1965\n",
      "Epoch 29/150\n",
      "3712/3712 [==============================] - 0s 111us/step - loss: 0.1844 - val_loss: 0.1880\n",
      "Epoch 30/150\n",
      "3712/3712 [==============================] - 0s 114us/step - loss: 0.1818 - val_loss: 0.1758\n",
      "Epoch 31/150\n",
      "3712/3712 [==============================] - 0s 102us/step - loss: 0.1796 - val_loss: 0.1794\n",
      "Epoch 32/150\n",
      "3712/3712 [==============================] - 0s 103us/step - loss: 0.1756 - val_loss: 0.1898\n",
      "Epoch 33/150\n",
      "3712/3712 [==============================] - 0s 112us/step - loss: 0.1757 - val_loss: 0.1830\n",
      "Epoch 34/150\n",
      "3712/3712 [==============================] - 0s 115us/step - loss: 0.1735 - val_loss: 0.1759\n",
      "Evaluating model with testing data...\n",
      "774/774 [==============================] - 0s 16us/step\n",
      "Getting distribution of predictions and covariance matrix...\n",
      "      1 of 20\n",
      "      2 of 20\n",
      "      3 of 20\n",
      "      4 of 20\n",
      "      5 of 20\n",
      "      6 of 20\n",
      "      7 of 20\n",
      "      8 of 20\n",
      "      9 of 20\n",
      "      10 of 20\n",
      "      11 of 20\n",
      "      12 of 20\n",
      "      13 of 20\n",
      "      14 of 20\n",
      "      15 of 20\n",
      "      16 of 20\n",
      "      17 of 20\n",
      "      18 of 20\n",
      "      19 of 20\n",
      "      20 of 20\n",
      "Computing ensemble means...\n",
      "Computing mean squared error...\n",
      "Iteration 24\n",
      "Train on 3852 samples, validate on 804 samples\n",
      "Epoch 1/150\n",
      "3852/3852 [==============================] - 0s 103us/step - loss: 0.5804 - val_loss: 0.4352\n",
      "Epoch 2/150\n",
      "3852/3852 [==============================] - 0s 100us/step - loss: 0.3893 - val_loss: 0.3701\n",
      "Epoch 3/150\n",
      "3852/3852 [==============================] - 0s 102us/step - loss: 0.3403 - val_loss: 0.3120\n",
      "Epoch 4/150\n",
      "3852/3852 [==============================] - 0s 113us/step - loss: 0.2872 - val_loss: 0.2679\n",
      "Epoch 5/150\n",
      "3852/3852 [==============================] - 0s 104us/step - loss: 0.2576 - val_loss: 0.2411\n",
      "Epoch 6/150\n",
      "3852/3852 [==============================] - 0s 109us/step - loss: 0.2316 - val_loss: 0.2237\n",
      "Epoch 7/150\n",
      "3852/3852 [==============================] - 0s 117us/step - loss: 0.2206 - val_loss: 0.2165\n",
      "Epoch 8/150\n",
      "3852/3852 [==============================] - 0s 100us/step - loss: 0.2103 - val_loss: 0.2126\n",
      "Epoch 9/150\n",
      "3852/3852 [==============================] - 0s 117us/step - loss: 0.2008 - val_loss: 0.2124\n",
      "Epoch 10/150\n",
      "3852/3852 [==============================] - 0s 106us/step - loss: 0.1991 - val_loss: 0.1985\n",
      "Epoch 11/150\n",
      "3852/3852 [==============================] - 0s 110us/step - loss: 0.1920 - val_loss: 0.1997\n",
      "Epoch 12/150\n",
      "3852/3852 [==============================] - 0s 117us/step - loss: 0.1907 - val_loss: 0.1924\n",
      "Epoch 13/150\n",
      "3852/3852 [==============================] - 0s 104us/step - loss: 0.1862 - val_loss: 0.1881\n",
      "Epoch 14/150\n",
      "3852/3852 [==============================] - 0s 116us/step - loss: 0.1832 - val_loss: 0.1792\n",
      "Epoch 15/150\n",
      "3852/3852 [==============================] - 0s 117us/step - loss: 0.1761 - val_loss: 0.1814\n",
      "Epoch 16/150\n",
      "3852/3852 [==============================] - 0s 105us/step - loss: 0.1751 - val_loss: 0.1745\n",
      "Epoch 17/150\n",
      "3852/3852 [==============================] - 0s 117us/step - loss: 0.1705 - val_loss: 0.1743\n",
      "Epoch 18/150\n",
      "3852/3852 [==============================] - 0s 110us/step - loss: 0.1687 - val_loss: 0.1706\n",
      "Epoch 19/150\n",
      "3852/3852 [==============================] - 0s 101us/step - loss: 0.1624 - val_loss: 0.1698\n",
      "Epoch 20/150\n",
      "3852/3852 [==============================] - 0s 109us/step - loss: 0.1631 - val_loss: 0.1654\n",
      "Epoch 21/150\n",
      "3852/3852 [==============================] - 0s 112us/step - loss: 0.1619 - val_loss: 0.1550\n",
      "Epoch 22/150\n",
      "3852/3852 [==============================] - 0s 118us/step - loss: 0.1597 - val_loss: 0.1504\n",
      "Epoch 23/150\n",
      "3852/3852 [==============================] - 0s 117us/step - loss: 0.1608 - val_loss: 0.1681\n",
      "Epoch 24/150\n",
      "3852/3852 [==============================] - 0s 106us/step - loss: 0.1571 - val_loss: 0.1568\n",
      "Epoch 25/150\n",
      "3852/3852 [==============================] - 0s 116us/step - loss: 0.1524 - val_loss: 0.1546\n",
      "Epoch 26/150\n",
      "3852/3852 [==============================] - 0s 104us/step - loss: 0.1540 - val_loss: 0.1688\n",
      "Evaluating model with testing data...\n",
      "804/804 [==============================] - 0s 16us/step\n",
      "Getting distribution of predictions and covariance matrix...\n",
      "      1 of 20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      2 of 20\n",
      "      3 of 20\n",
      "      4 of 20\n",
      "      5 of 20\n",
      "      6 of 20\n",
      "      7 of 20\n",
      "      8 of 20\n",
      "      9 of 20\n",
      "      10 of 20\n",
      "      11 of 20\n",
      "      12 of 20\n",
      "      13 of 20\n",
      "      14 of 20\n",
      "      15 of 20\n",
      "      16 of 20\n",
      "      17 of 20\n",
      "      18 of 20\n",
      "      19 of 20\n",
      "      20 of 20\n",
      "Computing ensemble means...\n",
      "Computing mean squared error...\n",
      "Iteration 25\n",
      "Train on 3992 samples, validate on 834 samples\n",
      "Epoch 1/150\n",
      "3992/3992 [==============================] - 1s 128us/step - loss: 0.5898 - val_loss: 0.4589\n",
      "Epoch 2/150\n",
      "3992/3992 [==============================] - 0s 89us/step - loss: 0.4222 - val_loss: 0.3914\n",
      "Epoch 3/150\n",
      "3992/3992 [==============================] - 0s 118us/step - loss: 0.3584 - val_loss: 0.3459\n",
      "Epoch 4/150\n",
      "3992/3992 [==============================] - 0s 118us/step - loss: 0.3214 - val_loss: 0.3106\n",
      "Epoch 5/150\n",
      "3992/3992 [==============================] - 0s 118us/step - loss: 0.3049 - val_loss: 0.3036\n",
      "Epoch 6/150\n",
      "3992/3992 [==============================] - 0s 117us/step - loss: 0.2858 - val_loss: 0.2836\n",
      "Epoch 7/150\n",
      "3992/3992 [==============================] - 0s 104us/step - loss: 0.2778 - val_loss: 0.2788\n",
      "Epoch 8/150\n",
      "3992/3992 [==============================] - 0s 118us/step - loss: 0.2674 - val_loss: 0.2712\n",
      "Epoch 9/150\n",
      "3992/3992 [==============================] - 0s 118us/step - loss: 0.2571 - val_loss: 0.2630\n",
      "Epoch 10/150\n",
      "3992/3992 [==============================] - 0s 118us/step - loss: 0.2519 - val_loss: 0.2451\n",
      "Epoch 11/150\n",
      "3992/3992 [==============================] - 0s 118us/step - loss: 0.2391 - val_loss: 0.2331\n",
      "Epoch 12/150\n",
      "3992/3992 [==============================] - 0s 117us/step - loss: 0.2317 - val_loss: 0.2312\n",
      "Epoch 13/150\n",
      "3992/3992 [==============================] - 0s 118us/step - loss: 0.2248 - val_loss: 0.2264\n",
      "Epoch 14/150\n",
      "3992/3992 [==============================] - 0s 118us/step - loss: 0.2152 - val_loss: 0.2184\n",
      "Epoch 15/150\n",
      "3992/3992 [==============================] - 0s 118us/step - loss: 0.2121 - val_loss: 0.2171\n",
      "Epoch 16/150\n",
      "3992/3992 [==============================] - 0s 117us/step - loss: 0.2106 - val_loss: 0.2076\n",
      "Epoch 17/150\n",
      "3992/3992 [==============================] - 0s 117us/step - loss: 0.2061 - val_loss: 0.2182\n",
      "Epoch 18/150\n",
      "3992/3992 [==============================] - 0s 118us/step - loss: 0.2013 - val_loss: 0.2122\n",
      "Epoch 19/150\n",
      "3992/3992 [==============================] - 0s 117us/step - loss: 0.1967 - val_loss: 0.2112\n",
      "Epoch 20/150\n",
      "3992/3992 [==============================] - 0s 117us/step - loss: 0.1994 - val_loss: 0.1962\n",
      "Epoch 21/150\n",
      "3992/3992 [==============================] - 0s 117us/step - loss: 0.1968 - val_loss: 0.1993\n",
      "Epoch 22/150\n",
      "3992/3992 [==============================] - 0s 119us/step - loss: 0.1907 - val_loss: 0.2012\n",
      "Epoch 23/150\n",
      "3992/3992 [==============================] - 0s 111us/step - loss: 0.1876 - val_loss: 0.1957\n",
      "Epoch 24/150\n",
      "3992/3992 [==============================] - 0s 114us/step - loss: 0.1899 - val_loss: 0.1950\n",
      "Epoch 25/150\n",
      "3992/3992 [==============================] - 0s 117us/step - loss: 0.1870 - val_loss: 0.1832\n",
      "Epoch 26/150\n",
      "3992/3992 [==============================] - 0s 117us/step - loss: 0.1843 - val_loss: 0.1764\n",
      "Epoch 27/150\n",
      "3992/3992 [==============================] - 0s 117us/step - loss: 0.1829 - val_loss: 0.1837\n",
      "Epoch 28/150\n",
      "3992/3992 [==============================] - 0s 117us/step - loss: 0.1804 - val_loss: 0.1824\n",
      "Epoch 29/150\n",
      "3992/3992 [==============================] - 0s 118us/step - loss: 0.1768 - val_loss: 0.1940\n",
      "Epoch 30/150\n",
      "3992/3992 [==============================] - 0s 117us/step - loss: 0.1727 - val_loss: 0.1827\n",
      "Evaluating model with testing data...\n",
      "834/834 [==============================] - 0s 16us/step\n",
      "Getting distribution of predictions and covariance matrix...\n",
      "      1 of 20\n",
      "      2 of 20\n",
      "      3 of 20\n",
      "      4 of 20\n",
      "      5 of 20\n",
      "      6 of 20\n",
      "      7 of 20\n",
      "      8 of 20\n",
      "      9 of 20\n",
      "      10 of 20\n",
      "      11 of 20\n",
      "      12 of 20\n",
      "      13 of 20\n",
      "      14 of 20\n",
      "      15 of 20\n",
      "      16 of 20\n",
      "      17 of 20\n",
      "      18 of 20\n",
      "      19 of 20\n",
      "      20 of 20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|          | 0/20 [00:00<?, ?it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing ensemble means...\n",
      "Computing mean squared error...\n",
      "Getting distribution of predictions...\n",
      "      1 of 20\n",
      "1600/1600 [==============================] - 0s 27us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  5%|▌         | 1/20 [00:29<09:18, 29.40s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      2 of 20\n",
      "1600/1600 [==============================] - 0s 29us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 10%|█         | 2/20 [00:58<08:48, 29.37s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      3 of 20\n",
      "1600/1600 [==============================] - 0s 29us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 15%|█▌        | 3/20 [01:28<08:19, 29.41s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      4 of 20\n",
      "1600/1600 [==============================] - 0s 29us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 20%|██        | 4/20 [01:57<07:50, 29.38s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      5 of 20\n",
      "1600/1600 [==============================] - 0s 29us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 25%|██▌       | 5/20 [02:27<07:21, 29.45s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      6 of 20\n",
      "1600/1600 [==============================] - 0s 28us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 30%|███       | 6/20 [02:56<06:53, 29.53s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      7 of 20\n",
      "1600/1600 [==============================] - 0s 28us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 35%|███▌      | 7/20 [03:26<06:23, 29.47s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      8 of 20\n",
      "1600/1600 [==============================] - 0s 30us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 40%|████      | 8/20 [03:55<05:53, 29.46s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      9 of 20\n",
      "1600/1600 [==============================] - 0s 29us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 45%|████▌     | 9/20 [04:25<05:24, 29.54s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      10 of 20\n",
      "1600/1600 [==============================] - 0s 30us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 50%|█████     | 10/20 [04:54<04:55, 29.51s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      11 of 20\n",
      "1600/1600 [==============================] - 0s 30us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 55%|█████▌    | 11/20 [05:24<04:25, 29.52s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      12 of 20\n",
      "1600/1600 [==============================] - 0s 29us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 60%|██████    | 12/20 [05:54<03:57, 29.66s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      13 of 20\n",
      "1600/1600 [==============================] - 0s 30us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 65%|██████▌   | 13/20 [06:23<03:27, 29.59s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      14 of 20\n",
      "1600/1600 [==============================] - 0s 28us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 70%|███████   | 14/20 [06:53<02:57, 29.61s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      15 of 20\n",
      "1600/1600 [==============================] - 0s 29us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 75%|███████▌  | 15/20 [07:22<02:27, 29.59s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      16 of 20\n",
      "1600/1600 [==============================] - 0s 30us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 80%|████████  | 16/20 [07:52<01:58, 29.59s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      17 of 20\n",
      "1600/1600 [==============================] - 0s 47us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 85%|████████▌ | 17/20 [08:22<01:29, 29.73s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      18 of 20\n",
      "1600/1600 [==============================] - 0s 28us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 90%|█████████ | 18/20 [08:52<00:59, 29.72s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      19 of 20\n",
      "1600/1600 [==============================] - 0s 29us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 95%|█████████▌| 19/20 [09:21<00:29, 29.65s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      20 of 20\n",
      "1600/1600 [==============================] - 0s 29us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 20/20 [09:51<00:00, 29.58s/it]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing ensemble predictions...\n",
      "Iteration 26\n",
      "Train on 4132 samples, validate on 864 samples\n",
      "Epoch 1/150\n",
      "4132/4132 [==============================] - 1s 133us/step - loss: 0.6446 - val_loss: 0.4489\n",
      "Epoch 2/150\n",
      "4132/4132 [==============================] - 0s 98us/step - loss: 0.3992 - val_loss: 0.3848\n",
      "Epoch 3/150\n",
      "4132/4132 [==============================] - 0s 115us/step - loss: 0.3412 - val_loss: 0.3308\n",
      "Epoch 4/150\n",
      "4132/4132 [==============================] - 0s 117us/step - loss: 0.2946 - val_loss: 0.2835\n",
      "Epoch 5/150\n",
      "4132/4132 [==============================] - 0s 117us/step - loss: 0.2659 - val_loss: 0.2587\n",
      "Epoch 6/150\n",
      "4132/4132 [==============================] - 0s 116us/step - loss: 0.2512 - val_loss: 0.2538\n",
      "Epoch 7/150\n",
      "4132/4132 [==============================] - 0s 116us/step - loss: 0.2333 - val_loss: 0.2410\n",
      "Epoch 8/150\n",
      "4132/4132 [==============================] - 0s 115us/step - loss: 0.2231 - val_loss: 0.2249\n",
      "Epoch 9/150\n",
      "4132/4132 [==============================] - 0s 117us/step - loss: 0.2145 - val_loss: 0.2219\n",
      "Epoch 10/150\n",
      "4132/4132 [==============================] - 0s 115us/step - loss: 0.2066 - val_loss: 0.2131\n",
      "Epoch 11/150\n",
      "4132/4132 [==============================] - 0s 117us/step - loss: 0.1968 - val_loss: 0.1911\n",
      "Epoch 12/150\n",
      "4132/4132 [==============================] - 0s 116us/step - loss: 0.1897 - val_loss: 0.1862\n",
      "Epoch 13/150\n",
      "4132/4132 [==============================] - 0s 117us/step - loss: 0.1794 - val_loss: 0.1819\n",
      "Epoch 14/150\n",
      "4132/4132 [==============================] - 0s 117us/step - loss: 0.1755 - val_loss: 0.1831\n",
      "Epoch 15/150\n",
      "4132/4132 [==============================] - 0s 117us/step - loss: 0.1704 - val_loss: 0.1817\n",
      "Epoch 16/150\n",
      "4132/4132 [==============================] - 0s 117us/step - loss: 0.1698 - val_loss: 0.1766\n",
      "Epoch 17/150\n",
      "4132/4132 [==============================] - 0s 117us/step - loss: 0.1675 - val_loss: 0.1746\n",
      "Epoch 18/150\n",
      "4132/4132 [==============================] - 0s 106us/step - loss: 0.1600 - val_loss: 0.1681\n",
      "Epoch 19/150\n",
      "4132/4132 [==============================] - 0s 113us/step - loss: 0.1622 - val_loss: 0.1676\n",
      "Epoch 20/150\n",
      "4132/4132 [==============================] - 0s 117us/step - loss: 0.1610 - val_loss: 0.1649\n",
      "Epoch 21/150\n",
      "4132/4132 [==============================] - 0s 117us/step - loss: 0.1577 - val_loss: 0.1662\n",
      "Epoch 22/150\n",
      "4132/4132 [==============================] - 0s 117us/step - loss: 0.1557 - val_loss: 0.1575\n",
      "Epoch 23/150\n",
      "4132/4132 [==============================] - 0s 117us/step - loss: 0.1560 - val_loss: 0.1575\n",
      "Epoch 24/150\n",
      "4132/4132 [==============================] - 0s 116us/step - loss: 0.1535 - val_loss: 0.1546\n",
      "Epoch 25/150\n",
      "4132/4132 [==============================] - 0s 117us/step - loss: 0.1515 - val_loss: 0.1576\n",
      "Epoch 26/150\n",
      "4132/4132 [==============================] - 0s 117us/step - loss: 0.1475 - val_loss: 0.1591\n",
      "Epoch 27/150\n",
      "4132/4132 [==============================] - 0s 116us/step - loss: 0.1472 - val_loss: 0.1568\n",
      "Epoch 28/150\n",
      "4132/4132 [==============================] - 0s 112us/step - loss: 0.1463 - val_loss: 0.1521\n",
      "Epoch 29/150\n",
      "4132/4132 [==============================] - 0s 117us/step - loss: 0.1480 - val_loss: 0.1504\n",
      "Epoch 30/150\n",
      "4132/4132 [==============================] - 0s 116us/step - loss: 0.1483 - val_loss: 0.1442\n",
      "Epoch 31/150\n",
      "4132/4132 [==============================] - 0s 115us/step - loss: 0.1433 - val_loss: 0.1515\n",
      "Epoch 32/150\n",
      "4132/4132 [==============================] - 0s 116us/step - loss: 0.1435 - val_loss: 0.1440\n",
      "Epoch 33/150\n",
      "4132/4132 [==============================] - 0s 116us/step - loss: 0.1432 - val_loss: 0.1505\n",
      "Epoch 34/150\n",
      "4132/4132 [==============================] - 0s 115us/step - loss: 0.1415 - val_loss: 0.1434\n",
      "Epoch 35/150\n",
      "4132/4132 [==============================] - 0s 116us/step - loss: 0.1424 - val_loss: 0.1414\n",
      "Epoch 36/150\n",
      "4132/4132 [==============================] - 0s 107us/step - loss: 0.1412 - val_loss: 0.1429\n",
      "Epoch 37/150\n",
      "4132/4132 [==============================] - 0s 116us/step - loss: 0.1360 - val_loss: 0.1457\n",
      "Epoch 38/150\n",
      "4132/4132 [==============================] - 0s 116us/step - loss: 0.1378 - val_loss: 0.1499\n",
      "Epoch 39/150\n",
      "4132/4132 [==============================] - 0s 117us/step - loss: 0.1374 - val_loss: 0.1419\n",
      "Evaluating model with testing data...\n",
      "864/864 [==============================] - 0s 16us/step\n",
      "Getting distribution of predictions and covariance matrix...\n",
      "      1 of 20\n",
      "      2 of 20\n",
      "      3 of 20\n",
      "      4 of 20\n",
      "      5 of 20\n",
      "      6 of 20\n",
      "      7 of 20\n",
      "      8 of 20\n",
      "      9 of 20\n",
      "      10 of 20\n",
      "      11 of 20\n",
      "      12 of 20\n",
      "      13 of 20\n",
      "      14 of 20\n",
      "      15 of 20\n",
      "      16 of 20\n",
      "      17 of 20\n",
      "      18 of 20\n",
      "      19 of 20\n",
      "      20 of 20\n",
      "Computing ensemble means...\n",
      "Computing mean squared error...\n",
      "Iteration 27\n",
      "Train on 4272 samples, validate on 894 samples\n",
      "Epoch 1/150\n",
      "4272/4272 [==============================] - 0s 100us/step - loss: 0.6998 - val_loss: 0.3942\n",
      "Epoch 2/150\n",
      "4272/4272 [==============================] - 0s 99us/step - loss: 0.3669 - val_loss: 0.3511\n",
      "Epoch 3/150\n",
      "4272/4272 [==============================] - 0s 106us/step - loss: 0.3359 - val_loss: 0.3230\n",
      "Epoch 4/150\n",
      "4272/4272 [==============================] - 0s 110us/step - loss: 0.3074 - val_loss: 0.2980\n",
      "Epoch 5/150\n",
      "4272/4272 [==============================] - 0s 115us/step - loss: 0.2908 - val_loss: 0.2863\n",
      "Epoch 6/150\n",
      "4272/4272 [==============================] - 0s 103us/step - loss: 0.2716 - val_loss: 0.2706\n",
      "Epoch 7/150\n",
      "4272/4272 [==============================] - 0s 115us/step - loss: 0.2581 - val_loss: 0.2515\n",
      "Epoch 8/150\n",
      "4272/4272 [==============================] - 0s 97us/step - loss: 0.2523 - val_loss: 0.2490\n",
      "Epoch 9/150\n",
      "4272/4272 [==============================] - 0s 108us/step - loss: 0.2407 - val_loss: 0.2372\n",
      "Epoch 10/150\n",
      "4272/4272 [==============================] - 0s 115us/step - loss: 0.2354 - val_loss: 0.2385\n",
      "Epoch 11/150\n",
      "4272/4272 [==============================] - 0s 113us/step - loss: 0.2283 - val_loss: 0.2185\n",
      "Epoch 12/150\n",
      "4272/4272 [==============================] - 0s 107us/step - loss: 0.2278 - val_loss: 0.2200\n",
      "Epoch 13/150\n",
      "4272/4272 [==============================] - 0s 110us/step - loss: 0.2161 - val_loss: 0.2084\n",
      "Epoch 14/150\n",
      "4272/4272 [==============================] - 0s 115us/step - loss: 0.2123 - val_loss: 0.2165\n",
      "Epoch 15/150\n",
      "4272/4272 [==============================] - 0s 114us/step - loss: 0.2103 - val_loss: 0.2043\n",
      "Epoch 16/150\n",
      "4272/4272 [==============================] - 0s 99us/step - loss: 0.2063 - val_loss: 0.2004\n",
      "Epoch 17/150\n",
      "4272/4272 [==============================] - 0s 111us/step - loss: 0.1969 - val_loss: 0.2028\n",
      "Epoch 18/150\n",
      "4272/4272 [==============================] - 0s 111us/step - loss: 0.1996 - val_loss: 0.2031\n",
      "Epoch 19/150\n",
      "4272/4272 [==============================] - 0s 109us/step - loss: 0.1946 - val_loss: 0.1951\n",
      "Epoch 20/150\n",
      "4272/4272 [==============================] - 0s 100us/step - loss: 0.1913 - val_loss: 0.1891\n",
      "Epoch 21/150\n",
      "4272/4272 [==============================] - 0s 109us/step - loss: 0.1911 - val_loss: 0.1861\n",
      "Epoch 22/150\n",
      "4272/4272 [==============================] - 0s 109us/step - loss: 0.1885 - val_loss: 0.1950\n",
      "Epoch 23/150\n",
      "4272/4272 [==============================] - 0s 115us/step - loss: 0.1842 - val_loss: 0.1929\n",
      "Epoch 24/150\n",
      "4272/4272 [==============================] - 0s 106us/step - loss: 0.1811 - val_loss: 0.1757\n",
      "Epoch 25/150\n",
      "4272/4272 [==============================] - 0s 105us/step - loss: 0.1782 - val_loss: 0.1755\n",
      "Epoch 26/150\n",
      "4272/4272 [==============================] - 0s 110us/step - loss: 0.1751 - val_loss: 0.1745\n",
      "Epoch 27/150\n",
      "4272/4272 [==============================] - 0s 99us/step - loss: 0.1702 - val_loss: 0.1732\n",
      "Epoch 28/150\n",
      "4272/4272 [==============================] - 0s 115us/step - loss: 0.1713 - val_loss: 0.1735\n",
      "Epoch 29/150\n",
      "4272/4272 [==============================] - 0s 115us/step - loss: 0.1712 - val_loss: 0.1679\n",
      "Epoch 30/150\n",
      "4272/4272 [==============================] - 0s 106us/step - loss: 0.1678 - val_loss: 0.1737\n",
      "Epoch 31/150\n",
      "4272/4272 [==============================] - 0s 111us/step - loss: 0.1707 - val_loss: 0.1685\n",
      "Epoch 32/150\n",
      "4272/4272 [==============================] - 0s 91us/step - loss: 0.1676 - val_loss: 0.1647\n",
      "Epoch 33/150\n",
      "4272/4272 [==============================] - 0s 110us/step - loss: 0.1671 - val_loss: 0.1611\n",
      "Epoch 34/150\n",
      "4272/4272 [==============================] - 0s 115us/step - loss: 0.1618 - val_loss: 0.1573\n",
      "Epoch 35/150\n",
      "4272/4272 [==============================] - 0s 115us/step - loss: 0.1648 - val_loss: 0.1622\n",
      "Epoch 36/150\n",
      "4272/4272 [==============================] - 0s 115us/step - loss: 0.1608 - val_loss: 0.1589\n",
      "Epoch 37/150\n",
      "4272/4272 [==============================] - 0s 81us/step - loss: 0.1595 - val_loss: 0.1615\n",
      "Epoch 38/150\n",
      "4272/4272 [==============================] - 0s 111us/step - loss: 0.1603 - val_loss: 0.1545\n",
      "Epoch 39/150\n",
      "4272/4272 [==============================] - 1s 117us/step - loss: 0.1600 - val_loss: 0.1599\n",
      "Epoch 40/150\n",
      "4272/4272 [==============================] - 0s 116us/step - loss: 0.1553 - val_loss: 0.1568\n",
      "Epoch 41/150\n",
      "4272/4272 [==============================] - 0s 115us/step - loss: 0.1507 - val_loss: 0.1607\n",
      "Epoch 42/150\n",
      "4272/4272 [==============================] - 0s 115us/step - loss: 0.1564 - val_loss: 0.1574\n",
      "Evaluating model with testing data...\n",
      "894/894 [==============================] - 0s 16us/step\n",
      "Getting distribution of predictions and covariance matrix...\n",
      "      1 of 20\n",
      "      2 of 20\n",
      "      3 of 20\n",
      "      4 of 20\n",
      "      5 of 20\n",
      "      6 of 20\n",
      "      7 of 20\n",
      "      8 of 20\n",
      "      9 of 20\n",
      "      10 of 20\n",
      "      11 of 20\n",
      "      12 of 20\n",
      "      13 of 20\n",
      "      14 of 20\n",
      "      15 of 20\n",
      "      16 of 20\n",
      "      17 of 20\n",
      "      18 of 20\n",
      "      19 of 20\n",
      "      20 of 20\n",
      "Computing ensemble means...\n",
      "Computing mean squared error...\n",
      "Iteration 28\n",
      "Train on 4412 samples, validate on 924 samples\n",
      "Epoch 1/150\n",
      "4412/4412 [==============================] - 0s 101us/step - loss: 0.5134 - val_loss: 0.3959\n",
      "Epoch 2/150\n",
      "4412/4412 [==============================] - 0s 74us/step - loss: 0.3476 - val_loss: 0.3151\n",
      "Epoch 3/150\n",
      "4412/4412 [==============================] - 1s 115us/step - loss: 0.2877 - val_loss: 0.2674\n",
      "Epoch 4/150\n",
      "4412/4412 [==============================] - 1s 116us/step - loss: 0.2545 - val_loss: 0.2481\n",
      "Epoch 5/150\n",
      "4412/4412 [==============================] - 1s 116us/step - loss: 0.2394 - val_loss: 0.2356\n",
      "Epoch 6/150\n",
      "4412/4412 [==============================] - 1s 118us/step - loss: 0.2297 - val_loss: 0.2161\n",
      "Epoch 7/150\n",
      "4412/4412 [==============================] - 1s 116us/step - loss: 0.2144 - val_loss: 0.2065\n",
      "Epoch 8/150\n",
      "4412/4412 [==============================] - 1s 115us/step - loss: 0.2020 - val_loss: 0.1967\n",
      "Epoch 9/150\n",
      "4412/4412 [==============================] - 1s 116us/step - loss: 0.1903 - val_loss: 0.1918\n",
      "Epoch 10/150\n",
      "4412/4412 [==============================] - 1s 116us/step - loss: 0.1877 - val_loss: 0.1862\n",
      "Epoch 11/150\n",
      "4412/4412 [==============================] - 0s 103us/step - loss: 0.1817 - val_loss: 0.1839\n",
      "Epoch 12/150\n",
      "4412/4412 [==============================] - 0s 102us/step - loss: 0.1805 - val_loss: 0.1770\n",
      "Epoch 13/150\n",
      "4412/4412 [==============================] - 1s 115us/step - loss: 0.1691 - val_loss: 0.1781\n",
      "Epoch 14/150\n",
      "4412/4412 [==============================] - 0s 109us/step - loss: 0.1722 - val_loss: 0.1677\n",
      "Epoch 15/150\n",
      "4412/4412 [==============================] - 0s 108us/step - loss: 0.1645 - val_loss: 0.1627\n",
      "Epoch 16/150\n",
      "4412/4412 [==============================] - 1s 115us/step - loss: 0.1664 - val_loss: 0.1612\n",
      "Epoch 17/150\n",
      "4412/4412 [==============================] - 1s 116us/step - loss: 0.1603 - val_loss: 0.1655\n",
      "Epoch 18/150\n",
      "4412/4412 [==============================] - 1s 116us/step - loss: 0.1585 - val_loss: 0.1614\n",
      "Epoch 19/150\n",
      "4412/4412 [==============================] - 1s 116us/step - loss: 0.1558 - val_loss: 0.1515\n",
      "Epoch 20/150\n",
      "4412/4412 [==============================] - 0s 108us/step - loss: 0.1547 - val_loss: 0.1593\n",
      "Epoch 21/150\n",
      "4412/4412 [==============================] - 1s 116us/step - loss: 0.1553 - val_loss: 0.1550\n",
      "Epoch 22/150\n",
      "4412/4412 [==============================] - 1s 116us/step - loss: 0.1535 - val_loss: 0.1456\n",
      "Epoch 23/150\n",
      "4412/4412 [==============================] - 0s 101us/step - loss: 0.1502 - val_loss: 0.1499\n",
      "Epoch 24/150\n",
      "4412/4412 [==============================] - 0s 108us/step - loss: 0.1505 - val_loss: 0.1420\n",
      "Epoch 25/150\n",
      "4412/4412 [==============================] - 1s 119us/step - loss: 0.1482 - val_loss: 0.1454\n",
      "Epoch 26/150\n",
      "4412/4412 [==============================] - 0s 112us/step - loss: 0.1453 - val_loss: 0.1410\n",
      "Epoch 27/150\n",
      "4412/4412 [==============================] - 0s 109us/step - loss: 0.1434 - val_loss: 0.1381\n",
      "Epoch 28/150\n",
      "4412/4412 [==============================] - 1s 116us/step - loss: 0.1424 - val_loss: 0.1513\n",
      "Epoch 29/150\n",
      "4412/4412 [==============================] - 0s 113us/step - loss: 0.1389 - val_loss: 0.1400\n",
      "Epoch 30/150\n",
      "4412/4412 [==============================] - 1s 117us/step - loss: 0.1394 - val_loss: 0.1356\n",
      "Epoch 31/150\n",
      "4412/4412 [==============================] - 1s 117us/step - loss: 0.1378 - val_loss: 0.1413\n",
      "Epoch 32/150\n",
      "4412/4412 [==============================] - 0s 105us/step - loss: 0.1362 - val_loss: 0.1371\n",
      "Epoch 33/150\n",
      "4412/4412 [==============================] - 1s 116us/step - loss: 0.1371 - val_loss: 0.1364\n",
      "Epoch 34/150\n",
      "4412/4412 [==============================] - 0s 110us/step - loss: 0.1334 - val_loss: 0.1406\n",
      "Evaluating model with testing data...\n",
      "924/924 [==============================] - 0s 16us/step\n",
      "Getting distribution of predictions and covariance matrix...\n",
      "      1 of 20\n",
      "      2 of 20\n",
      "      3 of 20\n",
      "      4 of 20\n",
      "      5 of 20\n",
      "      6 of 20\n",
      "      7 of 20\n",
      "      8 of 20\n",
      "      9 of 20\n",
      "      10 of 20\n",
      "      11 of 20\n",
      "      12 of 20\n",
      "      13 of 20\n",
      "      14 of 20\n",
      "      15 of 20\n",
      "      16 of 20\n",
      "      17 of 20\n",
      "      18 of 20\n",
      "      19 of 20\n",
      "      20 of 20\n",
      "Computing ensemble means...\n",
      "Computing mean squared error...\n",
      "Iteration 29\n",
      "Train on 4552 samples, validate on 954 samples\n",
      "Epoch 1/150\n",
      "4552/4552 [==============================] - 1s 127us/step - loss: 0.8335 - val_loss: 0.4093\n",
      "Epoch 2/150\n",
      "4552/4552 [==============================] - 0s 100us/step - loss: 0.3794 - val_loss: 0.3655\n",
      "Epoch 3/150\n",
      "4552/4552 [==============================] - 0s 99us/step - loss: 0.3451 - val_loss: 0.3329\n",
      "Epoch 4/150\n",
      "4552/4552 [==============================] - 1s 115us/step - loss: 0.3142 - val_loss: 0.3117\n",
      "Epoch 5/150\n",
      "4552/4552 [==============================] - 0s 107us/step - loss: 0.2914 - val_loss: 0.2964\n",
      "Epoch 6/150\n",
      "4552/4552 [==============================] - 0s 92us/step - loss: 0.2701 - val_loss: 0.2685\n",
      "Epoch 7/150\n",
      "4552/4552 [==============================] - 1s 112us/step - loss: 0.2566 - val_loss: 0.2455\n",
      "Epoch 8/150\n",
      "4552/4552 [==============================] - 0s 104us/step - loss: 0.2467 - val_loss: 0.2567\n",
      "Epoch 9/150\n",
      "4552/4552 [==============================] - 1s 114us/step - loss: 0.2434 - val_loss: 0.2389\n",
      "Epoch 10/150\n",
      "4552/4552 [==============================] - 1s 115us/step - loss: 0.2357 - val_loss: 0.2428\n",
      "Epoch 11/150\n",
      "4552/4552 [==============================] - 0s 105us/step - loss: 0.2268 - val_loss: 0.2244\n",
      "Epoch 12/150\n",
      "4552/4552 [==============================] - 1s 111us/step - loss: 0.2233 - val_loss: 0.2261\n",
      "Epoch 13/150\n",
      "4552/4552 [==============================] - 0s 109us/step - loss: 0.2187 - val_loss: 0.2230\n",
      "Epoch 14/150\n",
      "4552/4552 [==============================] - 0s 107us/step - loss: 0.2131 - val_loss: 0.2114\n",
      "Epoch 15/150\n",
      "4552/4552 [==============================] - 0s 108us/step - loss: 0.2079 - val_loss: 0.2026\n",
      "Epoch 16/150\n",
      "4552/4552 [==============================] - 0s 98us/step - loss: 0.2038 - val_loss: 0.1983\n",
      "Epoch 17/150\n",
      "4552/4552 [==============================] - 1s 117us/step - loss: 0.2004 - val_loss: 0.1960\n",
      "Epoch 18/150\n",
      "4552/4552 [==============================] - 1s 114us/step - loss: 0.1958 - val_loss: 0.1894\n",
      "Epoch 19/150\n",
      "4552/4552 [==============================] - 0s 96us/step - loss: 0.1954 - val_loss: 0.1883\n",
      "Epoch 20/150\n",
      "4552/4552 [==============================] - 0s 105us/step - loss: 0.1911 - val_loss: 0.1880\n",
      "Epoch 21/150\n",
      "4552/4552 [==============================] - 0s 103us/step - loss: 0.1891 - val_loss: 0.1894\n",
      "Epoch 22/150\n",
      "4552/4552 [==============================] - 0s 104us/step - loss: 0.1860 - val_loss: 0.1871\n",
      "Epoch 23/150\n",
      "4552/4552 [==============================] - 0s 106us/step - loss: 0.1886 - val_loss: 0.1780\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 24/150\n",
      "4552/4552 [==============================] - 1s 118us/step - loss: 0.1824 - val_loss: 0.1817\n",
      "Epoch 25/150\n",
      "4552/4552 [==============================] - 1s 117us/step - loss: 0.1846 - val_loss: 0.1782\n",
      "Epoch 26/150\n",
      "4552/4552 [==============================] - 0s 83us/step - loss: 0.1789 - val_loss: 0.1809\n",
      "Epoch 27/150\n",
      "4552/4552 [==============================] - 1s 117us/step - loss: 0.1785 - val_loss: 0.1776\n",
      "Epoch 28/150\n",
      "4552/4552 [==============================] - 1s 116us/step - loss: 0.1734 - val_loss: 0.1797\n",
      "Epoch 29/150\n",
      "4552/4552 [==============================] - 1s 115us/step - loss: 0.1776 - val_loss: 0.1755\n",
      "Epoch 30/150\n",
      "4552/4552 [==============================] - 1s 115us/step - loss: 0.1740 - val_loss: 0.1758\n",
      "Epoch 31/150\n",
      "4552/4552 [==============================] - 1s 115us/step - loss: 0.1747 - val_loss: 0.1815\n",
      "Epoch 32/150\n",
      "4552/4552 [==============================] - 0s 106us/step - loss: 0.1732 - val_loss: 0.1742\n",
      "Epoch 33/150\n",
      "4552/4552 [==============================] - 1s 114us/step - loss: 0.1698 - val_loss: 0.1731\n",
      "Epoch 34/150\n",
      "4552/4552 [==============================] - 1s 115us/step - loss: 0.1735 - val_loss: 0.1664\n",
      "Epoch 35/150\n",
      "4552/4552 [==============================] - 1s 114us/step - loss: 0.1698 - val_loss: 0.1724\n",
      "Epoch 36/150\n",
      "4552/4552 [==============================] - 1s 114us/step - loss: 0.1714 - val_loss: 0.1800\n",
      "Epoch 37/150\n",
      "4552/4552 [==============================] - 0s 106us/step - loss: 0.1669 - val_loss: 0.1703\n",
      "Epoch 38/150\n",
      "4552/4552 [==============================] - 1s 115us/step - loss: 0.1679 - val_loss: 0.1695\n",
      "Evaluating model with testing data...\n",
      "954/954 [==============================] - 0s 16us/step\n",
      "Getting distribution of predictions and covariance matrix...\n",
      "      1 of 20\n",
      "      2 of 20\n",
      "      3 of 20\n",
      "      4 of 20\n",
      "      5 of 20\n",
      "      6 of 20\n",
      "      7 of 20\n",
      "      8 of 20\n",
      "      9 of 20\n",
      "      10 of 20\n",
      "      11 of 20\n",
      "      12 of 20\n",
      "      13 of 20\n",
      "      14 of 20\n",
      "      15 of 20\n",
      "      16 of 20\n",
      "      17 of 20\n",
      "      18 of 20\n",
      "      19 of 20\n",
      "      20 of 20\n",
      "Computing ensemble means...\n",
      "Computing mean squared error...\n",
      "Iteration 30\n",
      "Train on 4692 samples, validate on 984 samples\n",
      "Epoch 1/150\n",
      "4692/4692 [==============================] - 1s 120us/step - loss: 0.6169 - val_loss: 0.4592\n",
      "Epoch 2/150\n",
      "4692/4692 [==============================] - 0s 102us/step - loss: 0.4214 - val_loss: 0.3996\n",
      "Epoch 3/150\n",
      "4692/4692 [==============================] - 1s 112us/step - loss: 0.3714 - val_loss: 0.3576\n",
      "Epoch 4/150\n",
      "4692/4692 [==============================] - 1s 109us/step - loss: 0.3391 - val_loss: 0.3343\n",
      "Epoch 5/150\n",
      "4692/4692 [==============================] - 1s 111us/step - loss: 0.3135 - val_loss: 0.3141\n",
      "Epoch 6/150\n",
      "4692/4692 [==============================] - 0s 95us/step - loss: 0.2937 - val_loss: 0.2906\n",
      "Epoch 7/150\n",
      "4692/4692 [==============================] - 0s 59us/step - loss: 0.2814 - val_loss: 0.2768\n",
      "Epoch 8/150\n",
      "4692/4692 [==============================] - 0s 58us/step - loss: 0.2677 - val_loss: 0.2621\n",
      "Epoch 9/150\n",
      "4692/4692 [==============================] - 0s 59us/step - loss: 0.2573 - val_loss: 0.2515\n",
      "Epoch 10/150\n",
      "4692/4692 [==============================] - 0s 59us/step - loss: 0.2480 - val_loss: 0.2427\n",
      "Epoch 11/150\n",
      "4692/4692 [==============================] - 0s 71us/step - loss: 0.2438 - val_loss: 0.2438\n",
      "Epoch 12/150\n",
      "4692/4692 [==============================] - 1s 114us/step - loss: 0.2349 - val_loss: 0.2423\n",
      "Epoch 13/150\n",
      "4692/4692 [==============================] - 0s 101us/step - loss: 0.2296 - val_loss: 0.2309\n",
      "Epoch 14/150\n",
      "4692/4692 [==============================] - 0s 99us/step - loss: 0.2252 - val_loss: 0.2196\n",
      "Epoch 15/150\n",
      "4692/4692 [==============================] - 1s 109us/step - loss: 0.2162 - val_loss: 0.2216\n",
      "Epoch 16/150\n",
      "4692/4692 [==============================] - 1s 115us/step - loss: 0.2136 - val_loss: 0.2149\n",
      "Epoch 17/150\n",
      "4692/4692 [==============================] - 1s 111us/step - loss: 0.2058 - val_loss: 0.2129\n",
      "Epoch 18/150\n",
      "4692/4692 [==============================] - 1s 115us/step - loss: 0.2065 - val_loss: 0.2021\n",
      "Epoch 19/150\n",
      "4692/4692 [==============================] - 1s 115us/step - loss: 0.1988 - val_loss: 0.2053\n",
      "Epoch 20/150\n",
      "4692/4692 [==============================] - 1s 108us/step - loss: 0.1930 - val_loss: 0.1943\n",
      "Epoch 21/150\n",
      "4692/4692 [==============================] - 0s 106us/step - loss: 0.1939 - val_loss: 0.1954\n",
      "Epoch 22/150\n",
      "4692/4692 [==============================] - 1s 111us/step - loss: 0.1928 - val_loss: 0.1981\n",
      "Epoch 23/150\n",
      "4692/4692 [==============================] - 0s 105us/step - loss: 0.1916 - val_loss: 0.1865\n",
      "Epoch 24/150\n",
      "4692/4692 [==============================] - 1s 108us/step - loss: 0.1900 - val_loss: 0.1850\n",
      "Epoch 25/150\n",
      "4692/4692 [==============================] - 1s 114us/step - loss: 0.1865 - val_loss: 0.1830\n",
      "Epoch 26/150\n",
      "4692/4692 [==============================] - 0s 100us/step - loss: 0.1885 - val_loss: 0.1839\n",
      "Epoch 27/150\n",
      "4692/4692 [==============================] - 1s 115us/step - loss: 0.1842 - val_loss: 0.1874\n",
      "Epoch 28/150\n",
      "4692/4692 [==============================] - 1s 114us/step - loss: 0.1825 - val_loss: 0.1930\n",
      "Epoch 29/150\n",
      "4692/4692 [==============================] - 1s 108us/step - loss: 0.1781 - val_loss: 0.1816\n",
      "Epoch 30/150\n",
      "4692/4692 [==============================] - 1s 108us/step - loss: 0.1784 - val_loss: 0.1842\n",
      "Epoch 31/150\n",
      "4692/4692 [==============================] - 1s 107us/step - loss: 0.1822 - val_loss: 0.1873\n",
      "Epoch 32/150\n",
      "4692/4692 [==============================] - 1s 109us/step - loss: 0.1811 - val_loss: 0.1835\n",
      "Epoch 33/150\n",
      "4692/4692 [==============================] - 0s 106us/step - loss: 0.1803 - val_loss: 0.1785\n",
      "Epoch 34/150\n",
      "4692/4692 [==============================] - 1s 109us/step - loss: 0.1778 - val_loss: 0.1807\n",
      "Epoch 35/150\n",
      "4692/4692 [==============================] - 0s 103us/step - loss: 0.1768 - val_loss: 0.1803\n",
      "Epoch 36/150\n",
      "4692/4692 [==============================] - 1s 115us/step - loss: 0.1758 - val_loss: 0.1710\n",
      "Epoch 37/150\n",
      "4692/4692 [==============================] - 1s 114us/step - loss: 0.1725 - val_loss: 0.1789\n",
      "Epoch 38/150\n",
      "4692/4692 [==============================] - 1s 113us/step - loss: 0.1731 - val_loss: 0.1681\n",
      "Epoch 39/150\n",
      "4692/4692 [==============================] - 0s 103us/step - loss: 0.1717 - val_loss: 0.1757\n",
      "Epoch 40/150\n",
      "4692/4692 [==============================] - 0s 96us/step - loss: 0.1708 - val_loss: 0.1683\n",
      "Epoch 41/150\n",
      "4692/4692 [==============================] - 1s 115us/step - loss: 0.1701 - val_loss: 0.1756\n",
      "Epoch 42/150\n",
      "4692/4692 [==============================] - 1s 115us/step - loss: 0.1694 - val_loss: 0.1650\n",
      "Epoch 43/150\n",
      "4692/4692 [==============================] - 0s 99us/step - loss: 0.1706 - val_loss: 0.1661\n",
      "Epoch 44/150\n",
      "4692/4692 [==============================] - 1s 114us/step - loss: 0.1670 - val_loss: 0.1733\n",
      "Epoch 45/150\n",
      "4692/4692 [==============================] - 1s 114us/step - loss: 0.1678 - val_loss: 0.1784\n",
      "Epoch 46/150\n",
      "4692/4692 [==============================] - 1s 114us/step - loss: 0.1666 - val_loss: 0.1655\n",
      "Evaluating model with testing data...\n",
      "984/984 [==============================] - 0s 16us/step\n",
      "Getting distribution of predictions and covariance matrix...\n",
      "      1 of 20\n",
      "      2 of 20\n",
      "      3 of 20\n",
      "      4 of 20\n",
      "      5 of 20\n",
      "      6 of 20\n",
      "      7 of 20\n",
      "      8 of 20\n",
      "      9 of 20\n",
      "      10 of 20\n",
      "      11 of 20\n",
      "      12 of 20\n",
      "      13 of 20\n",
      "      14 of 20\n",
      "      15 of 20\n",
      "      16 of 20\n",
      "      17 of 20\n",
      "      18 of 20\n",
      "      19 of 20\n",
      "      20 of 20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|          | 0/20 [00:00<?, ?it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing ensemble means...\n",
      "Computing mean squared error...\n",
      "Getting distribution of predictions...\n",
      "      1 of 20\n",
      "1600/1600 [==============================] - 0s 27us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  5%|▌         | 1/20 [00:29<09:26, 29.80s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      2 of 20\n",
      "1600/1600 [==============================] - 0s 30us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 10%|█         | 2/20 [00:59<08:57, 29.86s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      3 of 20\n",
      "1600/1600 [==============================] - 0s 29us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 15%|█▌        | 3/20 [01:29<08:27, 29.87s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      4 of 20\n",
      "1600/1600 [==============================] - 0s 30us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 20%|██        | 4/20 [01:58<07:53, 29.60s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      5 of 20\n",
      "1600/1600 [==============================] - 0s 29us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 25%|██▌       | 5/20 [02:28<07:24, 29.62s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      6 of 20\n",
      "1600/1600 [==============================] - 0s 29us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 30%|███       | 6/20 [02:57<06:54, 29.63s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      7 of 20\n",
      "1600/1600 [==============================] - 0s 29us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 35%|███▌      | 7/20 [03:27<06:25, 29.63s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      8 of 20\n",
      "1600/1600 [==============================] - 0s 29us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 40%|████      | 8/20 [03:57<05:55, 29.62s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      9 of 20\n",
      "1600/1600 [==============================] - 0s 29us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 45%|████▌     | 9/20 [04:26<05:25, 29.58s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      10 of 20\n",
      "1600/1600 [==============================] - 0s 29us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 50%|█████     | 10/20 [04:56<04:55, 29.59s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      11 of 20\n",
      "1600/1600 [==============================] - 0s 29us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 55%|█████▌    | 11/20 [05:26<04:26, 29.63s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      12 of 20\n",
      "1600/1600 [==============================] - 0s 30us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 60%|██████    | 12/20 [05:55<03:56, 29.56s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      13 of 20\n",
      "1600/1600 [==============================] - 0s 29us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 65%|██████▌   | 13/20 [06:24<03:26, 29.50s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      14 of 20\n",
      "1600/1600 [==============================] - 0s 29us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 70%|███████   | 14/20 [06:54<02:56, 29.50s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      15 of 20\n",
      "1600/1600 [==============================] - 0s 29us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 75%|███████▌  | 15/20 [07:24<02:27, 29.58s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      16 of 20\n",
      "1600/1600 [==============================] - 0s 29us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 80%|████████  | 16/20 [07:53<01:58, 29.57s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      17 of 20\n",
      "1600/1600 [==============================] - 0s 29us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 85%|████████▌ | 17/20 [08:23<01:28, 29.57s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      18 of 20\n",
      "1600/1600 [==============================] - 0s 29us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 90%|█████████ | 18/20 [08:52<00:59, 29.58s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      19 of 20\n",
      "1600/1600 [==============================] - 0s 29us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 95%|█████████▌| 19/20 [09:22<00:29, 29.56s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      20 of 20\n",
      "1600/1600 [==============================] - 0s 29us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 20/20 [09:51<00:00, 29.60s/it]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing ensemble predictions...\n",
      "Iteration 31\n",
      "Train on 4832 samples, validate on 1014 samples\n",
      "Epoch 1/150\n",
      "4832/4832 [==============================] - 1s 128us/step - loss: 0.7107 - val_loss: 0.4661\n",
      "Epoch 2/150\n",
      "4832/4832 [==============================] - 1s 104us/step - loss: 0.4281 - val_loss: 0.4027\n",
      "Epoch 3/150\n",
      "4832/4832 [==============================] - 1s 116us/step - loss: 0.3621 - val_loss: 0.3402\n",
      "Epoch 4/150\n",
      "4832/4832 [==============================] - 1s 116us/step - loss: 0.3193 - val_loss: 0.3030\n",
      "Epoch 5/150\n",
      "4832/4832 [==============================] - 1s 116us/step - loss: 0.2897 - val_loss: 0.2854\n",
      "Epoch 6/150\n",
      "4832/4832 [==============================] - 1s 115us/step - loss: 0.2754 - val_loss: 0.2638\n",
      "Epoch 7/150\n",
      "4832/4832 [==============================] - 1s 116us/step - loss: 0.2617 - val_loss: 0.2500\n",
      "Epoch 8/150\n",
      "4832/4832 [==============================] - 1s 116us/step - loss: 0.2521 - val_loss: 0.2436\n",
      "Epoch 9/150\n",
      "4832/4832 [==============================] - 1s 111us/step - loss: 0.2503 - val_loss: 0.2467\n",
      "Epoch 10/150\n",
      "4832/4832 [==============================] - 1s 116us/step - loss: 0.2400 - val_loss: 0.2381\n",
      "Epoch 11/150\n",
      "4832/4832 [==============================] - 1s 116us/step - loss: 0.2347 - val_loss: 0.2411\n",
      "Epoch 12/150\n",
      "4832/4832 [==============================] - 1s 117us/step - loss: 0.2315 - val_loss: 0.2356\n",
      "Epoch 13/150\n",
      "4832/4832 [==============================] - 1s 116us/step - loss: 0.2212 - val_loss: 0.2229\n",
      "Epoch 14/150\n",
      "4832/4832 [==============================] - 1s 116us/step - loss: 0.2183 - val_loss: 0.2188\n",
      "Epoch 15/150\n",
      "4832/4832 [==============================] - 1s 116us/step - loss: 0.2117 - val_loss: 0.2139\n",
      "Epoch 16/150\n",
      "4832/4832 [==============================] - 1s 116us/step - loss: 0.2081 - val_loss: 0.2108\n",
      "Epoch 17/150\n",
      "4832/4832 [==============================] - 1s 116us/step - loss: 0.2031 - val_loss: 0.2023\n",
      "Epoch 18/150\n",
      "4832/4832 [==============================] - 1s 109us/step - loss: 0.2005 - val_loss: 0.2093\n",
      "Epoch 19/150\n",
      "4832/4832 [==============================] - 1s 115us/step - loss: 0.1999 - val_loss: 0.1991\n",
      "Epoch 20/150\n",
      "4832/4832 [==============================] - 0s 102us/step - loss: 0.1956 - val_loss: 0.1982\n",
      "Epoch 21/150\n",
      "4832/4832 [==============================] - 1s 116us/step - loss: 0.1942 - val_loss: 0.1977\n",
      "Epoch 22/150\n",
      "4832/4832 [==============================] - 1s 116us/step - loss: 0.1941 - val_loss: 0.1955\n",
      "Epoch 23/150\n",
      "4832/4832 [==============================] - 1s 116us/step - loss: 0.1897 - val_loss: 0.1896\n",
      "Epoch 24/150\n",
      "4832/4832 [==============================] - 1s 113us/step - loss: 0.1850 - val_loss: 0.1913\n",
      "Epoch 25/150\n",
      "4832/4832 [==============================] - 1s 111us/step - loss: 0.1790 - val_loss: 0.1780\n",
      "Epoch 26/150\n",
      "4832/4832 [==============================] - 1s 117us/step - loss: 0.1783 - val_loss: 0.1849\n",
      "Epoch 27/150\n",
      "4832/4832 [==============================] - 1s 116us/step - loss: 0.1822 - val_loss: 0.1814\n",
      "Epoch 28/150\n",
      "4832/4832 [==============================] - 0s 102us/step - loss: 0.1780 - val_loss: 0.1746\n",
      "Epoch 29/150\n",
      "4832/4832 [==============================] - 1s 110us/step - loss: 0.1763 - val_loss: 0.1748\n",
      "Epoch 30/150\n",
      "4832/4832 [==============================] - 1s 116us/step - loss: 0.1731 - val_loss: 0.1755\n",
      "Epoch 31/150\n",
      "4832/4832 [==============================] - 1s 110us/step - loss: 0.1717 - val_loss: 0.1793\n",
      "Epoch 32/150\n",
      "4832/4832 [==============================] - 1s 116us/step - loss: 0.1703 - val_loss: 0.1757\n",
      "Evaluating model with testing data...\n",
      "1014/1014 [==============================] - 0s 16us/step\n",
      "Getting distribution of predictions and covariance matrix...\n",
      "      1 of 20\n",
      "      2 of 20\n",
      "      3 of 20\n",
      "      4 of 20\n",
      "      5 of 20\n",
      "      6 of 20\n",
      "      7 of 20\n",
      "      8 of 20\n",
      "      9 of 20\n",
      "      10 of 20\n",
      "      11 of 20\n",
      "      12 of 20\n",
      "      13 of 20\n",
      "      14 of 20\n",
      "      15 of 20\n",
      "      16 of 20\n",
      "      17 of 20\n",
      "      18 of 20\n",
      "      19 of 20\n",
      "      20 of 20\n",
      "Computing ensemble means...\n",
      "Computing mean squared error...\n",
      "Iteration 32\n",
      "Train on 4972 samples, validate on 1044 samples\n",
      "Epoch 1/150\n",
      "4972/4972 [==============================] - 1s 125us/step - loss: 0.6268 - val_loss: 0.4050\n",
      "Epoch 2/150\n",
      "4972/4972 [==============================] - 1s 104us/step - loss: 0.3519 - val_loss: 0.3297\n",
      "Epoch 3/150\n",
      "4972/4972 [==============================] - 1s 117us/step - loss: 0.3096 - val_loss: 0.3010\n",
      "Epoch 4/150\n",
      "4972/4972 [==============================] - 1s 117us/step - loss: 0.2836 - val_loss: 0.2811\n",
      "Epoch 5/150\n",
      "4972/4972 [==============================] - 1s 108us/step - loss: 0.2707 - val_loss: 0.2656\n",
      "Epoch 6/150\n",
      "4972/4972 [==============================] - 1s 104us/step - loss: 0.2536 - val_loss: 0.2447\n",
      "Epoch 7/150\n",
      "4972/4972 [==============================] - 1s 116us/step - loss: 0.2427 - val_loss: 0.2422\n",
      "Epoch 8/150\n",
      "4972/4972 [==============================] - 1s 116us/step - loss: 0.2308 - val_loss: 0.2264\n",
      "Epoch 9/150\n",
      "4972/4972 [==============================] - 1s 117us/step - loss: 0.2268 - val_loss: 0.2289\n",
      "Epoch 10/150\n",
      "4972/4972 [==============================] - 1s 110us/step - loss: 0.2225 - val_loss: 0.2221\n",
      "Epoch 11/150\n",
      "4972/4972 [==============================] - 0s 100us/step - loss: 0.2173 - val_loss: 0.2156\n",
      "Epoch 12/150\n",
      "4972/4972 [==============================] - 1s 111us/step - loss: 0.2140 - val_loss: 0.2131\n",
      "Epoch 13/150\n",
      "4972/4972 [==============================] - 0s 100us/step - loss: 0.2045 - val_loss: 0.2210\n",
      "Epoch 14/150\n",
      "4972/4972 [==============================] - 1s 105us/step - loss: 0.2031 - val_loss: 0.2135\n",
      "Epoch 15/150\n",
      "4972/4972 [==============================] - 1s 113us/step - loss: 0.2005 - val_loss: 0.2005\n",
      "Epoch 16/150\n",
      "4972/4972 [==============================] - 1s 117us/step - loss: 0.1993 - val_loss: 0.2033\n",
      "Epoch 17/150\n",
      "4972/4972 [==============================] - 1s 116us/step - loss: 0.1965 - val_loss: 0.1964\n",
      "Epoch 18/150\n",
      "4972/4972 [==============================] - 1s 110us/step - loss: 0.1990 - val_loss: 0.2022\n",
      "Epoch 19/150\n",
      "4972/4972 [==============================] - 0s 100us/step - loss: 0.1951 - val_loss: 0.1964\n",
      "Epoch 20/150\n",
      "4972/4972 [==============================] - 0s 98us/step - loss: 0.1937 - val_loss: 0.1908\n",
      "Epoch 21/150\n",
      "4972/4972 [==============================] - 1s 115us/step - loss: 0.1866 - val_loss: 0.1850\n",
      "Epoch 22/150\n",
      "4972/4972 [==============================] - 1s 107us/step - loss: 0.1884 - val_loss: 0.1836\n",
      "Epoch 23/150\n",
      "4972/4972 [==============================] - 0s 99us/step - loss: 0.1883 - val_loss: 0.1860\n",
      "Epoch 24/150\n",
      "4972/4972 [==============================] - 1s 113us/step - loss: 0.1853 - val_loss: 0.1901\n",
      "Epoch 25/150\n",
      "4972/4972 [==============================] - 1s 116us/step - loss: 0.1858 - val_loss: 0.1798\n",
      "Epoch 26/150\n",
      "4972/4972 [==============================] - 1s 116us/step - loss: 0.1804 - val_loss: 0.1898\n",
      "Epoch 27/150\n",
      "4972/4972 [==============================] - 1s 117us/step - loss: 0.1810 - val_loss: 0.1811\n",
      "Epoch 28/150\n",
      "4972/4972 [==============================] - 1s 116us/step - loss: 0.1800 - val_loss: 0.1868\n",
      "Epoch 29/150\n",
      "4972/4972 [==============================] - 1s 109us/step - loss: 0.1784 - val_loss: 0.1841\n",
      "Evaluating model with testing data...\n",
      "1044/1044 [==============================] - 0s 16us/step\n",
      "Getting distribution of predictions and covariance matrix...\n",
      "      1 of 20\n",
      "      2 of 20\n",
      "      3 of 20\n",
      "      4 of 20\n",
      "      5 of 20\n",
      "      6 of 20\n",
      "      7 of 20\n",
      "      8 of 20\n",
      "      9 of 20\n",
      "      10 of 20\n",
      "      11 of 20\n",
      "      12 of 20\n",
      "      13 of 20\n",
      "      14 of 20\n",
      "      15 of 20\n",
      "      16 of 20\n",
      "      17 of 20\n",
      "      18 of 20\n",
      "      19 of 20\n",
      "      20 of 20\n",
      "Computing ensemble means...\n",
      "Computing mean squared error...\n",
      "Iteration 33\n",
      "Train on 5112 samples, validate on 1074 samples\n",
      "Epoch 1/150\n",
      "5112/5112 [==============================] - 1s 112us/step - loss: 0.5875 - val_loss: 0.4501\n",
      "Epoch 2/150\n",
      "5112/5112 [==============================] - 1s 103us/step - loss: 0.3887 - val_loss: 0.3363\n",
      "Epoch 3/150\n",
      "5112/5112 [==============================] - 1s 98us/step - loss: 0.3026 - val_loss: 0.2743\n",
      "Epoch 4/150\n",
      "5112/5112 [==============================] - 1s 112us/step - loss: 0.2618 - val_loss: 0.2541\n",
      "Epoch 5/150\n",
      "5112/5112 [==============================] - 1s 109us/step - loss: 0.2402 - val_loss: 0.2309\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6/150\n",
      "5112/5112 [==============================] - 1s 114us/step - loss: 0.2214 - val_loss: 0.2221\n",
      "Epoch 7/150\n",
      "5112/5112 [==============================] - 1s 116us/step - loss: 0.2143 - val_loss: 0.2125\n",
      "Epoch 8/150\n",
      "5112/5112 [==============================] - 1s 116us/step - loss: 0.2077 - val_loss: 0.2000\n",
      "Epoch 9/150\n",
      "5112/5112 [==============================] - 1s 116us/step - loss: 0.2015 - val_loss: 0.2000\n",
      "Epoch 10/150\n",
      "5112/5112 [==============================] - 1s 116us/step - loss: 0.2000 - val_loss: 0.1900\n",
      "Epoch 11/150\n",
      "5112/5112 [==============================] - 1s 116us/step - loss: 0.1960 - val_loss: 0.1887\n",
      "Epoch 12/150\n",
      "5112/5112 [==============================] - 1s 116us/step - loss: 0.1925 - val_loss: 0.1839\n",
      "Epoch 13/150\n",
      "5112/5112 [==============================] - 1s 116us/step - loss: 0.1895 - val_loss: 0.1846\n",
      "Epoch 14/150\n",
      "5112/5112 [==============================] - 1s 113us/step - loss: 0.1832 - val_loss: 0.1841\n",
      "Epoch 15/150\n",
      "5112/5112 [==============================] - 1s 115us/step - loss: 0.1801 - val_loss: 0.1840\n",
      "Epoch 16/150\n",
      "5112/5112 [==============================] - 1s 115us/step - loss: 0.1804 - val_loss: 0.1809\n",
      "Epoch 17/150\n",
      "5112/5112 [==============================] - 1s 115us/step - loss: 0.1755 - val_loss: 0.1744\n",
      "Epoch 18/150\n",
      "5112/5112 [==============================] - 1s 114us/step - loss: 0.1729 - val_loss: 0.1748\n",
      "Epoch 19/150\n",
      "5112/5112 [==============================] - 1s 114us/step - loss: 0.1711 - val_loss: 0.1673\n",
      "Epoch 20/150\n",
      "5112/5112 [==============================] - 1s 114us/step - loss: 0.1647 - val_loss: 0.1717\n",
      "Epoch 21/150\n",
      "5112/5112 [==============================] - 1s 114us/step - loss: 0.1650 - val_loss: 0.1646\n",
      "Epoch 22/150\n",
      "5112/5112 [==============================] - 1s 113us/step - loss: 0.1619 - val_loss: 0.1551\n",
      "Epoch 23/150\n",
      "5112/5112 [==============================] - 1s 115us/step - loss: 0.1577 - val_loss: 0.1617\n",
      "Epoch 24/150\n",
      "5112/5112 [==============================] - 1s 109us/step - loss: 0.1564 - val_loss: 0.1558\n",
      "Epoch 25/150\n",
      "5112/5112 [==============================] - 1s 115us/step - loss: 0.1556 - val_loss: 0.1521\n",
      "Epoch 26/150\n",
      "5112/5112 [==============================] - 1s 111us/step - loss: 0.1533 - val_loss: 0.1517\n",
      "Epoch 27/150\n",
      "5112/5112 [==============================] - 1s 115us/step - loss: 0.1515 - val_loss: 0.1536\n",
      "Epoch 28/150\n",
      "5112/5112 [==============================] - 1s 116us/step - loss: 0.1531 - val_loss: 0.1533\n",
      "Epoch 29/150\n",
      "5112/5112 [==============================] - 1s 116us/step - loss: 0.1489 - val_loss: 0.1541\n",
      "Epoch 30/150\n",
      "5112/5112 [==============================] - 1s 110us/step - loss: 0.1470 - val_loss: 0.1478\n",
      "Epoch 31/150\n",
      "5112/5112 [==============================] - 1s 116us/step - loss: 0.1505 - val_loss: 0.1510\n",
      "Epoch 32/150\n",
      "5112/5112 [==============================] - 1s 116us/step - loss: 0.1467 - val_loss: 0.1545\n",
      "Epoch 33/150\n",
      "5112/5112 [==============================] - 1s 105us/step - loss: 0.1475 - val_loss: 0.1474\n",
      "Epoch 34/150\n",
      "5112/5112 [==============================] - 1s 105us/step - loss: 0.1472 - val_loss: 0.1393\n",
      "Epoch 35/150\n",
      "5112/5112 [==============================] - 1s 112us/step - loss: 0.1431 - val_loss: 0.1459\n",
      "Epoch 36/150\n",
      "5112/5112 [==============================] - 1s 116us/step - loss: 0.1415 - val_loss: 0.1452\n",
      "Epoch 37/150\n",
      "5112/5112 [==============================] - 1s 106us/step - loss: 0.1439 - val_loss: 0.1463\n",
      "Epoch 38/150\n",
      "5112/5112 [==============================] - 1s 107us/step - loss: 0.1409 - val_loss: 0.1389\n",
      "Epoch 39/150\n",
      "5112/5112 [==============================] - 1s 116us/step - loss: 0.1416 - val_loss: 0.1394\n",
      "Epoch 40/150\n",
      "5112/5112 [==============================] - 0s 96us/step - loss: 0.1397 - val_loss: 0.1459\n",
      "Epoch 41/150\n",
      "5112/5112 [==============================] - 1s 107us/step - loss: 0.1393 - val_loss: 0.1424\n",
      "Epoch 42/150\n",
      "5112/5112 [==============================] - 1s 117us/step - loss: 0.1351 - val_loss: 0.1355\n",
      "Epoch 43/150\n",
      "5112/5112 [==============================] - 1s 111us/step - loss: 0.1367 - val_loss: 0.1346\n",
      "Epoch 44/150\n",
      "5112/5112 [==============================] - 1s 112us/step - loss: 0.1377 - val_loss: 0.1371\n",
      "Epoch 45/150\n",
      "5112/5112 [==============================] - 1s 116us/step - loss: 0.1358 - val_loss: 0.1343\n",
      "Epoch 46/150\n",
      "5112/5112 [==============================] - 1s 115us/step - loss: 0.1365 - val_loss: 0.1316\n",
      "Epoch 47/150\n",
      "5112/5112 [==============================] - 1s 110us/step - loss: 0.1348 - val_loss: 0.1352\n",
      "Epoch 48/150\n",
      "5112/5112 [==============================] - 1s 116us/step - loss: 0.1338 - val_loss: 0.1349\n",
      "Epoch 49/150\n",
      "5112/5112 [==============================] - 1s 117us/step - loss: 0.1373 - val_loss: 0.1352\n",
      "Epoch 50/150\n",
      "5112/5112 [==============================] - 1s 101us/step - loss: 0.1320 - val_loss: 0.1318\n",
      "Evaluating model with testing data...\n",
      "1074/1074 [==============================] - 0s 16us/step\n",
      "Getting distribution of predictions and covariance matrix...\n",
      "      1 of 20\n",
      "      2 of 20\n",
      "      3 of 20\n",
      "      4 of 20\n",
      "      5 of 20\n",
      "      6 of 20\n",
      "      7 of 20\n",
      "      8 of 20\n",
      "      9 of 20\n",
      "      10 of 20\n",
      "      11 of 20\n",
      "      12 of 20\n",
      "      13 of 20\n",
      "      14 of 20\n",
      "      15 of 20\n",
      "      16 of 20\n",
      "      17 of 20\n",
      "      18 of 20\n",
      "      19 of 20\n",
      "      20 of 20\n",
      "Computing ensemble means...\n",
      "Computing mean squared error...\n",
      "Iteration 34\n",
      "Train on 5252 samples, validate on 1104 samples\n",
      "Epoch 1/150\n",
      "5252/5252 [==============================] - 1s 125us/step - loss: 0.6141 - val_loss: 0.4668\n",
      "Epoch 2/150\n",
      "5252/5252 [==============================] - 1s 98us/step - loss: 0.4338 - val_loss: 0.4198\n",
      "Epoch 3/150\n",
      "5252/5252 [==============================] - 1s 116us/step - loss: 0.3904 - val_loss: 0.3774\n",
      "Epoch 4/150\n",
      "5252/5252 [==============================] - 1s 116us/step - loss: 0.3605 - val_loss: 0.3519\n",
      "Epoch 5/150\n",
      "5252/5252 [==============================] - 1s 116us/step - loss: 0.3311 - val_loss: 0.3243\n",
      "Epoch 6/150\n",
      "5252/5252 [==============================] - 1s 109us/step - loss: 0.2973 - val_loss: 0.2925\n",
      "Epoch 7/150\n",
      "5252/5252 [==============================] - 1s 116us/step - loss: 0.2852 - val_loss: 0.2822\n",
      "Epoch 8/150\n",
      "5252/5252 [==============================] - 1s 104us/step - loss: 0.2694 - val_loss: 0.2776\n",
      "Epoch 9/150\n",
      "5252/5252 [==============================] - 1s 108us/step - loss: 0.2601 - val_loss: 0.2617\n",
      "Epoch 10/150\n",
      "5252/5252 [==============================] - 1s 116us/step - loss: 0.2588 - val_loss: 0.2568\n",
      "Epoch 11/150\n",
      "5252/5252 [==============================] - 1s 111us/step - loss: 0.2606 - val_loss: 0.2576\n",
      "Epoch 12/150\n",
      "5252/5252 [==============================] - 1s 106us/step - loss: 0.2498 - val_loss: 0.2507\n",
      "Epoch 13/150\n",
      "5252/5252 [==============================] - 1s 100us/step - loss: 0.2468 - val_loss: 0.2540\n",
      "Epoch 14/150\n",
      "5252/5252 [==============================] - 1s 116us/step - loss: 0.2389 - val_loss: 0.2294\n",
      "Epoch 15/150\n",
      "5252/5252 [==============================] - 1s 110us/step - loss: 0.2355 - val_loss: 0.2370\n",
      "Epoch 16/150\n",
      "5252/5252 [==============================] - 1s 101us/step - loss: 0.2309 - val_loss: 0.2342\n",
      "Epoch 17/150\n",
      "5252/5252 [==============================] - 1s 117us/step - loss: 0.2336 - val_loss: 0.2299\n",
      "Epoch 18/150\n",
      "5252/5252 [==============================] - 1s 108us/step - loss: 0.2300 - val_loss: 0.2356\n",
      "Evaluating model with testing data...\n",
      "1104/1104 [==============================] - 0s 16us/step\n",
      "Getting distribution of predictions and covariance matrix...\n",
      "      1 of 20\n",
      "      2 of 20\n",
      "      3 of 20\n",
      "      4 of 20\n",
      "      5 of 20\n",
      "      6 of 20\n",
      "      7 of 20\n",
      "      8 of 20\n",
      "      9 of 20\n",
      "      10 of 20\n",
      "      11 of 20\n",
      "      12 of 20\n",
      "      13 of 20\n",
      "      14 of 20\n",
      "      15 of 20\n",
      "      16 of 20\n",
      "      17 of 20\n",
      "      18 of 20\n",
      "      19 of 20\n",
      "      20 of 20\n",
      "Computing ensemble means...\n",
      "Computing mean squared error...\n",
      "Iteration 35\n",
      "Train on 5392 samples, validate on 1134 samples\n",
      "Epoch 1/150\n",
      "5392/5392 [==============================] - 0s 91us/step - loss: 0.6162 - val_loss: 0.4423\n",
      "Epoch 2/150\n",
      "5392/5392 [==============================] - 0s 87us/step - loss: 0.3774 - val_loss: 0.3241\n",
      "Epoch 3/150\n",
      "5392/5392 [==============================] - 1s 117us/step - loss: 0.3070 - val_loss: 0.2727\n",
      "Epoch 4/150\n",
      "5392/5392 [==============================] - 1s 105us/step - loss: 0.2626 - val_loss: 0.2494\n",
      "Epoch 5/150\n",
      "5392/5392 [==============================] - 1s 117us/step - loss: 0.2355 - val_loss: 0.2321\n",
      "Epoch 6/150\n",
      "5392/5392 [==============================] - 1s 117us/step - loss: 0.2235 - val_loss: 0.2236\n",
      "Epoch 7/150\n",
      "5392/5392 [==============================] - 1s 117us/step - loss: 0.2108 - val_loss: 0.2120\n",
      "Epoch 8/150\n",
      "5392/5392 [==============================] - 1s 117us/step - loss: 0.2043 - val_loss: 0.1906\n",
      "Epoch 9/150\n",
      "5392/5392 [==============================] - 1s 118us/step - loss: 0.1919 - val_loss: 0.1872\n",
      "Epoch 10/150\n",
      "5392/5392 [==============================] - 1s 117us/step - loss: 0.1859 - val_loss: 0.1816\n",
      "Epoch 11/150\n",
      "5392/5392 [==============================] - 1s 117us/step - loss: 0.1765 - val_loss: 0.1774\n",
      "Epoch 12/150\n",
      "5392/5392 [==============================] - 1s 117us/step - loss: 0.1707 - val_loss: 0.1671\n",
      "Epoch 13/150\n",
      "5392/5392 [==============================] - 1s 117us/step - loss: 0.1684 - val_loss: 0.1629\n",
      "Epoch 14/150\n",
      "5392/5392 [==============================] - 1s 117us/step - loss: 0.1630 - val_loss: 0.1629\n",
      "Epoch 15/150\n",
      "5392/5392 [==============================] - 1s 117us/step - loss: 0.1594 - val_loss: 0.1557\n",
      "Epoch 16/150\n",
      "5392/5392 [==============================] - 1s 117us/step - loss: 0.1542 - val_loss: 0.1573\n",
      "Epoch 17/150\n",
      "5392/5392 [==============================] - 1s 117us/step - loss: 0.1549 - val_loss: 0.1538\n",
      "Epoch 18/150\n",
      "5392/5392 [==============================] - 1s 117us/step - loss: 0.1513 - val_loss: 0.1516\n",
      "Epoch 19/150\n",
      "5392/5392 [==============================] - 1s 113us/step - loss: 0.1471 - val_loss: 0.1513\n",
      "Epoch 20/150\n",
      "5392/5392 [==============================] - 1s 116us/step - loss: 0.1454 - val_loss: 0.1460\n",
      "Epoch 21/150\n",
      "5392/5392 [==============================] - 1s 117us/step - loss: 0.1443 - val_loss: 0.1460\n",
      "Epoch 22/150\n",
      "5392/5392 [==============================] - 1s 117us/step - loss: 0.1439 - val_loss: 0.1463\n",
      "Epoch 23/150\n",
      "5392/5392 [==============================] - 1s 117us/step - loss: 0.1396 - val_loss: 0.1397\n",
      "Epoch 24/150\n",
      "5392/5392 [==============================] - 1s 117us/step - loss: 0.1407 - val_loss: 0.1444\n",
      "Epoch 25/150\n",
      "5392/5392 [==============================] - 1s 117us/step - loss: 0.1393 - val_loss: 0.1354\n",
      "Epoch 26/150\n",
      "5392/5392 [==============================] - 1s 117us/step - loss: 0.1359 - val_loss: 0.1379\n",
      "Epoch 27/150\n",
      "5392/5392 [==============================] - 1s 117us/step - loss: 0.1330 - val_loss: 0.1309\n",
      "Epoch 28/150\n",
      "5392/5392 [==============================] - 1s 117us/step - loss: 0.1353 - val_loss: 0.1328\n",
      "Epoch 29/150\n",
      "5392/5392 [==============================] - 1s 118us/step - loss: 0.1345 - val_loss: 0.1375\n",
      "Epoch 30/150\n",
      "5392/5392 [==============================] - 1s 117us/step - loss: 0.1320 - val_loss: 0.1338\n",
      "Epoch 31/150\n",
      "5392/5392 [==============================] - 1s 117us/step - loss: 0.1329 - val_loss: 0.1343\n",
      "Evaluating model with testing data...\n",
      "1134/1134 [==============================] - 0s 16us/step\n",
      "Getting distribution of predictions and covariance matrix...\n",
      "      1 of 20\n",
      "      2 of 20\n",
      "      3 of 20\n",
      "      4 of 20\n",
      "      5 of 20\n",
      "      6 of 20\n",
      "      7 of 20\n",
      "      8 of 20\n",
      "      9 of 20\n",
      "      10 of 20\n",
      "      11 of 20\n",
      "      12 of 20\n",
      "      13 of 20\n",
      "      14 of 20\n",
      "      15 of 20\n",
      "      16 of 20\n",
      "      17 of 20\n",
      "      18 of 20\n",
      "      19 of 20\n",
      "      20 of 20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|          | 0/20 [00:00<?, ?it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing ensemble means...\n",
      "Computing mean squared error...\n",
      "Getting distribution of predictions...\n",
      "      1 of 20\n",
      "1600/1600 [==============================] - 0s 27us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  5%|▌         | 1/20 [00:29<09:19, 29.47s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      2 of 20\n",
      "1600/1600 [==============================] - 0s 28us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 10%|█         | 2/20 [00:58<08:50, 29.47s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      3 of 20\n",
      "1600/1600 [==============================] - 0s 29us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 15%|█▌        | 3/20 [01:28<08:21, 29.49s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      4 of 20\n",
      "1600/1600 [==============================] - 0s 28us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 20%|██        | 4/20 [01:58<07:52, 29.53s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      5 of 20\n",
      "1600/1600 [==============================] - 0s 29us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 25%|██▌       | 5/20 [02:27<07:22, 29.47s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      6 of 20\n",
      "1600/1600 [==============================] - 0s 29us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 30%|███       | 6/20 [02:57<06:53, 29.54s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      7 of 20\n",
      "1600/1600 [==============================] - 0s 28us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 35%|███▌      | 7/20 [03:26<06:25, 29.62s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      8 of 20\n",
      "1600/1600 [==============================] - 0s 29us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 40%|████      | 8/20 [03:56<05:55, 29.63s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      9 of 20\n",
      "1600/1600 [==============================] - 0s 28us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 45%|████▌     | 9/20 [04:26<05:25, 29.58s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      10 of 20\n",
      "1600/1600 [==============================] - 0s 29us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 50%|█████     | 10/20 [04:55<04:55, 29.58s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      11 of 20\n",
      "1600/1600 [==============================] - 0s 29us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 55%|█████▌    | 11/20 [05:25<04:27, 29.67s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      12 of 20\n",
      "1600/1600 [==============================] - 0s 28us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 60%|██████    | 12/20 [05:55<03:57, 29.71s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      13 of 20\n",
      "1600/1600 [==============================] - 0s 29us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 65%|██████▌   | 13/20 [06:24<03:27, 29.60s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      14 of 20\n",
      "1600/1600 [==============================] - 0s 30us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 70%|███████   | 14/20 [06:54<02:57, 29.62s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      15 of 20\n",
      "1600/1600 [==============================] - 0s 29us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 75%|███████▌  | 15/20 [07:24<02:28, 29.75s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      16 of 20\n",
      "1600/1600 [==============================] - 0s 29us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 80%|████████  | 16/20 [07:54<01:58, 29.74s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      17 of 20\n",
      "1600/1600 [==============================] - 0s 29us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 85%|████████▌ | 17/20 [08:23<01:28, 29.66s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      18 of 20\n",
      "1600/1600 [==============================] - 0s 29us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 90%|█████████ | 18/20 [08:53<00:59, 29.71s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      19 of 20\n",
      "1600/1600 [==============================] - 0s 30us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 95%|█████████▌| 19/20 [09:23<00:29, 29.77s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      20 of 20\n",
      "1600/1600 [==============================] - 0s 29us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 20/20 [09:52<00:00, 29.64s/it]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing ensemble predictions...\n",
      "Iteration 36\n",
      "Train on 5532 samples, validate on 1164 samples\n",
      "Epoch 1/150\n",
      "5532/5532 [==============================] - 1s 106us/step - loss: 0.7032 - val_loss: 0.4487\n",
      "Epoch 2/150\n",
      "5532/5532 [==============================] - 1s 104us/step - loss: 0.4116 - val_loss: 0.3917\n",
      "Epoch 3/150\n",
      "5532/5532 [==============================] - 1s 118us/step - loss: 0.3602 - val_loss: 0.3474\n",
      "Epoch 4/150\n",
      "5532/5532 [==============================] - 1s 118us/step - loss: 0.3330 - val_loss: 0.3210\n",
      "Epoch 5/150\n",
      "5532/5532 [==============================] - 1s 117us/step - loss: 0.3106 - val_loss: 0.3054\n",
      "Epoch 6/150\n",
      "5532/5532 [==============================] - 1s 115us/step - loss: 0.2996 - val_loss: 0.2953\n",
      "Epoch 7/150\n",
      "5532/5532 [==============================] - 1s 107us/step - loss: 0.2900 - val_loss: 0.2813\n",
      "Epoch 8/150\n",
      "5532/5532 [==============================] - 1s 118us/step - loss: 0.2831 - val_loss: 0.2889\n",
      "Epoch 9/150\n",
      "5532/5532 [==============================] - 1s 118us/step - loss: 0.2753 - val_loss: 0.2757\n",
      "Epoch 10/150\n",
      "5532/5532 [==============================] - 1s 117us/step - loss: 0.2682 - val_loss: 0.2680\n",
      "Epoch 11/150\n",
      "5532/5532 [==============================] - 1s 115us/step - loss: 0.2617 - val_loss: 0.2601\n",
      "Epoch 12/150\n",
      "5532/5532 [==============================] - 1s 117us/step - loss: 0.2583 - val_loss: 0.2655\n",
      "Epoch 13/150\n",
      "5532/5532 [==============================] - 1s 118us/step - loss: 0.2573 - val_loss: 0.2652\n",
      "Epoch 14/150\n",
      "5532/5532 [==============================] - 1s 118us/step - loss: 0.2489 - val_loss: 0.2527\n",
      "Epoch 15/150\n",
      "5532/5532 [==============================] - 1s 106us/step - loss: 0.2493 - val_loss: 0.2489\n",
      "Epoch 16/150\n",
      "5532/5532 [==============================] - 1s 116us/step - loss: 0.2442 - val_loss: 0.2451\n",
      "Epoch 17/150\n",
      "5532/5532 [==============================] - 1s 115us/step - loss: 0.2364 - val_loss: 0.2386\n",
      "Epoch 18/150\n",
      "5532/5532 [==============================] - 1s 114us/step - loss: 0.2332 - val_loss: 0.2288\n",
      "Epoch 19/150\n",
      "5532/5532 [==============================] - 1s 113us/step - loss: 0.2297 - val_loss: 0.2357\n",
      "Epoch 20/150\n",
      "5532/5532 [==============================] - 1s 115us/step - loss: 0.2285 - val_loss: 0.2320\n",
      "Epoch 21/150\n",
      "5532/5532 [==============================] - 1s 112us/step - loss: 0.2265 - val_loss: 0.2314\n",
      "Epoch 22/150\n",
      "5532/5532 [==============================] - 1s 115us/step - loss: 0.2240 - val_loss: 0.2425\n",
      "Evaluating model with testing data...\n",
      "1164/1164 [==============================] - 0s 15us/step\n",
      "Getting distribution of predictions and covariance matrix...\n",
      "      1 of 20\n",
      "      2 of 20\n",
      "      3 of 20\n",
      "      4 of 20\n",
      "      5 of 20\n",
      "      6 of 20\n",
      "      7 of 20\n",
      "      8 of 20\n",
      "      9 of 20\n",
      "      10 of 20\n",
      "      11 of 20\n",
      "      12 of 20\n",
      "      13 of 20\n",
      "      14 of 20\n",
      "      15 of 20\n",
      "      16 of 20\n",
      "      17 of 20\n",
      "      18 of 20\n",
      "      19 of 20\n",
      "      20 of 20\n",
      "Computing ensemble means...\n",
      "Computing mean squared error...\n",
      "Iteration 37\n",
      "Train on 5672 samples, validate on 1194 samples\n",
      "Epoch 1/150\n",
      "5672/5672 [==============================] - 1s 95us/step - loss: 0.5855 - val_loss: 0.3770\n",
      "Epoch 2/150\n",
      "5672/5672 [==============================] - 1s 108us/step - loss: 0.3398 - val_loss: 0.3059\n",
      "Epoch 3/150\n",
      "5672/5672 [==============================] - 0s 79us/step - loss: 0.2941 - val_loss: 0.2820\n",
      "Epoch 4/150\n",
      "5672/5672 [==============================] - 0s 60us/step - loss: 0.2694 - val_loss: 0.2543\n",
      "Epoch 5/150\n",
      "5672/5672 [==============================] - 0s 60us/step - loss: 0.2550 - val_loss: 0.2550\n",
      "Epoch 6/150\n",
      "5672/5672 [==============================] - 0s 60us/step - loss: 0.2453 - val_loss: 0.2449\n",
      "Epoch 7/150\n",
      "5672/5672 [==============================] - 1s 92us/step - loss: 0.2366 - val_loss: 0.2286\n",
      "Epoch 8/150\n",
      "5672/5672 [==============================] - 1s 115us/step - loss: 0.2298 - val_loss: 0.2236\n",
      "Epoch 9/150\n",
      "5672/5672 [==============================] - 1s 110us/step - loss: 0.2192 - val_loss: 0.2173\n",
      "Epoch 10/150\n",
      "5672/5672 [==============================] - 1s 109us/step - loss: 0.2091 - val_loss: 0.2026\n",
      "Epoch 11/150\n",
      "5672/5672 [==============================] - 1s 110us/step - loss: 0.2018 - val_loss: 0.2105\n",
      "Epoch 12/150\n",
      "5672/5672 [==============================] - 1s 115us/step - loss: 0.1938 - val_loss: 0.2020\n",
      "Epoch 13/150\n",
      "5672/5672 [==============================] - 1s 107us/step - loss: 0.1917 - val_loss: 0.1920\n",
      "Epoch 14/150\n",
      "5672/5672 [==============================] - 1s 115us/step - loss: 0.1865 - val_loss: 0.1837\n",
      "Epoch 15/150\n",
      "5672/5672 [==============================] - 1s 115us/step - loss: 0.1848 - val_loss: 0.1866\n",
      "Epoch 16/150\n",
      "5672/5672 [==============================] - 1s 108us/step - loss: 0.1786 - val_loss: 0.1839\n",
      "Epoch 17/150\n",
      "5672/5672 [==============================] - 1s 107us/step - loss: 0.1723 - val_loss: 0.1745\n",
      "Epoch 18/150\n",
      "5672/5672 [==============================] - 1s 117us/step - loss: 0.1661 - val_loss: 0.1653\n",
      "Epoch 19/150\n",
      "5672/5672 [==============================] - 1s 117us/step - loss: 0.1614 - val_loss: 0.1628\n",
      "Epoch 20/150\n",
      "5672/5672 [==============================] - 1s 116us/step - loss: 0.1568 - val_loss: 0.1578\n",
      "Epoch 21/150\n",
      "5672/5672 [==============================] - 1s 106us/step - loss: 0.1567 - val_loss: 0.1515\n",
      "Epoch 22/150\n",
      "5672/5672 [==============================] - 1s 101us/step - loss: 0.1536 - val_loss: 0.1550\n",
      "Epoch 23/150\n",
      "5672/5672 [==============================] - 1s 109us/step - loss: 0.1490 - val_loss: 0.1484\n",
      "Epoch 24/150\n",
      "5672/5672 [==============================] - 1s 117us/step - loss: 0.1478 - val_loss: 0.1481\n",
      "Epoch 25/150\n",
      "5672/5672 [==============================] - 1s 106us/step - loss: 0.1488 - val_loss: 0.1420\n",
      "Epoch 26/150\n",
      "5672/5672 [==============================] - 1s 109us/step - loss: 0.1461 - val_loss: 0.1434\n",
      "Epoch 27/150\n",
      "5672/5672 [==============================] - 1s 116us/step - loss: 0.1425 - val_loss: 0.1454\n",
      "Epoch 28/150\n",
      "5672/5672 [==============================] - 1s 109us/step - loss: 0.1422 - val_loss: 0.1457\n",
      "Epoch 29/150\n",
      "5672/5672 [==============================] - 1s 114us/step - loss: 0.1420 - val_loss: 0.1465\n",
      "Evaluating model with testing data...\n",
      "1194/1194 [==============================] - 0s 15us/step\n",
      "Getting distribution of predictions and covariance matrix...\n",
      "      1 of 20\n",
      "      2 of 20\n",
      "      3 of 20\n",
      "      4 of 20\n",
      "      5 of 20\n",
      "      6 of 20\n",
      "      7 of 20\n",
      "      8 of 20\n",
      "      9 of 20\n",
      "      10 of 20\n",
      "      11 of 20\n",
      "      12 of 20\n",
      "      13 of 20\n",
      "      14 of 20\n",
      "      15 of 20\n",
      "      16 of 20\n",
      "      17 of 20\n",
      "      18 of 20\n",
      "      19 of 20\n",
      "      20 of 20\n",
      "Computing ensemble means...\n",
      "Computing mean squared error...\n",
      "Iteration 38\n",
      "Train on 5812 samples, validate on 1224 samples\n",
      "Epoch 1/150\n",
      "5812/5812 [==============================] - 1s 115us/step - loss: 0.4684 - val_loss: 0.3455\n",
      "Epoch 2/150\n",
      "5812/5812 [==============================] - 1s 106us/step - loss: 0.2980 - val_loss: 0.2584\n",
      "Epoch 3/150\n",
      "5812/5812 [==============================] - 1s 115us/step - loss: 0.2443 - val_loss: 0.2311\n",
      "Epoch 4/150\n",
      "5812/5812 [==============================] - 1s 116us/step - loss: 0.2197 - val_loss: 0.2132\n",
      "Epoch 5/150\n",
      "5812/5812 [==============================] - 1s 112us/step - loss: 0.2054 - val_loss: 0.2073\n",
      "Epoch 6/150\n",
      "5812/5812 [==============================] - 1s 116us/step - loss: 0.1940 - val_loss: 0.1950\n",
      "Epoch 7/150\n",
      "5812/5812 [==============================] - 1s 116us/step - loss: 0.1879 - val_loss: 0.1820\n",
      "Epoch 8/150\n",
      "5812/5812 [==============================] - 1s 117us/step - loss: 0.1799 - val_loss: 0.1779\n",
      "Epoch 9/150\n",
      "5812/5812 [==============================] - 1s 114us/step - loss: 0.1764 - val_loss: 0.1796\n",
      "Epoch 10/150\n",
      "5812/5812 [==============================] - 1s 103us/step - loss: 0.1736 - val_loss: 0.1753\n",
      "Epoch 11/150\n",
      "5812/5812 [==============================] - 1s 116us/step - loss: 0.1669 - val_loss: 0.1711\n",
      "Epoch 12/150\n",
      "5812/5812 [==============================] - 1s 110us/step - loss: 0.1657 - val_loss: 0.1625\n",
      "Epoch 13/150\n",
      "5812/5812 [==============================] - 1s 102us/step - loss: 0.1581 - val_loss: 0.1606\n",
      "Epoch 14/150\n",
      "5812/5812 [==============================] - 1s 109us/step - loss: 0.1593 - val_loss: 0.1602\n",
      "Epoch 15/150\n",
      "5812/5812 [==============================] - 1s 111us/step - loss: 0.1528 - val_loss: 0.1554\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 16/150\n",
      "5812/5812 [==============================] - 1s 108us/step - loss: 0.1527 - val_loss: 0.1470\n",
      "Epoch 17/150\n",
      "5812/5812 [==============================] - 1s 117us/step - loss: 0.1488 - val_loss: 0.1435\n",
      "Epoch 18/150\n",
      "5812/5812 [==============================] - 1s 116us/step - loss: 0.1484 - val_loss: 0.1470\n",
      "Epoch 19/150\n",
      "5812/5812 [==============================] - 1s 117us/step - loss: 0.1438 - val_loss: 0.1419\n",
      "Epoch 20/150\n",
      "5812/5812 [==============================] - 1s 117us/step - loss: 0.1406 - val_loss: 0.1447\n",
      "Epoch 21/150\n",
      "5812/5812 [==============================] - 1s 117us/step - loss: 0.1376 - val_loss: 0.1416\n",
      "Epoch 22/150\n",
      "5812/5812 [==============================] - 1s 116us/step - loss: 0.1392 - val_loss: 0.1470\n",
      "Epoch 23/150\n",
      "5812/5812 [==============================] - 1s 116us/step - loss: 0.1366 - val_loss: 0.1384\n",
      "Epoch 24/150\n",
      "5812/5812 [==============================] - 1s 116us/step - loss: 0.1360 - val_loss: 0.1377\n",
      "Epoch 25/150\n",
      "5812/5812 [==============================] - 1s 116us/step - loss: 0.1383 - val_loss: 0.1324\n",
      "Epoch 26/150\n",
      "5812/5812 [==============================] - 1s 119us/step - loss: 0.1324 - val_loss: 0.1279\n",
      "Epoch 27/150\n",
      "5812/5812 [==============================] - 1s 117us/step - loss: 0.1337 - val_loss: 0.1321\n",
      "Epoch 28/150\n",
      "5812/5812 [==============================] - 1s 117us/step - loss: 0.1321 - val_loss: 0.1339\n",
      "Epoch 29/150\n",
      "5812/5812 [==============================] - 1s 116us/step - loss: 0.1294 - val_loss: 0.1274\n",
      "Epoch 30/150\n",
      "5812/5812 [==============================] - 1s 117us/step - loss: 0.1324 - val_loss: 0.1263\n",
      "Epoch 31/150\n",
      "5812/5812 [==============================] - 1s 117us/step - loss: 0.1293 - val_loss: 0.1362\n",
      "Epoch 32/150\n",
      "5812/5812 [==============================] - 1s 110us/step - loss: 0.1279 - val_loss: 0.1279\n",
      "Epoch 33/150\n",
      "5812/5812 [==============================] - 1s 116us/step - loss: 0.1271 - val_loss: 0.1316\n",
      "Epoch 34/150\n",
      "5812/5812 [==============================] - 1s 115us/step - loss: 0.1285 - val_loss: 0.1295\n",
      "Evaluating model with testing data...\n",
      "1224/1224 [==============================] - 0s 15us/step\n",
      "Getting distribution of predictions and covariance matrix...\n",
      "      1 of 20\n",
      "      2 of 20\n",
      "      3 of 20\n",
      "      4 of 20\n",
      "      5 of 20\n",
      "      6 of 20\n",
      "      7 of 20\n",
      "      8 of 20\n",
      "      9 of 20\n",
      "      10 of 20\n",
      "      11 of 20\n",
      "      12 of 20\n",
      "      13 of 20\n",
      "      14 of 20\n",
      "      15 of 20\n",
      "      16 of 20\n",
      "      17 of 20\n",
      "      18 of 20\n",
      "      19 of 20\n",
      "      20 of 20\n",
      "Computing ensemble means...\n",
      "Computing mean squared error...\n",
      "Iteration 39\n",
      "Train on 5952 samples, validate on 1254 samples\n",
      "Epoch 1/150\n",
      "5952/5952 [==============================] - 1s 109us/step - loss: 0.5445 - val_loss: 0.3953\n",
      "Epoch 2/150\n",
      "5952/5952 [==============================] - 1s 108us/step - loss: 0.3495 - val_loss: 0.3146\n",
      "Epoch 3/150\n",
      "5952/5952 [==============================] - 1s 114us/step - loss: 0.2908 - val_loss: 0.2813\n",
      "Epoch 4/150\n",
      "5952/5952 [==============================] - 1s 107us/step - loss: 0.2612 - val_loss: 0.2522\n",
      "Epoch 5/150\n",
      "5952/5952 [==============================] - 1s 116us/step - loss: 0.2401 - val_loss: 0.2308\n",
      "Epoch 6/150\n",
      "5952/5952 [==============================] - 1s 116us/step - loss: 0.2277 - val_loss: 0.2200\n",
      "Epoch 7/150\n",
      "5952/5952 [==============================] - 1s 116us/step - loss: 0.2176 - val_loss: 0.2141\n",
      "Epoch 8/150\n",
      "5952/5952 [==============================] - 1s 116us/step - loss: 0.2115 - val_loss: 0.2036\n",
      "Epoch 9/150\n",
      "5952/5952 [==============================] - 1s 116us/step - loss: 0.1996 - val_loss: 0.1952\n",
      "Epoch 10/150\n",
      "5952/5952 [==============================] - 1s 116us/step - loss: 0.1947 - val_loss: 0.1921\n",
      "Epoch 11/150\n",
      "5952/5952 [==============================] - 1s 116us/step - loss: 0.1888 - val_loss: 0.1852\n",
      "Epoch 12/150\n",
      "5952/5952 [==============================] - 1s 116us/step - loss: 0.1799 - val_loss: 0.1786\n",
      "Epoch 13/150\n",
      "5952/5952 [==============================] - 1s 116us/step - loss: 0.1728 - val_loss: 0.1720\n",
      "Epoch 14/150\n",
      "5952/5952 [==============================] - 1s 112us/step - loss: 0.1661 - val_loss: 0.1668\n",
      "Epoch 15/150\n",
      "5952/5952 [==============================] - 1s 112us/step - loss: 0.1596 - val_loss: 0.1629\n",
      "Epoch 16/150\n",
      "5952/5952 [==============================] - 1s 107us/step - loss: 0.1551 - val_loss: 0.1514\n",
      "Epoch 17/150\n",
      "5952/5952 [==============================] - 1s 116us/step - loss: 0.1522 - val_loss: 0.1516\n",
      "Epoch 18/150\n",
      "5952/5952 [==============================] - 1s 116us/step - loss: 0.1489 - val_loss: 0.1547\n",
      "Epoch 19/150\n",
      "5952/5952 [==============================] - 1s 116us/step - loss: 0.1454 - val_loss: 0.1493\n",
      "Epoch 20/150\n",
      "5952/5952 [==============================] - 1s 116us/step - loss: 0.1434 - val_loss: 0.1430\n",
      "Epoch 21/150\n",
      "5952/5952 [==============================] - 1s 115us/step - loss: 0.1419 - val_loss: 0.1420\n",
      "Epoch 22/150\n",
      "5952/5952 [==============================] - 1s 116us/step - loss: 0.1397 - val_loss: 0.1453\n",
      "Epoch 23/150\n",
      "5952/5952 [==============================] - 1s 116us/step - loss: 0.1411 - val_loss: 0.1359\n",
      "Epoch 24/150\n",
      "5952/5952 [==============================] - 1s 116us/step - loss: 0.1355 - val_loss: 0.1394\n",
      "Epoch 25/150\n",
      "5952/5952 [==============================] - 1s 111us/step - loss: 0.1346 - val_loss: 0.1361\n",
      "Epoch 26/150\n",
      "5952/5952 [==============================] - 1s 116us/step - loss: 0.1352 - val_loss: 0.1319\n",
      "Epoch 27/150\n",
      "5952/5952 [==============================] - 1s 116us/step - loss: 0.1327 - val_loss: 0.1422\n",
      "Epoch 28/150\n",
      "5952/5952 [==============================] - 1s 116us/step - loss: 0.1292 - val_loss: 0.1272\n",
      "Epoch 29/150\n",
      "5952/5952 [==============================] - 1s 110us/step - loss: 0.1284 - val_loss: 0.1300\n",
      "Epoch 30/150\n",
      "5952/5952 [==============================] - 1s 109us/step - loss: 0.1285 - val_loss: 0.1304\n",
      "Epoch 31/150\n",
      "5952/5952 [==============================] - 1s 116us/step - loss: 0.1280 - val_loss: 0.1238\n",
      "Epoch 32/150\n",
      "5952/5952 [==============================] - 1s 112us/step - loss: 0.1271 - val_loss: 0.1281\n",
      "Epoch 33/150\n",
      "5952/5952 [==============================] - 1s 103us/step - loss: 0.1273 - val_loss: 0.1288\n",
      "Epoch 34/150\n",
      "5952/5952 [==============================] - 1s 116us/step - loss: 0.1235 - val_loss: 0.1216\n",
      "Epoch 35/150\n",
      "5952/5952 [==============================] - 1s 116us/step - loss: 0.1251 - val_loss: 0.1261\n",
      "Epoch 36/150\n",
      "5952/5952 [==============================] - 1s 110us/step - loss: 0.1225 - val_loss: 0.1233\n",
      "Epoch 37/150\n",
      "5952/5952 [==============================] - 1s 105us/step - loss: 0.1206 - val_loss: 0.1223\n",
      "Epoch 38/150\n",
      "5952/5952 [==============================] - 1s 110us/step - loss: 0.1207 - val_loss: 0.1216\n",
      "Epoch 39/150\n",
      "5952/5952 [==============================] - 1s 112us/step - loss: 0.1217 - val_loss: 0.1177\n",
      "Epoch 40/150\n",
      "5952/5952 [==============================] - 1s 110us/step - loss: 0.1204 - val_loss: 0.1210\n",
      "Epoch 41/150\n",
      "5952/5952 [==============================] - 1s 114us/step - loss: 0.1165 - val_loss: 0.1170\n",
      "Epoch 42/150\n",
      "5952/5952 [==============================] - 1s 116us/step - loss: 0.1209 - val_loss: 0.1213\n",
      "Epoch 43/150\n",
      "5952/5952 [==============================] - 1s 111us/step - loss: 0.1155 - val_loss: 0.1166\n",
      "Epoch 44/150\n",
      "5952/5952 [==============================] - 1s 107us/step - loss: 0.1160 - val_loss: 0.1145\n",
      "Epoch 45/150\n",
      "5952/5952 [==============================] - 1s 113us/step - loss: 0.1155 - val_loss: 0.1185\n",
      "Epoch 46/150\n",
      "5952/5952 [==============================] - 1s 106us/step - loss: 0.1182 - val_loss: 0.1180\n",
      "Epoch 47/150\n",
      "5952/5952 [==============================] - 1s 110us/step - loss: 0.1167 - val_loss: 0.1139\n",
      "Epoch 48/150\n",
      "5952/5952 [==============================] - 1s 116us/step - loss: 0.1156 - val_loss: 0.1113\n",
      "Epoch 49/150\n",
      "5952/5952 [==============================] - 1s 101us/step - loss: 0.1134 - val_loss: 0.1171\n",
      "Epoch 50/150\n",
      "5952/5952 [==============================] - 1s 107us/step - loss: 0.1151 - val_loss: 0.1112\n",
      "Epoch 51/150\n",
      "5952/5952 [==============================] - 1s 105us/step - loss: 0.1128 - val_loss: 0.1172\n",
      "Epoch 52/150\n",
      "5952/5952 [==============================] - 1s 98us/step - loss: 0.1129 - val_loss: 0.1142\n",
      "Epoch 53/150\n",
      "5952/5952 [==============================] - 1s 116us/step - loss: 0.1124 - val_loss: 0.1088\n",
      "Epoch 54/150\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5952/5952 [==============================] - 1s 105us/step - loss: 0.1136 - val_loss: 0.1110\n",
      "Epoch 55/150\n",
      "5952/5952 [==============================] - 1s 116us/step - loss: 0.1104 - val_loss: 0.1119\n",
      "Epoch 56/150\n",
      "5952/5952 [==============================] - 1s 116us/step - loss: 0.1100 - val_loss: 0.1161\n",
      "Epoch 57/150\n",
      "5952/5952 [==============================] - 1s 116us/step - loss: 0.1103 - val_loss: 0.1124\n",
      "Evaluating model with testing data...\n",
      "1254/1254 [==============================] - 0s 15us/step\n",
      "Getting distribution of predictions and covariance matrix...\n",
      "      1 of 20\n",
      "      2 of 20\n",
      "      3 of 20\n",
      "      4 of 20\n",
      "      5 of 20\n",
      "      6 of 20\n",
      "      7 of 20\n",
      "      8 of 20\n",
      "      9 of 20\n",
      "      10 of 20\n",
      "      11 of 20\n",
      "      12 of 20\n",
      "      13 of 20\n",
      "      14 of 20\n",
      "      15 of 20\n",
      "      16 of 20\n",
      "      17 of 20\n",
      "      18 of 20\n",
      "      19 of 20\n",
      "      20 of 20\n",
      "Computing ensemble means...\n",
      "Computing mean squared error...\n",
      "Iteration 40\n",
      "Train on 6092 samples, validate on 1284 samples\n",
      "Epoch 1/150\n",
      "6092/6092 [==============================] - 1s 113us/step - loss: 0.5670 - val_loss: 0.3973\n",
      "Epoch 2/150\n",
      "6092/6092 [==============================] - 1s 104us/step - loss: 0.3449 - val_loss: 0.3163\n",
      "Epoch 3/150\n",
      "6092/6092 [==============================] - 1s 115us/step - loss: 0.2921 - val_loss: 0.2769\n",
      "Epoch 4/150\n",
      "6092/6092 [==============================] - 1s 112us/step - loss: 0.2537 - val_loss: 0.2387\n",
      "Epoch 5/150\n",
      "6092/6092 [==============================] - 1s 116us/step - loss: 0.2254 - val_loss: 0.2233\n",
      "Epoch 6/150\n",
      "6092/6092 [==============================] - 1s 114us/step - loss: 0.2079 - val_loss: 0.2043\n",
      "Epoch 7/150\n",
      "6092/6092 [==============================] - 1s 115us/step - loss: 0.1969 - val_loss: 0.1974\n",
      "Epoch 8/150\n",
      "6092/6092 [==============================] - 1s 115us/step - loss: 0.1926 - val_loss: 0.1876\n",
      "Epoch 9/150\n",
      "6092/6092 [==============================] - 1s 116us/step - loss: 0.1825 - val_loss: 0.1813\n",
      "Epoch 10/150\n",
      "6092/6092 [==============================] - 1s 117us/step - loss: 0.1726 - val_loss: 0.1751\n",
      "Epoch 11/150\n",
      "6092/6092 [==============================] - 1s 116us/step - loss: 0.1696 - val_loss: 0.1627\n",
      "Epoch 12/150\n",
      "6092/6092 [==============================] - 1s 114us/step - loss: 0.1639 - val_loss: 0.1648\n",
      "Epoch 13/150\n",
      "6092/6092 [==============================] - 1s 115us/step - loss: 0.1578 - val_loss: 0.1614\n",
      "Epoch 14/150\n",
      "6092/6092 [==============================] - 1s 109us/step - loss: 0.1534 - val_loss: 0.1621\n",
      "Epoch 15/150\n",
      "6092/6092 [==============================] - 1s 111us/step - loss: 0.1508 - val_loss: 0.1544\n",
      "Epoch 16/150\n",
      "6092/6092 [==============================] - 1s 112us/step - loss: 0.1453 - val_loss: 0.1566\n",
      "Epoch 17/150\n",
      "6092/6092 [==============================] - 1s 112us/step - loss: 0.1489 - val_loss: 0.1475\n",
      "Epoch 18/150\n",
      "6092/6092 [==============================] - 1s 117us/step - loss: 0.1425 - val_loss: 0.1435\n",
      "Epoch 19/150\n",
      "6092/6092 [==============================] - 1s 112us/step - loss: 0.1405 - val_loss: 0.1427\n",
      "Epoch 20/150\n",
      "6092/6092 [==============================] - 1s 113us/step - loss: 0.1385 - val_loss: 0.1355\n",
      "Epoch 21/150\n",
      "6092/6092 [==============================] - 1s 117us/step - loss: 0.1348 - val_loss: 0.1348\n",
      "Epoch 22/150\n",
      "6092/6092 [==============================] - 1s 117us/step - loss: 0.1340 - val_loss: 0.1378\n",
      "Epoch 23/150\n",
      "6092/6092 [==============================] - 1s 117us/step - loss: 0.1320 - val_loss: 0.1404\n",
      "Epoch 24/150\n",
      "6092/6092 [==============================] - 1s 115us/step - loss: 0.1325 - val_loss: 0.1340\n",
      "Epoch 25/150\n",
      "6092/6092 [==============================] - 1s 102us/step - loss: 0.1281 - val_loss: 0.1300\n",
      "Epoch 26/150\n",
      "6092/6092 [==============================] - 1s 108us/step - loss: 0.1293 - val_loss: 0.1287\n",
      "Epoch 27/150\n",
      "6092/6092 [==============================] - 1s 117us/step - loss: 0.1259 - val_loss: 0.1274\n",
      "Epoch 28/150\n",
      "6092/6092 [==============================] - 1s 116us/step - loss: 0.1269 - val_loss: 0.1242\n",
      "Epoch 29/150\n",
      "6092/6092 [==============================] - 1s 109us/step - loss: 0.1256 - val_loss: 0.1273\n",
      "Epoch 30/150\n",
      "6092/6092 [==============================] - 1s 113us/step - loss: 0.1264 - val_loss: 0.1236\n",
      "Epoch 31/150\n",
      "6092/6092 [==============================] - 1s 114us/step - loss: 0.1239 - val_loss: 0.1279\n",
      "Epoch 32/150\n",
      "6092/6092 [==============================] - 1s 115us/step - loss: 0.1221 - val_loss: 0.1260\n",
      "Epoch 33/150\n",
      "6092/6092 [==============================] - 1s 117us/step - loss: 0.1215 - val_loss: 0.1225\n",
      "Epoch 34/150\n",
      "6092/6092 [==============================] - 1s 116us/step - loss: 0.1206 - val_loss: 0.1216\n",
      "Epoch 35/150\n",
      "6092/6092 [==============================] - 1s 116us/step - loss: 0.1200 - val_loss: 0.1209\n",
      "Epoch 36/150\n",
      "6092/6092 [==============================] - 1s 116us/step - loss: 0.1173 - val_loss: 0.1256\n",
      "Epoch 37/150\n",
      "6092/6092 [==============================] - 1s 106us/step - loss: 0.1221 - val_loss: 0.1181\n",
      "Epoch 38/150\n",
      "6092/6092 [==============================] - 1s 100us/step - loss: 0.1167 - val_loss: 0.1175\n",
      "Epoch 39/150\n",
      "6092/6092 [==============================] - 1s 116us/step - loss: 0.1182 - val_loss: 0.1190\n",
      "Epoch 40/150\n",
      "6092/6092 [==============================] - 1s 113us/step - loss: 0.1190 - val_loss: 0.1155\n",
      "Epoch 41/150\n",
      "6092/6092 [==============================] - 1s 116us/step - loss: 0.1166 - val_loss: 0.1237\n",
      "Epoch 42/150\n",
      "6092/6092 [==============================] - 1s 109us/step - loss: 0.1164 - val_loss: 0.1168\n",
      "Epoch 43/150\n",
      "6092/6092 [==============================] - 1s 107us/step - loss: 0.1155 - val_loss: 0.1174\n",
      "Epoch 44/150\n",
      "6092/6092 [==============================] - 1s 110us/step - loss: 0.1146 - val_loss: 0.1207\n",
      "Evaluating model with testing data...\n",
      "1284/1284 [==============================] - 0s 15us/step\n",
      "Getting distribution of predictions and covariance matrix...\n",
      "      1 of 20\n",
      "      2 of 20\n",
      "      3 of 20\n",
      "      4 of 20\n",
      "      5 of 20\n",
      "      6 of 20\n",
      "      7 of 20\n",
      "      8 of 20\n",
      "      9 of 20\n",
      "      10 of 20\n",
      "      11 of 20\n",
      "      12 of 20\n",
      "      13 of 20\n",
      "      14 of 20\n",
      "      15 of 20\n",
      "      16 of 20\n",
      "      17 of 20\n",
      "      18 of 20\n",
      "      19 of 20\n",
      "      20 of 20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|          | 0/20 [00:00<?, ?it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing ensemble means...\n",
      "Computing mean squared error...\n",
      "Getting distribution of predictions...\n",
      "      1 of 20\n",
      "1600/1600 [==============================] - 0s 28us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  5%|▌         | 1/20 [00:29<09:11, 29.02s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      2 of 20\n",
      "1600/1600 [==============================] - 0s 29us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 10%|█         | 2/20 [00:58<08:46, 29.22s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      3 of 20\n",
      "1600/1600 [==============================] - 0s 29us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 15%|█▌        | 3/20 [01:28<08:19, 29.36s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      4 of 20\n",
      "1600/1600 [==============================] - 0s 30us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 20%|██        | 4/20 [01:57<07:49, 29.36s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      5 of 20\n",
      "1600/1600 [==============================] - 0s 29us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 25%|██▌       | 5/20 [02:27<07:20, 29.35s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      6 of 20\n",
      "1600/1600 [==============================] - 0s 29us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 30%|███       | 6/20 [02:56<06:51, 29.38s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      7 of 20\n",
      "1600/1600 [==============================] - 0s 29us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 35%|███▌      | 7/20 [03:26<06:23, 29.50s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      8 of 20\n",
      "1600/1600 [==============================] - 0s 30us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 40%|████      | 8/20 [03:55<05:54, 29.53s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      9 of 20\n",
      "1600/1600 [==============================] - 0s 29us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 45%|████▌     | 9/20 [04:25<05:24, 29.49s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      10 of 20\n",
      "1600/1600 [==============================] - 0s 29us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 50%|█████     | 10/20 [04:55<04:55, 29.56s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      11 of 20\n",
      "1600/1600 [==============================] - 0s 29us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 55%|█████▌    | 11/20 [05:24<04:26, 29.59s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      12 of 20\n",
      "1600/1600 [==============================] - 0s 29us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 60%|██████    | 12/20 [05:54<03:56, 29.59s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      13 of 20\n",
      "1600/1600 [==============================] - 0s 30us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 65%|██████▌   | 13/20 [06:23<03:26, 29.54s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      14 of 20\n",
      "1600/1600 [==============================] - 0s 29us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 70%|███████   | 14/20 [06:53<02:57, 29.56s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      15 of 20\n",
      "1600/1600 [==============================] - 0s 28us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 75%|███████▌  | 15/20 [07:22<02:27, 29.57s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      16 of 20\n",
      "1600/1600 [==============================] - 0s 30us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 80%|████████  | 16/20 [07:52<01:58, 29.64s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      17 of 20\n",
      "1600/1600 [==============================] - 0s 28us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 85%|████████▌ | 17/20 [08:21<01:28, 29.50s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      18 of 20\n",
      "1600/1600 [==============================] - 0s 29us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 90%|█████████ | 18/20 [08:51<00:59, 29.64s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      19 of 20\n",
      "1600/1600 [==============================] - 0s 29us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 95%|█████████▌| 19/20 [09:21<00:29, 29.76s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      20 of 20\n",
      "1600/1600 [==============================] - 0s 29us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 20/20 [09:51<00:00, 29.58s/it]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing ensemble predictions...\n",
      "Iteration 41\n",
      "Train on 6232 samples, validate on 1314 samples\n",
      "Epoch 1/150\n",
      "6232/6232 [==============================] - 1s 115us/step - loss: 0.6333 - val_loss: 0.4315\n",
      "Epoch 2/150\n",
      "6232/6232 [==============================] - 1s 103us/step - loss: 0.3725 - val_loss: 0.3276\n",
      "Epoch 3/150\n",
      "6232/6232 [==============================] - 1s 115us/step - loss: 0.3046 - val_loss: 0.2882\n",
      "Epoch 4/150\n",
      "6232/6232 [==============================] - 1s 108us/step - loss: 0.2679 - val_loss: 0.2669\n",
      "Epoch 5/150\n",
      "6232/6232 [==============================] - 1s 114us/step - loss: 0.2478 - val_loss: 0.2410\n",
      "Epoch 6/150\n",
      "6232/6232 [==============================] - 1s 114us/step - loss: 0.2333 - val_loss: 0.2388\n",
      "Epoch 7/150\n",
      "6232/6232 [==============================] - 1s 115us/step - loss: 0.2294 - val_loss: 0.2227\n",
      "Epoch 8/150\n",
      "6232/6232 [==============================] - 1s 116us/step - loss: 0.2241 - val_loss: 0.2235\n",
      "Epoch 9/150\n",
      "6232/6232 [==============================] - 1s 108us/step - loss: 0.2169 - val_loss: 0.2203\n",
      "Epoch 10/150\n",
      "6232/6232 [==============================] - 1s 112us/step - loss: 0.2118 - val_loss: 0.2147\n",
      "Epoch 11/150\n",
      "6232/6232 [==============================] - 1s 115us/step - loss: 0.2095 - val_loss: 0.2132\n",
      "Epoch 12/150\n",
      "6232/6232 [==============================] - 1s 116us/step - loss: 0.2049 - val_loss: 0.2037\n",
      "Epoch 13/150\n",
      "6232/6232 [==============================] - 1s 115us/step - loss: 0.2021 - val_loss: 0.2044\n",
      "Epoch 14/150\n",
      "6232/6232 [==============================] - 1s 114us/step - loss: 0.1951 - val_loss: 0.1977\n",
      "Epoch 15/150\n",
      "6232/6232 [==============================] - 1s 107us/step - loss: 0.1941 - val_loss: 0.1963\n",
      "Epoch 16/150\n",
      "6232/6232 [==============================] - 1s 107us/step - loss: 0.1882 - val_loss: 0.1866\n",
      "Epoch 17/150\n",
      "6232/6232 [==============================] - 1s 115us/step - loss: 0.1850 - val_loss: 0.1846\n",
      "Epoch 18/150\n",
      "6232/6232 [==============================] - 1s 112us/step - loss: 0.1811 - val_loss: 0.1758\n",
      "Epoch 19/150\n",
      "6232/6232 [==============================] - 1s 114us/step - loss: 0.1797 - val_loss: 0.1801\n",
      "Epoch 20/150\n",
      "6232/6232 [==============================] - 1s 113us/step - loss: 0.1757 - val_loss: 0.1830\n",
      "Epoch 21/150\n",
      "6232/6232 [==============================] - 1s 115us/step - loss: 0.1736 - val_loss: 0.1736\n",
      "Epoch 22/150\n",
      "6232/6232 [==============================] - 1s 115us/step - loss: 0.1724 - val_loss: 0.1703\n",
      "Epoch 23/150\n",
      "6232/6232 [==============================] - 1s 111us/step - loss: 0.1706 - val_loss: 0.1711\n",
      "Epoch 24/150\n",
      "6232/6232 [==============================] - 1s 98us/step - loss: 0.1697 - val_loss: 0.1705\n",
      "Epoch 25/150\n",
      "6232/6232 [==============================] - 0s 59us/step - loss: 0.1658 - val_loss: 0.1676\n",
      "Epoch 26/150\n",
      "6232/6232 [==============================] - 0s 59us/step - loss: 0.1656 - val_loss: 0.1645\n",
      "Epoch 27/150\n",
      "6232/6232 [==============================] - 0s 58us/step - loss: 0.1655 - val_loss: 0.1655\n",
      "Epoch 28/150\n",
      "6232/6232 [==============================] - 0s 77us/step - loss: 0.1644 - val_loss: 0.1639\n",
      "Epoch 29/150\n",
      "6232/6232 [==============================] - 1s 110us/step - loss: 0.1608 - val_loss: 0.1608\n",
      "Epoch 30/150\n",
      "6232/6232 [==============================] - 1s 114us/step - loss: 0.1578 - val_loss: 0.1599\n",
      "Epoch 31/150\n",
      "6232/6232 [==============================] - 1s 98us/step - loss: 0.1562 - val_loss: 0.1609\n",
      "Epoch 32/150\n",
      "6232/6232 [==============================] - 1s 114us/step - loss: 0.1578 - val_loss: 0.1520\n",
      "Epoch 33/150\n",
      "6232/6232 [==============================] - 1s 108us/step - loss: 0.1564 - val_loss: 0.1603\n",
      "Epoch 34/150\n",
      "6232/6232 [==============================] - 1s 115us/step - loss: 0.1556 - val_loss: 0.1515\n",
      "Epoch 35/150\n",
      "6232/6232 [==============================] - 1s 113us/step - loss: 0.1516 - val_loss: 0.1545\n",
      "Epoch 36/150\n",
      "6232/6232 [==============================] - 1s 110us/step - loss: 0.1507 - val_loss: 0.1508\n",
      "Epoch 37/150\n",
      "6232/6232 [==============================] - 1s 114us/step - loss: 0.1496 - val_loss: 0.1471\n",
      "Epoch 38/150\n",
      "6232/6232 [==============================] - 1s 112us/step - loss: 0.1452 - val_loss: 0.1469\n",
      "Epoch 39/150\n",
      "6232/6232 [==============================] - 1s 110us/step - loss: 0.1454 - val_loss: 0.1455\n",
      "Epoch 40/150\n",
      "6232/6232 [==============================] - 1s 114us/step - loss: 0.1460 - val_loss: 0.1468\n",
      "Epoch 41/150\n",
      "6232/6232 [==============================] - 1s 105us/step - loss: 0.1490 - val_loss: 0.1435\n",
      "Epoch 42/150\n",
      "6232/6232 [==============================] - 1s 114us/step - loss: 0.1453 - val_loss: 0.1460\n",
      "Epoch 43/150\n",
      "6232/6232 [==============================] - 1s 102us/step - loss: 0.1444 - val_loss: 0.1410\n",
      "Epoch 44/150\n",
      "6232/6232 [==============================] - 1s 114us/step - loss: 0.1461 - val_loss: 0.1479\n",
      "Epoch 45/150\n",
      "6232/6232 [==============================] - 1s 115us/step - loss: 0.1451 - val_loss: 0.1448\n",
      "Epoch 46/150\n",
      "6232/6232 [==============================] - 1s 108us/step - loss: 0.1424 - val_loss: 0.1436\n",
      "Epoch 47/150\n",
      "6232/6232 [==============================] - 1s 103us/step - loss: 0.1422 - val_loss: 0.1440\n",
      "Evaluating model with testing data...\n",
      "1314/1314 [==============================] - 0s 15us/step\n",
      "Getting distribution of predictions and covariance matrix...\n",
      "      1 of 20\n",
      "      2 of 20\n",
      "      3 of 20\n",
      "      4 of 20\n",
      "      5 of 20\n",
      "      6 of 20\n",
      "      7 of 20\n",
      "      8 of 20\n",
      "      9 of 20\n",
      "      10 of 20\n",
      "      11 of 20\n",
      "      12 of 20\n",
      "      13 of 20\n",
      "      14 of 20\n",
      "      15 of 20\n",
      "      16 of 20\n",
      "      17 of 20\n",
      "      18 of 20\n",
      "      19 of 20\n",
      "      20 of 20\n",
      "Computing ensemble means...\n",
      "Computing mean squared error...\n",
      "Iteration 42\n",
      "Train on 6372 samples, validate on 1344 samples\n",
      "Epoch 1/150\n",
      "6372/6372 [==============================] - 1s 104us/step - loss: 0.6163 - val_loss: 0.4593\n",
      "Epoch 2/150\n",
      "6372/6372 [==============================] - 1s 104us/step - loss: 0.4130 - val_loss: 0.3649\n",
      "Epoch 3/150\n",
      "6372/6372 [==============================] - 1s 100us/step - loss: 0.3219 - val_loss: 0.2947\n",
      "Epoch 4/150\n",
      "6372/6372 [==============================] - 1s 114us/step - loss: 0.2814 - val_loss: 0.2649\n",
      "Epoch 5/150\n",
      "6372/6372 [==============================] - 1s 109us/step - loss: 0.2506 - val_loss: 0.2450\n",
      "Epoch 6/150\n",
      "6372/6372 [==============================] - 1s 105us/step - loss: 0.2299 - val_loss: 0.2351\n",
      "Epoch 7/150\n",
      "6372/6372 [==============================] - 1s 108us/step - loss: 0.2100 - val_loss: 0.2074\n",
      "Epoch 8/150\n",
      "6372/6372 [==============================] - 1s 111us/step - loss: 0.1986 - val_loss: 0.2032\n",
      "Epoch 9/150\n",
      "6372/6372 [==============================] - 1s 107us/step - loss: 0.1920 - val_loss: 0.1928\n",
      "Epoch 10/150\n",
      "6372/6372 [==============================] - 1s 114us/step - loss: 0.1854 - val_loss: 0.1887\n",
      "Epoch 11/150\n",
      "6372/6372 [==============================] - 1s 104us/step - loss: 0.1811 - val_loss: 0.1720\n",
      "Epoch 12/150\n",
      "6372/6372 [==============================] - 1s 112us/step - loss: 0.1763 - val_loss: 0.1787\n",
      "Epoch 13/150\n",
      "6372/6372 [==============================] - 1s 109us/step - loss: 0.1742 - val_loss: 0.1756\n",
      "Epoch 14/150\n",
      "6372/6372 [==============================] - 1s 106us/step - loss: 0.1700 - val_loss: 0.1645\n",
      "Epoch 15/150\n",
      "6372/6372 [==============================] - 1s 106us/step - loss: 0.1653 - val_loss: 0.1648\n",
      "Epoch 16/150\n",
      "6372/6372 [==============================] - 1s 105us/step - loss: 0.1628 - val_loss: 0.1612\n",
      "Epoch 17/150\n",
      "6372/6372 [==============================] - 1s 89us/step - loss: 0.1596 - val_loss: 0.1602\n",
      "Epoch 18/150\n",
      "6372/6372 [==============================] - 1s 108us/step - loss: 0.1551 - val_loss: 0.1560\n",
      "Epoch 19/150\n",
      "6372/6372 [==============================] - 1s 105us/step - loss: 0.1538 - val_loss: 0.1550\n",
      "Epoch 20/150\n",
      "6372/6372 [==============================] - 1s 106us/step - loss: 0.1500 - val_loss: 0.1503\n",
      "Epoch 21/150\n",
      "6372/6372 [==============================] - 1s 114us/step - loss: 0.1509 - val_loss: 0.1492\n",
      "Epoch 22/150\n",
      "6372/6372 [==============================] - 1s 115us/step - loss: 0.1470 - val_loss: 0.1537\n",
      "Epoch 23/150\n",
      "6372/6372 [==============================] - 1s 98us/step - loss: 0.1484 - val_loss: 0.1407\n",
      "Epoch 24/150\n",
      "6372/6372 [==============================] - 1s 103us/step - loss: 0.1442 - val_loss: 0.1476\n",
      "Epoch 25/150\n",
      "6372/6372 [==============================] - 1s 107us/step - loss: 0.1441 - val_loss: 0.1463\n",
      "Epoch 26/150\n",
      "6372/6372 [==============================] - 1s 114us/step - loss: 0.1418 - val_loss: 0.1450\n",
      "Epoch 27/150\n",
      "6372/6372 [==============================] - 1s 115us/step - loss: 0.1444 - val_loss: 0.1422\n",
      "Evaluating model with testing data...\n",
      "1344/1344 [==============================] - 0s 17us/step\n",
      "Getting distribution of predictions and covariance matrix...\n",
      "      1 of 20\n",
      "      2 of 20\n",
      "      3 of 20\n",
      "      4 of 20\n",
      "      5 of 20\n",
      "      6 of 20\n",
      "      7 of 20\n",
      "      8 of 20\n",
      "      9 of 20\n",
      "      10 of 20\n",
      "      11 of 20\n",
      "      12 of 20\n",
      "      13 of 20\n",
      "      14 of 20\n",
      "      15 of 20\n",
      "      16 of 20\n",
      "      17 of 20\n",
      "      18 of 20\n",
      "      19 of 20\n",
      "      20 of 20\n",
      "Computing ensemble means...\n",
      "Computing mean squared error...\n",
      "Iteration 43\n",
      "Train on 6512 samples, validate on 1374 samples\n",
      "Epoch 1/150\n",
      "6512/6512 [==============================] - 1s 101us/step - loss: 0.5288 - val_loss: 0.4189\n",
      "Epoch 2/150\n",
      "6512/6512 [==============================] - 1s 100us/step - loss: 0.3776 - val_loss: 0.3489\n",
      "Epoch 3/150\n",
      "6512/6512 [==============================] - 1s 116us/step - loss: 0.3232 - val_loss: 0.3046\n",
      "Epoch 4/150\n",
      "6512/6512 [==============================] - 1s 107us/step - loss: 0.2896 - val_loss: 0.2801\n",
      "Epoch 5/150\n",
      "6512/6512 [==============================] - 1s 109us/step - loss: 0.2692 - val_loss: 0.2615\n",
      "Epoch 6/150\n",
      "6512/6512 [==============================] - 1s 115us/step - loss: 0.2565 - val_loss: 0.2595\n",
      "Epoch 7/150\n",
      "6512/6512 [==============================] - 1s 115us/step - loss: 0.2518 - val_loss: 0.2501\n",
      "Epoch 8/150\n",
      "6512/6512 [==============================] - 1s 116us/step - loss: 0.2435 - val_loss: 0.2412\n",
      "Epoch 9/150\n",
      "6512/6512 [==============================] - 1s 115us/step - loss: 0.2368 - val_loss: 0.2373\n",
      "Epoch 10/150\n",
      "6512/6512 [==============================] - 1s 113us/step - loss: 0.2288 - val_loss: 0.2239\n",
      "Epoch 11/150\n",
      "6512/6512 [==============================] - 1s 111us/step - loss: 0.2192 - val_loss: 0.2257\n",
      "Epoch 12/150\n",
      "6512/6512 [==============================] - 1s 115us/step - loss: 0.2173 - val_loss: 0.2244\n",
      "Epoch 13/150\n",
      "6512/6512 [==============================] - 1s 113us/step - loss: 0.2112 - val_loss: 0.2068\n",
      "Epoch 14/150\n",
      "6512/6512 [==============================] - 1s 100us/step - loss: 0.2021 - val_loss: 0.1947\n",
      "Epoch 15/150\n",
      "6512/6512 [==============================] - 1s 108us/step - loss: 0.1969 - val_loss: 0.1903\n",
      "Epoch 16/150\n",
      "6512/6512 [==============================] - 1s 117us/step - loss: 0.1908 - val_loss: 0.1930\n",
      "Epoch 17/150\n",
      "6512/6512 [==============================] - 1s 106us/step - loss: 0.1876 - val_loss: 0.1897\n",
      "Epoch 18/150\n",
      "6512/6512 [==============================] - 1s 115us/step - loss: 0.1835 - val_loss: 0.1906\n",
      "Epoch 19/150\n",
      "6512/6512 [==============================] - 1s 96us/step - loss: 0.1825 - val_loss: 0.1936\n",
      "Epoch 20/150\n",
      "6512/6512 [==============================] - 1s 109us/step - loss: 0.1815 - val_loss: 0.1825\n",
      "Epoch 21/150\n",
      "6512/6512 [==============================] - 1s 112us/step - loss: 0.1807 - val_loss: 0.1804\n",
      "Epoch 22/150\n",
      "6512/6512 [==============================] - 1s 114us/step - loss: 0.1773 - val_loss: 0.1829\n",
      "Epoch 23/150\n",
      "6512/6512 [==============================] - 1s 116us/step - loss: 0.1785 - val_loss: 0.1812\n",
      "Epoch 24/150\n",
      "6512/6512 [==============================] - 1s 117us/step - loss: 0.1765 - val_loss: 0.1762\n",
      "Epoch 25/150\n",
      "6512/6512 [==============================] - 1s 113us/step - loss: 0.1736 - val_loss: 0.1803\n",
      "Epoch 26/150\n",
      "6512/6512 [==============================] - 1s 116us/step - loss: 0.1709 - val_loss: 0.1706\n",
      "Epoch 27/150\n",
      "6512/6512 [==============================] - 1s 112us/step - loss: 0.1710 - val_loss: 0.1741\n",
      "Epoch 28/150\n",
      "6512/6512 [==============================] - 1s 111us/step - loss: 0.1698 - val_loss: 0.1663\n",
      "Epoch 29/150\n",
      "6512/6512 [==============================] - 1s 116us/step - loss: 0.1722 - val_loss: 0.1698\n",
      "Epoch 30/150\n",
      "6512/6512 [==============================] - 1s 110us/step - loss: 0.1651 - val_loss: 0.1698\n",
      "Epoch 31/150\n",
      "6512/6512 [==============================] - 1s 110us/step - loss: 0.1685 - val_loss: 0.1671\n",
      "Epoch 32/150\n",
      "6512/6512 [==============================] - 1s 116us/step - loss: 0.1667 - val_loss: 0.1706\n",
      "Evaluating model with testing data...\n",
      "1374/1374 [==============================] - 0s 16us/step\n",
      "Getting distribution of predictions and covariance matrix...\n",
      "      1 of 20\n",
      "      2 of 20\n",
      "      3 of 20\n",
      "      4 of 20\n",
      "      5 of 20\n",
      "      6 of 20\n",
      "      7 of 20\n",
      "      8 of 20\n",
      "      9 of 20\n",
      "      10 of 20\n",
      "      11 of 20\n",
      "      12 of 20\n",
      "      13 of 20\n",
      "      14 of 20\n",
      "      15 of 20\n",
      "      16 of 20\n",
      "      17 of 20\n",
      "      18 of 20\n",
      "      19 of 20\n",
      "      20 of 20\n",
      "Computing ensemble means...\n",
      "Computing mean squared error...\n",
      "Iteration 44\n",
      "Train on 6652 samples, validate on 1404 samples\n",
      "Epoch 1/150\n",
      "6652/6652 [==============================] - 1s 110us/step - loss: 0.4799 - val_loss: 0.3520\n",
      "Epoch 2/150\n",
      "6652/6652 [==============================] - 1s 106us/step - loss: 0.3309 - val_loss: 0.3092\n",
      "Epoch 3/150\n",
      "6652/6652 [==============================] - 1s 112us/step - loss: 0.2982 - val_loss: 0.2895\n",
      "Epoch 4/150\n",
      "6652/6652 [==============================] - 1s 115us/step - loss: 0.2758 - val_loss: 0.2697\n",
      "Epoch 5/150\n",
      "6652/6652 [==============================] - 1s 114us/step - loss: 0.2577 - val_loss: 0.2511\n",
      "Epoch 6/150\n",
      "6652/6652 [==============================] - 1s 112us/step - loss: 0.2461 - val_loss: 0.2414\n",
      "Epoch 7/150\n",
      "6652/6652 [==============================] - 1s 109us/step - loss: 0.2271 - val_loss: 0.2125\n",
      "Epoch 8/150\n",
      "6652/6652 [==============================] - 1s 114us/step - loss: 0.2075 - val_loss: 0.2028\n",
      "Epoch 9/150\n",
      "6652/6652 [==============================] - 1s 111us/step - loss: 0.2009 - val_loss: 0.1948\n",
      "Epoch 10/150\n",
      "6652/6652 [==============================] - 1s 109us/step - loss: 0.1914 - val_loss: 0.1824\n",
      "Epoch 11/150\n",
      "6652/6652 [==============================] - 1s 106us/step - loss: 0.1848 - val_loss: 0.1861\n",
      "Epoch 12/150\n",
      "6652/6652 [==============================] - 1s 108us/step - loss: 0.1788 - val_loss: 0.1778\n",
      "Epoch 13/150\n",
      "6652/6652 [==============================] - 1s 104us/step - loss: 0.1772 - val_loss: 0.1767\n",
      "Epoch 14/150\n",
      "6652/6652 [==============================] - 1s 102us/step - loss: 0.1714 - val_loss: 0.1740\n",
      "Epoch 15/150\n",
      "6652/6652 [==============================] - 1s 110us/step - loss: 0.1727 - val_loss: 0.1680\n",
      "Epoch 16/150\n",
      "6652/6652 [==============================] - 1s 112us/step - loss: 0.1682 - val_loss: 0.1696\n",
      "Epoch 17/150\n",
      "6652/6652 [==============================] - 1s 107us/step - loss: 0.1648 - val_loss: 0.1630\n",
      "Epoch 18/150\n",
      "6652/6652 [==============================] - 1s 111us/step - loss: 0.1635 - val_loss: 0.1668\n",
      "Epoch 19/150\n",
      "6652/6652 [==============================] - 1s 113us/step - loss: 0.1620 - val_loss: 0.1577\n",
      "Epoch 20/150\n",
      "6652/6652 [==============================] - 1s 111us/step - loss: 0.1624 - val_loss: 0.1606\n",
      "Epoch 21/150\n",
      "6652/6652 [==============================] - 1s 107us/step - loss: 0.1588 - val_loss: 0.1587\n",
      "Epoch 22/150\n",
      "6652/6652 [==============================] - 1s 116us/step - loss: 0.1605 - val_loss: 0.1621\n",
      "Epoch 23/150\n",
      "6652/6652 [==============================] - 1s 113us/step - loss: 0.1569 - val_loss: 0.1516\n",
      "Epoch 24/150\n",
      "6652/6652 [==============================] - 1s 94us/step - loss: 0.1557 - val_loss: 0.1598\n",
      "Epoch 25/150\n",
      "6652/6652 [==============================] - 1s 109us/step - loss: 0.1574 - val_loss: 0.1531\n",
      "Epoch 26/150\n",
      "6652/6652 [==============================] - 1s 109us/step - loss: 0.1551 - val_loss: 0.1522\n",
      "Epoch 27/150\n",
      "6652/6652 [==============================] - 1s 107us/step - loss: 0.1561 - val_loss: 0.1517\n",
      "Evaluating model with testing data...\n",
      "1404/1404 [==============================] - 0s 16us/step\n",
      "Getting distribution of predictions and covariance matrix...\n",
      "      1 of 20\n",
      "      2 of 20\n",
      "      3 of 20\n",
      "      4 of 20\n",
      "      5 of 20\n",
      "      6 of 20\n",
      "      7 of 20\n",
      "      8 of 20\n",
      "      9 of 20\n",
      "      10 of 20\n",
      "      11 of 20\n",
      "      12 of 20\n",
      "      13 of 20\n",
      "      14 of 20\n",
      "      15 of 20\n",
      "      16 of 20\n",
      "      17 of 20\n",
      "      18 of 20\n",
      "      19 of 20\n",
      "      20 of 20\n",
      "Computing ensemble means...\n",
      "Computing mean squared error...\n",
      "Iteration 45\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 6792 samples, validate on 1434 samples\n",
      "Epoch 1/150\n",
      "6792/6792 [==============================] - 1s 119us/step - loss: 0.5828 - val_loss: 0.4366\n",
      "Epoch 2/150\n",
      "6792/6792 [==============================] - 1s 107us/step - loss: 0.3955 - val_loss: 0.3622\n",
      "Epoch 3/150\n",
      "6792/6792 [==============================] - 1s 115us/step - loss: 0.3282 - val_loss: 0.3135\n",
      "Epoch 4/150\n",
      "6792/6792 [==============================] - 1s 115us/step - loss: 0.2948 - val_loss: 0.2887\n",
      "Epoch 5/150\n",
      "6792/6792 [==============================] - 1s 107us/step - loss: 0.2719 - val_loss: 0.2714\n",
      "Epoch 6/150\n",
      "6792/6792 [==============================] - 1s 115us/step - loss: 0.2587 - val_loss: 0.2570\n",
      "Epoch 7/150\n",
      "6792/6792 [==============================] - 1s 115us/step - loss: 0.2505 - val_loss: 0.2462\n",
      "Epoch 8/150\n",
      "6792/6792 [==============================] - 1s 115us/step - loss: 0.2447 - val_loss: 0.2387\n",
      "Epoch 9/150\n",
      "6792/6792 [==============================] - 1s 115us/step - loss: 0.2340 - val_loss: 0.2268\n",
      "Epoch 10/150\n",
      "6792/6792 [==============================] - 1s 114us/step - loss: 0.2284 - val_loss: 0.2205\n",
      "Epoch 11/150\n",
      "6792/6792 [==============================] - 1s 114us/step - loss: 0.2261 - val_loss: 0.2159\n",
      "Epoch 12/150\n",
      "6792/6792 [==============================] - 1s 114us/step - loss: 0.2182 - val_loss: 0.2110\n",
      "Epoch 13/150\n",
      "6792/6792 [==============================] - 1s 116us/step - loss: 0.2151 - val_loss: 0.2140\n",
      "Epoch 14/150\n",
      "6792/6792 [==============================] - 1s 115us/step - loss: 0.2135 - val_loss: 0.2025\n",
      "Epoch 15/150\n",
      "6792/6792 [==============================] - 1s 114us/step - loss: 0.2135 - val_loss: 0.2133\n",
      "Epoch 16/150\n",
      "6792/6792 [==============================] - 1s 111us/step - loss: 0.2121 - val_loss: 0.2028\n",
      "Epoch 17/150\n",
      "6792/6792 [==============================] - 1s 112us/step - loss: 0.2072 - val_loss: 0.2017\n",
      "Epoch 18/150\n",
      "6792/6792 [==============================] - 1s 112us/step - loss: 0.2039 - val_loss: 0.2023\n",
      "Epoch 19/150\n",
      "6792/6792 [==============================] - 1s 115us/step - loss: 0.2064 - val_loss: 0.1996\n",
      "Epoch 20/150\n",
      "6792/6792 [==============================] - 1s 115us/step - loss: 0.2010 - val_loss: 0.1995\n",
      "Epoch 21/150\n",
      "6792/6792 [==============================] - 1s 115us/step - loss: 0.2004 - val_loss: 0.1915\n",
      "Epoch 22/150\n",
      "6792/6792 [==============================] - 1s 115us/step - loss: 0.1995 - val_loss: 0.2091\n",
      "Epoch 23/150\n",
      "6792/6792 [==============================] - 1s 115us/step - loss: 0.2066 - val_loss: 0.1995\n",
      "Epoch 24/150\n",
      "6792/6792 [==============================] - 1s 115us/step - loss: 0.1974 - val_loss: 0.1995\n",
      "Epoch 25/150\n",
      "6792/6792 [==============================] - 1s 110us/step - loss: 0.1948 - val_loss: 0.1923\n",
      "Evaluating model with testing data...\n",
      "1434/1434 [==============================] - 0s 16us/step\n",
      "Getting distribution of predictions and covariance matrix...\n",
      "      1 of 20\n",
      "      2 of 20\n",
      "      3 of 20\n",
      "      4 of 20\n",
      "      5 of 20\n",
      "      6 of 20\n",
      "      7 of 20\n",
      "      8 of 20\n",
      "      9 of 20\n",
      "      10 of 20\n",
      "      11 of 20\n",
      "      12 of 20\n",
      "      13 of 20\n",
      "      14 of 20\n",
      "      15 of 20\n",
      "      16 of 20\n",
      "      17 of 20\n",
      "      18 of 20\n",
      "      19 of 20\n",
      "      20 of 20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|          | 0/20 [00:00<?, ?it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing ensemble means...\n",
      "Computing mean squared error...\n",
      "Getting distribution of predictions...\n",
      "      1 of 20\n",
      "1600/1600 [==============================] - 0s 27us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  5%|▌         | 1/20 [00:29<09:15, 29.23s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      2 of 20\n",
      "1600/1600 [==============================] - 0s 29us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 10%|█         | 2/20 [00:58<08:48, 29.37s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      3 of 20\n",
      "1600/1600 [==============================] - 0s 36us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 15%|█▌        | 3/20 [01:28<08:20, 29.42s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      4 of 20\n",
      "1600/1600 [==============================] - 0s 30us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 20%|██        | 4/20 [01:58<07:52, 29.54s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      5 of 20\n",
      "1600/1600 [==============================] - 0s 28us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 25%|██▌       | 5/20 [02:27<07:21, 29.45s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      6 of 20\n",
      "1600/1600 [==============================] - 0s 30us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 30%|███       | 6/20 [02:57<06:53, 29.50s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      7 of 20\n",
      "1600/1600 [==============================] - 0s 29us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 35%|███▌      | 7/20 [03:26<06:23, 29.52s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      8 of 20\n",
      "1600/1600 [==============================] - 0s 29us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 40%|████      | 8/20 [03:56<05:54, 29.54s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      9 of 20\n",
      "1600/1600 [==============================] - 0s 29us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 45%|████▌     | 9/20 [04:25<05:24, 29.52s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      10 of 20\n",
      "1600/1600 [==============================] - 0s 30us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 50%|█████     | 10/20 [04:55<04:54, 29.48s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      11 of 20\n",
      "1600/1600 [==============================] - 0s 29us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 55%|█████▌    | 11/20 [05:24<04:25, 29.50s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      12 of 20\n",
      "1600/1600 [==============================] - 0s 29us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 60%|██████    | 12/20 [05:54<03:55, 29.49s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      13 of 20\n",
      "1600/1600 [==============================] - 0s 29us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 65%|██████▌   | 13/20 [06:23<03:26, 29.44s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      14 of 20\n",
      "1600/1600 [==============================] - 0s 29us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 70%|███████   | 14/20 [06:52<02:56, 29.43s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      15 of 20\n",
      "1600/1600 [==============================] - 0s 30us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 75%|███████▌  | 15/20 [07:22<02:27, 29.50s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      16 of 20\n",
      "1600/1600 [==============================] - 0s 28us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 80%|████████  | 16/20 [07:52<01:58, 29.50s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      17 of 20\n",
      "1600/1600 [==============================] - 0s 29us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 85%|████████▌ | 17/20 [08:21<01:28, 29.44s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      18 of 20\n",
      "1600/1600 [==============================] - 0s 29us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 90%|█████████ | 18/20 [08:51<00:59, 29.54s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      19 of 20\n",
      "1600/1600 [==============================] - 0s 29us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 95%|█████████▌| 19/20 [09:20<00:29, 29.57s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      20 of 20\n",
      "1600/1600 [==============================] - 0s 29us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 20/20 [09:50<00:00, 29.53s/it]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing ensemble predictions...\n",
      "Iteration 46\n",
      "Train on 6932 samples, validate on 1464 samples\n",
      "Epoch 1/150\n",
      "6932/6932 [==============================] - 1s 112us/step - loss: 0.5551 - val_loss: 0.4094\n",
      "Epoch 2/150\n",
      "6932/6932 [==============================] - 1s 108us/step - loss: 0.3663 - val_loss: 0.3346\n",
      "Epoch 3/150\n",
      "6932/6932 [==============================] - 1s 115us/step - loss: 0.2965 - val_loss: 0.2668\n",
      "Epoch 4/150\n",
      "6932/6932 [==============================] - 1s 115us/step - loss: 0.2570 - val_loss: 0.2440\n",
      "Epoch 5/150\n",
      "6932/6932 [==============================] - 1s 115us/step - loss: 0.2286 - val_loss: 0.2201\n",
      "Epoch 6/150\n",
      "6932/6932 [==============================] - 1s 106us/step - loss: 0.2173 - val_loss: 0.2155\n",
      "Epoch 7/150\n",
      "6932/6932 [==============================] - 1s 115us/step - loss: 0.2022 - val_loss: 0.2034\n",
      "Epoch 8/150\n",
      "6932/6932 [==============================] - 1s 114us/step - loss: 0.1971 - val_loss: 0.1997\n",
      "Epoch 9/150\n",
      "6932/6932 [==============================] - 1s 115us/step - loss: 0.1888 - val_loss: 0.1820\n",
      "Epoch 10/150\n",
      "6932/6932 [==============================] - 1s 115us/step - loss: 0.1839 - val_loss: 0.1818\n",
      "Epoch 11/150\n",
      "6932/6932 [==============================] - 1s 115us/step - loss: 0.1778 - val_loss: 0.1751\n",
      "Epoch 12/150\n",
      "6932/6932 [==============================] - 1s 116us/step - loss: 0.1724 - val_loss: 0.1748\n",
      "Epoch 13/150\n",
      "6932/6932 [==============================] - 1s 116us/step - loss: 0.1698 - val_loss: 0.1704\n",
      "Epoch 14/150\n",
      "6932/6932 [==============================] - 1s 114us/step - loss: 0.1674 - val_loss: 0.1653\n",
      "Epoch 15/150\n",
      "6932/6932 [==============================] - 1s 115us/step - loss: 0.1640 - val_loss: 0.1670\n",
      "Epoch 16/150\n",
      "6932/6932 [==============================] - 1s 114us/step - loss: 0.1624 - val_loss: 0.1570\n",
      "Epoch 17/150\n",
      "6932/6932 [==============================] - 1s 115us/step - loss: 0.1622 - val_loss: 0.1619\n",
      "Epoch 18/150\n",
      "6932/6932 [==============================] - 1s 115us/step - loss: 0.1580 - val_loss: 0.1539\n",
      "Epoch 19/150\n",
      "6932/6932 [==============================] - 1s 115us/step - loss: 0.1572 - val_loss: 0.1557\n",
      "Epoch 20/150\n",
      "6932/6932 [==============================] - 1s 115us/step - loss: 0.1533 - val_loss: 0.1549\n",
      "Epoch 21/150\n",
      "6932/6932 [==============================] - 1s 110us/step - loss: 0.1551 - val_loss: 0.1510\n",
      "Epoch 22/150\n",
      "6932/6932 [==============================] - 1s 115us/step - loss: 0.1566 - val_loss: 0.1492\n",
      "Epoch 23/150\n",
      "6932/6932 [==============================] - 1s 115us/step - loss: 0.1528 - val_loss: 0.1507\n",
      "Epoch 24/150\n",
      "6932/6932 [==============================] - 1s 115us/step - loss: 0.1545 - val_loss: 0.1504\n",
      "Epoch 25/150\n",
      "6932/6932 [==============================] - 1s 115us/step - loss: 0.1505 - val_loss: 0.1534\n",
      "Epoch 26/150\n",
      "6932/6932 [==============================] - 1s 115us/step - loss: 0.1519 - val_loss: 0.1510\n",
      "Evaluating model with testing data...\n",
      "1464/1464 [==============================] - 0s 16us/step\n",
      "Getting distribution of predictions and covariance matrix...\n",
      "      1 of 20\n",
      "      2 of 20\n",
      "      3 of 20\n",
      "      4 of 20\n",
      "      5 of 20\n",
      "      6 of 20\n",
      "      7 of 20\n",
      "      8 of 20\n",
      "      9 of 20\n",
      "      10 of 20\n",
      "      11 of 20\n",
      "      12 of 20\n",
      "      13 of 20\n",
      "      14 of 20\n",
      "      15 of 20\n",
      "      16 of 20\n",
      "      17 of 20\n",
      "      18 of 20\n",
      "      19 of 20\n",
      "      20 of 20\n",
      "Computing ensemble means...\n",
      "Computing mean squared error...\n",
      "Iteration 47\n",
      "Train on 7072 samples, validate on 1494 samples\n",
      "Epoch 1/150\n",
      "7072/7072 [==============================] - 1s 114us/step - loss: 0.5364 - val_loss: 0.4140\n",
      "Epoch 2/150\n",
      "7072/7072 [==============================] - 1s 101us/step - loss: 0.3620 - val_loss: 0.3296\n",
      "Epoch 3/150\n",
      "7072/7072 [==============================] - 1s 115us/step - loss: 0.2976 - val_loss: 0.2802\n",
      "Epoch 4/150\n",
      "7072/7072 [==============================] - 1s 116us/step - loss: 0.2657 - val_loss: 0.2656\n",
      "Epoch 5/150\n",
      "7072/7072 [==============================] - 1s 110us/step - loss: 0.2461 - val_loss: 0.2347\n",
      "Epoch 6/150\n",
      "7072/7072 [==============================] - 1s 114us/step - loss: 0.2291 - val_loss: 0.2277\n",
      "Epoch 7/150\n",
      "7072/7072 [==============================] - 1s 106us/step - loss: 0.2193 - val_loss: 0.2150\n",
      "Epoch 8/150\n",
      "7072/7072 [==============================] - 0s 60us/step - loss: 0.2132 - val_loss: 0.2103\n",
      "Epoch 9/150\n",
      "7072/7072 [==============================] - 0s 60us/step - loss: 0.2033 - val_loss: 0.1964\n",
      "Epoch 10/150\n",
      "7072/7072 [==============================] - 0s 60us/step - loss: 0.1988 - val_loss: 0.1933\n",
      "Epoch 11/150\n",
      "7072/7072 [==============================] - 1s 108us/step - loss: 0.1929 - val_loss: 0.1881\n",
      "Epoch 12/150\n",
      "7072/7072 [==============================] - 1s 116us/step - loss: 0.1852 - val_loss: 0.1824\n",
      "Epoch 13/150\n",
      "7072/7072 [==============================] - 1s 98us/step - loss: 0.1854 - val_loss: 0.1829\n",
      "Epoch 14/150\n",
      "7072/7072 [==============================] - 1s 97us/step - loss: 0.1817 - val_loss: 0.1747\n",
      "Epoch 15/150\n",
      "7072/7072 [==============================] - 1s 113us/step - loss: 0.1763 - val_loss: 0.1764\n",
      "Epoch 16/150\n",
      "7072/7072 [==============================] - 1s 116us/step - loss: 0.1687 - val_loss: 0.1740\n",
      "Epoch 17/150\n",
      "7072/7072 [==============================] - 1s 116us/step - loss: 0.1653 - val_loss: 0.1723\n",
      "Epoch 18/150\n",
      "7072/7072 [==============================] - 1s 116us/step - loss: 0.1647 - val_loss: 0.1700\n",
      "Epoch 19/150\n",
      "7072/7072 [==============================] - 1s 113us/step - loss: 0.1626 - val_loss: 0.1655\n",
      "Epoch 20/150\n",
      "7072/7072 [==============================] - 1s 112us/step - loss: 0.1605 - val_loss: 0.1609\n",
      "Epoch 21/150\n",
      "7072/7072 [==============================] - 1s 114us/step - loss: 0.1621 - val_loss: 0.1584\n",
      "Epoch 22/150\n",
      "7072/7072 [==============================] - 1s 108us/step - loss: 0.1602 - val_loss: 0.1620\n",
      "Epoch 23/150\n",
      "7072/7072 [==============================] - 1s 110us/step - loss: 0.1556 - val_loss: 0.1531\n",
      "Epoch 24/150\n",
      "7072/7072 [==============================] - 1s 107us/step - loss: 0.1535 - val_loss: 0.1557\n",
      "Epoch 25/150\n",
      "7072/7072 [==============================] - 1s 113us/step - loss: 0.1551 - val_loss: 0.1519\n",
      "Epoch 26/150\n",
      "7072/7072 [==============================] - 1s 114us/step - loss: 0.1544 - val_loss: 0.1519\n",
      "Epoch 27/150\n",
      "7072/7072 [==============================] - 1s 114us/step - loss: 0.1497 - val_loss: 0.1523\n",
      "Epoch 28/150\n",
      "7072/7072 [==============================] - 1s 116us/step - loss: 0.1497 - val_loss: 0.1480\n",
      "Epoch 29/150\n",
      "7072/7072 [==============================] - 1s 115us/step - loss: 0.1502 - val_loss: 0.1451\n",
      "Epoch 30/150\n",
      "7072/7072 [==============================] - 1s 117us/step - loss: 0.1477 - val_loss: 0.1490\n",
      "Epoch 31/150\n",
      "7072/7072 [==============================] - 1s 90us/step - loss: 0.1460 - val_loss: 0.1473\n",
      "Epoch 32/150\n",
      "7072/7072 [==============================] - 1s 114us/step - loss: 0.1497 - val_loss: 0.1464\n",
      "Epoch 33/150\n",
      "7072/7072 [==============================] - 1s 101us/step - loss: 0.1471 - val_loss: 0.1426\n",
      "Epoch 34/150\n",
      "7072/7072 [==============================] - 1s 110us/step - loss: 0.1466 - val_loss: 0.1559\n",
      "Epoch 35/150\n",
      "7072/7072 [==============================] - 1s 101us/step - loss: 0.1471 - val_loss: 0.1472\n",
      "Epoch 36/150\n",
      "7072/7072 [==============================] - 1s 104us/step - loss: 0.1443 - val_loss: 0.1427\n",
      "Epoch 37/150\n",
      "7072/7072 [==============================] - 1s 110us/step - loss: 0.1456 - val_loss: 0.1468\n",
      "Evaluating model with testing data...\n",
      "1494/1494 [==============================] - 0s 16us/step\n",
      "Getting distribution of predictions and covariance matrix...\n",
      "      1 of 20\n",
      "      2 of 20\n",
      "      3 of 20\n",
      "      4 of 20\n",
      "      5 of 20\n",
      "      6 of 20\n",
      "      7 of 20\n",
      "      8 of 20\n",
      "      9 of 20\n",
      "      10 of 20\n",
      "      11 of 20\n",
      "      12 of 20\n",
      "      13 of 20\n",
      "      14 of 20\n",
      "      15 of 20\n",
      "      16 of 20\n",
      "      17 of 20\n",
      "      18 of 20\n",
      "      19 of 20\n",
      "      20 of 20\n",
      "Computing ensemble means...\n",
      "Computing mean squared error...\n",
      "Iteration 48\n",
      "Train on 7212 samples, validate on 1524 samples\n",
      "Epoch 1/150\n",
      "7212/7212 [==============================] - 1s 101us/step - loss: 0.4845 - val_loss: 0.3844\n",
      "Epoch 2/150\n",
      "7212/7212 [==============================] - 1s 106us/step - loss: 0.3309 - val_loss: 0.2859\n",
      "Epoch 3/150\n",
      "7212/7212 [==============================] - 1s 106us/step - loss: 0.2592 - val_loss: 0.2436\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4/150\n",
      "7212/7212 [==============================] - 1s 107us/step - loss: 0.2291 - val_loss: 0.2094\n",
      "Epoch 5/150\n",
      "7212/7212 [==============================] - 1s 110us/step - loss: 0.2113 - val_loss: 0.2003\n",
      "Epoch 6/150\n",
      "7212/7212 [==============================] - 1s 115us/step - loss: 0.2010 - val_loss: 0.1984\n",
      "Epoch 7/150\n",
      "7212/7212 [==============================] - 1s 112us/step - loss: 0.1900 - val_loss: 0.1842\n",
      "Epoch 8/150\n",
      "7212/7212 [==============================] - 1s 114us/step - loss: 0.1834 - val_loss: 0.1775\n",
      "Epoch 9/150\n",
      "7212/7212 [==============================] - 1s 114us/step - loss: 0.1788 - val_loss: 0.1686\n",
      "Epoch 10/150\n",
      "7212/7212 [==============================] - 1s 107us/step - loss: 0.1745 - val_loss: 0.1709\n",
      "Epoch 11/150\n",
      "7212/7212 [==============================] - 1s 114us/step - loss: 0.1704 - val_loss: 0.1639\n",
      "Epoch 12/150\n",
      "7212/7212 [==============================] - 1s 115us/step - loss: 0.1673 - val_loss: 0.1665\n",
      "Epoch 13/150\n",
      "7212/7212 [==============================] - 1s 114us/step - loss: 0.1656 - val_loss: 0.1626\n",
      "Epoch 14/150\n",
      "7212/7212 [==============================] - 1s 113us/step - loss: 0.1606 - val_loss: 0.1686\n",
      "Epoch 15/150\n",
      "7212/7212 [==============================] - 1s 115us/step - loss: 0.1575 - val_loss: 0.1567\n",
      "Epoch 16/150\n",
      "7212/7212 [==============================] - 1s 115us/step - loss: 0.1543 - val_loss: 0.1536\n",
      "Epoch 17/150\n",
      "7212/7212 [==============================] - 1s 114us/step - loss: 0.1568 - val_loss: 0.1568\n",
      "Epoch 18/150\n",
      "7212/7212 [==============================] - 1s 107us/step - loss: 0.1508 - val_loss: 0.1497\n",
      "Epoch 19/150\n",
      "7212/7212 [==============================] - 1s 115us/step - loss: 0.1513 - val_loss: 0.1451\n",
      "Epoch 20/150\n",
      "7212/7212 [==============================] - 1s 115us/step - loss: 0.1477 - val_loss: 0.1461\n",
      "Epoch 21/150\n",
      "7212/7212 [==============================] - 1s 115us/step - loss: 0.1470 - val_loss: 0.1470\n",
      "Epoch 22/150\n",
      "7212/7212 [==============================] - 1s 114us/step - loss: 0.1457 - val_loss: 0.1493\n",
      "Epoch 23/150\n",
      "7212/7212 [==============================] - 1s 113us/step - loss: 0.1437 - val_loss: 0.1503\n",
      "Evaluating model with testing data...\n",
      "1524/1524 [==============================] - 0s 16us/step\n",
      "Getting distribution of predictions and covariance matrix...\n",
      "      1 of 20\n",
      "      2 of 20\n",
      "      3 of 20\n",
      "      4 of 20\n",
      "      5 of 20\n",
      "      6 of 20\n",
      "      7 of 20\n",
      "      8 of 20\n",
      "      9 of 20\n",
      "      10 of 20\n",
      "      11 of 20\n",
      "      12 of 20\n",
      "      13 of 20\n",
      "      14 of 20\n",
      "      15 of 20\n",
      "      16 of 20\n",
      "      17 of 20\n",
      "      18 of 20\n",
      "      19 of 20\n",
      "      20 of 20\n",
      "Computing ensemble means...\n",
      "Computing mean squared error...\n",
      "Iteration 49\n",
      "Train on 7352 samples, validate on 1554 samples\n",
      "Epoch 1/150\n",
      "7352/7352 [==============================] - 1s 120us/step - loss: 0.5317 - val_loss: 0.3790\n",
      "Epoch 2/150\n",
      "7352/7352 [==============================] - 1s 107us/step - loss: 0.3256 - val_loss: 0.2911\n",
      "Epoch 3/150\n",
      "7352/7352 [==============================] - 1s 112us/step - loss: 0.2652 - val_loss: 0.2542\n",
      "Epoch 4/150\n",
      "7352/7352 [==============================] - 1s 115us/step - loss: 0.2393 - val_loss: 0.2288\n",
      "Epoch 5/150\n",
      "7352/7352 [==============================] - 1s 115us/step - loss: 0.2218 - val_loss: 0.2150\n",
      "Epoch 6/150\n",
      "7352/7352 [==============================] - 1s 115us/step - loss: 0.2097 - val_loss: 0.2036\n",
      "Epoch 7/150\n",
      "7352/7352 [==============================] - 1s 115us/step - loss: 0.2012 - val_loss: 0.1988\n",
      "Epoch 8/150\n",
      "7352/7352 [==============================] - 1s 115us/step - loss: 0.1964 - val_loss: 0.1900\n",
      "Epoch 9/150\n",
      "7352/7352 [==============================] - 1s 106us/step - loss: 0.1877 - val_loss: 0.1862\n",
      "Epoch 10/150\n",
      "7352/7352 [==============================] - 1s 107us/step - loss: 0.1820 - val_loss: 0.1736\n",
      "Epoch 11/150\n",
      "7352/7352 [==============================] - 1s 115us/step - loss: 0.1707 - val_loss: 0.1622\n",
      "Epoch 12/150\n",
      "7352/7352 [==============================] - 1s 111us/step - loss: 0.1656 - val_loss: 0.1733\n",
      "Epoch 13/150\n",
      "7352/7352 [==============================] - 1s 106us/step - loss: 0.1644 - val_loss: 0.1630\n",
      "Epoch 14/150\n",
      "7352/7352 [==============================] - 1s 108us/step - loss: 0.1626 - val_loss: 0.1603\n",
      "Epoch 15/150\n",
      "7352/7352 [==============================] - 1s 112us/step - loss: 0.1568 - val_loss: 0.1531\n",
      "Epoch 16/150\n",
      "7352/7352 [==============================] - 1s 99us/step - loss: 0.1568 - val_loss: 0.1569\n",
      "Epoch 17/150\n",
      "7352/7352 [==============================] - 1s 113us/step - loss: 0.1559 - val_loss: 0.1530\n",
      "Epoch 18/150\n",
      "7352/7352 [==============================] - 1s 113us/step - loss: 0.1490 - val_loss: 0.1494\n",
      "Epoch 19/150\n",
      "7352/7352 [==============================] - 1s 110us/step - loss: 0.1519 - val_loss: 0.1430\n",
      "Epoch 20/150\n",
      "7352/7352 [==============================] - 1s 112us/step - loss: 0.1497 - val_loss: 0.1466\n",
      "Epoch 21/150\n",
      "7352/7352 [==============================] - 1s 115us/step - loss: 0.1472 - val_loss: 0.1479\n",
      "Epoch 22/150\n",
      "7352/7352 [==============================] - 1s 104us/step - loss: 0.1451 - val_loss: 0.1404\n",
      "Epoch 23/150\n",
      "7352/7352 [==============================] - 1s 109us/step - loss: 0.1432 - val_loss: 0.1414\n",
      "Epoch 24/150\n",
      "7352/7352 [==============================] - 1s 115us/step - loss: 0.1432 - val_loss: 0.1445\n",
      "Epoch 25/150\n",
      "7352/7352 [==============================] - 1s 115us/step - loss: 0.1394 - val_loss: 0.1421\n",
      "Epoch 26/150\n",
      "7352/7352 [==============================] - 1s 108us/step - loss: 0.1417 - val_loss: 0.1391\n",
      "Epoch 27/150\n",
      "7352/7352 [==============================] - 1s 112us/step - loss: 0.1416 - val_loss: 0.1385\n",
      "Epoch 28/150\n",
      "7352/7352 [==============================] - 1s 114us/step - loss: 0.1399 - val_loss: 0.1368\n",
      "Epoch 29/150\n",
      "7352/7352 [==============================] - 1s 110us/step - loss: 0.1382 - val_loss: 0.1393\n",
      "Epoch 30/150\n",
      "7352/7352 [==============================] - 1s 111us/step - loss: 0.1355 - val_loss: 0.1389\n",
      "Epoch 31/150\n",
      "7352/7352 [==============================] - 1s 108us/step - loss: 0.1346 - val_loss: 0.1355\n",
      "Epoch 32/150\n",
      "7352/7352 [==============================] - 1s 113us/step - loss: 0.1336 - val_loss: 0.1330\n",
      "Epoch 33/150\n",
      "7352/7352 [==============================] - 1s 106us/step - loss: 0.1355 - val_loss: 0.1345\n",
      "Epoch 34/150\n",
      "7352/7352 [==============================] - 1s 114us/step - loss: 0.1331 - val_loss: 0.1292\n",
      "Epoch 35/150\n",
      "7352/7352 [==============================] - 1s 112us/step - loss: 0.1306 - val_loss: 0.1332\n",
      "Epoch 36/150\n",
      "7352/7352 [==============================] - 1s 103us/step - loss: 0.1316 - val_loss: 0.1338\n",
      "Epoch 37/150\n",
      "7352/7352 [==============================] - 1s 109us/step - loss: 0.1288 - val_loss: 0.1363\n",
      "Epoch 38/150\n",
      "7352/7352 [==============================] - 1s 112us/step - loss: 0.1317 - val_loss: 0.1309\n",
      "Evaluating model with testing data...\n",
      "1554/1554 [==============================] - 0s 16us/step\n",
      "Getting distribution of predictions and covariance matrix...\n",
      "      1 of 20\n",
      "      2 of 20\n",
      "      3 of 20\n",
      "      4 of 20\n",
      "      5 of 20\n",
      "      6 of 20\n",
      "      7 of 20\n",
      "      8 of 20\n",
      "      9 of 20\n",
      "      10 of 20\n",
      "      11 of 20\n",
      "      12 of 20\n",
      "      13 of 20\n",
      "      14 of 20\n",
      "      15 of 20\n",
      "      16 of 20\n",
      "      17 of 20\n",
      "      18 of 20\n",
      "      19 of 20\n",
      "      20 of 20\n",
      "Computing ensemble means...\n",
      "Computing mean squared error...\n",
      "Iteration 50\n",
      "Train on 7492 samples, validate on 1584 samples\n",
      "Epoch 1/150\n",
      "7492/7492 [==============================] - 1s 114us/step - loss: 0.5415 - val_loss: 0.3719\n",
      "Epoch 2/150\n",
      "7492/7492 [==============================] - 1s 106us/step - loss: 0.3270 - val_loss: 0.3031\n",
      "Epoch 3/150\n",
      "7492/7492 [==============================] - 1s 104us/step - loss: 0.2795 - val_loss: 0.2561\n",
      "Epoch 4/150\n",
      "7492/7492 [==============================] - 1s 105us/step - loss: 0.2536 - val_loss: 0.2412\n",
      "Epoch 5/150\n",
      "7492/7492 [==============================] - 1s 111us/step - loss: 0.2382 - val_loss: 0.2353\n",
      "Epoch 6/150\n",
      "7492/7492 [==============================] - 1s 105us/step - loss: 0.2256 - val_loss: 0.2189\n",
      "Epoch 7/150\n",
      "7492/7492 [==============================] - 1s 97us/step - loss: 0.2160 - val_loss: 0.2117\n",
      "Epoch 8/150\n",
      "7492/7492 [==============================] - 1s 104us/step - loss: 0.2047 - val_loss: 0.1993\n",
      "Epoch 9/150\n",
      "7492/7492 [==============================] - 1s 108us/step - loss: 0.1982 - val_loss: 0.1933\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10/150\n",
      "7492/7492 [==============================] - 1s 104us/step - loss: 0.1926 - val_loss: 0.1918\n",
      "Epoch 11/150\n",
      "7492/7492 [==============================] - 1s 114us/step - loss: 0.1892 - val_loss: 0.1834\n",
      "Epoch 12/150\n",
      "7492/7492 [==============================] - 1s 113us/step - loss: 0.1844 - val_loss: 0.1830\n",
      "Epoch 13/150\n",
      "7492/7492 [==============================] - 1s 111us/step - loss: 0.1794 - val_loss: 0.1748\n",
      "Epoch 14/150\n",
      "7492/7492 [==============================] - 1s 115us/step - loss: 0.1778 - val_loss: 0.1743\n",
      "Epoch 15/150\n",
      "7492/7492 [==============================] - 1s 116us/step - loss: 0.1717 - val_loss: 0.1727\n",
      "Epoch 16/150\n",
      "7492/7492 [==============================] - 1s 114us/step - loss: 0.1721 - val_loss: 0.1722\n",
      "Epoch 17/150\n",
      "7492/7492 [==============================] - 1s 116us/step - loss: 0.1705 - val_loss: 0.1695\n",
      "Epoch 18/150\n",
      "7492/7492 [==============================] - 1s 116us/step - loss: 0.1670 - val_loss: 0.1719\n",
      "Epoch 19/150\n",
      "7492/7492 [==============================] - 1s 116us/step - loss: 0.1672 - val_loss: 0.1649\n",
      "Epoch 20/150\n",
      "7492/7492 [==============================] - 1s 116us/step - loss: 0.1666 - val_loss: 0.1590\n",
      "Epoch 21/150\n",
      "7492/7492 [==============================] - 1s 114us/step - loss: 0.1623 - val_loss: 0.1603\n",
      "Epoch 22/150\n",
      "7492/7492 [==============================] - 1s 116us/step - loss: 0.1602 - val_loss: 0.1568\n",
      "Epoch 23/150\n",
      "7492/7492 [==============================] - 1s 116us/step - loss: 0.1582 - val_loss: 0.1617\n",
      "Epoch 24/150\n",
      "7492/7492 [==============================] - 1s 116us/step - loss: 0.1559 - val_loss: 0.1520\n",
      "Epoch 25/150\n",
      "7492/7492 [==============================] - 1s 116us/step - loss: 0.1565 - val_loss: 0.1553\n",
      "Epoch 26/150\n",
      "7492/7492 [==============================] - 1s 111us/step - loss: 0.1540 - val_loss: 0.1543\n",
      "Epoch 27/150\n",
      "7492/7492 [==============================] - 1s 116us/step - loss: 0.1542 - val_loss: 0.1558\n",
      "Epoch 28/150\n",
      "7492/7492 [==============================] - 1s 115us/step - loss: 0.1520 - val_loss: 0.1516\n",
      "Epoch 29/150\n",
      "7492/7492 [==============================] - 1s 117us/step - loss: 0.1505 - val_loss: 0.1504\n",
      "Epoch 30/150\n",
      "7492/7492 [==============================] - 1s 111us/step - loss: 0.1493 - val_loss: 0.1441\n",
      "Epoch 31/150\n",
      "7492/7492 [==============================] - 1s 116us/step - loss: 0.1474 - val_loss: 0.1441\n",
      "Epoch 32/150\n",
      "7492/7492 [==============================] - 1s 114us/step - loss: 0.1468 - val_loss: 0.1481\n",
      "Epoch 33/150\n",
      "7492/7492 [==============================] - 1s 116us/step - loss: 0.1474 - val_loss: 0.1444\n",
      "Epoch 34/150\n",
      "7492/7492 [==============================] - 1s 111us/step - loss: 0.1497 - val_loss: 0.1433\n",
      "Epoch 35/150\n",
      "7492/7492 [==============================] - 1s 113us/step - loss: 0.1432 - val_loss: 0.1422\n",
      "Epoch 36/150\n",
      "7492/7492 [==============================] - 1s 116us/step - loss: 0.1439 - val_loss: 0.1413\n",
      "Epoch 37/150\n",
      "7492/7492 [==============================] - 1s 108us/step - loss: 0.1442 - val_loss: 0.1450\n",
      "Epoch 38/150\n",
      "7492/7492 [==============================] - 1s 110us/step - loss: 0.1464 - val_loss: 0.1441\n",
      "Epoch 39/150\n",
      "7492/7492 [==============================] - 1s 117us/step - loss: 0.1429 - val_loss: 0.1399\n",
      "Epoch 40/150\n",
      "7492/7492 [==============================] - 1s 115us/step - loss: 0.1415 - val_loss: 0.1363\n",
      "Epoch 41/150\n",
      "7492/7492 [==============================] - 1s 111us/step - loss: 0.1430 - val_loss: 0.1446\n",
      "Epoch 42/150\n",
      "7492/7492 [==============================] - 1s 114us/step - loss: 0.1425 - val_loss: 0.1402\n",
      "Epoch 43/150\n",
      "7492/7492 [==============================] - 1s 116us/step - loss: 0.1411 - val_loss: 0.1388\n",
      "Epoch 44/150\n",
      "7492/7492 [==============================] - 1s 116us/step - loss: 0.1405 - val_loss: 0.1413\n",
      "Evaluating model with testing data...\n",
      "1584/1584 [==============================] - 0s 16us/step\n",
      "Getting distribution of predictions and covariance matrix...\n",
      "      1 of 20\n",
      "      2 of 20\n",
      "      3 of 20\n",
      "      4 of 20\n",
      "      5 of 20\n",
      "      6 of 20\n",
      "      7 of 20\n",
      "      8 of 20\n",
      "      9 of 20\n",
      "      10 of 20\n",
      "      11 of 20\n",
      "      12 of 20\n",
      "      13 of 20\n",
      "      14 of 20\n",
      "      15 of 20\n",
      "      16 of 20\n",
      "      17 of 20\n",
      "      18 of 20\n",
      "      19 of 20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|          | 0/20 [00:00<?, ?it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      20 of 20\n",
      "Computing ensemble means...\n",
      "Computing mean squared error...\n",
      "Getting distribution of predictions...\n",
      "      1 of 20\n",
      "1600/1600 [==============================] - 0s 28us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  5%|▌         | 1/20 [00:29<09:21, 29.53s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      2 of 20\n",
      "1600/1600 [==============================] - 0s 30us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 10%|█         | 2/20 [00:59<08:52, 29.56s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      3 of 20\n",
      "1600/1600 [==============================] - 0s 30us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 15%|█▌        | 3/20 [01:28<08:22, 29.54s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      4 of 20\n",
      "1600/1600 [==============================] - 0s 30us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 20%|██        | 4/20 [01:58<07:52, 29.54s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      5 of 20\n",
      "1600/1600 [==============================] - 0s 28us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 25%|██▌       | 5/20 [02:27<07:22, 29.50s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      6 of 20\n",
      "1600/1600 [==============================] - 0s 29us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 30%|███       | 6/20 [02:57<06:53, 29.52s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      7 of 20\n",
      "1600/1600 [==============================] - 0s 29us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 35%|███▌      | 7/20 [03:26<06:23, 29.51s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      8 of 20\n",
      "1600/1600 [==============================] - 0s 29us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 40%|████      | 8/20 [03:56<05:54, 29.54s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      9 of 20\n",
      "1600/1600 [==============================] - 0s 30us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 45%|████▌     | 9/20 [04:25<05:24, 29.50s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      10 of 20\n",
      "1600/1600 [==============================] - 0s 29us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 50%|█████     | 10/20 [04:55<04:55, 29.57s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      11 of 20\n",
      "1600/1600 [==============================] - 0s 29us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 55%|█████▌    | 11/20 [05:25<04:26, 29.67s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      12 of 20\n",
      "1600/1600 [==============================] - 0s 29us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 60%|██████    | 12/20 [05:55<03:57, 29.75s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      13 of 20\n",
      "1600/1600 [==============================] - 0s 30us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 65%|██████▌   | 13/20 [06:24<03:27, 29.71s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      14 of 20\n",
      "1600/1600 [==============================] - 0s 28us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 70%|███████   | 14/20 [06:54<02:58, 29.71s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      15 of 20\n",
      "1600/1600 [==============================] - 0s 29us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 75%|███████▌  | 15/20 [07:24<02:28, 29.68s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      16 of 20\n",
      "1600/1600 [==============================] - 0s 29us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 80%|████████  | 16/20 [07:53<01:58, 29.72s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      17 of 20\n",
      "1600/1600 [==============================] - 0s 29us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 85%|████████▌ | 17/20 [08:23<01:29, 29.68s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      18 of 20\n",
      "1600/1600 [==============================] - 0s 29us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 90%|█████████ | 18/20 [08:53<00:59, 29.64s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      19 of 20\n",
      "1600/1600 [==============================] - 0s 29us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 95%|█████████▌| 19/20 [09:22<00:29, 29.71s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      20 of 20\n",
      "1600/1600 [==============================] - 0s 29us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 20/20 [09:52<00:00, 29.62s/it]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing ensemble predictions...\n",
      "Iteration 51\n",
      "Train on 7632 samples, validate on 1614 samples\n",
      "Epoch 1/150\n",
      "7632/7632 [==============================] - 1s 118us/step - loss: 0.5524 - val_loss: 0.3850\n",
      "Epoch 2/150\n",
      "7632/7632 [==============================] - 1s 101us/step - loss: 0.3609 - val_loss: 0.3418\n",
      "Epoch 3/150\n",
      "7632/7632 [==============================] - 1s 117us/step - loss: 0.3242 - val_loss: 0.3032\n",
      "Epoch 4/150\n",
      "7632/7632 [==============================] - 1s 116us/step - loss: 0.2861 - val_loss: 0.2695\n",
      "Epoch 5/150\n",
      "7632/7632 [==============================] - 1s 116us/step - loss: 0.2655 - val_loss: 0.2548\n",
      "Epoch 6/150\n",
      "7632/7632 [==============================] - 1s 116us/step - loss: 0.2531 - val_loss: 0.2433\n",
      "Epoch 7/150\n",
      "7632/7632 [==============================] - 1s 116us/step - loss: 0.2401 - val_loss: 0.2299\n",
      "Epoch 8/150\n",
      "7632/7632 [==============================] - 1s 111us/step - loss: 0.2220 - val_loss: 0.2250\n",
      "Epoch 9/150\n",
      "7632/7632 [==============================] - 1s 116us/step - loss: 0.2124 - val_loss: 0.2034\n",
      "Epoch 10/150\n",
      "7632/7632 [==============================] - 1s 114us/step - loss: 0.1966 - val_loss: 0.2015\n",
      "Epoch 11/150\n",
      "7632/7632 [==============================] - 1s 117us/step - loss: 0.1901 - val_loss: 0.1918\n",
      "Epoch 12/150\n",
      "7632/7632 [==============================] - 1s 112us/step - loss: 0.1867 - val_loss: 0.1875\n",
      "Epoch 13/150\n",
      "7632/7632 [==============================] - 1s 116us/step - loss: 0.1847 - val_loss: 0.1797\n",
      "Epoch 14/150\n",
      "7632/7632 [==============================] - 1s 116us/step - loss: 0.1789 - val_loss: 0.1821\n",
      "Epoch 15/150\n",
      "7632/7632 [==============================] - 1s 99us/step - loss: 0.1803 - val_loss: 0.1769\n",
      "Epoch 16/150\n",
      "7632/7632 [==============================] - 0s 59us/step - loss: 0.1745 - val_loss: 0.1737\n",
      "Epoch 17/150\n",
      "7632/7632 [==============================] - 0s 60us/step - loss: 0.1735 - val_loss: 0.1718\n",
      "Epoch 18/150\n",
      "7632/7632 [==============================] - 1s 68us/step - loss: 0.1733 - val_loss: 0.1699\n",
      "Epoch 19/150\n",
      "7632/7632 [==============================] - 1s 116us/step - loss: 0.1730 - val_loss: 0.1728\n",
      "Epoch 20/150\n",
      "7632/7632 [==============================] - 1s 117us/step - loss: 0.1700 - val_loss: 0.1705\n",
      "Epoch 21/150\n",
      "7632/7632 [==============================] - 1s 112us/step - loss: 0.1642 - val_loss: 0.1576\n",
      "Epoch 22/150\n",
      "7632/7632 [==============================] - 1s 117us/step - loss: 0.1620 - val_loss: 0.1681\n",
      "Epoch 23/150\n",
      "7632/7632 [==============================] - 1s 111us/step - loss: 0.1633 - val_loss: 0.1585\n",
      "Epoch 24/150\n",
      "7632/7632 [==============================] - 1s 115us/step - loss: 0.1619 - val_loss: 0.1602\n",
      "Epoch 25/150\n",
      "7632/7632 [==============================] - 1s 116us/step - loss: 0.1589 - val_loss: 0.1589\n",
      "Evaluating model with testing data...\n",
      "1614/1614 [==============================] - 0s 16us/step\n",
      "Getting distribution of predictions and covariance matrix...\n",
      "      1 of 20\n",
      "      2 of 20\n",
      "      3 of 20\n",
      "      4 of 20\n",
      "      5 of 20\n",
      "      6 of 20\n",
      "      7 of 20\n",
      "      8 of 20\n",
      "      9 of 20\n",
      "      10 of 20\n",
      "      11 of 20\n",
      "      12 of 20\n",
      "      13 of 20\n",
      "      14 of 20\n",
      "      15 of 20\n",
      "      16 of 20\n",
      "      17 of 20\n",
      "      18 of 20\n",
      "      19 of 20\n",
      "      20 of 20\n",
      "Computing ensemble means...\n",
      "Computing mean squared error...\n",
      "Iteration 52\n",
      "Train on 7772 samples, validate on 1644 samples\n",
      "Epoch 1/150\n",
      "7772/7772 [==============================] - 1s 110us/step - loss: 0.4605 - val_loss: 0.3211\n",
      "Epoch 2/150\n",
      "7772/7772 [==============================] - 1s 104us/step - loss: 0.2927 - val_loss: 0.2640\n",
      "Epoch 3/150\n",
      "7772/7772 [==============================] - 1s 105us/step - loss: 0.2464 - val_loss: 0.2292\n",
      "Epoch 4/150\n",
      "7772/7772 [==============================] - 1s 114us/step - loss: 0.2228 - val_loss: 0.2098\n",
      "Epoch 5/150\n",
      "7772/7772 [==============================] - 1s 112us/step - loss: 0.2129 - val_loss: 0.2113\n",
      "Epoch 6/150\n",
      "7772/7772 [==============================] - 1s 110us/step - loss: 0.2080 - val_loss: 0.2003\n",
      "Epoch 7/150\n",
      "7772/7772 [==============================] - 1s 110us/step - loss: 0.2007 - val_loss: 0.1929\n",
      "Epoch 8/150\n",
      "7772/7772 [==============================] - 1s 114us/step - loss: 0.1934 - val_loss: 0.1902\n",
      "Epoch 9/150\n",
      "7772/7772 [==============================] - 1s 115us/step - loss: 0.1842 - val_loss: 0.1879\n",
      "Epoch 10/150\n",
      "7772/7772 [==============================] - 1s 112us/step - loss: 0.1831 - val_loss: 0.1885\n",
      "Epoch 11/150\n",
      "7772/7772 [==============================] - 1s 107us/step - loss: 0.1822 - val_loss: 0.1785\n",
      "Epoch 12/150\n",
      "7772/7772 [==============================] - 1s 111us/step - loss: 0.1747 - val_loss: 0.1667\n",
      "Epoch 13/150\n",
      "7772/7772 [==============================] - 1s 115us/step - loss: 0.1693 - val_loss: 0.1695\n",
      "Epoch 14/150\n",
      "7772/7772 [==============================] - 1s 101us/step - loss: 0.1674 - val_loss: 0.1590\n",
      "Epoch 15/150\n",
      "7772/7772 [==============================] - 1s 106us/step - loss: 0.1613 - val_loss: 0.1612\n",
      "Epoch 16/150\n",
      "7772/7772 [==============================] - 1s 106us/step - loss: 0.1596 - val_loss: 0.1636\n",
      "Epoch 17/150\n",
      "7772/7772 [==============================] - 1s 114us/step - loss: 0.1574 - val_loss: 0.1550\n",
      "Epoch 18/150\n",
      "7772/7772 [==============================] - 1s 112us/step - loss: 0.1541 - val_loss: 0.1529\n",
      "Epoch 19/150\n",
      "7772/7772 [==============================] - 1s 110us/step - loss: 0.1549 - val_loss: 0.1581\n",
      "Epoch 20/150\n",
      "7772/7772 [==============================] - 1s 105us/step - loss: 0.1561 - val_loss: 0.1515\n",
      "Epoch 21/150\n",
      "7772/7772 [==============================] - 1s 112us/step - loss: 0.1515 - val_loss: 0.1476\n",
      "Epoch 22/150\n",
      "7772/7772 [==============================] - 1s 113us/step - loss: 0.1517 - val_loss: 0.1523\n",
      "Epoch 23/150\n",
      "7772/7772 [==============================] - 1s 115us/step - loss: 0.1516 - val_loss: 0.1456\n",
      "Epoch 24/150\n",
      "7772/7772 [==============================] - 1s 109us/step - loss: 0.1487 - val_loss: 0.1442\n",
      "Epoch 25/150\n",
      "7772/7772 [==============================] - 1s 109us/step - loss: 0.1497 - val_loss: 0.1465\n",
      "Epoch 26/150\n",
      "7772/7772 [==============================] - 1s 113us/step - loss: 0.1470 - val_loss: 0.1481\n",
      "Epoch 27/150\n",
      "7772/7772 [==============================] - 1s 109us/step - loss: 0.1482 - val_loss: 0.1429\n",
      "Epoch 28/150\n",
      "7772/7772 [==============================] - 1s 104us/step - loss: 0.1445 - val_loss: 0.1472\n",
      "Epoch 29/150\n",
      "7772/7772 [==============================] - 1s 110us/step - loss: 0.1468 - val_loss: 0.1402\n",
      "Epoch 30/150\n",
      "7772/7772 [==============================] - 1s 111us/step - loss: 0.1439 - val_loss: 0.1425\n",
      "Epoch 31/150\n",
      "7772/7772 [==============================] - 1s 112us/step - loss: 0.1422 - val_loss: 0.1384\n",
      "Epoch 32/150\n",
      "7772/7772 [==============================] - 1s 108us/step - loss: 0.1419 - val_loss: 0.1414\n",
      "Epoch 33/150\n",
      "7772/7772 [==============================] - 1s 107us/step - loss: 0.1418 - val_loss: 0.1369\n",
      "Epoch 34/150\n",
      "7772/7772 [==============================] - 1s 110us/step - loss: 0.1423 - val_loss: 0.1397\n",
      "Epoch 35/150\n",
      "7772/7772 [==============================] - 1s 109us/step - loss: 0.1393 - val_loss: 0.1372\n",
      "Epoch 36/150\n",
      "7772/7772 [==============================] - 1s 113us/step - loss: 0.1406 - val_loss: 0.1364\n",
      "Epoch 37/150\n",
      "7772/7772 [==============================] - 1s 98us/step - loss: 0.1408 - val_loss: 0.1377\n",
      "Epoch 38/150\n",
      "7772/7772 [==============================] - 1s 104us/step - loss: 0.1377 - val_loss: 0.1388\n",
      "Epoch 39/150\n",
      "7772/7772 [==============================] - 1s 114us/step - loss: 0.1388 - val_loss: 0.1391\n",
      "Epoch 40/150\n",
      "7772/7772 [==============================] - 1s 106us/step - loss: 0.1375 - val_loss: 0.1389\n",
      "Evaluating model with testing data...\n",
      "1644/1644 [==============================] - 0s 16us/step\n",
      "Getting distribution of predictions and covariance matrix...\n",
      "      1 of 20\n",
      "      2 of 20\n",
      "      3 of 20\n",
      "      4 of 20\n",
      "      5 of 20\n",
      "      6 of 20\n",
      "      7 of 20\n",
      "      8 of 20\n",
      "      9 of 20\n",
      "      10 of 20\n",
      "      11 of 20\n",
      "      12 of 20\n",
      "      13 of 20\n",
      "      14 of 20\n",
      "      15 of 20\n",
      "      16 of 20\n",
      "      17 of 20\n",
      "      18 of 20\n",
      "      19 of 20\n",
      "      20 of 20\n",
      "Computing ensemble means...\n",
      "Computing mean squared error...\n",
      "Iteration 53\n",
      "Train on 7912 samples, validate on 1674 samples\n",
      "Epoch 1/150\n",
      "7912/7912 [==============================] - 1s 116us/step - loss: 0.5406 - val_loss: 0.4181\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/150\n",
      "7912/7912 [==============================] - 1s 110us/step - loss: 0.3686 - val_loss: 0.3483\n",
      "Epoch 3/150\n",
      "7912/7912 [==============================] - 1s 115us/step - loss: 0.3439 - val_loss: 0.3407\n",
      "Epoch 4/150\n",
      "7912/7912 [==============================] - 1s 115us/step - loss: 0.3308 - val_loss: 0.3201\n",
      "Epoch 5/150\n",
      "7912/7912 [==============================] - 1s 114us/step - loss: 0.3095 - val_loss: 0.3031\n",
      "Epoch 6/150\n",
      "7912/7912 [==============================] - 1s 116us/step - loss: 0.2919 - val_loss: 0.2848\n",
      "Epoch 7/150\n",
      "7912/7912 [==============================] - 1s 112us/step - loss: 0.2810 - val_loss: 0.2661\n",
      "Epoch 8/150\n",
      "7912/7912 [==============================] - 1s 116us/step - loss: 0.2681 - val_loss: 0.2662\n",
      "Epoch 9/150\n",
      "7912/7912 [==============================] - 1s 116us/step - loss: 0.2613 - val_loss: 0.2616\n",
      "Epoch 10/150\n",
      "7912/7912 [==============================] - 1s 113us/step - loss: 0.2530 - val_loss: 0.2540\n",
      "Epoch 11/150\n",
      "7912/7912 [==============================] - 1s 116us/step - loss: 0.2480 - val_loss: 0.2410\n",
      "Epoch 12/150\n",
      "7912/7912 [==============================] - 1s 116us/step - loss: 0.2368 - val_loss: 0.2381\n",
      "Epoch 13/150\n",
      "7912/7912 [==============================] - 1s 116us/step - loss: 0.2310 - val_loss: 0.2287\n",
      "Epoch 14/150\n",
      "7912/7912 [==============================] - 1s 114us/step - loss: 0.2300 - val_loss: 0.2261\n",
      "Epoch 15/150\n",
      "7912/7912 [==============================] - 1s 117us/step - loss: 0.2262 - val_loss: 0.2280\n",
      "Epoch 16/150\n",
      "7912/7912 [==============================] - 1s 112us/step - loss: 0.2152 - val_loss: 0.2119\n",
      "Epoch 17/150\n",
      "7912/7912 [==============================] - 1s 116us/step - loss: 0.2093 - val_loss: 0.2102\n",
      "Epoch 18/150\n",
      "7912/7912 [==============================] - 1s 111us/step - loss: 0.2066 - val_loss: 0.2024\n",
      "Epoch 19/150\n",
      "7912/7912 [==============================] - 1s 116us/step - loss: 0.2065 - val_loss: 0.2073\n",
      "Epoch 20/150\n",
      "7912/7912 [==============================] - 1s 109us/step - loss: 0.2046 - val_loss: 0.2065\n",
      "Epoch 21/150\n",
      "7912/7912 [==============================] - 1s 114us/step - loss: 0.2044 - val_loss: 0.2022\n",
      "Epoch 22/150\n",
      "7912/7912 [==============================] - 1s 109us/step - loss: 0.2027 - val_loss: 0.1968\n",
      "Epoch 23/150\n",
      "7912/7912 [==============================] - 1s 110us/step - loss: 0.2015 - val_loss: 0.1980\n",
      "Epoch 24/150\n",
      "7912/7912 [==============================] - 1s 114us/step - loss: 0.1999 - val_loss: 0.1976\n",
      "Epoch 25/150\n",
      "7912/7912 [==============================] - 1s 114us/step - loss: 0.2020 - val_loss: 0.1992\n",
      "Epoch 26/150\n",
      "7912/7912 [==============================] - 1s 111us/step - loss: 0.2019 - val_loss: 0.2043\n",
      "Evaluating model with testing data...\n",
      "1674/1674 [==============================] - 0s 16us/step\n",
      "Getting distribution of predictions and covariance matrix...\n",
      "      1 of 20\n",
      "      2 of 20\n",
      "      3 of 20\n",
      "      4 of 20\n",
      "      5 of 20\n",
      "      6 of 20\n",
      "      7 of 20\n",
      "      8 of 20\n",
      "      9 of 20\n",
      "      10 of 20\n",
      "      11 of 20\n",
      "      12 of 20\n",
      "      13 of 20\n",
      "      14 of 20\n",
      "      15 of 20\n",
      "      16 of 20\n",
      "      17 of 20\n",
      "      18 of 20\n",
      "      19 of 20\n",
      "      20 of 20\n",
      "Computing ensemble means...\n",
      "Computing mean squared error...\n",
      "Iteration 54\n",
      "Train on 8052 samples, validate on 1704 samples\n",
      "Epoch 1/150\n",
      "8052/8052 [==============================] - 1s 111us/step - loss: 0.5334 - val_loss: 0.3656\n",
      "Epoch 2/150\n",
      "8052/8052 [==============================] - 1s 108us/step - loss: 0.3259 - val_loss: 0.2918\n",
      "Epoch 3/150\n",
      "8052/8052 [==============================] - 1s 114us/step - loss: 0.2772 - val_loss: 0.2638\n",
      "Epoch 4/150\n",
      "8052/8052 [==============================] - 1s 108us/step - loss: 0.2518 - val_loss: 0.2439\n",
      "Epoch 5/150\n",
      "8052/8052 [==============================] - 1s 107us/step - loss: 0.2338 - val_loss: 0.2275\n",
      "Epoch 6/150\n",
      "8052/8052 [==============================] - 1s 112us/step - loss: 0.2201 - val_loss: 0.2192\n",
      "Epoch 7/150\n",
      "8052/8052 [==============================] - 1s 90us/step - loss: 0.2157 - val_loss: 0.2135\n",
      "Epoch 8/150\n",
      "8052/8052 [==============================] - 1s 114us/step - loss: 0.2055 - val_loss: 0.2069\n",
      "Epoch 9/150\n",
      "8052/8052 [==============================] - 1s 115us/step - loss: 0.1993 - val_loss: 0.1961\n",
      "Epoch 10/150\n",
      "8052/8052 [==============================] - 1s 108us/step - loss: 0.1929 - val_loss: 0.1937\n",
      "Epoch 11/150\n",
      "8052/8052 [==============================] - 1s 109us/step - loss: 0.1832 - val_loss: 0.1799\n",
      "Epoch 12/150\n",
      "8052/8052 [==============================] - 1s 106us/step - loss: 0.1771 - val_loss: 0.1701\n",
      "Epoch 13/150\n",
      "8052/8052 [==============================] - 1s 105us/step - loss: 0.1734 - val_loss: 0.1696\n",
      "Epoch 14/150\n",
      "8052/8052 [==============================] - 1s 108us/step - loss: 0.1659 - val_loss: 0.1622\n",
      "Epoch 15/150\n",
      "8052/8052 [==============================] - 1s 109us/step - loss: 0.1626 - val_loss: 0.1619\n",
      "Epoch 16/150\n",
      "8052/8052 [==============================] - 1s 108us/step - loss: 0.1582 - val_loss: 0.1539\n",
      "Epoch 17/150\n",
      "8052/8052 [==============================] - 1s 107us/step - loss: 0.1566 - val_loss: 0.1531\n",
      "Epoch 18/150\n",
      "8052/8052 [==============================] - 1s 111us/step - loss: 0.1522 - val_loss: 0.1534\n",
      "Epoch 19/150\n",
      "8052/8052 [==============================] - 1s 115us/step - loss: 0.1523 - val_loss: 0.1491\n",
      "Epoch 20/150\n",
      "8052/8052 [==============================] - 1s 109us/step - loss: 0.1495 - val_loss: 0.1492\n",
      "Epoch 21/150\n",
      "8052/8052 [==============================] - 1s 112us/step - loss: 0.1506 - val_loss: 0.1509\n",
      "Epoch 22/150\n",
      "8052/8052 [==============================] - 1s 103us/step - loss: 0.1466 - val_loss: 0.1517\n",
      "Epoch 23/150\n",
      "8052/8052 [==============================] - 1s 115us/step - loss: 0.1464 - val_loss: 0.1502\n",
      "Evaluating model with testing data...\n",
      "1704/1704 [==============================] - 0s 15us/step\n",
      "Getting distribution of predictions and covariance matrix...\n",
      "      1 of 20\n",
      "      2 of 20\n",
      "      3 of 20\n",
      "      4 of 20\n",
      "      5 of 20\n",
      "      6 of 20\n",
      "      7 of 20\n",
      "      8 of 20\n",
      "      9 of 20\n",
      "      10 of 20\n",
      "      11 of 20\n",
      "      12 of 20\n",
      "      13 of 20\n",
      "      14 of 20\n",
      "      15 of 20\n",
      "      16 of 20\n",
      "      17 of 20\n",
      "      18 of 20\n",
      "      19 of 20\n",
      "      20 of 20\n",
      "Computing ensemble means...\n",
      "Computing mean squared error...\n",
      "Iteration 55\n",
      "Train on 8192 samples, validate on 1734 samples\n",
      "Epoch 1/150\n",
      "8192/8192 [==============================] - 1s 108us/step - loss: 0.5346 - val_loss: 0.4192\n",
      "Epoch 2/150\n",
      "8192/8192 [==============================] - 1s 111us/step - loss: 0.3785 - val_loss: 0.3435\n",
      "Epoch 3/150\n",
      "8192/8192 [==============================] - 1s 113us/step - loss: 0.3160 - val_loss: 0.2955\n",
      "Epoch 4/150\n",
      "8192/8192 [==============================] - 1s 114us/step - loss: 0.2824 - val_loss: 0.2630\n",
      "Epoch 5/150\n",
      "8192/8192 [==============================] - 1s 103us/step - loss: 0.2566 - val_loss: 0.2450\n",
      "Epoch 6/150\n",
      "8192/8192 [==============================] - 1s 109us/step - loss: 0.2392 - val_loss: 0.2235\n",
      "Epoch 7/150\n",
      "8192/8192 [==============================] - 1s 108us/step - loss: 0.2264 - val_loss: 0.2217\n",
      "Epoch 8/150\n",
      "8192/8192 [==============================] - 1s 104us/step - loss: 0.2165 - val_loss: 0.2090\n",
      "Epoch 9/150\n",
      "8192/8192 [==============================] - 1s 110us/step - loss: 0.2106 - val_loss: 0.2111\n",
      "Epoch 10/150\n",
      "8192/8192 [==============================] - 1s 115us/step - loss: 0.2042 - val_loss: 0.2012\n",
      "Epoch 11/150\n",
      "8192/8192 [==============================] - 1s 102us/step - loss: 0.2009 - val_loss: 0.2053\n",
      "Epoch 12/150\n",
      "8192/8192 [==============================] - 1s 109us/step - loss: 0.1955 - val_loss: 0.1873\n",
      "Epoch 13/150\n",
      "8192/8192 [==============================] - 1s 107us/step - loss: 0.1902 - val_loss: 0.1827\n",
      "Epoch 14/150\n",
      "8192/8192 [==============================] - 1s 105us/step - loss: 0.1840 - val_loss: 0.1764\n",
      "Epoch 15/150\n",
      "8192/8192 [==============================] - 1s 108us/step - loss: 0.1800 - val_loss: 0.1763\n",
      "Epoch 16/150\n",
      "8192/8192 [==============================] - 1s 104us/step - loss: 0.1802 - val_loss: 0.1787\n",
      "Epoch 17/150\n",
      "8192/8192 [==============================] - 1s 96us/step - loss: 0.1796 - val_loss: 0.1754\n",
      "Epoch 18/150\n",
      "8192/8192 [==============================] - 1s 101us/step - loss: 0.1754 - val_loss: 0.1764\n",
      "Epoch 19/150\n",
      "8192/8192 [==============================] - 1s 100us/step - loss: 0.1773 - val_loss: 0.1720\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 20/150\n",
      "8192/8192 [==============================] - 1s 113us/step - loss: 0.1711 - val_loss: 0.1702\n",
      "Epoch 21/150\n",
      "8192/8192 [==============================] - 1s 103us/step - loss: 0.1715 - val_loss: 0.1700\n",
      "Epoch 22/150\n",
      "8192/8192 [==============================] - 1s 114us/step - loss: 0.1706 - val_loss: 0.1649\n",
      "Epoch 23/150\n",
      "8192/8192 [==============================] - 1s 114us/step - loss: 0.1716 - val_loss: 0.1676\n",
      "Epoch 24/150\n",
      "8192/8192 [==============================] - 1s 113us/step - loss: 0.1687 - val_loss: 0.1689\n",
      "Epoch 25/150\n",
      "8192/8192 [==============================] - 1s 114us/step - loss: 0.1680 - val_loss: 0.1589\n",
      "Epoch 26/150\n",
      "8192/8192 [==============================] - 1s 114us/step - loss: 0.1671 - val_loss: 0.1634\n",
      "Epoch 27/150\n",
      "8192/8192 [==============================] - 1s 114us/step - loss: 0.1675 - val_loss: 0.1681\n",
      "Epoch 28/150\n",
      "8192/8192 [==============================] - 1s 113us/step - loss: 0.1658 - val_loss: 0.1629\n",
      "Epoch 29/150\n",
      "8192/8192 [==============================] - 1s 111us/step - loss: 0.1661 - val_loss: 0.1627\n",
      "Evaluating model with testing data...\n",
      "1734/1734 [==============================] - 0s 15us/step\n",
      "Getting distribution of predictions and covariance matrix...\n",
      "      1 of 20\n",
      "      2 of 20\n",
      "      3 of 20\n",
      "      4 of 20\n",
      "      5 of 20\n",
      "      6 of 20\n",
      "      7 of 20\n",
      "      8 of 20\n",
      "      9 of 20\n",
      "      10 of 20\n",
      "      11 of 20\n",
      "      12 of 20\n",
      "      13 of 20\n",
      "      14 of 20\n",
      "      15 of 20\n",
      "      16 of 20\n",
      "      17 of 20\n",
      "      18 of 20\n",
      "      19 of 20\n",
      "      20 of 20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|          | 0/20 [00:00<?, ?it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing ensemble means...\n",
      "Computing mean squared error...\n",
      "Getting distribution of predictions...\n",
      "      1 of 20\n",
      "1600/1600 [==============================] - 0s 27us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  5%|▌         | 1/20 [00:29<09:18, 29.42s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      2 of 20\n",
      "1600/1600 [==============================] - 0s 28us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 10%|█         | 2/20 [00:58<08:49, 29.44s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      3 of 20\n",
      "1600/1600 [==============================] - 0s 31us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 15%|█▌        | 3/20 [01:28<08:20, 29.46s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      4 of 20\n",
      "1600/1600 [==============================] - 0s 30us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 20%|██        | 4/20 [01:58<07:52, 29.51s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      5 of 20\n",
      "1600/1600 [==============================] - 0s 29us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 25%|██▌       | 5/20 [02:27<07:21, 29.45s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      6 of 20\n",
      "1600/1600 [==============================] - 0s 30us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 30%|███       | 6/20 [02:57<06:53, 29.52s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      7 of 20\n",
      "1600/1600 [==============================] - 0s 28us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 35%|███▌      | 7/20 [03:26<06:22, 29.45s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      8 of 20\n",
      "1600/1600 [==============================] - 0s 28us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 40%|████      | 8/20 [03:55<05:53, 29.48s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      9 of 20\n",
      "1600/1600 [==============================] - 0s 29us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 45%|████▌     | 9/20 [04:25<05:24, 29.47s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      10 of 20\n",
      "1600/1600 [==============================] - 0s 29us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 50%|█████     | 10/20 [04:54<04:54, 29.49s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      11 of 20\n",
      "1600/1600 [==============================] - 0s 29us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 55%|█████▌    | 11/20 [05:24<04:26, 29.57s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      12 of 20\n",
      "1600/1600 [==============================] - 0s 29us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 60%|██████    | 12/20 [05:54<03:56, 29.58s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      13 of 20\n",
      "1600/1600 [==============================] - 0s 29us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 65%|██████▌   | 13/20 [06:23<03:26, 29.53s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      14 of 20\n",
      "1600/1600 [==============================] - 0s 29us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 70%|███████   | 14/20 [06:53<02:57, 29.56s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      15 of 20\n",
      "1600/1600 [==============================] - 0s 29us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 75%|███████▌  | 15/20 [07:22<02:27, 29.59s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      16 of 20\n",
      "1600/1600 [==============================] - 0s 29us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 80%|████████  | 16/20 [07:52<01:58, 29.64s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      17 of 20\n",
      "1600/1600 [==============================] - 0s 28us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 85%|████████▌ | 17/20 [08:22<01:28, 29.61s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      18 of 20\n",
      "1600/1600 [==============================] - 0s 30us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 90%|█████████ | 18/20 [08:51<00:59, 29.61s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      19 of 20\n",
      "1600/1600 [==============================] - 0s 29us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 95%|█████████▌| 19/20 [09:21<00:29, 29.63s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      20 of 20\n",
      "1600/1600 [==============================] - 0s 29us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 20/20 [09:51<00:00, 29.57s/it]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing ensemble predictions...\n",
      "Iteration 56\n",
      "Train on 8332 samples, validate on 1764 samples\n",
      "Epoch 1/150\n",
      "8332/8332 [==============================] - 1s 117us/step - loss: 0.4734 - val_loss: 0.3304\n",
      "Epoch 2/150\n",
      "8332/8332 [==============================] - 1s 109us/step - loss: 0.2735 - val_loss: 0.2376\n",
      "Epoch 3/150\n",
      "8332/8332 [==============================] - 1s 111us/step - loss: 0.2201 - val_loss: 0.2062\n",
      "Epoch 4/150\n",
      "8332/8332 [==============================] - 1s 115us/step - loss: 0.1971 - val_loss: 0.1859\n",
      "Epoch 5/150\n",
      "8332/8332 [==============================] - 1s 112us/step - loss: 0.1818 - val_loss: 0.1755\n",
      "Epoch 6/150\n",
      "8332/8332 [==============================] - 1s 115us/step - loss: 0.1727 - val_loss: 0.1663\n",
      "Epoch 7/150\n",
      "8332/8332 [==============================] - 1s 115us/step - loss: 0.1655 - val_loss: 0.1648\n",
      "Epoch 8/150\n",
      "8332/8332 [==============================] - 1s 107us/step - loss: 0.1603 - val_loss: 0.1569\n",
      "Epoch 9/150\n",
      "8332/8332 [==============================] - 1s 115us/step - loss: 0.1543 - val_loss: 0.1510\n",
      "Epoch 10/150\n",
      "8332/8332 [==============================] - 1s 115us/step - loss: 0.1525 - val_loss: 0.1478\n",
      "Epoch 11/150\n",
      "8332/8332 [==============================] - 1s 98us/step - loss: 0.1466 - val_loss: 0.1424\n",
      "Epoch 12/150\n",
      "8332/8332 [==============================] - 0s 59us/step - loss: 0.1466 - val_loss: 0.1473\n",
      "Epoch 13/150\n",
      "8332/8332 [==============================] - 0s 59us/step - loss: 0.1417 - val_loss: 0.1418\n",
      "Epoch 14/150\n",
      "8332/8332 [==============================] - 1s 82us/step - loss: 0.1420 - val_loss: 0.1379\n",
      "Epoch 15/150\n",
      "8332/8332 [==============================] - 1s 115us/step - loss: 0.1383 - val_loss: 0.1372\n",
      "Epoch 16/150\n",
      "8332/8332 [==============================] - 1s 105us/step - loss: 0.1362 - val_loss: 0.1308\n",
      "Epoch 17/150\n",
      "8332/8332 [==============================] - 1s 114us/step - loss: 0.1327 - val_loss: 0.1282\n",
      "Epoch 18/150\n",
      "8332/8332 [==============================] - 1s 107us/step - loss: 0.1323 - val_loss: 0.1277\n",
      "Epoch 19/150\n",
      "8332/8332 [==============================] - 1s 116us/step - loss: 0.1308 - val_loss: 0.1262\n",
      "Epoch 20/150\n",
      "8332/8332 [==============================] - 1s 114us/step - loss: 0.1291 - val_loss: 0.1313\n",
      "Epoch 21/150\n",
      "8332/8332 [==============================] - 1s 116us/step - loss: 0.1292 - val_loss: 0.1264\n",
      "Epoch 22/150\n",
      "8332/8332 [==============================] - 1s 105us/step - loss: 0.1267 - val_loss: 0.1282\n",
      "Epoch 23/150\n",
      "8332/8332 [==============================] - 1s 112us/step - loss: 0.1281 - val_loss: 0.1278\n",
      "Evaluating model with testing data...\n",
      "1764/1764 [==============================] - 0s 16us/step\n",
      "Getting distribution of predictions and covariance matrix...\n",
      "      1 of 20\n",
      "      2 of 20\n",
      "      3 of 20\n",
      "      4 of 20\n",
      "      5 of 20\n",
      "      6 of 20\n",
      "      7 of 20\n",
      "      8 of 20\n",
      "      9 of 20\n",
      "      10 of 20\n",
      "      11 of 20\n",
      "      12 of 20\n",
      "      13 of 20\n",
      "      14 of 20\n",
      "      15 of 20\n",
      "      16 of 20\n",
      "      17 of 20\n",
      "      18 of 20\n",
      "      19 of 20\n",
      "      20 of 20\n",
      "Computing ensemble means...\n",
      "Computing mean squared error...\n",
      "Iteration 57\n",
      "Train on 8472 samples, validate on 1794 samples\n",
      "Epoch 1/150\n",
      "8472/8472 [==============================] - 1s 113us/step - loss: 0.4461 - val_loss: 0.3103\n",
      "Epoch 2/150\n",
      "8472/8472 [==============================] - 1s 103us/step - loss: 0.2692 - val_loss: 0.2400\n",
      "Epoch 3/150\n",
      "8472/8472 [==============================] - 1s 115us/step - loss: 0.2183 - val_loss: 0.2001\n",
      "Epoch 4/150\n",
      "8472/8472 [==============================] - 1s 112us/step - loss: 0.1984 - val_loss: 0.1938\n",
      "Epoch 5/150\n",
      "8472/8472 [==============================] - 1s 110us/step - loss: 0.1854 - val_loss: 0.1853\n",
      "Epoch 6/150\n",
      "8472/8472 [==============================] - 1s 111us/step - loss: 0.1793 - val_loss: 0.1732\n",
      "Epoch 7/150\n",
      "8472/8472 [==============================] - 1s 113us/step - loss: 0.1727 - val_loss: 0.1690\n",
      "Epoch 8/150\n",
      "8472/8472 [==============================] - 1s 115us/step - loss: 0.1662 - val_loss: 0.1641\n",
      "Epoch 9/150\n",
      "8472/8472 [==============================] - 1s 105us/step - loss: 0.1624 - val_loss: 0.1546\n",
      "Epoch 10/150\n",
      "8472/8472 [==============================] - 1s 109us/step - loss: 0.1542 - val_loss: 0.1521\n",
      "Epoch 11/150\n",
      "8472/8472 [==============================] - 1s 107us/step - loss: 0.1503 - val_loss: 0.1492\n",
      "Epoch 12/150\n",
      "8472/8472 [==============================] - 1s 111us/step - loss: 0.1464 - val_loss: 0.1437\n",
      "Epoch 13/150\n",
      "8472/8472 [==============================] - 1s 115us/step - loss: 0.1430 - val_loss: 0.1409\n",
      "Epoch 14/150\n",
      "8472/8472 [==============================] - 1s 108us/step - loss: 0.1401 - val_loss: 0.1331\n",
      "Epoch 15/150\n",
      "8472/8472 [==============================] - 1s 97us/step - loss: 0.1367 - val_loss: 0.1338\n",
      "Epoch 16/150\n",
      "8472/8472 [==============================] - 1s 108us/step - loss: 0.1354 - val_loss: 0.1354\n",
      "Epoch 17/150\n",
      "8472/8472 [==============================] - 1s 97us/step - loss: 0.1348 - val_loss: 0.1355\n",
      "Epoch 18/150\n",
      "8472/8472 [==============================] - 1s 109us/step - loss: 0.1339 - val_loss: 0.1327\n",
      "Epoch 19/150\n",
      "8472/8472 [==============================] - 1s 110us/step - loss: 0.1328 - val_loss: 0.1312\n",
      "Epoch 20/150\n",
      "8472/8472 [==============================] - 1s 109us/step - loss: 0.1319 - val_loss: 0.1295\n",
      "Epoch 21/150\n",
      "8472/8472 [==============================] - 1s 115us/step - loss: 0.1306 - val_loss: 0.1312\n",
      "Epoch 22/150\n",
      "8472/8472 [==============================] - 1s 115us/step - loss: 0.1285 - val_loss: 0.1295\n",
      "Epoch 23/150\n",
      "8472/8472 [==============================] - 1s 108us/step - loss: 0.1262 - val_loss: 0.1265\n",
      "Epoch 24/150\n",
      "8472/8472 [==============================] - 1s 104us/step - loss: 0.1266 - val_loss: 0.1263\n",
      "Epoch 25/150\n",
      "8472/8472 [==============================] - 1s 114us/step - loss: 0.1269 - val_loss: 0.1229\n",
      "Epoch 26/150\n",
      "8472/8472 [==============================] - 1s 109us/step - loss: 0.1232 - val_loss: 0.1196\n",
      "Epoch 27/150\n",
      "8472/8472 [==============================] - 1s 108us/step - loss: 0.1234 - val_loss: 0.1219\n",
      "Epoch 28/150\n",
      "8472/8472 [==============================] - 1s 109us/step - loss: 0.1250 - val_loss: 0.1248\n",
      "Epoch 29/150\n",
      "8472/8472 [==============================] - 1s 113us/step - loss: 0.1240 - val_loss: 0.1237\n",
      "Epoch 30/150\n",
      "8472/8472 [==============================] - 1s 110us/step - loss: 0.1218 - val_loss: 0.1257\n",
      "Evaluating model with testing data...\n",
      "1794/1794 [==============================] - 0s 15us/step\n",
      "Getting distribution of predictions and covariance matrix...\n",
      "      1 of 20\n",
      "      2 of 20\n",
      "      3 of 20\n",
      "      4 of 20\n",
      "      5 of 20\n",
      "      6 of 20\n",
      "      7 of 20\n",
      "      8 of 20\n",
      "      9 of 20\n",
      "      10 of 20\n",
      "      11 of 20\n",
      "      12 of 20\n",
      "      13 of 20\n",
      "      14 of 20\n",
      "      15 of 20\n",
      "      16 of 20\n",
      "      17 of 20\n",
      "      18 of 20\n",
      "      19 of 20\n",
      "      20 of 20\n",
      "Computing ensemble means...\n",
      "Computing mean squared error...\n",
      "Iteration 58\n",
      "Train on 8612 samples, validate on 1824 samples\n",
      "Epoch 1/150\n",
      "8612/8612 [==============================] - 1s 109us/step - loss: 0.6396 - val_loss: 0.3956\n",
      "Epoch 2/150\n",
      "8612/8612 [==============================] - 1s 105us/step - loss: 0.3398 - val_loss: 0.2962\n",
      "Epoch 3/150\n",
      "8612/8612 [==============================] - 1s 108us/step - loss: 0.2749 - val_loss: 0.2529\n",
      "Epoch 4/150\n",
      "8612/8612 [==============================] - 1s 104us/step - loss: 0.2486 - val_loss: 0.2404\n",
      "Epoch 5/150\n",
      "8612/8612 [==============================] - 1s 102us/step - loss: 0.2321 - val_loss: 0.2336\n",
      "Epoch 6/150\n",
      "8612/8612 [==============================] - 1s 111us/step - loss: 0.2240 - val_loss: 0.2247\n",
      "Epoch 7/150\n",
      "8612/8612 [==============================] - 1s 110us/step - loss: 0.2193 - val_loss: 0.2133\n",
      "Epoch 8/150\n",
      "8612/8612 [==============================] - 1s 108us/step - loss: 0.2122 - val_loss: 0.2113\n",
      "Epoch 9/150\n",
      "8612/8612 [==============================] - 1s 112us/step - loss: 0.2077 - val_loss: 0.2058\n",
      "Epoch 10/150\n",
      "8612/8612 [==============================] - 1s 108us/step - loss: 0.2013 - val_loss: 0.1973\n",
      "Epoch 11/150\n",
      "8612/8612 [==============================] - 1s 107us/step - loss: 0.2002 - val_loss: 0.1931\n",
      "Epoch 12/150\n",
      "8612/8612 [==============================] - 1s 109us/step - loss: 0.1934 - val_loss: 0.1932\n",
      "Epoch 13/150\n",
      "8612/8612 [==============================] - 1s 111us/step - loss: 0.1908 - val_loss: 0.1883\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 14/150\n",
      "8612/8612 [==============================] - 1s 114us/step - loss: 0.1881 - val_loss: 0.1852\n",
      "Epoch 15/150\n",
      "8612/8612 [==============================] - 1s 112us/step - loss: 0.1870 - val_loss: 0.1767\n",
      "Epoch 16/150\n",
      "8612/8612 [==============================] - 1s 115us/step - loss: 0.1822 - val_loss: 0.1771\n",
      "Epoch 17/150\n",
      "8612/8612 [==============================] - 1s 115us/step - loss: 0.1821 - val_loss: 0.1788\n",
      "Epoch 18/150\n",
      "8612/8612 [==============================] - 1s 113us/step - loss: 0.1784 - val_loss: 0.1838\n",
      "Epoch 19/150\n",
      "8612/8612 [==============================] - 1s 115us/step - loss: 0.1788 - val_loss: 0.1744\n",
      "Epoch 20/150\n",
      "8612/8612 [==============================] - 1s 115us/step - loss: 0.1761 - val_loss: 0.1733\n",
      "Epoch 21/150\n",
      "8612/8612 [==============================] - 1s 115us/step - loss: 0.1732 - val_loss: 0.1759\n",
      "Epoch 22/150\n",
      "8612/8612 [==============================] - 1s 115us/step - loss: 0.1747 - val_loss: 0.1799\n",
      "Epoch 23/150\n",
      "8612/8612 [==============================] - 1s 115us/step - loss: 0.1769 - val_loss: 0.1738\n",
      "Epoch 24/150\n",
      "8612/8612 [==============================] - 1s 115us/step - loss: 0.1716 - val_loss: 0.1692\n",
      "Epoch 25/150\n",
      "8612/8612 [==============================] - 1s 113us/step - loss: 0.1739 - val_loss: 0.1708\n",
      "Epoch 26/150\n",
      "8612/8612 [==============================] - 1s 110us/step - loss: 0.1737 - val_loss: 0.1690\n",
      "Epoch 27/150\n",
      "8612/8612 [==============================] - 1s 115us/step - loss: 0.1716 - val_loss: 0.1661\n",
      "Epoch 28/150\n",
      "8612/8612 [==============================] - 1s 113us/step - loss: 0.1743 - val_loss: 0.1726\n",
      "Epoch 29/150\n",
      "8612/8612 [==============================] - 1s 115us/step - loss: 0.1692 - val_loss: 0.1738\n",
      "Epoch 30/150\n",
      "8612/8612 [==============================] - 1s 114us/step - loss: 0.1721 - val_loss: 0.1670\n",
      "Epoch 31/150\n",
      "8612/8612 [==============================] - 1s 112us/step - loss: 0.1702 - val_loss: 0.1721\n",
      "Evaluating model with testing data...\n",
      "1824/1824 [==============================] - 0s 15us/step\n",
      "Getting distribution of predictions and covariance matrix...\n",
      "      1 of 20\n",
      "      2 of 20\n",
      "      3 of 20\n",
      "      4 of 20\n",
      "      5 of 20\n",
      "      6 of 20\n",
      "      7 of 20\n",
      "      8 of 20\n",
      "      9 of 20\n",
      "      10 of 20\n",
      "      11 of 20\n",
      "      12 of 20\n",
      "      13 of 20\n",
      "      14 of 20\n",
      "      15 of 20\n",
      "      16 of 20\n",
      "      17 of 20\n",
      "      18 of 20\n",
      "      19 of 20\n",
      "      20 of 20\n",
      "Computing ensemble means...\n",
      "Computing mean squared error...\n",
      "Iteration 59\n",
      "Train on 8752 samples, validate on 1854 samples\n",
      "Epoch 1/150\n",
      "8752/8752 [==============================] - 1s 100us/step - loss: 0.5390 - val_loss: 0.4648\n",
      "Epoch 2/150\n",
      "8752/8752 [==============================] - 1s 107us/step - loss: 0.4457 - val_loss: 0.4270\n",
      "Epoch 3/150\n",
      "8752/8752 [==============================] - 1s 115us/step - loss: 0.4117 - val_loss: 0.3963\n",
      "Epoch 4/150\n",
      "8752/8752 [==============================] - 1s 114us/step - loss: 0.3845 - val_loss: 0.3722\n",
      "Epoch 5/150\n",
      "8752/8752 [==============================] - 1s 110us/step - loss: 0.3634 - val_loss: 0.3540\n",
      "Epoch 6/150\n",
      "8752/8752 [==============================] - 1s 115us/step - loss: 0.3475 - val_loss: 0.3404\n",
      "Epoch 7/150\n",
      "8752/8752 [==============================] - 1s 108us/step - loss: 0.3358 - val_loss: 0.3306\n",
      "Epoch 8/150\n",
      "8752/8752 [==============================] - 1s 113us/step - loss: 0.3276 - val_loss: 0.3237\n",
      "Epoch 9/150\n",
      "8752/8752 [==============================] - 1s 114us/step - loss: 0.3219 - val_loss: 0.3191\n",
      "Epoch 10/150\n",
      "8752/8752 [==============================] - 1s 115us/step - loss: 0.3180 - val_loss: 0.3160\n",
      "Epoch 11/150\n",
      "8752/8752 [==============================] - 1s 112us/step - loss: 0.3156 - val_loss: 0.3142\n",
      "Epoch 12/150\n",
      "8752/8752 [==============================] - 1s 110us/step - loss: 0.3141 - val_loss: 0.3129\n",
      "Epoch 13/150\n",
      "8752/8752 [==============================] - 1s 115us/step - loss: 0.3132 - val_loss: 0.3123\n",
      "Epoch 14/150\n",
      "8752/8752 [==============================] - 1s 115us/step - loss: 0.3126 - val_loss: 0.3119\n",
      "Epoch 15/150\n",
      "8752/8752 [==============================] - 1s 112us/step - loss: 0.3124 - val_loss: 0.3116\n",
      "Epoch 16/150\n",
      "8752/8752 [==============================] - 1s 108us/step - loss: 0.3122 - val_loss: 0.3116\n",
      "Epoch 17/150\n",
      "8752/8752 [==============================] - 1s 108us/step - loss: 0.3121 - val_loss: 0.3116\n",
      "Epoch 18/150\n",
      "8752/8752 [==============================] - 1s 109us/step - loss: 0.3121 - val_loss: 0.3115\n",
      "Epoch 19/150\n",
      "8752/8752 [==============================] - 1s 107us/step - loss: 0.3121 - val_loss: 0.3115\n",
      "Epoch 20/150\n",
      "8752/8752 [==============================] - 1s 115us/step - loss: 0.3120 - val_loss: 0.3114\n",
      "Epoch 21/150\n",
      "8752/8752 [==============================] - 1s 104us/step - loss: 0.3121 - val_loss: 0.3115\n",
      "Epoch 22/150\n",
      "8752/8752 [==============================] - 1s 115us/step - loss: 0.3120 - val_loss: 0.3114\n",
      "Epoch 23/150\n",
      "8752/8752 [==============================] - 1s 112us/step - loss: 0.3120 - val_loss: 0.3115\n",
      "Epoch 24/150\n",
      "8752/8752 [==============================] - 1s 112us/step - loss: 0.3121 - val_loss: 0.3115\n",
      "Epoch 25/150\n",
      "8752/8752 [==============================] - 1s 105us/step - loss: 0.3121 - val_loss: 0.3116\n",
      "Epoch 26/150\n",
      "8752/8752 [==============================] - 1s 111us/step - loss: 0.3120 - val_loss: 0.3114\n",
      "Evaluating model with testing data...\n",
      "1854/1854 [==============================] - 0s 15us/step\n",
      "Getting distribution of predictions and covariance matrix...\n",
      "      1 of 20\n",
      "      2 of 20\n",
      "      3 of 20\n",
      "      4 of 20\n",
      "      5 of 20\n",
      "      6 of 20\n",
      "      7 of 20\n",
      "      8 of 20\n",
      "      9 of 20\n",
      "      10 of 20\n",
      "      11 of 20\n",
      "      12 of 20\n",
      "      13 of 20\n",
      "      14 of 20\n",
      "      15 of 20\n",
      "      16 of 20\n",
      "      17 of 20\n",
      "      18 of 20\n",
      "      19 of 20\n",
      "      20 of 20\n",
      "Computing ensemble means...\n",
      "Computing mean squared error...\n",
      "Iteration 60\n",
      "Train on 8892 samples, validate on 1884 samples\n",
      "Epoch 1/150\n",
      "8892/8892 [==============================] - 1s 116us/step - loss: 0.5335 - val_loss: 0.3972\n",
      "Epoch 2/150\n",
      "8892/8892 [==============================] - 1s 109us/step - loss: 0.3448 - val_loss: 0.2898\n",
      "Epoch 3/150\n",
      "8892/8892 [==============================] - 1s 104us/step - loss: 0.2819 - val_loss: 0.2599\n",
      "Epoch 4/150\n",
      "8892/8892 [==============================] - 1s 113us/step - loss: 0.2519 - val_loss: 0.2383\n",
      "Epoch 5/150\n",
      "8892/8892 [==============================] - 1s 110us/step - loss: 0.2322 - val_loss: 0.2248\n",
      "Epoch 6/150\n",
      "8892/8892 [==============================] - 1s 108us/step - loss: 0.2165 - val_loss: 0.2141\n",
      "Epoch 7/150\n",
      "8892/8892 [==============================] - 1s 115us/step - loss: 0.2093 - val_loss: 0.2106\n",
      "Epoch 8/150\n",
      "8892/8892 [==============================] - 1s 115us/step - loss: 0.2047 - val_loss: 0.2031\n",
      "Epoch 9/150\n",
      "8892/8892 [==============================] - 1s 104us/step - loss: 0.1989 - val_loss: 0.1944\n",
      "Epoch 10/150\n",
      "8892/8892 [==============================] - 1s 106us/step - loss: 0.1892 - val_loss: 0.1954\n",
      "Epoch 11/150\n",
      "8892/8892 [==============================] - 1s 106us/step - loss: 0.1879 - val_loss: 0.1927\n",
      "Epoch 12/150\n",
      "8892/8892 [==============================] - 1s 106us/step - loss: 0.1799 - val_loss: 0.1734\n",
      "Epoch 13/150\n",
      "8892/8892 [==============================] - 1s 110us/step - loss: 0.1712 - val_loss: 0.1694\n",
      "Epoch 14/150\n",
      "8892/8892 [==============================] - 1s 108us/step - loss: 0.1692 - val_loss: 0.1691\n",
      "Epoch 15/150\n",
      "8892/8892 [==============================] - 1s 105us/step - loss: 0.1681 - val_loss: 0.1660\n",
      "Epoch 16/150\n",
      "8892/8892 [==============================] - 1s 104us/step - loss: 0.1644 - val_loss: 0.1587\n",
      "Epoch 17/150\n",
      "8892/8892 [==============================] - 1s 110us/step - loss: 0.1626 - val_loss: 0.1588\n",
      "Epoch 18/150\n",
      "8892/8892 [==============================] - 1s 107us/step - loss: 0.1614 - val_loss: 0.1611\n",
      "Epoch 19/150\n",
      "8892/8892 [==============================] - 1s 103us/step - loss: 0.1602 - val_loss: 0.1624\n",
      "Epoch 20/150\n",
      "8892/8892 [==============================] - 1s 111us/step - loss: 0.1610 - val_loss: 0.1625\n",
      "Evaluating model with testing data...\n",
      "1884/1884 [==============================] - 0s 16us/step\n",
      "Getting distribution of predictions and covariance matrix...\n",
      "      1 of 20\n",
      "      2 of 20\n",
      "      3 of 20\n",
      "      4 of 20\n",
      "      5 of 20\n",
      "      6 of 20\n",
      "      7 of 20\n",
      "      8 of 20\n",
      "      9 of 20\n",
      "      10 of 20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      11 of 20\n",
      "      12 of 20\n",
      "      13 of 20\n",
      "      14 of 20\n",
      "      15 of 20\n",
      "      16 of 20\n",
      "      17 of 20\n",
      "      18 of 20\n",
      "      19 of 20\n",
      "      20 of 20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|          | 0/20 [00:00<?, ?it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing ensemble means...\n",
      "Computing mean squared error...\n",
      "Getting distribution of predictions...\n",
      "      1 of 20\n",
      "1600/1600 [==============================] - 0s 28us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  5%|▌         | 1/20 [00:29<09:14, 29.20s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      2 of 20\n",
      "1600/1600 [==============================] - 0s 29us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 10%|█         | 2/20 [00:58<08:48, 29.34s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      3 of 20\n",
      "1600/1600 [==============================] - 0s 30us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 15%|█▌        | 3/20 [01:28<08:21, 29.48s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      4 of 20\n",
      "1600/1600 [==============================] - 0s 31us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 20%|██        | 4/20 [01:58<07:52, 29.53s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      5 of 20\n",
      "1600/1600 [==============================] - 0s 29us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 25%|██▌       | 5/20 [02:27<07:21, 29.46s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      6 of 20\n",
      "1600/1600 [==============================] - 0s 29us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 30%|███       | 6/20 [02:56<06:52, 29.43s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      7 of 20\n",
      "1600/1600 [==============================] - 0s 28us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 35%|███▌      | 7/20 [03:26<06:24, 29.54s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      8 of 20\n",
      "1600/1600 [==============================] - 0s 30us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 40%|████      | 8/20 [03:56<05:55, 29.60s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      9 of 20\n",
      "1600/1600 [==============================] - 0s 29us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 45%|████▌     | 9/20 [04:25<05:24, 29.49s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      10 of 20\n",
      "1600/1600 [==============================] - 0s 29us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 50%|█████     | 10/20 [04:55<04:55, 29.55s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      11 of 20\n",
      "1600/1600 [==============================] - 0s 29us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 55%|█████▌    | 11/20 [05:25<04:25, 29.55s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      12 of 20\n",
      "1600/1600 [==============================] - 0s 29us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 60%|██████    | 12/20 [05:54<03:57, 29.65s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      13 of 20\n",
      "1600/1600 [==============================] - 0s 30us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 65%|██████▌   | 13/20 [06:24<03:27, 29.61s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      14 of 20\n",
      "1600/1600 [==============================] - 0s 29us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 70%|███████   | 14/20 [06:53<02:57, 29.60s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      15 of 20\n",
      "1600/1600 [==============================] - 0s 30us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 75%|███████▌  | 15/20 [07:23<02:27, 29.59s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      16 of 20\n",
      "1600/1600 [==============================] - 0s 30us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 80%|████████  | 16/20 [07:53<01:58, 29.58s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      17 of 20\n",
      "1600/1600 [==============================] - 0s 29us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 85%|████████▌ | 17/20 [08:22<01:28, 29.45s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      18 of 20\n",
      "1600/1600 [==============================] - 0s 30us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 90%|█████████ | 18/20 [08:52<00:59, 29.59s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      19 of 20\n",
      "1600/1600 [==============================] - 0s 28us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 95%|█████████▌| 19/20 [09:21<00:29, 29.65s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      20 of 20\n",
      "1600/1600 [==============================] - 0s 29us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 20/20 [09:51<00:00, 29.57s/it]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing ensemble predictions...\n",
      "Iteration 61\n",
      "Train on 9032 samples, validate on 1914 samples\n",
      "Epoch 1/150\n",
      "9032/9032 [==============================] - 1s 118us/step - loss: 0.5993 - val_loss: 0.4423\n",
      "Epoch 2/150\n",
      "9032/9032 [==============================] - 1s 106us/step - loss: 0.3854 - val_loss: 0.3421\n",
      "Epoch 3/150\n",
      "9032/9032 [==============================] - 1s 114us/step - loss: 0.3178 - val_loss: 0.3069\n",
      "Epoch 4/150\n",
      "9032/9032 [==============================] - 1s 114us/step - loss: 0.2990 - val_loss: 0.2922\n",
      "Epoch 5/150\n",
      "9032/9032 [==============================] - 1s 114us/step - loss: 0.2807 - val_loss: 0.2687\n",
      "Epoch 6/150\n",
      "9032/9032 [==============================] - 1s 114us/step - loss: 0.2629 - val_loss: 0.2586\n",
      "Epoch 7/150\n",
      "9032/9032 [==============================] - 1s 107us/step - loss: 0.2547 - val_loss: 0.2496\n",
      "Epoch 8/150\n",
      "9032/9032 [==============================] - 1s 111us/step - loss: 0.2452 - val_loss: 0.2388\n",
      "Epoch 9/150\n",
      "9032/9032 [==============================] - 1s 86us/step - loss: 0.2263 - val_loss: 0.2178\n",
      "Epoch 10/150\n",
      "9032/9032 [==============================] - 1s 59us/step - loss: 0.2107 - val_loss: 0.2080\n",
      "Epoch 11/150\n",
      "9032/9032 [==============================] - 1s 58us/step - loss: 0.2028 - val_loss: 0.2017\n",
      "Epoch 12/150\n",
      "9032/9032 [==============================] - 1s 98us/step - loss: 0.1960 - val_loss: 0.1937\n",
      "Epoch 13/150\n",
      "9032/9032 [==============================] - 1s 115us/step - loss: 0.1928 - val_loss: 0.1924\n",
      "Epoch 14/150\n",
      "9032/9032 [==============================] - 1s 111us/step - loss: 0.1893 - val_loss: 0.1897\n",
      "Epoch 15/150\n",
      "9032/9032 [==============================] - 1s 108us/step - loss: 0.1869 - val_loss: 0.1875\n",
      "Epoch 16/150\n",
      "9032/9032 [==============================] - 1s 110us/step - loss: 0.1853 - val_loss: 0.1860\n",
      "Epoch 17/150\n",
      "9032/9032 [==============================] - 1s 114us/step - loss: 0.1810 - val_loss: 0.1842\n",
      "Epoch 18/150\n",
      "9032/9032 [==============================] - 1s 115us/step - loss: 0.1805 - val_loss: 0.1754\n",
      "Epoch 19/150\n",
      "9032/9032 [==============================] - 1s 109us/step - loss: 0.1752 - val_loss: 0.1716\n",
      "Epoch 20/150\n",
      "9032/9032 [==============================] - 1s 110us/step - loss: 0.1724 - val_loss: 0.1773\n",
      "Epoch 21/150\n",
      "9032/9032 [==============================] - 1s 114us/step - loss: 0.1724 - val_loss: 0.1721\n",
      "Epoch 22/150\n",
      "9032/9032 [==============================] - 1s 110us/step - loss: 0.1692 - val_loss: 0.1742\n",
      "Epoch 23/150\n",
      "9032/9032 [==============================] - 1s 107us/step - loss: 0.1682 - val_loss: 0.1697\n",
      "Epoch 24/150\n",
      "9032/9032 [==============================] - 1s 107us/step - loss: 0.1696 - val_loss: 0.1672\n",
      "Epoch 25/150\n",
      "9032/9032 [==============================] - 1s 108us/step - loss: 0.1665 - val_loss: 0.1715\n",
      "Epoch 26/150\n",
      "9032/9032 [==============================] - 1s 110us/step - loss: 0.1654 - val_loss: 0.1657\n",
      "Epoch 27/150\n",
      "9032/9032 [==============================] - 1s 114us/step - loss: 0.1662 - val_loss: 0.1684\n",
      "Epoch 28/150\n",
      "9032/9032 [==============================] - 1s 107us/step - loss: 0.1613 - val_loss: 0.1591\n",
      "Epoch 29/150\n",
      "9032/9032 [==============================] - 1s 108us/step - loss: 0.1595 - val_loss: 0.1669\n",
      "Epoch 30/150\n",
      "9032/9032 [==============================] - 1s 98us/step - loss: 0.1582 - val_loss: 0.1592\n",
      "Epoch 31/150\n",
      "9032/9032 [==============================] - 1s 113us/step - loss: 0.1585 - val_loss: 0.1591\n",
      "Epoch 32/150\n",
      "9032/9032 [==============================] - 1s 75us/step - loss: 0.1551 - val_loss: 0.1604\n",
      "Evaluating model with testing data...\n",
      "1914/1914 [==============================] - 0s 15us/step\n",
      "Getting distribution of predictions and covariance matrix...\n",
      "      1 of 20\n",
      "      2 of 20\n",
      "      3 of 20\n",
      "      4 of 20\n",
      "      5 of 20\n",
      "      6 of 20\n",
      "      7 of 20\n",
      "      8 of 20\n",
      "      9 of 20\n",
      "      10 of 20\n",
      "      11 of 20\n",
      "      12 of 20\n",
      "      13 of 20\n",
      "      14 of 20\n",
      "      15 of 20\n",
      "      16 of 20\n",
      "      17 of 20\n",
      "      18 of 20\n",
      "      19 of 20\n",
      "      20 of 20\n",
      "Computing ensemble means...\n",
      "Computing mean squared error...\n",
      "Iteration 62\n",
      "Train on 9172 samples, validate on 1944 samples\n",
      "Epoch 1/150\n",
      "9172/9172 [==============================] - 1s 108us/step - loss: 0.4573 - val_loss: 0.3457\n",
      "Epoch 2/150\n",
      "9172/9172 [==============================] - 1s 107us/step - loss: 0.2920 - val_loss: 0.2556\n",
      "Epoch 3/150\n",
      "9172/9172 [==============================] - 1s 104us/step - loss: 0.2307 - val_loss: 0.2153\n",
      "Epoch 4/150\n",
      "9172/9172 [==============================] - 1s 109us/step - loss: 0.2041 - val_loss: 0.2031\n",
      "Epoch 5/150\n",
      "9172/9172 [==============================] - 1s 114us/step - loss: 0.1894 - val_loss: 0.1888\n",
      "Epoch 6/150\n",
      "9172/9172 [==============================] - 1s 109us/step - loss: 0.1833 - val_loss: 0.1789\n",
      "Epoch 7/150\n",
      "9172/9172 [==============================] - 1s 106us/step - loss: 0.1743 - val_loss: 0.1680\n",
      "Epoch 8/150\n",
      "9172/9172 [==============================] - 1s 105us/step - loss: 0.1680 - val_loss: 0.1664\n",
      "Epoch 9/150\n",
      "9172/9172 [==============================] - 1s 109us/step - loss: 0.1615 - val_loss: 0.1621\n",
      "Epoch 10/150\n",
      "9172/9172 [==============================] - 1s 110us/step - loss: 0.1574 - val_loss: 0.1535\n",
      "Epoch 11/150\n",
      "9172/9172 [==============================] - 1s 100us/step - loss: 0.1498 - val_loss: 0.1485\n",
      "Epoch 12/150\n",
      "9172/9172 [==============================] - 1s 112us/step - loss: 0.1455 - val_loss: 0.1495\n",
      "Epoch 13/150\n",
      "9172/9172 [==============================] - 1s 108us/step - loss: 0.1462 - val_loss: 0.1451\n",
      "Epoch 14/150\n",
      "9172/9172 [==============================] - 1s 110us/step - loss: 0.1411 - val_loss: 0.1418\n",
      "Epoch 15/150\n",
      "9172/9172 [==============================] - 1s 102us/step - loss: 0.1368 - val_loss: 0.1392\n",
      "Epoch 16/150\n",
      "9172/9172 [==============================] - 1s 110us/step - loss: 0.1339 - val_loss: 0.1350\n",
      "Epoch 17/150\n",
      "9172/9172 [==============================] - 1s 103us/step - loss: 0.1331 - val_loss: 0.1374\n",
      "Epoch 18/150\n",
      "9172/9172 [==============================] - 1s 113us/step - loss: 0.1344 - val_loss: 0.1330\n",
      "Epoch 19/150\n",
      "9172/9172 [==============================] - 1s 111us/step - loss: 0.1310 - val_loss: 0.1330\n",
      "Epoch 20/150\n",
      "9172/9172 [==============================] - 1s 109us/step - loss: 0.1292 - val_loss: 0.1330\n",
      "Epoch 21/150\n",
      "9172/9172 [==============================] - 1s 111us/step - loss: 0.1283 - val_loss: 0.1304\n",
      "Epoch 22/150\n",
      "9172/9172 [==============================] - 1s 104us/step - loss: 0.1280 - val_loss: 0.1293\n",
      "Epoch 23/150\n",
      "9172/9172 [==============================] - 1s 105us/step - loss: 0.1256 - val_loss: 0.1324\n",
      "Epoch 24/150\n",
      "9172/9172 [==============================] - 1s 109us/step - loss: 0.1254 - val_loss: 0.1306\n",
      "Epoch 25/150\n",
      "9172/9172 [==============================] - 1s 103us/step - loss: 0.1259 - val_loss: 0.1313\n",
      "Epoch 26/150\n",
      "9172/9172 [==============================] - 1s 110us/step - loss: 0.1240 - val_loss: 0.1228\n",
      "Epoch 27/150\n",
      "9172/9172 [==============================] - 1s 110us/step - loss: 0.1228 - val_loss: 0.1265\n",
      "Epoch 28/150\n",
      "9172/9172 [==============================] - 1s 105us/step - loss: 0.1222 - val_loss: 0.1223\n",
      "Epoch 29/150\n",
      "9172/9172 [==============================] - 1s 112us/step - loss: 0.1192 - val_loss: 0.1246\n",
      "Epoch 30/150\n",
      "9172/9172 [==============================] - 1s 110us/step - loss: 0.1201 - val_loss: 0.1236\n",
      "Epoch 31/150\n",
      "9172/9172 [==============================] - 1s 102us/step - loss: 0.1198 - val_loss: 0.1182\n",
      "Epoch 32/150\n",
      "9172/9172 [==============================] - 1s 112us/step - loss: 0.1200 - val_loss: 0.1206\n",
      "Epoch 33/150\n",
      "9172/9172 [==============================] - 1s 110us/step - loss: 0.1180 - val_loss: 0.1204\n",
      "Epoch 34/150\n",
      "9172/9172 [==============================] - 1s 104us/step - loss: 0.1184 - val_loss: 0.1230\n",
      "Epoch 35/150\n",
      "9172/9172 [==============================] - 1s 109us/step - loss: 0.1203 - val_loss: 0.1211\n",
      "Evaluating model with testing data...\n",
      "1944/1944 [==============================] - 0s 15us/step\n",
      "Getting distribution of predictions and covariance matrix...\n",
      "      1 of 20\n",
      "      2 of 20\n",
      "      3 of 20\n",
      "      4 of 20\n",
      "      5 of 20\n",
      "      6 of 20\n",
      "      7 of 20\n",
      "      8 of 20\n",
      "      9 of 20\n",
      "      10 of 20\n",
      "      11 of 20\n",
      "      12 of 20\n",
      "      13 of 20\n",
      "      14 of 20\n",
      "      15 of 20\n",
      "      16 of 20\n",
      "      17 of 20\n",
      "      18 of 20\n",
      "      19 of 20\n",
      "      20 of 20\n",
      "Computing ensemble means...\n",
      "Computing mean squared error...\n",
      "Iteration 63\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 9312 samples, validate on 1974 samples\n",
      "Epoch 1/150\n",
      "9312/9312 [==============================] - 1s 118us/step - loss: 0.5377 - val_loss: 0.3607\n",
      "Epoch 2/150\n",
      "9312/9312 [==============================] - 1s 107us/step - loss: 0.3326 - val_loss: 0.3127\n",
      "Epoch 3/150\n",
      "9312/9312 [==============================] - 1s 114us/step - loss: 0.3014 - val_loss: 0.2898\n",
      "Epoch 4/150\n",
      "9312/9312 [==============================] - 1s 114us/step - loss: 0.2735 - val_loss: 0.2583\n",
      "Epoch 5/150\n",
      "9312/9312 [==============================] - 1s 114us/step - loss: 0.2459 - val_loss: 0.2356\n",
      "Epoch 6/150\n",
      "9312/9312 [==============================] - 1s 114us/step - loss: 0.2293 - val_loss: 0.2283\n",
      "Epoch 7/150\n",
      "9312/9312 [==============================] - 1s 114us/step - loss: 0.2170 - val_loss: 0.2101\n",
      "Epoch 8/150\n",
      "9312/9312 [==============================] - 1s 114us/step - loss: 0.2100 - val_loss: 0.2108\n",
      "Epoch 9/150\n",
      "9312/9312 [==============================] - 1s 114us/step - loss: 0.2056 - val_loss: 0.2044\n",
      "Epoch 10/150\n",
      "9312/9312 [==============================] - 1s 114us/step - loss: 0.2011 - val_loss: 0.1992\n",
      "Epoch 11/150\n",
      "9312/9312 [==============================] - 1s 113us/step - loss: 0.1935 - val_loss: 0.1971\n",
      "Epoch 12/150\n",
      "9312/9312 [==============================] - 1s 113us/step - loss: 0.1925 - val_loss: 0.1942\n",
      "Epoch 13/150\n",
      "9312/9312 [==============================] - 1s 113us/step - loss: 0.1895 - val_loss: 0.1933\n",
      "Epoch 14/150\n",
      "9312/9312 [==============================] - 1s 112us/step - loss: 0.1830 - val_loss: 0.1797\n",
      "Epoch 15/150\n",
      "9312/9312 [==============================] - 1s 110us/step - loss: 0.1754 - val_loss: 0.1740\n",
      "Epoch 16/150\n",
      "9312/9312 [==============================] - 1s 114us/step - loss: 0.1689 - val_loss: 0.1671\n",
      "Epoch 17/150\n",
      "9312/9312 [==============================] - 1s 114us/step - loss: 0.1665 - val_loss: 0.1687\n",
      "Epoch 18/150\n",
      "9312/9312 [==============================] - 1s 113us/step - loss: 0.1683 - val_loss: 0.1704\n",
      "Epoch 19/150\n",
      "9312/9312 [==============================] - 1s 111us/step - loss: 0.1646 - val_loss: 0.1614\n",
      "Epoch 20/150\n",
      "9312/9312 [==============================] - 1s 114us/step - loss: 0.1611 - val_loss: 0.1641\n",
      "Epoch 21/150\n",
      "9312/9312 [==============================] - 1s 110us/step - loss: 0.1601 - val_loss: 0.1561\n",
      "Epoch 22/150\n",
      "9312/9312 [==============================] - 1s 113us/step - loss: 0.1593 - val_loss: 0.1613\n",
      "Epoch 23/150\n",
      "9312/9312 [==============================] - 1s 108us/step - loss: 0.1584 - val_loss: 0.1657\n",
      "Epoch 24/150\n",
      "9312/9312 [==============================] - 1s 106us/step - loss: 0.1563 - val_loss: 0.1607\n",
      "Epoch 25/150\n",
      "9312/9312 [==============================] - 1s 114us/step - loss: 0.1558 - val_loss: 0.1519\n",
      "Epoch 26/150\n",
      "9312/9312 [==============================] - 1s 112us/step - loss: 0.1545 - val_loss: 0.1602\n",
      "Epoch 27/150\n",
      "9312/9312 [==============================] - 1s 108us/step - loss: 0.1542 - val_loss: 0.1608\n",
      "Epoch 28/150\n",
      "9312/9312 [==============================] - 1s 110us/step - loss: 0.1538 - val_loss: 0.1531\n",
      "Epoch 29/150\n",
      "9312/9312 [==============================] - 1s 115us/step - loss: 0.1530 - val_loss: 0.1601\n",
      "Evaluating model with testing data...\n",
      "1974/1974 [==============================] - 0s 15us/step\n",
      "Getting distribution of predictions and covariance matrix...\n",
      "      1 of 20\n",
      "      2 of 20\n",
      "      3 of 20\n",
      "      4 of 20\n",
      "      5 of 20\n",
      "      6 of 20\n",
      "      7 of 20\n",
      "      8 of 20\n",
      "      9 of 20\n",
      "      10 of 20\n",
      "      11 of 20\n",
      "      12 of 20\n",
      "      13 of 20\n",
      "      14 of 20\n",
      "      15 of 20\n",
      "      16 of 20\n",
      "      17 of 20\n",
      "      18 of 20\n",
      "      19 of 20\n",
      "      20 of 20\n",
      "Computing ensemble means...\n",
      "Computing mean squared error...\n",
      "Iteration 64\n",
      "Train on 9452 samples, validate on 2004 samples\n",
      "Epoch 1/150\n",
      "9452/9452 [==============================] - 1s 120us/step - loss: 0.4990 - val_loss: 0.3810\n",
      "Epoch 2/150\n",
      "9452/9452 [==============================] - 1s 104us/step - loss: 0.3457 - val_loss: 0.3096\n",
      "Epoch 3/150\n",
      "9452/9452 [==============================] - 1s 104us/step - loss: 0.2916 - val_loss: 0.2749\n",
      "Epoch 4/150\n",
      "9452/9452 [==============================] - 1s 115us/step - loss: 0.2620 - val_loss: 0.2523\n",
      "Epoch 5/150\n",
      "9452/9452 [==============================] - 1s 109us/step - loss: 0.2422 - val_loss: 0.2319\n",
      "Epoch 6/150\n",
      "9452/9452 [==============================] - 1s 107us/step - loss: 0.2259 - val_loss: 0.2233\n",
      "Epoch 7/150\n",
      "9452/9452 [==============================] - 1s 106us/step - loss: 0.2153 - val_loss: 0.2079\n",
      "Epoch 8/150\n",
      "9452/9452 [==============================] - 1s 105us/step - loss: 0.2013 - val_loss: 0.1906\n",
      "Epoch 9/150\n",
      "9452/9452 [==============================] - 1s 104us/step - loss: 0.1887 - val_loss: 0.1809\n",
      "Epoch 10/150\n",
      "9452/9452 [==============================] - 1s 111us/step - loss: 0.1753 - val_loss: 0.1710\n",
      "Epoch 11/150\n",
      "9452/9452 [==============================] - 1s 110us/step - loss: 0.1666 - val_loss: 0.1631\n",
      "Epoch 12/150\n",
      "9452/9452 [==============================] - 1s 114us/step - loss: 0.1620 - val_loss: 0.1582\n",
      "Epoch 13/150\n",
      "9452/9452 [==============================] - 1s 114us/step - loss: 0.1553 - val_loss: 0.1598\n",
      "Epoch 14/150\n",
      "9452/9452 [==============================] - 1s 112us/step - loss: 0.1515 - val_loss: 0.1495\n",
      "Epoch 15/150\n",
      "9452/9452 [==============================] - 1s 113us/step - loss: 0.1500 - val_loss: 0.1481\n",
      "Epoch 16/150\n",
      "9452/9452 [==============================] - 1s 112us/step - loss: 0.1454 - val_loss: 0.1512\n",
      "Epoch 17/150\n",
      "9452/9452 [==============================] - 1s 114us/step - loss: 0.1458 - val_loss: 0.1482\n",
      "Epoch 18/150\n",
      "9452/9452 [==============================] - 1s 111us/step - loss: 0.1450 - val_loss: 0.1507\n",
      "Epoch 19/150\n",
      "9452/9452 [==============================] - 1s 103us/step - loss: 0.1457 - val_loss: 0.1427\n",
      "Epoch 20/150\n",
      "9452/9452 [==============================] - 1s 114us/step - loss: 0.1449 - val_loss: 0.1465\n",
      "Epoch 21/150\n",
      "9452/9452 [==============================] - 1s 107us/step - loss: 0.1419 - val_loss: 0.1383\n",
      "Epoch 22/150\n",
      "9452/9452 [==============================] - 1s 114us/step - loss: 0.1397 - val_loss: 0.1423\n",
      "Epoch 23/150\n",
      "9452/9452 [==============================] - 1s 113us/step - loss: 0.1391 - val_loss: 0.1403\n",
      "Epoch 24/150\n",
      "9452/9452 [==============================] - 1s 113us/step - loss: 0.1395 - val_loss: 0.1419\n",
      "Epoch 25/150\n",
      "9452/9452 [==============================] - 1s 108us/step - loss: 0.1383 - val_loss: 0.1438\n",
      "Evaluating model with testing data...\n",
      "2004/2004 [==============================] - 0s 15us/step\n",
      "Getting distribution of predictions and covariance matrix...\n",
      "      1 of 20\n",
      "      2 of 20\n",
      "      3 of 20\n",
      "      4 of 20\n",
      "      5 of 20\n",
      "      6 of 20\n",
      "      7 of 20\n",
      "      8 of 20\n",
      "      9 of 20\n",
      "      10 of 20\n",
      "      11 of 20\n",
      "      12 of 20\n",
      "      13 of 20\n",
      "      14 of 20\n",
      "      15 of 20\n",
      "      16 of 20\n",
      "      17 of 20\n",
      "      18 of 20\n",
      "      19 of 20\n",
      "      20 of 20\n",
      "Computing ensemble means...\n",
      "Computing mean squared error...\n",
      "Iteration 65\n",
      "Train on 9592 samples, validate on 2034 samples\n",
      "Epoch 1/150\n",
      "9592/9592 [==============================] - 1s 89us/step - loss: 0.4727 - val_loss: 0.3092\n",
      "Epoch 2/150\n",
      "9592/9592 [==============================] - 1s 59us/step - loss: 0.2767 - val_loss: 0.2526\n",
      "Epoch 3/150\n",
      "9592/9592 [==============================] - 1s 59us/step - loss: 0.2397 - val_loss: 0.2283\n",
      "Epoch 4/150\n",
      "9592/9592 [==============================] - 1s 89us/step - loss: 0.2200 - val_loss: 0.2118\n",
      "Epoch 5/150\n",
      "9592/9592 [==============================] - 1s 107us/step - loss: 0.2082 - val_loss: 0.2043\n",
      "Epoch 6/150\n",
      "9592/9592 [==============================] - 1s 104us/step - loss: 0.1993 - val_loss: 0.1926\n",
      "Epoch 7/150\n",
      "9592/9592 [==============================] - 1s 113us/step - loss: 0.1883 - val_loss: 0.1864\n",
      "Epoch 8/150\n",
      "9592/9592 [==============================] - 1s 104us/step - loss: 0.1836 - val_loss: 0.1798\n",
      "Epoch 9/150\n",
      "9592/9592 [==============================] - 1s 106us/step - loss: 0.1720 - val_loss: 0.1689\n",
      "Epoch 10/150\n",
      "9592/9592 [==============================] - 1s 108us/step - loss: 0.1657 - val_loss: 0.1613\n",
      "Epoch 11/150\n",
      "9592/9592 [==============================] - 1s 103us/step - loss: 0.1591 - val_loss: 0.1574\n",
      "Epoch 12/150\n",
      "9592/9592 [==============================] - 1s 101us/step - loss: 0.1587 - val_loss: 0.1542\n",
      "Epoch 13/150\n",
      "9592/9592 [==============================] - 1s 113us/step - loss: 0.1532 - val_loss: 0.1509\n",
      "Epoch 14/150\n",
      "9592/9592 [==============================] - 1s 114us/step - loss: 0.1494 - val_loss: 0.1482\n",
      "Epoch 15/150\n",
      "9592/9592 [==============================] - 1s 114us/step - loss: 0.1484 - val_loss: 0.1468\n",
      "Epoch 16/150\n",
      "9592/9592 [==============================] - 1s 113us/step - loss: 0.1475 - val_loss: 0.1478\n",
      "Epoch 17/150\n",
      "9592/9592 [==============================] - 1s 113us/step - loss: 0.1453 - val_loss: 0.1472\n",
      "Epoch 18/150\n",
      "9592/9592 [==============================] - 1s 114us/step - loss: 0.1449 - val_loss: 0.1459\n",
      "Epoch 19/150\n",
      "9592/9592 [==============================] - 1s 111us/step - loss: 0.1431 - val_loss: 0.1420\n",
      "Epoch 20/150\n",
      "9592/9592 [==============================] - 1s 107us/step - loss: 0.1388 - val_loss: 0.1394\n",
      "Epoch 21/150\n",
      "9592/9592 [==============================] - 1s 111us/step - loss: 0.1397 - val_loss: 0.1427\n",
      "Epoch 22/150\n",
      "9592/9592 [==============================] - 1s 114us/step - loss: 0.1394 - val_loss: 0.1398\n",
      "Epoch 23/150\n",
      "9592/9592 [==============================] - 1s 110us/step - loss: 0.1396 - val_loss: 0.1408\n",
      "Epoch 24/150\n",
      "9592/9592 [==============================] - 1s 111us/step - loss: 0.1381 - val_loss: 0.1368\n",
      "Epoch 25/150\n",
      "9592/9592 [==============================] - 1s 111us/step - loss: 0.1378 - val_loss: 0.1428\n",
      "Epoch 26/150\n",
      "9592/9592 [==============================] - 1s 114us/step - loss: 0.1377 - val_loss: 0.1413\n",
      "Epoch 27/150\n",
      "9592/9592 [==============================] - 1s 108us/step - loss: 0.1364 - val_loss: 0.1426\n",
      "Epoch 28/150\n",
      "9592/9592 [==============================] - 1s 113us/step - loss: 0.1376 - val_loss: 0.1369\n",
      "Evaluating model with testing data...\n",
      "2034/2034 [==============================] - 0s 15us/step\n",
      "Getting distribution of predictions and covariance matrix...\n",
      "      1 of 20\n",
      "      2 of 20\n",
      "      3 of 20\n",
      "      4 of 20\n",
      "      5 of 20\n",
      "      6 of 20\n",
      "      7 of 20\n",
      "      8 of 20\n",
      "      9 of 20\n",
      "      10 of 20\n",
      "      11 of 20\n",
      "      12 of 20\n",
      "      13 of 20\n",
      "      14 of 20\n",
      "      15 of 20\n",
      "      16 of 20\n",
      "      17 of 20\n",
      "      18 of 20\n",
      "      19 of 20\n",
      "      20 of 20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|          | 0/20 [00:00<?, ?it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing ensemble means...\n",
      "Computing mean squared error...\n",
      "Getting distribution of predictions...\n",
      "      1 of 20\n",
      "1600/1600 [==============================] - 0s 27us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  5%|▌         | 1/20 [00:29<09:19, 29.43s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      2 of 20\n",
      "1600/1600 [==============================] - 0s 29us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 10%|█         | 2/20 [00:59<08:50, 29.50s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      3 of 20\n",
      "1600/1600 [==============================] - 0s 29us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 15%|█▌        | 3/20 [01:28<08:21, 29.51s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      4 of 20\n",
      "1600/1600 [==============================] - 0s 34us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 20%|██        | 4/20 [01:57<07:50, 29.43s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      5 of 20\n",
      "1600/1600 [==============================] - 0s 29us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 25%|██▌       | 5/20 [02:27<07:23, 29.56s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      6 of 20\n",
      "1600/1600 [==============================] - 0s 28us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 30%|███       | 6/20 [02:57<06:53, 29.51s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      7 of 20\n",
      "1600/1600 [==============================] - 0s 29us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 35%|███▌      | 7/20 [03:26<06:24, 29.56s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      8 of 20\n",
      "1600/1600 [==============================] - 0s 30us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 40%|████      | 8/20 [03:56<05:53, 29.48s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      9 of 20\n",
      "1600/1600 [==============================] - 0s 29us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 45%|████▌     | 9/20 [04:25<05:24, 29.51s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      10 of 20\n",
      "1600/1600 [==============================] - 0s 29us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 50%|█████     | 10/20 [04:55<04:55, 29.52s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      11 of 20\n",
      "1600/1600 [==============================] - 0s 29us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 55%|█████▌    | 11/20 [05:24<04:25, 29.51s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      12 of 20\n",
      "1600/1600 [==============================] - 0s 29us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 60%|██████    | 12/20 [05:54<03:55, 29.48s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      13 of 20\n",
      "1600/1600 [==============================] - 0s 30us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 65%|██████▌   | 13/20 [06:23<03:26, 29.53s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      14 of 20\n",
      "1600/1600 [==============================] - 0s 29us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 70%|███████   | 14/20 [06:53<02:57, 29.55s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      15 of 20\n",
      "1600/1600 [==============================] - 0s 28us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 75%|███████▌  | 15/20 [07:23<02:28, 29.61s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      16 of 20\n",
      "1600/1600 [==============================] - 0s 29us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 80%|████████  | 16/20 [07:52<01:58, 29.56s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      17 of 20\n",
      "1600/1600 [==============================] - 0s 30us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 85%|████████▌ | 17/20 [08:22<01:28, 29.64s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      18 of 20\n",
      "1600/1600 [==============================] - 0s 30us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 90%|█████████ | 18/20 [08:52<00:59, 29.64s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      19 of 20\n",
      "1600/1600 [==============================] - 0s 29us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 95%|█████████▌| 19/20 [09:21<00:29, 29.64s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      20 of 20\n",
      "1600/1600 [==============================] - 0s 29us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 20/20 [09:51<00:00, 29.55s/it]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing ensemble predictions...\n",
      "Iteration 66\n",
      "Train on 9732 samples, validate on 2064 samples\n",
      "Epoch 1/150\n",
      "9732/9732 [==============================] - 1s 117us/step - loss: 0.5659 - val_loss: 0.4402\n",
      "Epoch 2/150\n",
      "9732/9732 [==============================] - 1s 111us/step - loss: 0.3748 - val_loss: 0.3302\n",
      "Epoch 3/150\n",
      "9732/9732 [==============================] - 1s 114us/step - loss: 0.3003 - val_loss: 0.2802\n",
      "Epoch 4/150\n",
      "9732/9732 [==============================] - 1s 114us/step - loss: 0.2740 - val_loss: 0.2656\n",
      "Epoch 5/150\n",
      "9732/9732 [==============================] - 1s 114us/step - loss: 0.2573 - val_loss: 0.2547\n",
      "Epoch 6/150\n",
      "9732/9732 [==============================] - 1s 115us/step - loss: 0.2509 - val_loss: 0.2455\n",
      "Epoch 7/150\n",
      "9732/9732 [==============================] - 1s 112us/step - loss: 0.2439 - val_loss: 0.2472\n",
      "Epoch 8/150\n",
      "9732/9732 [==============================] - 1s 114us/step - loss: 0.2332 - val_loss: 0.2266\n",
      "Epoch 9/150\n",
      "9732/9732 [==============================] - 1s 114us/step - loss: 0.2247 - val_loss: 0.2242\n",
      "Epoch 10/150\n",
      "9732/9732 [==============================] - 1s 113us/step - loss: 0.2100 - val_loss: 0.2063\n",
      "Epoch 11/150\n",
      "9732/9732 [==============================] - 1s 115us/step - loss: 0.2008 - val_loss: 0.1957\n",
      "Epoch 12/150\n",
      "9732/9732 [==============================] - 1s 113us/step - loss: 0.1948 - val_loss: 0.1934\n",
      "Epoch 13/150\n",
      "9732/9732 [==============================] - 1s 115us/step - loss: 0.1877 - val_loss: 0.1867\n",
      "Epoch 14/150\n",
      "9732/9732 [==============================] - 1s 111us/step - loss: 0.1848 - val_loss: 0.1880\n",
      "Epoch 15/150\n",
      "9732/9732 [==============================] - 1s 111us/step - loss: 0.1836 - val_loss: 0.1824\n",
      "Epoch 16/150\n",
      "9732/9732 [==============================] - 1s 114us/step - loss: 0.1821 - val_loss: 0.1835\n",
      "Epoch 17/150\n",
      "9732/9732 [==============================] - 1s 114us/step - loss: 0.1813 - val_loss: 0.1824\n",
      "Epoch 18/150\n",
      "9732/9732 [==============================] - 1s 111us/step - loss: 0.1787 - val_loss: 0.1798\n",
      "Epoch 19/150\n",
      "9732/9732 [==============================] - 1s 109us/step - loss: 0.1764 - val_loss: 0.1731\n",
      "Epoch 20/150\n",
      "9732/9732 [==============================] - 1s 107us/step - loss: 0.1710 - val_loss: 0.1727\n",
      "Epoch 21/150\n",
      "9732/9732 [==============================] - 1s 115us/step - loss: 0.1670 - val_loss: 0.1696\n",
      "Epoch 22/150\n",
      "9732/9732 [==============================] - 1s 112us/step - loss: 0.1614 - val_loss: 0.1623\n",
      "Epoch 23/150\n",
      "9732/9732 [==============================] - 1s 109us/step - loss: 0.1649 - val_loss: 0.1635\n",
      "Epoch 24/150\n",
      "9732/9732 [==============================] - 1s 109us/step - loss: 0.1640 - val_loss: 0.1613\n",
      "Epoch 25/150\n",
      "9732/9732 [==============================] - 1s 111us/step - loss: 0.1599 - val_loss: 0.1610\n",
      "Epoch 26/150\n",
      "9732/9732 [==============================] - 1s 113us/step - loss: 0.1617 - val_loss: 0.1555\n",
      "Epoch 27/150\n",
      "9732/9732 [==============================] - 1s 99us/step - loss: 0.1589 - val_loss: 0.1567\n",
      "Epoch 28/150\n",
      "9732/9732 [==============================] - 1s 116us/step - loss: 0.1571 - val_loss: 0.1590\n",
      "Epoch 29/150\n",
      "9732/9732 [==============================] - 1s 108us/step - loss: 0.1523 - val_loss: 0.1598\n",
      "Epoch 30/150\n",
      "9732/9732 [==============================] - 1s 114us/step - loss: 0.1597 - val_loss: 0.1545\n",
      "Epoch 31/150\n",
      "9732/9732 [==============================] - 1s 109us/step - loss: 0.1548 - val_loss: 0.1610\n",
      "Epoch 32/150\n",
      "9732/9732 [==============================] - 1s 107us/step - loss: 0.1548 - val_loss: 0.1561\n",
      "Epoch 33/150\n",
      "9732/9732 [==============================] - 1s 110us/step - loss: 0.1525 - val_loss: 0.1539\n",
      "Epoch 34/150\n",
      "9732/9732 [==============================] - 1s 114us/step - loss: 0.1504 - val_loss: 0.1490\n",
      "Epoch 35/150\n",
      "9732/9732 [==============================] - 1s 115us/step - loss: 0.1484 - val_loss: 0.1504\n",
      "Epoch 36/150\n",
      "9732/9732 [==============================] - 1s 109us/step - loss: 0.1481 - val_loss: 0.1485\n",
      "Epoch 37/150\n",
      "9732/9732 [==============================] - 1s 110us/step - loss: 0.1477 - val_loss: 0.1486\n",
      "Epoch 38/150\n",
      "9732/9732 [==============================] - 1s 114us/step - loss: 0.1558 - val_loss: 0.1543\n",
      "Epoch 39/150\n",
      "9732/9732 [==============================] - 1s 114us/step - loss: 0.1474 - val_loss: 0.1470\n",
      "Epoch 40/150\n",
      "9732/9732 [==============================] - 1s 112us/step - loss: 0.1448 - val_loss: 0.1416\n",
      "Epoch 41/150\n",
      "9732/9732 [==============================] - 1s 114us/step - loss: 0.1450 - val_loss: 0.1465\n",
      "Epoch 42/150\n",
      "9732/9732 [==============================] - 1s 114us/step - loss: 0.1445 - val_loss: 0.1454\n",
      "Epoch 43/150\n",
      "9732/9732 [==============================] - 1s 109us/step - loss: 0.1408 - val_loss: 0.1387\n",
      "Epoch 44/150\n",
      "9732/9732 [==============================] - 1s 113us/step - loss: 0.1418 - val_loss: 0.1482\n",
      "Epoch 45/150\n",
      "9732/9732 [==============================] - 1s 114us/step - loss: 0.1509 - val_loss: 0.1493\n",
      "Epoch 46/150\n",
      "9732/9732 [==============================] - 1s 108us/step - loss: 0.1467 - val_loss: 0.1460\n",
      "Epoch 47/150\n",
      "9732/9732 [==============================] - 1s 114us/step - loss: 0.1454 - val_loss: 0.1449\n",
      "Evaluating model with testing data...\n",
      "2064/2064 [==============================] - 0s 15us/step\n",
      "Getting distribution of predictions and covariance matrix...\n",
      "      1 of 20\n",
      "      2 of 20\n",
      "      3 of 20\n",
      "      4 of 20\n",
      "      5 of 20\n",
      "      6 of 20\n",
      "      7 of 20\n",
      "      8 of 20\n",
      "      9 of 20\n",
      "      10 of 20\n",
      "      11 of 20\n",
      "      12 of 20\n",
      "      13 of 20\n",
      "      14 of 20\n",
      "      15 of 20\n",
      "      16 of 20\n",
      "      17 of 20\n",
      "      18 of 20\n",
      "      19 of 20\n",
      "      20 of 20\n",
      "Computing ensemble means...\n",
      "Computing mean squared error...\n",
      "Iteration 67\n",
      "Train on 9872 samples, validate on 2094 samples\n",
      "Epoch 1/150\n",
      "9872/9872 [==============================] - 1s 116us/step - loss: 0.4464 - val_loss: 0.3218\n",
      "Epoch 2/150\n",
      "9872/9872 [==============================] - 1s 99us/step - loss: 0.2693 - val_loss: 0.2298\n",
      "Epoch 3/150\n",
      "9872/9872 [==============================] - 1s 110us/step - loss: 0.2111 - val_loss: 0.1960\n",
      "Epoch 4/150\n",
      "9872/9872 [==============================] - 1s 104us/step - loss: 0.1859 - val_loss: 0.1788\n",
      "Epoch 5/150\n",
      "9872/9872 [==============================] - 1s 107us/step - loss: 0.1744 - val_loss: 0.1663\n",
      "Epoch 6/150\n",
      "9872/9872 [==============================] - 1s 113us/step - loss: 0.1609 - val_loss: 0.1635\n",
      "Epoch 7/150\n",
      "9872/9872 [==============================] - 1s 106us/step - loss: 0.1550 - val_loss: 0.1501\n",
      "Epoch 8/150\n",
      "9872/9872 [==============================] - 1s 111us/step - loss: 0.1478 - val_loss: 0.1438\n",
      "Epoch 9/150\n",
      "9872/9872 [==============================] - 1s 106us/step - loss: 0.1421 - val_loss: 0.1412\n",
      "Epoch 10/150\n",
      "9872/9872 [==============================] - 1s 102us/step - loss: 0.1376 - val_loss: 0.1407\n",
      "Epoch 11/150\n",
      "9872/9872 [==============================] - 1s 111us/step - loss: 0.1382 - val_loss: 0.1347\n",
      "Epoch 12/150\n",
      "9872/9872 [==============================] - 1s 110us/step - loss: 0.1327 - val_loss: 0.1336\n",
      "Epoch 13/150\n",
      "9872/9872 [==============================] - 1s 111us/step - loss: 0.1306 - val_loss: 0.1303\n",
      "Epoch 14/150\n",
      "9872/9872 [==============================] - 1s 103us/step - loss: 0.1275 - val_loss: 0.1301\n",
      "Epoch 15/150\n",
      "9872/9872 [==============================] - 1s 111us/step - loss: 0.1280 - val_loss: 0.1315\n",
      "Epoch 16/150\n",
      "9872/9872 [==============================] - 1s 98us/step - loss: 0.1267 - val_loss: 0.1273\n",
      "Epoch 17/150\n",
      "9872/9872 [==============================] - 1s 102us/step - loss: 0.1237 - val_loss: 0.1273\n",
      "Epoch 18/150\n",
      "9872/9872 [==============================] - 1s 107us/step - loss: 0.1233 - val_loss: 0.1254\n",
      "Epoch 19/150\n",
      "9872/9872 [==============================] - 1s 100us/step - loss: 0.1200 - val_loss: 0.1215\n",
      "Epoch 20/150\n",
      "9872/9872 [==============================] - 1s 103us/step - loss: 0.1184 - val_loss: 0.1242\n",
      "Epoch 21/150\n",
      "9872/9872 [==============================] - 1s 101us/step - loss: 0.1194 - val_loss: 0.1179\n",
      "Epoch 22/150\n",
      "9872/9872 [==============================] - 1s 108us/step - loss: 0.1161 - val_loss: 0.1205\n",
      "Epoch 23/150\n",
      "9872/9872 [==============================] - 1s 105us/step - loss: 0.1152 - val_loss: 0.1179\n",
      "Epoch 24/150\n",
      "9872/9872 [==============================] - 1s 98us/step - loss: 0.1158 - val_loss: 0.1158\n",
      "Epoch 25/150\n",
      "9872/9872 [==============================] - 1s 106us/step - loss: 0.1156 - val_loss: 0.1214\n",
      "Epoch 26/150\n",
      "9872/9872 [==============================] - 1s 108us/step - loss: 0.1131 - val_loss: 0.1166\n",
      "Epoch 27/150\n",
      "9872/9872 [==============================] - 1s 112us/step - loss: 0.1144 - val_loss: 0.1143\n",
      "Epoch 28/150\n",
      "9872/9872 [==============================] - 1s 114us/step - loss: 0.1108 - val_loss: 0.1143\n",
      "Epoch 29/150\n",
      "9872/9872 [==============================] - 1s 112us/step - loss: 0.1108 - val_loss: 0.1142\n",
      "Epoch 30/150\n",
      "9872/9872 [==============================] - 1s 115us/step - loss: 0.1096 - val_loss: 0.1139\n",
      "Epoch 31/150\n",
      "9872/9872 [==============================] - 1s 115us/step - loss: 0.1091 - val_loss: 0.1106\n",
      "Epoch 32/150\n",
      "9872/9872 [==============================] - 1s 112us/step - loss: 0.1101 - val_loss: 0.1118\n",
      "Epoch 33/150\n",
      "9872/9872 [==============================] - 1s 115us/step - loss: 0.1084 - val_loss: 0.1120\n",
      "Epoch 34/150\n",
      "9872/9872 [==============================] - 1s 114us/step - loss: 0.1090 - val_loss: 0.1087\n",
      "Epoch 35/150\n",
      "9872/9872 [==============================] - 1s 112us/step - loss: 0.1056 - val_loss: 0.1127\n",
      "Epoch 36/150\n",
      "9872/9872 [==============================] - 1s 115us/step - loss: 0.1062 - val_loss: 0.1142\n",
      "Epoch 37/150\n",
      "9872/9872 [==============================] - 1s 115us/step - loss: 0.1071 - val_loss: 0.1044\n",
      "Epoch 38/150\n",
      "9872/9872 [==============================] - 1s 115us/step - loss: 0.1064 - val_loss: 0.1070\n",
      "Epoch 39/150\n",
      "9872/9872 [==============================] - 1s 115us/step - loss: 0.1056 - val_loss: 0.1102\n",
      "Epoch 40/150\n",
      "9872/9872 [==============================] - 1s 110us/step - loss: 0.1042 - val_loss: 0.1116\n",
      "Epoch 41/150\n",
      "9872/9872 [==============================] - 1s 111us/step - loss: 0.1058 - val_loss: 0.1079\n",
      "Evaluating model with testing data...\n",
      "2094/2094 [==============================] - 0s 15us/step\n",
      "Getting distribution of predictions and covariance matrix...\n",
      "      1 of 20\n",
      "      2 of 20\n",
      "      3 of 20\n",
      "      4 of 20\n",
      "      5 of 20\n",
      "      6 of 20\n",
      "      7 of 20\n",
      "      8 of 20\n",
      "      9 of 20\n",
      "      10 of 20\n",
      "      11 of 20\n",
      "      12 of 20\n",
      "      13 of 20\n",
      "      14 of 20\n",
      "      15 of 20\n",
      "      16 of 20\n",
      "      17 of 20\n",
      "      18 of 20\n",
      "      19 of 20\n",
      "      20 of 20\n",
      "Computing ensemble means...\n",
      "Computing mean squared error...\n",
      "Iteration 68\n",
      "Train on 10012 samples, validate on 2124 samples\n",
      "Epoch 1/150\n",
      "10012/10012 [==============================] - 1s 106us/step - loss: 0.5429 - val_loss: 0.4170\n",
      "Epoch 2/150\n",
      "10012/10012 [==============================] - 1s 67us/step - loss: 0.3744 - val_loss: 0.3377\n",
      "Epoch 3/150\n",
      "10012/10012 [==============================] - 1s 61us/step - loss: 0.3009 - val_loss: 0.2719\n",
      "Epoch 4/150\n",
      "10012/10012 [==============================] - 1s 76us/step - loss: 0.2583 - val_loss: 0.2518\n",
      "Epoch 5/150\n",
      "10012/10012 [==============================] - 1s 106us/step - loss: 0.2431 - val_loss: 0.2425\n",
      "Epoch 6/150\n",
      "10012/10012 [==============================] - 1s 103us/step - loss: 0.2307 - val_loss: 0.2268\n",
      "Epoch 7/150\n",
      "10012/10012 [==============================] - 1s 113us/step - loss: 0.2171 - val_loss: 0.2140\n",
      "Epoch 8/150\n",
      "10012/10012 [==============================] - 1s 115us/step - loss: 0.2102 - val_loss: 0.2157\n",
      "Epoch 9/150\n",
      "10012/10012 [==============================] - 1s 114us/step - loss: 0.2061 - val_loss: 0.2068\n",
      "Epoch 10/150\n",
      "10012/10012 [==============================] - 1s 112us/step - loss: 0.2030 - val_loss: 0.2031\n",
      "Epoch 11/150\n",
      "10012/10012 [==============================] - 1s 115us/step - loss: 0.1987 - val_loss: 0.2035\n",
      "Epoch 12/150\n",
      "10012/10012 [==============================] - 1s 115us/step - loss: 0.1969 - val_loss: 0.1979\n",
      "Epoch 13/150\n",
      "10012/10012 [==============================] - 1s 114us/step - loss: 0.1933 - val_loss: 0.1964\n",
      "Epoch 14/150\n",
      "10012/10012 [==============================] - 1s 108us/step - loss: 0.1924 - val_loss: 0.1944\n",
      "Epoch 15/150\n",
      "10012/10012 [==============================] - 1s 108us/step - loss: 0.1910 - val_loss: 0.1954\n",
      "Epoch 16/150\n",
      "10012/10012 [==============================] - 1s 113us/step - loss: 0.1910 - val_loss: 0.1929\n",
      "Epoch 17/150\n",
      "10012/10012 [==============================] - 1s 108us/step - loss: 0.1870 - val_loss: 0.1887\n",
      "Epoch 18/150\n",
      "10012/10012 [==============================] - 1s 113us/step - loss: 0.1883 - val_loss: 0.1895\n",
      "Epoch 19/150\n",
      "10012/10012 [==============================] - 1s 102us/step - loss: 0.1850 - val_loss: 0.1873\n",
      "Epoch 20/150\n",
      "10012/10012 [==============================] - 1s 113us/step - loss: 0.1810 - val_loss: 0.1812\n",
      "Epoch 21/150\n",
      "10012/10012 [==============================] - 1s 108us/step - loss: 0.1807 - val_loss: 0.1855\n",
      "Epoch 22/150\n",
      "10012/10012 [==============================] - 1s 115us/step - loss: 0.1808 - val_loss: 0.1847\n",
      "Epoch 23/150\n",
      "10012/10012 [==============================] - 1s 111us/step - loss: 0.1803 - val_loss: 0.1843\n",
      "Epoch 24/150\n",
      "10012/10012 [==============================] - 1s 106us/step - loss: 0.1803 - val_loss: 0.1784\n",
      "Epoch 25/150\n",
      "10012/10012 [==============================] - 1s 111us/step - loss: 0.1771 - val_loss: 0.1766\n",
      "Epoch 26/150\n",
      "10012/10012 [==============================] - 1s 113us/step - loss: 0.1727 - val_loss: 0.1741\n",
      "Epoch 27/150\n",
      "10012/10012 [==============================] - 1s 102us/step - loss: 0.1713 - val_loss: 0.1755\n",
      "Epoch 28/150\n",
      "10012/10012 [==============================] - 1s 111us/step - loss: 0.1707 - val_loss: 0.1704\n",
      "Epoch 29/150\n",
      "10012/10012 [==============================] - 1s 109us/step - loss: 0.1710 - val_loss: 0.1667\n",
      "Epoch 30/150\n",
      "10012/10012 [==============================] - 1s 115us/step - loss: 0.1681 - val_loss: 0.1723\n",
      "Epoch 31/150\n",
      "10012/10012 [==============================] - 1s 112us/step - loss: 0.1679 - val_loss: 0.1693\n",
      "Epoch 32/150\n",
      "10012/10012 [==============================] - 1s 108us/step - loss: 0.1687 - val_loss: 0.1701\n",
      "Epoch 33/150\n",
      "10012/10012 [==============================] - 1s 114us/step - loss: 0.1675 - val_loss: 0.1709\n",
      "Evaluating model with testing data...\n",
      "2124/2124 [==============================] - 0s 15us/step\n",
      "Getting distribution of predictions and covariance matrix...\n",
      "      1 of 20\n",
      "      2 of 20\n",
      "      3 of 20\n",
      "      4 of 20\n",
      "      5 of 20\n",
      "      6 of 20\n",
      "      7 of 20\n",
      "      8 of 20\n",
      "      9 of 20\n",
      "      10 of 20\n",
      "      11 of 20\n",
      "      12 of 20\n",
      "      13 of 20\n",
      "      14 of 20\n",
      "      15 of 20\n",
      "      16 of 20\n",
      "      17 of 20\n",
      "      18 of 20\n",
      "      19 of 20\n",
      "      20 of 20\n",
      "Computing ensemble means...\n",
      "Computing mean squared error...\n",
      "Iteration 69\n",
      "Train on 10152 samples, validate on 2154 samples\n",
      "Epoch 1/150\n",
      "10152/10152 [==============================] - 1s 116us/step - loss: 0.4759 - val_loss: 0.3419\n",
      "Epoch 2/150\n",
      "10152/10152 [==============================] - 1s 105us/step - loss: 0.2966 - val_loss: 0.2731\n",
      "Epoch 3/150\n",
      "10152/10152 [==============================] - 1s 102us/step - loss: 0.2507 - val_loss: 0.2359\n",
      "Epoch 4/150\n",
      "10152/10152 [==============================] - 1s 105us/step - loss: 0.2290 - val_loss: 0.2205\n",
      "Epoch 5/150\n",
      "10152/10152 [==============================] - 1s 100us/step - loss: 0.2172 - val_loss: 0.2106\n",
      "Epoch 6/150\n",
      "10152/10152 [==============================] - 1s 101us/step - loss: 0.2041 - val_loss: 0.2049\n",
      "Epoch 7/150\n",
      "10152/10152 [==============================] - 1s 111us/step - loss: 0.1998 - val_loss: 0.2000\n",
      "Epoch 8/150\n",
      "10152/10152 [==============================] - 1s 105us/step - loss: 0.1933 - val_loss: 0.1914\n",
      "Epoch 9/150\n",
      "10152/10152 [==============================] - 1s 112us/step - loss: 0.1885 - val_loss: 0.1870\n",
      "Epoch 10/150\n",
      "10152/10152 [==============================] - 1s 112us/step - loss: 0.1865 - val_loss: 0.1841\n",
      "Epoch 11/150\n",
      "10152/10152 [==============================] - 1s 105us/step - loss: 0.1824 - val_loss: 0.1784\n",
      "Epoch 12/150\n",
      "10152/10152 [==============================] - 1s 103us/step - loss: 0.1805 - val_loss: 0.1826\n",
      "Epoch 13/150\n",
      "10152/10152 [==============================] - 1s 107us/step - loss: 0.1761 - val_loss: 0.1772\n",
      "Epoch 14/150\n",
      "10152/10152 [==============================] - 1s 104us/step - loss: 0.1757 - val_loss: 0.1744\n",
      "Epoch 15/150\n",
      "10152/10152 [==============================] - 1s 107us/step - loss: 0.1729 - val_loss: 0.1704\n",
      "Epoch 16/150\n",
      "10152/10152 [==============================] - 1s 101us/step - loss: 0.1690 - val_loss: 0.1711\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 17/150\n",
      "10152/10152 [==============================] - 1s 111us/step - loss: 0.1674 - val_loss: 0.1693\n",
      "Epoch 18/150\n",
      "10152/10152 [==============================] - 1s 114us/step - loss: 0.1686 - val_loss: 0.1694\n",
      "Epoch 19/150\n",
      "10152/10152 [==============================] - 1s 115us/step - loss: 0.1674 - val_loss: 0.1692\n",
      "Epoch 20/150\n",
      "10152/10152 [==============================] - 1s 111us/step - loss: 0.1658 - val_loss: 0.1674\n",
      "Epoch 21/150\n",
      "10152/10152 [==============================] - 1s 114us/step - loss: 0.1670 - val_loss: 0.1625\n",
      "Epoch 22/150\n",
      "10152/10152 [==============================] - 1s 114us/step - loss: 0.1648 - val_loss: 0.1614\n",
      "Epoch 23/150\n",
      "10152/10152 [==============================] - 1s 114us/step - loss: 0.1609 - val_loss: 0.1639\n",
      "Epoch 24/150\n",
      "10152/10152 [==============================] - 1s 111us/step - loss: 0.1606 - val_loss: 0.1608\n",
      "Epoch 25/150\n",
      "10152/10152 [==============================] - 1s 114us/step - loss: 0.1586 - val_loss: 0.1651\n",
      "Epoch 26/150\n",
      "10152/10152 [==============================] - 1s 114us/step - loss: 0.1581 - val_loss: 0.1566\n",
      "Epoch 27/150\n",
      "10152/10152 [==============================] - 1s 115us/step - loss: 0.1564 - val_loss: 0.1564\n",
      "Epoch 28/150\n",
      "10152/10152 [==============================] - 1s 110us/step - loss: 0.1556 - val_loss: 0.1571\n",
      "Epoch 29/150\n",
      "10152/10152 [==============================] - 1s 114us/step - loss: 0.1583 - val_loss: 0.1559\n",
      "Epoch 30/150\n",
      "10152/10152 [==============================] - 1s 110us/step - loss: 0.1554 - val_loss: 0.1562\n",
      "Epoch 31/150\n",
      "10152/10152 [==============================] - 1s 115us/step - loss: 0.1551 - val_loss: 0.1554\n",
      "Epoch 32/150\n",
      "10152/10152 [==============================] - 1s 114us/step - loss: 0.1548 - val_loss: 0.1582\n",
      "Epoch 33/150\n",
      "10152/10152 [==============================] - 1s 113us/step - loss: 0.1499 - val_loss: 0.1538\n",
      "Epoch 34/150\n",
      "10152/10152 [==============================] - 1s 111us/step - loss: 0.1488 - val_loss: 0.1478\n",
      "Epoch 35/150\n",
      "10152/10152 [==============================] - 1s 114us/step - loss: 0.1453 - val_loss: 0.1520\n",
      "Epoch 36/150\n",
      "10152/10152 [==============================] - 1s 114us/step - loss: 0.1439 - val_loss: 0.1436\n",
      "Epoch 37/150\n",
      "10152/10152 [==============================] - 1s 115us/step - loss: 0.1424 - val_loss: 0.1374\n",
      "Epoch 38/150\n",
      "10152/10152 [==============================] - 1s 102us/step - loss: 0.1435 - val_loss: 0.1443\n",
      "Epoch 39/150\n",
      "10152/10152 [==============================] - 1s 114us/step - loss: 0.1430 - val_loss: 0.1418\n",
      "Epoch 40/150\n",
      "10152/10152 [==============================] - 1s 114us/step - loss: 0.1409 - val_loss: 0.1472\n",
      "Epoch 41/150\n",
      "10152/10152 [==============================] - 1s 115us/step - loss: 0.1425 - val_loss: 0.1468\n",
      "Evaluating model with testing data...\n",
      "2154/2154 [==============================] - 0s 15us/step\n",
      "Getting distribution of predictions and covariance matrix...\n",
      "      1 of 20\n",
      "      2 of 20\n",
      "      3 of 20\n",
      "      4 of 20\n",
      "      5 of 20\n",
      "      6 of 20\n",
      "      7 of 20\n",
      "      8 of 20\n",
      "      9 of 20\n",
      "      10 of 20\n",
      "      11 of 20\n",
      "      12 of 20\n",
      "      13 of 20\n",
      "      14 of 20\n",
      "      15 of 20\n",
      "      16 of 20\n",
      "      17 of 20\n",
      "      18 of 20\n",
      "      19 of 20\n",
      "      20 of 20\n",
      "Computing ensemble means...\n",
      "Computing mean squared error...\n",
      "Iteration 70\n",
      "Train on 10292 samples, validate on 2184 samples\n",
      "Epoch 1/150\n",
      "10292/10292 [==============================] - 1s 106us/step - loss: 0.5295 - val_loss: 0.3574\n",
      "Epoch 2/150\n",
      "10292/10292 [==============================] - 1s 109us/step - loss: 0.3264 - val_loss: 0.3000\n",
      "Epoch 3/150\n",
      "10292/10292 [==============================] - 1s 113us/step - loss: 0.2920 - val_loss: 0.2836\n",
      "Epoch 4/150\n",
      "10292/10292 [==============================] - 1s 117us/step - loss: 0.2709 - val_loss: 0.2617\n",
      "Epoch 5/150\n",
      "10292/10292 [==============================] - 1s 115us/step - loss: 0.2487 - val_loss: 0.2339\n",
      "Epoch 6/150\n",
      "10292/10292 [==============================] - 1s 112us/step - loss: 0.2291 - val_loss: 0.2180\n",
      "Epoch 7/150\n",
      "10292/10292 [==============================] - 1s 111us/step - loss: 0.2137 - val_loss: 0.2121\n",
      "Epoch 8/150\n",
      "10292/10292 [==============================] - 1s 106us/step - loss: 0.2015 - val_loss: 0.1996\n",
      "Epoch 9/150\n",
      "10292/10292 [==============================] - 1s 110us/step - loss: 0.1946 - val_loss: 0.1909\n",
      "Epoch 10/150\n",
      "10292/10292 [==============================] - 1s 117us/step - loss: 0.1877 - val_loss: 0.1989\n",
      "Epoch 11/150\n",
      "10292/10292 [==============================] - 1s 116us/step - loss: 0.1850 - val_loss: 0.1806\n",
      "Epoch 12/150\n",
      "10292/10292 [==============================] - 1s 116us/step - loss: 0.1818 - val_loss: 0.1822\n",
      "Epoch 13/150\n",
      "10292/10292 [==============================] - 1s 109us/step - loss: 0.1784 - val_loss: 0.1789\n",
      "Epoch 14/150\n",
      "10292/10292 [==============================] - 1s 112us/step - loss: 0.1771 - val_loss: 0.1768\n",
      "Epoch 15/150\n",
      "10292/10292 [==============================] - 1s 106us/step - loss: 0.1744 - val_loss: 0.1773\n",
      "Epoch 16/150\n",
      "10292/10292 [==============================] - 1s 109us/step - loss: 0.1728 - val_loss: 0.1701\n",
      "Epoch 17/150\n",
      "10292/10292 [==============================] - 1s 117us/step - loss: 0.1701 - val_loss: 0.1706\n",
      "Epoch 18/150\n",
      "10292/10292 [==============================] - 1s 113us/step - loss: 0.1683 - val_loss: 0.1680\n",
      "Epoch 19/150\n",
      "10292/10292 [==============================] - 1s 117us/step - loss: 0.1678 - val_loss: 0.1727\n",
      "Epoch 20/150\n",
      "10292/10292 [==============================] - 1s 113us/step - loss: 0.1645 - val_loss: 0.1666\n",
      "Epoch 21/150\n",
      "10292/10292 [==============================] - 1s 103us/step - loss: 0.1616 - val_loss: 0.1676\n",
      "Epoch 22/150\n",
      "10292/10292 [==============================] - 1s 112us/step - loss: 0.1621 - val_loss: 0.1604\n",
      "Epoch 23/150\n",
      "10292/10292 [==============================] - 1s 107us/step - loss: 0.1603 - val_loss: 0.1634\n",
      "Epoch 24/150\n",
      "10292/10292 [==============================] - 1s 113us/step - loss: 0.1611 - val_loss: 0.1635\n",
      "Epoch 25/150\n",
      "10292/10292 [==============================] - 1s 103us/step - loss: 0.1622 - val_loss: 0.1682\n",
      "Epoch 26/150\n",
      "10292/10292 [==============================] - 1s 112us/step - loss: 0.1604 - val_loss: 0.1664\n",
      "Evaluating model with testing data...\n",
      "2184/2184 [==============================] - 0s 15us/step\n",
      "Getting distribution of predictions and covariance matrix...\n",
      "      1 of 20\n",
      "      2 of 20\n",
      "      3 of 20\n",
      "      4 of 20\n",
      "      5 of 20\n",
      "      6 of 20\n",
      "      7 of 20\n",
      "      8 of 20\n",
      "      9 of 20\n",
      "      10 of 20\n",
      "      11 of 20\n",
      "      12 of 20\n",
      "      13 of 20\n",
      "      14 of 20\n",
      "      15 of 20\n",
      "      16 of 20\n",
      "      17 of 20\n",
      "      18 of 20\n",
      "      19 of 20\n",
      "      20 of 20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|          | 0/20 [00:00<?, ?it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing ensemble means...\n",
      "Computing mean squared error...\n",
      "Getting distribution of predictions...\n",
      "      1 of 20\n",
      "1600/1600 [==============================] - 0s 27us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  5%|▌         | 1/20 [00:28<09:09, 28.92s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      2 of 20\n",
      "1600/1600 [==============================] - 0s 29us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 10%|█         | 2/20 [00:58<08:43, 29.08s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      3 of 20\n",
      "1600/1600 [==============================] - 0s 29us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 15%|█▌        | 3/20 [01:27<08:16, 29.21s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      4 of 20\n",
      "1600/1600 [==============================] - 0s 38us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 20%|██        | 4/20 [01:57<07:49, 29.32s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      5 of 20\n",
      "1600/1600 [==============================] - 0s 30us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 25%|██▌       | 5/20 [02:26<07:20, 29.34s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      6 of 20\n",
      "1600/1600 [==============================] - 0s 28us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 30%|███       | 6/20 [02:56<06:50, 29.32s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      7 of 20\n",
      "1600/1600 [==============================] - 0s 28us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 35%|███▌      | 7/20 [03:25<06:22, 29.45s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      8 of 20\n",
      "1600/1600 [==============================] - 0s 30us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 40%|████      | 8/20 [03:55<05:54, 29.57s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      9 of 20\n",
      "1600/1600 [==============================] - 0s 29us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 45%|████▌     | 9/20 [04:25<05:24, 29.54s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      10 of 20\n",
      "1600/1600 [==============================] - 0s 29us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 50%|█████     | 10/20 [04:54<04:54, 29.47s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      11 of 20\n",
      "1600/1600 [==============================] - 0s 29us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 55%|█████▌    | 11/20 [05:24<04:26, 29.57s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      12 of 20\n",
      "1600/1600 [==============================] - 0s 30us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 60%|██████    | 12/20 [05:54<03:57, 29.63s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      13 of 20\n",
      "1600/1600 [==============================] - 0s 30us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 65%|██████▌   | 13/20 [06:23<03:26, 29.56s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      14 of 20\n",
      "1600/1600 [==============================] - 0s 30us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 70%|███████   | 14/20 [06:53<02:57, 29.63s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      15 of 20\n",
      "1600/1600 [==============================] - 0s 30us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 75%|███████▌  | 15/20 [07:22<02:28, 29.61s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      16 of 20\n",
      "1600/1600 [==============================] - 0s 29us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 80%|████████  | 16/20 [07:52<01:58, 29.62s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      17 of 20\n",
      "1600/1600 [==============================] - 0s 29us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 85%|████████▌ | 17/20 [08:21<01:28, 29.50s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      18 of 20\n",
      "1600/1600 [==============================] - 0s 29us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 90%|█████████ | 18/20 [08:51<00:59, 29.60s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      19 of 20\n",
      "1600/1600 [==============================] - 0s 29us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 95%|█████████▌| 19/20 [09:21<00:29, 29.65s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      20 of 20\n",
      "1600/1600 [==============================] - 0s 28us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 20/20 [09:51<00:00, 29.55s/it]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing ensemble predictions...\n",
      "Iteration 71\n",
      "Train on 10432 samples, validate on 2214 samples\n",
      "Epoch 1/150\n",
      "10432/10432 [==============================] - 1s 107us/step - loss: 0.4845 - val_loss: 0.3569\n",
      "Epoch 2/150\n",
      "10432/10432 [==============================] - 1s 109us/step - loss: 0.3164 - val_loss: 0.2929\n",
      "Epoch 3/150\n",
      "10432/10432 [==============================] - 1s 114us/step - loss: 0.2745 - val_loss: 0.2589\n",
      "Epoch 4/150\n",
      "10432/10432 [==============================] - 1s 108us/step - loss: 0.2558 - val_loss: 0.2416\n",
      "Epoch 5/150\n",
      "10432/10432 [==============================] - 1s 112us/step - loss: 0.2373 - val_loss: 0.2243\n",
      "Epoch 6/150\n",
      "10432/10432 [==============================] - 1s 112us/step - loss: 0.2265 - val_loss: 0.2243\n",
      "Epoch 7/150\n",
      "10432/10432 [==============================] - 1s 110us/step - loss: 0.2073 - val_loss: 0.1981\n",
      "Epoch 8/150\n",
      "10432/10432 [==============================] - 1s 112us/step - loss: 0.1923 - val_loss: 0.1899\n",
      "Epoch 9/150\n",
      "10432/10432 [==============================] - 1s 114us/step - loss: 0.1881 - val_loss: 0.1773\n",
      "Epoch 10/150\n",
      "10432/10432 [==============================] - 1s 114us/step - loss: 0.1787 - val_loss: 0.1767\n",
      "Epoch 11/150\n",
      "10432/10432 [==============================] - 1s 111us/step - loss: 0.1726 - val_loss: 0.1727\n",
      "Epoch 12/150\n",
      "10432/10432 [==============================] - 1s 106us/step - loss: 0.1684 - val_loss: 0.1636\n",
      "Epoch 13/150\n",
      "10432/10432 [==============================] - 1s 69us/step - loss: 0.1663 - val_loss: 0.1615\n",
      "Epoch 14/150\n",
      "10432/10432 [==============================] - 1s 59us/step - loss: 0.1635 - val_loss: 0.1602\n",
      "Epoch 15/150\n",
      "10432/10432 [==============================] - 1s 78us/step - loss: 0.1611 - val_loss: 0.1606\n",
      "Epoch 16/150\n",
      "10432/10432 [==============================] - 1s 112us/step - loss: 0.1593 - val_loss: 0.1575\n",
      "Epoch 17/150\n",
      "10432/10432 [==============================] - 1s 106us/step - loss: 0.1570 - val_loss: 0.1657\n",
      "Epoch 18/150\n",
      "10432/10432 [==============================] - 1s 114us/step - loss: 0.1581 - val_loss: 0.1542\n",
      "Epoch 19/150\n",
      "10432/10432 [==============================] - 1s 112us/step - loss: 0.1574 - val_loss: 0.1574\n",
      "Epoch 20/150\n",
      "10432/10432 [==============================] - 1s 105us/step - loss: 0.1580 - val_loss: 0.1602\n",
      "Epoch 21/150\n",
      "10432/10432 [==============================] - 1s 111us/step - loss: 0.1552 - val_loss: 0.1555\n",
      "Epoch 22/150\n",
      "10432/10432 [==============================] - 1s 114us/step - loss: 0.1533 - val_loss: 0.1534\n",
      "Epoch 23/150\n",
      "10432/10432 [==============================] - 1s 112us/step - loss: 0.1562 - val_loss: 0.1594\n",
      "Epoch 24/150\n",
      "10432/10432 [==============================] - 1s 114us/step - loss: 0.1526 - val_loss: 0.1546\n",
      "Epoch 25/150\n",
      "10432/10432 [==============================] - 1s 114us/step - loss: 0.1523 - val_loss: 0.1511\n",
      "Epoch 26/150\n",
      "10432/10432 [==============================] - 1s 113us/step - loss: 0.1509 - val_loss: 0.1573\n",
      "Epoch 27/150\n",
      "10432/10432 [==============================] - 1s 110us/step - loss: 0.1490 - val_loss: 0.1534\n",
      "Epoch 28/150\n",
      "10432/10432 [==============================] - 1s 114us/step - loss: 0.1505 - val_loss: 0.1527\n",
      "Epoch 29/150\n",
      "10432/10432 [==============================] - 1s 111us/step - loss: 0.1490 - val_loss: 0.1513\n",
      "Evaluating model with testing data...\n",
      "2214/2214 [==============================] - 0s 15us/step\n",
      "Getting distribution of predictions and covariance matrix...\n",
      "      1 of 20\n",
      "      2 of 20\n",
      "      3 of 20\n",
      "      4 of 20\n",
      "      5 of 20\n",
      "      6 of 20\n",
      "      7 of 20\n",
      "      8 of 20\n",
      "      9 of 20\n",
      "      10 of 20\n",
      "      11 of 20\n",
      "      12 of 20\n",
      "      13 of 20\n",
      "      14 of 20\n",
      "      15 of 20\n",
      "      16 of 20\n",
      "      17 of 20\n",
      "      18 of 20\n",
      "      19 of 20\n",
      "      20 of 20\n",
      "Computing ensemble means...\n",
      "Computing mean squared error...\n",
      "Iteration 72\n",
      "Train on 10572 samples, validate on 2244 samples\n",
      "Epoch 1/150\n",
      "10572/10572 [==============================] - 1s 120us/step - loss: 0.5812 - val_loss: 0.3650\n",
      "Epoch 2/150\n",
      "10572/10572 [==============================] - 1s 116us/step - loss: 0.3264 - val_loss: 0.2930\n",
      "Epoch 3/150\n",
      "10572/10572 [==============================] - 1s 111us/step - loss: 0.2783 - val_loss: 0.2626\n",
      "Epoch 4/150\n",
      "10572/10572 [==============================] - 1s 116us/step - loss: 0.2560 - val_loss: 0.2499\n",
      "Epoch 5/150\n",
      "10572/10572 [==============================] - 1s 113us/step - loss: 0.2418 - val_loss: 0.2393\n",
      "Epoch 6/150\n",
      "10572/10572 [==============================] - 1s 116us/step - loss: 0.2287 - val_loss: 0.2254\n",
      "Epoch 7/150\n",
      "10572/10572 [==============================] - 1s 116us/step - loss: 0.2180 - val_loss: 0.2145\n",
      "Epoch 8/150\n",
      "10572/10572 [==============================] - 1s 112us/step - loss: 0.2056 - val_loss: 0.2103\n",
      "Epoch 9/150\n",
      "10572/10572 [==============================] - 1s 108us/step - loss: 0.2017 - val_loss: 0.2022\n",
      "Epoch 10/150\n",
      "10572/10572 [==============================] - 1s 115us/step - loss: 0.1983 - val_loss: 0.1933\n",
      "Epoch 11/150\n",
      "10572/10572 [==============================] - 1s 113us/step - loss: 0.1935 - val_loss: 0.2043\n",
      "Epoch 12/150\n",
      "10572/10572 [==============================] - 1s 107us/step - loss: 0.1912 - val_loss: 0.1888\n",
      "Epoch 13/150\n",
      "10572/10572 [==============================] - 1s 108us/step - loss: 0.1868 - val_loss: 0.1885\n",
      "Epoch 14/150\n",
      "10572/10572 [==============================] - 1s 112us/step - loss: 0.1829 - val_loss: 0.1785\n",
      "Epoch 15/150\n",
      "10572/10572 [==============================] - 1s 112us/step - loss: 0.1790 - val_loss: 0.1794\n",
      "Epoch 16/150\n",
      "10572/10572 [==============================] - 1s 114us/step - loss: 0.1790 - val_loss: 0.1829\n",
      "Epoch 17/150\n",
      "10572/10572 [==============================] - 1s 114us/step - loss: 0.1758 - val_loss: 0.1821\n",
      "Epoch 18/150\n",
      "10572/10572 [==============================] - 1s 107us/step - loss: 0.1744 - val_loss: 0.1821\n",
      "Evaluating model with testing data...\n",
      "2244/2244 [==============================] - 0s 15us/step\n",
      "Getting distribution of predictions and covariance matrix...\n",
      "      1 of 20\n",
      "      2 of 20\n",
      "      3 of 20\n",
      "      4 of 20\n",
      "      5 of 20\n",
      "      6 of 20\n",
      "      7 of 20\n",
      "      8 of 20\n",
      "      9 of 20\n",
      "      10 of 20\n",
      "      11 of 20\n",
      "      12 of 20\n",
      "      13 of 20\n",
      "      14 of 20\n",
      "      15 of 20\n",
      "      16 of 20\n",
      "      17 of 20\n",
      "      18 of 20\n",
      "      19 of 20\n",
      "      20 of 20\n",
      "Computing ensemble means...\n",
      "Computing mean squared error...\n",
      "Iteration 73\n",
      "Train on 10712 samples, validate on 2274 samples\n",
      "Epoch 1/150\n",
      "10712/10712 [==============================] - 1s 105us/step - loss: 0.4945 - val_loss: 0.3715\n",
      "Epoch 2/150\n",
      "10712/10712 [==============================] - 1s 102us/step - loss: 0.3230 - val_loss: 0.2878\n",
      "Epoch 3/150\n",
      "10712/10712 [==============================] - 1s 106us/step - loss: 0.2752 - val_loss: 0.2640\n",
      "Epoch 4/150\n",
      "10712/10712 [==============================] - 1s 112us/step - loss: 0.2523 - val_loss: 0.2419\n",
      "Epoch 5/150\n",
      "10712/10712 [==============================] - 1s 104us/step - loss: 0.2306 - val_loss: 0.2246\n",
      "Epoch 6/150\n",
      "10712/10712 [==============================] - 1s 103us/step - loss: 0.2176 - val_loss: 0.2138\n",
      "Epoch 7/150\n",
      "10712/10712 [==============================] - 1s 110us/step - loss: 0.2039 - val_loss: 0.1955\n",
      "Epoch 8/150\n",
      "10712/10712 [==============================] - 1s 103us/step - loss: 0.1992 - val_loss: 0.1915\n",
      "Epoch 9/150\n",
      "10712/10712 [==============================] - 1s 114us/step - loss: 0.1892 - val_loss: 0.1883\n",
      "Epoch 10/150\n",
      "10712/10712 [==============================] - 1s 111us/step - loss: 0.1872 - val_loss: 0.1889\n",
      "Epoch 11/150\n",
      "10712/10712 [==============================] - 1s 110us/step - loss: 0.1778 - val_loss: 0.1753\n",
      "Epoch 12/150\n",
      "10712/10712 [==============================] - 1s 106us/step - loss: 0.1755 - val_loss: 0.1708\n",
      "Epoch 13/150\n",
      "10712/10712 [==============================] - 1s 106us/step - loss: 0.1744 - val_loss: 0.1733\n",
      "Epoch 14/150\n",
      "10712/10712 [==============================] - 1s 106us/step - loss: 0.1729 - val_loss: 0.1745\n",
      "Epoch 15/150\n",
      "10712/10712 [==============================] - 1s 109us/step - loss: 0.1710 - val_loss: 0.1699\n",
      "Epoch 16/150\n",
      "10712/10712 [==============================] - 1s 108us/step - loss: 0.1686 - val_loss: 0.1751\n",
      "Epoch 17/150\n",
      "10712/10712 [==============================] - 1s 104us/step - loss: 0.1700 - val_loss: 0.1676\n",
      "Epoch 18/150\n",
      "10712/10712 [==============================] - 1s 112us/step - loss: 0.1674 - val_loss: 0.1694\n",
      "Epoch 19/150\n",
      "10712/10712 [==============================] - 1s 116us/step - loss: 0.1699 - val_loss: 0.1662\n",
      "Epoch 20/150\n",
      "10712/10712 [==============================] - 1s 116us/step - loss: 0.1664 - val_loss: 0.1664\n",
      "Epoch 21/150\n",
      "10712/10712 [==============================] - 1s 116us/step - loss: 0.1636 - val_loss: 0.1642\n",
      "Epoch 22/150\n",
      "10712/10712 [==============================] - 1s 116us/step - loss: 0.1607 - val_loss: 0.1585\n",
      "Epoch 23/150\n",
      "10712/10712 [==============================] - 1s 115us/step - loss: 0.1606 - val_loss: 0.1592\n",
      "Epoch 24/150\n",
      "10712/10712 [==============================] - 1s 116us/step - loss: 0.1563 - val_loss: 0.1574\n",
      "Epoch 25/150\n",
      "10712/10712 [==============================] - 1s 111us/step - loss: 0.1567 - val_loss: 0.1635\n",
      "Epoch 26/150\n",
      "10712/10712 [==============================] - 1s 116us/step - loss: 0.1572 - val_loss: 0.1561\n",
      "Epoch 27/150\n",
      "10712/10712 [==============================] - 1s 112us/step - loss: 0.1541 - val_loss: 0.1590\n",
      "Epoch 28/150\n",
      "10712/10712 [==============================] - 1s 97us/step - loss: 0.1560 - val_loss: 0.1516\n",
      "Epoch 29/150\n",
      "10712/10712 [==============================] - 1s 115us/step - loss: 0.1531 - val_loss: 0.1536\n",
      "Epoch 30/150\n",
      "10712/10712 [==============================] - 1s 115us/step - loss: 0.1528 - val_loss: 0.1524\n",
      "Epoch 31/150\n",
      "10712/10712 [==============================] - 1s 116us/step - loss: 0.1530 - val_loss: 0.1574\n",
      "Epoch 32/150\n",
      "10712/10712 [==============================] - 1s 113us/step - loss: 0.1528 - val_loss: 0.1563\n",
      "Evaluating model with testing data...\n",
      "2274/2274 [==============================] - 0s 15us/step\n",
      "Getting distribution of predictions and covariance matrix...\n",
      "      1 of 20\n",
      "      2 of 20\n",
      "      3 of 20\n",
      "      4 of 20\n",
      "      5 of 20\n",
      "      6 of 20\n",
      "      7 of 20\n",
      "      8 of 20\n",
      "      9 of 20\n",
      "      10 of 20\n",
      "      11 of 20\n",
      "      12 of 20\n",
      "      13 of 20\n",
      "      14 of 20\n",
      "      15 of 20\n",
      "      16 of 20\n",
      "      17 of 20\n",
      "      18 of 20\n",
      "      19 of 20\n",
      "      20 of 20\n",
      "Computing ensemble means...\n",
      "Computing mean squared error...\n",
      "Iteration 74\n",
      "Train on 10852 samples, validate on 2304 samples\n",
      "Epoch 1/150\n",
      "10852/10852 [==============================] - 1s 114us/step - loss: 0.4099 - val_loss: 0.2772\n",
      "Epoch 2/150\n",
      "10852/10852 [==============================] - 1s 108us/step - loss: 0.2452 - val_loss: 0.2262\n",
      "Epoch 3/150\n",
      "10852/10852 [==============================] - 1s 109us/step - loss: 0.2097 - val_loss: 0.1956\n",
      "Epoch 4/150\n",
      "10852/10852 [==============================] - 1s 108us/step - loss: 0.1970 - val_loss: 0.1887\n",
      "Epoch 5/150\n",
      "10852/10852 [==============================] - 1s 109us/step - loss: 0.1813 - val_loss: 0.1765\n",
      "Epoch 6/150\n",
      "10852/10852 [==============================] - 1s 114us/step - loss: 0.1701 - val_loss: 0.1713\n",
      "Epoch 7/150\n",
      "10852/10852 [==============================] - 1s 109us/step - loss: 0.1623 - val_loss: 0.1605\n",
      "Epoch 8/150\n",
      "10852/10852 [==============================] - 1s 113us/step - loss: 0.1587 - val_loss: 0.1549\n",
      "Epoch 9/150\n",
      "10852/10852 [==============================] - 1s 113us/step - loss: 0.1559 - val_loss: 0.1544\n",
      "Epoch 10/150\n",
      "10852/10852 [==============================] - 1s 111us/step - loss: 0.1514 - val_loss: 0.1543\n",
      "Epoch 11/150\n",
      "10852/10852 [==============================] - 1s 108us/step - loss: 0.1478 - val_loss: 0.1480\n",
      "Epoch 12/150\n",
      "10852/10852 [==============================] - 1s 106us/step - loss: 0.1462 - val_loss: 0.1481\n",
      "Epoch 13/150\n",
      "10852/10852 [==============================] - 1s 110us/step - loss: 0.1425 - val_loss: 0.1405\n",
      "Epoch 14/150\n",
      "10852/10852 [==============================] - 1s 107us/step - loss: 0.1393 - val_loss: 0.1411\n",
      "Epoch 15/150\n",
      "10852/10852 [==============================] - 1s 113us/step - loss: 0.1374 - val_loss: 0.1376\n",
      "Epoch 16/150\n",
      "10852/10852 [==============================] - 1s 108us/step - loss: 0.1368 - val_loss: 0.1387\n",
      "Epoch 17/150\n",
      "10852/10852 [==============================] - 1s 106us/step - loss: 0.1344 - val_loss: 0.1377\n",
      "Epoch 18/150\n",
      "10852/10852 [==============================] - 1s 109us/step - loss: 0.1342 - val_loss: 0.1405\n",
      "Epoch 19/150\n",
      "10852/10852 [==============================] - 1s 111us/step - loss: 0.1294 - val_loss: 0.1374\n",
      "Epoch 20/150\n",
      "10852/10852 [==============================] - 1s 112us/step - loss: 0.1291 - val_loss: 0.1323\n",
      "Epoch 21/150\n",
      "10852/10852 [==============================] - 1s 113us/step - loss: 0.1286 - val_loss: 0.1292\n",
      "Epoch 22/150\n",
      "10852/10852 [==============================] - 1s 112us/step - loss: 0.1286 - val_loss: 0.1284\n",
      "Epoch 23/150\n",
      "10852/10852 [==============================] - 1s 88us/step - loss: 0.1278 - val_loss: 0.1272\n",
      "Epoch 24/150\n",
      "10852/10852 [==============================] - 1s 102us/step - loss: 0.1255 - val_loss: 0.1303\n",
      "Epoch 25/150\n",
      "10852/10852 [==============================] - 1s 109us/step - loss: 0.1249 - val_loss: 0.1266\n",
      "Epoch 26/150\n",
      "10852/10852 [==============================] - 1s 106us/step - loss: 0.1242 - val_loss: 0.1269\n",
      "Epoch 27/150\n",
      "10852/10852 [==============================] - 1s 112us/step - loss: 0.1218 - val_loss: 0.1255\n",
      "Epoch 28/150\n",
      "10852/10852 [==============================] - 1s 107us/step - loss: 0.1231 - val_loss: 0.1251\n",
      "Epoch 29/150\n",
      "10852/10852 [==============================] - 1s 110us/step - loss: 0.1219 - val_loss: 0.1248\n",
      "Epoch 30/150\n",
      "10852/10852 [==============================] - 1s 113us/step - loss: 0.1220 - val_loss: 0.1242\n",
      "Epoch 31/150\n",
      "10852/10852 [==============================] - 1s 113us/step - loss: 0.1209 - val_loss: 0.1271\n",
      "Epoch 32/150\n",
      "10852/10852 [==============================] - 1s 88us/step - loss: 0.1221 - val_loss: 0.1229\n",
      "Epoch 33/150\n",
      "10852/10852 [==============================] - 1s 58us/step - loss: 0.1196 - val_loss: 0.1211\n",
      "Epoch 34/150\n",
      "10852/10852 [==============================] - 1s 62us/step - loss: 0.1188 - val_loss: 0.1173\n",
      "Epoch 35/150\n",
      "10852/10852 [==============================] - 1s 100us/step - loss: 0.1189 - val_loss: 0.1193\n",
      "Epoch 36/150\n",
      "10852/10852 [==============================] - 1s 105us/step - loss: 0.1166 - val_loss: 0.1242\n",
      "Epoch 37/150\n",
      "10852/10852 [==============================] - 1s 109us/step - loss: 0.1171 - val_loss: 0.1237\n",
      "Epoch 38/150\n",
      "10852/10852 [==============================] - 1s 103us/step - loss: 0.1141 - val_loss: 0.1155\n",
      "Epoch 39/150\n",
      "10852/10852 [==============================] - 1s 112us/step - loss: 0.1145 - val_loss: 0.1191\n",
      "Epoch 40/150\n",
      "10852/10852 [==============================] - 1s 101us/step - loss: 0.1150 - val_loss: 0.1147\n",
      "Epoch 41/150\n",
      "10852/10852 [==============================] - 1s 108us/step - loss: 0.1144 - val_loss: 0.1156\n",
      "Epoch 42/150\n",
      "10852/10852 [==============================] - 1s 105us/step - loss: 0.1150 - val_loss: 0.1127\n",
      "Epoch 43/150\n",
      "10852/10852 [==============================] - 1s 103us/step - loss: 0.1139 - val_loss: 0.1158\n",
      "Epoch 44/150\n",
      "10852/10852 [==============================] - 1s 108us/step - loss: 0.1129 - val_loss: 0.1130\n",
      "Epoch 45/150\n",
      "10852/10852 [==============================] - 1s 111us/step - loss: 0.1122 - val_loss: 0.1149\n",
      "Epoch 46/150\n",
      "10852/10852 [==============================] - 1s 110us/step - loss: 0.1118 - val_loss: 0.1120\n",
      "Epoch 47/150\n",
      "10852/10852 [==============================] - 1s 111us/step - loss: 0.1112 - val_loss: 0.1106\n",
      "Epoch 48/150\n",
      "10852/10852 [==============================] - 1s 107us/step - loss: 0.1118 - val_loss: 0.1112\n",
      "Epoch 49/150\n",
      "10852/10852 [==============================] - 1s 100us/step - loss: 0.1114 - val_loss: 0.1105\n",
      "Epoch 50/150\n",
      "10852/10852 [==============================] - 1s 105us/step - loss: 0.1103 - val_loss: 0.1151\n",
      "Epoch 51/150\n",
      "10852/10852 [==============================] - 1s 112us/step - loss: 0.1080 - val_loss: 0.1113\n",
      "Epoch 52/150\n",
      "10852/10852 [==============================] - 1s 99us/step - loss: 0.1088 - val_loss: 0.1148\n",
      "Epoch 53/150\n",
      "10852/10852 [==============================] - 1s 108us/step - loss: 0.1080 - val_loss: 0.1108\n",
      "Evaluating model with testing data...\n",
      "2304/2304 [==============================] - 0s 15us/step\n",
      "Getting distribution of predictions and covariance matrix...\n",
      "      1 of 20\n",
      "      2 of 20\n",
      "      3 of 20\n",
      "      4 of 20\n",
      "      5 of 20\n",
      "      6 of 20\n",
      "      7 of 20\n",
      "      8 of 20\n",
      "      9 of 20\n",
      "      10 of 20\n",
      "      11 of 20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      12 of 20\n",
      "      13 of 20\n",
      "      14 of 20\n",
      "      15 of 20\n",
      "      16 of 20\n",
      "      17 of 20\n",
      "      18 of 20\n",
      "      19 of 20\n",
      "      20 of 20\n",
      "Computing ensemble means...\n",
      "Computing mean squared error...\n",
      "Iteration 75\n",
      "Train on 10992 samples, validate on 2334 samples\n",
      "Epoch 1/150\n",
      "10992/10992 [==============================] - 1s 102us/step - loss: 0.4816 - val_loss: 0.3428\n",
      "Epoch 2/150\n",
      "10992/10992 [==============================] - 1s 108us/step - loss: 0.2848 - val_loss: 0.2402\n",
      "Epoch 3/150\n",
      "10992/10992 [==============================] - 1s 114us/step - loss: 0.2292 - val_loss: 0.2183\n",
      "Epoch 4/150\n",
      "10992/10992 [==============================] - 1s 114us/step - loss: 0.2104 - val_loss: 0.1990\n",
      "Epoch 5/150\n",
      "10992/10992 [==============================] - 1s 114us/step - loss: 0.1962 - val_loss: 0.2013\n",
      "Epoch 6/150\n",
      "10992/10992 [==============================] - 1s 108us/step - loss: 0.1846 - val_loss: 0.1821\n",
      "Epoch 7/150\n",
      "10992/10992 [==============================] - 1s 110us/step - loss: 0.1791 - val_loss: 0.1767\n",
      "Epoch 8/150\n",
      "10992/10992 [==============================] - 1s 114us/step - loss: 0.1732 - val_loss: 0.1673\n",
      "Epoch 9/150\n",
      "10992/10992 [==============================] - 1s 115us/step - loss: 0.1659 - val_loss: 0.1715\n",
      "Epoch 10/150\n",
      "10992/10992 [==============================] - 1s 115us/step - loss: 0.1665 - val_loss: 0.1685\n",
      "Epoch 11/150\n",
      "10992/10992 [==============================] - 1s 114us/step - loss: 0.1616 - val_loss: 0.1603\n",
      "Epoch 12/150\n",
      "10992/10992 [==============================] - 1s 113us/step - loss: 0.1579 - val_loss: 0.1615\n",
      "Epoch 13/150\n",
      "10992/10992 [==============================] - 1s 114us/step - loss: 0.1561 - val_loss: 0.1608\n",
      "Epoch 14/150\n",
      "10992/10992 [==============================] - 1s 110us/step - loss: 0.1553 - val_loss: 0.1577\n",
      "Epoch 15/150\n",
      "10992/10992 [==============================] - 1s 114us/step - loss: 0.1534 - val_loss: 0.1591\n",
      "Epoch 16/150\n",
      "10992/10992 [==============================] - 1s 114us/step - loss: 0.1518 - val_loss: 0.1522\n",
      "Epoch 17/150\n",
      "10992/10992 [==============================] - 1s 110us/step - loss: 0.1511 - val_loss: 0.1528\n",
      "Epoch 18/150\n",
      "10992/10992 [==============================] - 1s 114us/step - loss: 0.1510 - val_loss: 0.1506\n",
      "Epoch 19/150\n",
      "10992/10992 [==============================] - 1s 111us/step - loss: 0.1497 - val_loss: 0.1577\n",
      "Epoch 20/150\n",
      "10992/10992 [==============================] - 1s 109us/step - loss: 0.1460 - val_loss: 0.1448\n",
      "Epoch 21/150\n",
      "10992/10992 [==============================] - 1s 115us/step - loss: 0.1481 - val_loss: 0.1518\n",
      "Epoch 22/150\n",
      "10992/10992 [==============================] - 1s 114us/step - loss: 0.1456 - val_loss: 0.1466\n",
      "Epoch 23/150\n",
      "10992/10992 [==============================] - 1s 115us/step - loss: 0.1456 - val_loss: 0.1495\n",
      "Epoch 24/150\n",
      "10992/10992 [==============================] - 1s 113us/step - loss: 0.1442 - val_loss: 0.1470\n",
      "Evaluating model with testing data...\n",
      "2334/2334 [==============================] - 0s 15us/step\n",
      "Getting distribution of predictions and covariance matrix...\n",
      "      1 of 20\n",
      "      2 of 20\n",
      "      3 of 20\n",
      "      4 of 20\n",
      "      5 of 20\n",
      "      6 of 20\n",
      "      7 of 20\n",
      "      8 of 20\n",
      "      9 of 20\n",
      "      10 of 20\n",
      "      11 of 20\n",
      "      12 of 20\n",
      "      13 of 20\n",
      "      14 of 20\n",
      "      15 of 20\n",
      "      16 of 20\n",
      "      17 of 20\n",
      "      18 of 20\n",
      "      19 of 20\n",
      "      20 of 20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|          | 0/20 [00:00<?, ?it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing ensemble means...\n",
      "Computing mean squared error...\n",
      "Getting distribution of predictions...\n",
      "      1 of 20\n",
      "1600/1600 [==============================] - 0s 28us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  5%|▌         | 1/20 [00:29<09:23, 29.64s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      2 of 20\n",
      "1600/1600 [==============================] - 0s 28us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 10%|█         | 2/20 [00:59<08:52, 29.59s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      3 of 20\n",
      "1600/1600 [==============================] - 0s 31us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 15%|█▌        | 3/20 [01:28<08:20, 29.46s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      4 of 20\n",
      "1600/1600 [==============================] - 0s 29us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 20%|██        | 4/20 [01:57<07:52, 29.53s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      5 of 20\n",
      "1600/1600 [==============================] - 0s 29us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 25%|██▌       | 5/20 [02:27<07:24, 29.62s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      6 of 20\n",
      "1600/1600 [==============================] - 0s 29us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 30%|███       | 6/20 [02:57<06:55, 29.71s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      7 of 20\n",
      "1600/1600 [==============================] - 0s 30us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 35%|███▌      | 7/20 [03:27<06:24, 29.61s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      8 of 20\n",
      "1600/1600 [==============================] - 0s 29us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 40%|████      | 8/20 [03:56<05:55, 29.60s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      9 of 20\n",
      "1600/1600 [==============================] - 0s 28us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 45%|████▌     | 9/20 [04:26<05:25, 29.57s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      10 of 20\n",
      "1600/1600 [==============================] - 0s 29us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 50%|█████     | 10/20 [04:55<04:56, 29.60s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      11 of 20\n",
      "1600/1600 [==============================] - 0s 29us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 55%|█████▌    | 11/20 [05:25<04:26, 29.56s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      12 of 20\n",
      "1600/1600 [==============================] - 0s 30us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 60%|██████    | 12/20 [05:54<03:56, 29.57s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      13 of 20\n",
      "1600/1600 [==============================] - 0s 29us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 65%|██████▌   | 13/20 [06:24<03:27, 29.59s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      14 of 20\n",
      "1600/1600 [==============================] - 0s 29us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 70%|███████   | 14/20 [06:53<02:57, 29.51s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      15 of 20\n",
      "1600/1600 [==============================] - 0s 29us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 75%|███████▌  | 15/20 [07:23<02:27, 29.46s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      16 of 20\n",
      "1600/1600 [==============================] - 0s 29us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 80%|████████  | 16/20 [07:52<01:58, 29.52s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      17 of 20\n",
      "1600/1600 [==============================] - 0s 29us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 85%|████████▌ | 17/20 [08:22<01:28, 29.58s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      18 of 20\n",
      "1600/1600 [==============================] - 0s 29us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 90%|█████████ | 18/20 [08:52<00:59, 29.63s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      19 of 20\n",
      "1600/1600 [==============================] - 0s 29us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 95%|█████████▌| 19/20 [09:21<00:29, 29.59s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      20 of 20\n",
      "1600/1600 [==============================] - 0s 29us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 20/20 [09:51<00:00, 29.58s/it]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing ensemble predictions...\n",
      "Iteration 76\n",
      "Train on 11132 samples, validate on 2364 samples\n",
      "Epoch 1/150\n",
      "11132/11132 [==============================] - 1s 111us/step - loss: 0.4936 - val_loss: 0.3651\n",
      "Epoch 2/150\n",
      "11132/11132 [==============================] - 1s 111us/step - loss: 0.3078 - val_loss: 0.2632\n",
      "Epoch 3/150\n",
      "11132/11132 [==============================] - 1s 111us/step - loss: 0.2525 - val_loss: 0.2405\n",
      "Epoch 4/150\n",
      "11132/11132 [==============================] - 1s 113us/step - loss: 0.2296 - val_loss: 0.2231\n",
      "Epoch 5/150\n",
      "11132/11132 [==============================] - 1s 113us/step - loss: 0.2179 - val_loss: 0.2042\n",
      "Epoch 6/150\n",
      "11132/11132 [==============================] - 1s 114us/step - loss: 0.2085 - val_loss: 0.2029\n",
      "Epoch 7/150\n",
      "11132/11132 [==============================] - 1s 103us/step - loss: 0.1972 - val_loss: 0.1903\n",
      "Epoch 8/150\n",
      "11132/11132 [==============================] - 1s 110us/step - loss: 0.1889 - val_loss: 0.1887\n",
      "Epoch 9/150\n",
      "11132/11132 [==============================] - 1s 113us/step - loss: 0.1827 - val_loss: 0.1811\n",
      "Epoch 10/150\n",
      "11132/11132 [==============================] - 1s 113us/step - loss: 0.1789 - val_loss: 0.1786\n",
      "Epoch 11/150\n",
      "11132/11132 [==============================] - 1s 110us/step - loss: 0.1719 - val_loss: 0.1727\n",
      "Epoch 12/150\n",
      "11132/11132 [==============================] - 1s 109us/step - loss: 0.1695 - val_loss: 0.1696\n",
      "Epoch 13/150\n",
      "11132/11132 [==============================] - 1s 114us/step - loss: 0.1661 - val_loss: 0.1652\n",
      "Epoch 14/150\n",
      "11132/11132 [==============================] - 1s 113us/step - loss: 0.1623 - val_loss: 0.1632\n",
      "Epoch 15/150\n",
      "11132/11132 [==============================] - 1s 113us/step - loss: 0.1622 - val_loss: 0.1590\n",
      "Epoch 16/150\n",
      "11132/11132 [==============================] - 1s 113us/step - loss: 0.1599 - val_loss: 0.1611\n",
      "Epoch 17/150\n",
      "11132/11132 [==============================] - 1s 114us/step - loss: 0.1588 - val_loss: 0.1626\n",
      "Epoch 18/150\n",
      "11132/11132 [==============================] - 1s 113us/step - loss: 0.1584 - val_loss: 0.1637\n",
      "Epoch 19/150\n",
      "11132/11132 [==============================] - 1s 114us/step - loss: 0.1582 - val_loss: 0.1572\n",
      "Epoch 20/150\n",
      "11132/11132 [==============================] - 1s 113us/step - loss: 0.1552 - val_loss: 0.1597\n",
      "Epoch 21/150\n",
      "11132/11132 [==============================] - 1s 112us/step - loss: 0.1557 - val_loss: 0.1561\n",
      "Epoch 22/150\n",
      "11132/11132 [==============================] - 1s 114us/step - loss: 0.1544 - val_loss: 0.1586\n",
      "Epoch 23/150\n",
      "11132/11132 [==============================] - 1s 113us/step - loss: 0.1536 - val_loss: 0.1553\n",
      "Epoch 24/150\n",
      "11132/11132 [==============================] - 1s 107us/step - loss: 0.1510 - val_loss: 0.1560\n",
      "Epoch 25/150\n",
      "11132/11132 [==============================] - 1s 109us/step - loss: 0.1523 - val_loss: 0.1578\n",
      "Epoch 26/150\n",
      "11132/11132 [==============================] - 1s 107us/step - loss: 0.1513 - val_loss: 0.1604\n",
      "Epoch 27/150\n",
      "11132/11132 [==============================] - 1s 111us/step - loss: 0.1521 - val_loss: 0.1607\n",
      "Evaluating model with testing data...\n",
      "2364/2364 [==============================] - 0s 15us/step\n",
      "Getting distribution of predictions and covariance matrix...\n",
      "      1 of 20\n",
      "      2 of 20\n",
      "      3 of 20\n",
      "      4 of 20\n",
      "      5 of 20\n",
      "      6 of 20\n",
      "      7 of 20\n",
      "      8 of 20\n",
      "      9 of 20\n",
      "      10 of 20\n",
      "      11 of 20\n",
      "      12 of 20\n",
      "      13 of 20\n",
      "      14 of 20\n",
      "      15 of 20\n",
      "      16 of 20\n",
      "      17 of 20\n",
      "      18 of 20\n",
      "      19 of 20\n",
      "      20 of 20\n",
      "Computing ensemble means...\n",
      "Computing mean squared error...\n",
      "Iteration 77\n",
      "Train on 11272 samples, validate on 2394 samples\n",
      "Epoch 1/150\n",
      "11272/11272 [==============================] - 1s 111us/step - loss: 0.3926 - val_loss: 0.2675\n",
      "Epoch 2/150\n",
      "11272/11272 [==============================] - 1s 104us/step - loss: 0.2333 - val_loss: 0.2127\n",
      "Epoch 3/150\n",
      "11272/11272 [==============================] - 1s 114us/step - loss: 0.2004 - val_loss: 0.1911\n",
      "Epoch 4/150\n",
      "11272/11272 [==============================] - 1s 113us/step - loss: 0.1839 - val_loss: 0.1829\n",
      "Epoch 5/150\n",
      "11272/11272 [==============================] - 1s 112us/step - loss: 0.1772 - val_loss: 0.1721\n",
      "Epoch 6/150\n",
      "11272/11272 [==============================] - 1s 111us/step - loss: 0.1710 - val_loss: 0.1657\n",
      "Epoch 7/150\n",
      "11272/11272 [==============================] - 1s 111us/step - loss: 0.1622 - val_loss: 0.1670\n",
      "Epoch 8/150\n",
      "11272/11272 [==============================] - 1s 109us/step - loss: 0.1586 - val_loss: 0.1591\n",
      "Epoch 9/150\n",
      "11272/11272 [==============================] - 1s 102us/step - loss: 0.1523 - val_loss: 0.1499\n",
      "Epoch 10/150\n",
      "11272/11272 [==============================] - 1s 114us/step - loss: 0.1460 - val_loss: 0.1495\n",
      "Epoch 11/150\n",
      "11272/11272 [==============================] - 1s 107us/step - loss: 0.1464 - val_loss: 0.1457\n",
      "Epoch 12/150\n",
      "11272/11272 [==============================] - 1s 110us/step - loss: 0.1421 - val_loss: 0.1451\n",
      "Epoch 13/150\n",
      "11272/11272 [==============================] - 1s 111us/step - loss: 0.1402 - val_loss: 0.1380\n",
      "Epoch 14/150\n",
      "11272/11272 [==============================] - 1s 109us/step - loss: 0.1371 - val_loss: 0.1361\n",
      "Epoch 15/150\n",
      "11272/11272 [==============================] - 1s 106us/step - loss: 0.1342 - val_loss: 0.1321\n",
      "Epoch 16/150\n",
      "11272/11272 [==============================] - 1s 115us/step - loss: 0.1275 - val_loss: 0.1284\n",
      "Epoch 17/150\n",
      "11272/11272 [==============================] - 1s 108us/step - loss: 0.1272 - val_loss: 0.1263\n",
      "Epoch 18/150\n",
      "11272/11272 [==============================] - 1s 109us/step - loss: 0.1264 - val_loss: 0.1325\n",
      "Epoch 19/150\n",
      "11272/11272 [==============================] - 1s 102us/step - loss: 0.1242 - val_loss: 0.1272\n",
      "Epoch 20/150\n",
      "11272/11272 [==============================] - 1s 106us/step - loss: 0.1234 - val_loss: 0.1200\n",
      "Epoch 21/150\n",
      "11272/11272 [==============================] - 1s 107us/step - loss: 0.1185 - val_loss: 0.1267\n",
      "Epoch 22/150\n",
      "11272/11272 [==============================] - 1s 108us/step - loss: 0.1212 - val_loss: 0.1228\n",
      "Epoch 23/150\n",
      "11272/11272 [==============================] - 1s 112us/step - loss: 0.1198 - val_loss: 0.1282\n",
      "Epoch 24/150\n",
      "11272/11272 [==============================] - 1s 106us/step - loss: 0.1218 - val_loss: 0.1204\n",
      "Evaluating model with testing data...\n",
      "2394/2394 [==============================] - 0s 15us/step\n",
      "Getting distribution of predictions and covariance matrix...\n",
      "      1 of 20\n",
      "      2 of 20\n",
      "      3 of 20\n",
      "      4 of 20\n",
      "      5 of 20\n",
      "      6 of 20\n",
      "      7 of 20\n",
      "      8 of 20\n",
      "      9 of 20\n",
      "      10 of 20\n",
      "      11 of 20\n",
      "      12 of 20\n",
      "      13 of 20\n",
      "      14 of 20\n",
      "      15 of 20\n",
      "      16 of 20\n",
      "      17 of 20\n",
      "      18 of 20\n",
      "      19 of 20\n",
      "      20 of 20\n",
      "Computing ensemble means...\n",
      "Computing mean squared error...\n",
      "Iteration 78\n",
      "Train on 11412 samples, validate on 2424 samples\n",
      "Epoch 1/150\n",
      "11412/11412 [==============================] - 1s 109us/step - loss: 0.4975 - val_loss: 0.3625\n",
      "Epoch 2/150\n",
      "11412/11412 [==============================] - 1s 92us/step - loss: 0.3150 - val_loss: 0.2757\n",
      "Epoch 3/150\n",
      "11412/11412 [==============================] - 1s 108us/step - loss: 0.2463 - val_loss: 0.2263\n",
      "Epoch 4/150\n",
      "11412/11412 [==============================] - 1s 98us/step - loss: 0.2153 - val_loss: 0.2008\n",
      "Epoch 5/150\n",
      "11412/11412 [==============================] - 1s 82us/step - loss: 0.1936 - val_loss: 0.1913\n",
      "Epoch 6/150\n",
      "11412/11412 [==============================] - 1s 59us/step - loss: 0.1834 - val_loss: 0.1883\n",
      "Epoch 7/150\n",
      "11412/11412 [==============================] - 1s 69us/step - loss: 0.1778 - val_loss: 0.1768\n",
      "Epoch 8/150\n",
      "11412/11412 [==============================] - 1s 105us/step - loss: 0.1723 - val_loss: 0.1709\n",
      "Epoch 9/150\n",
      "11412/11412 [==============================] - 1s 101us/step - loss: 0.1686 - val_loss: 0.1685\n",
      "Epoch 10/150\n",
      "11412/11412 [==============================] - 1s 103us/step - loss: 0.1618 - val_loss: 0.1585\n",
      "Epoch 11/150\n",
      "11412/11412 [==============================] - 1s 103us/step - loss: 0.1583 - val_loss: 0.1601\n",
      "Epoch 12/150\n",
      "11412/11412 [==============================] - 1s 106us/step - loss: 0.1575 - val_loss: 0.1559\n",
      "Epoch 13/150\n",
      "11412/11412 [==============================] - 1s 104us/step - loss: 0.1547 - val_loss: 0.1559\n",
      "Epoch 14/150\n",
      "11412/11412 [==============================] - 1s 112us/step - loss: 0.1530 - val_loss: 0.1544\n",
      "Epoch 15/150\n",
      "11412/11412 [==============================] - 1s 114us/step - loss: 0.1518 - val_loss: 0.1562\n",
      "Epoch 16/150\n",
      "11412/11412 [==============================] - 1s 116us/step - loss: 0.1487 - val_loss: 0.1525\n",
      "Epoch 17/150\n",
      "11412/11412 [==============================] - 1s 117us/step - loss: 0.1472 - val_loss: 0.1496\n",
      "Epoch 18/150\n",
      "11412/11412 [==============================] - 1s 117us/step - loss: 0.1487 - val_loss: 0.1553\n",
      "Epoch 19/150\n",
      "11412/11412 [==============================] - 1s 116us/step - loss: 0.1468 - val_loss: 0.1486\n",
      "Epoch 20/150\n",
      "11412/11412 [==============================] - 1s 116us/step - loss: 0.1455 - val_loss: 0.1480\n",
      "Epoch 21/150\n",
      "11412/11412 [==============================] - 1s 116us/step - loss: 0.1441 - val_loss: 0.1452\n",
      "Epoch 22/150\n",
      "11412/11412 [==============================] - 1s 117us/step - loss: 0.1428 - val_loss: 0.1457\n",
      "Epoch 23/150\n",
      "11412/11412 [==============================] - 1s 111us/step - loss: 0.1448 - val_loss: 0.1454\n",
      "Epoch 24/150\n",
      "11412/11412 [==============================] - 1s 115us/step - loss: 0.1405 - val_loss: 0.1454\n",
      "Epoch 25/150\n",
      "11412/11412 [==============================] - 1s 113us/step - loss: 0.1432 - val_loss: 0.1430\n",
      "Epoch 26/150\n",
      "11412/11412 [==============================] - 1s 115us/step - loss: 0.1430 - val_loss: 0.1457\n",
      "Epoch 27/150\n",
      "11412/11412 [==============================] - 1s 112us/step - loss: 0.1416 - val_loss: 0.1425\n",
      "Epoch 28/150\n",
      "11412/11412 [==============================] - 1s 116us/step - loss: 0.1410 - val_loss: 0.1421\n",
      "Epoch 29/150\n",
      "11412/11412 [==============================] - 1s 115us/step - loss: 0.1393 - val_loss: 0.1440\n",
      "Epoch 30/150\n",
      "11412/11412 [==============================] - 1s 116us/step - loss: 0.1384 - val_loss: 0.1412\n",
      "Epoch 31/150\n",
      "11412/11412 [==============================] - 1s 116us/step - loss: 0.1387 - val_loss: 0.1414\n",
      "Epoch 32/150\n",
      "11412/11412 [==============================] - 1s 116us/step - loss: 0.1382 - val_loss: 0.1420\n",
      "Epoch 33/150\n",
      "11412/11412 [==============================] - 1s 116us/step - loss: 0.1373 - val_loss: 0.1387\n",
      "Epoch 34/150\n",
      "11412/11412 [==============================] - 1s 114us/step - loss: 0.1381 - val_loss: 0.1426\n",
      "Epoch 35/150\n",
      "11412/11412 [==============================] - 1s 109us/step - loss: 0.1387 - val_loss: 0.1388\n",
      "Epoch 36/150\n",
      "11412/11412 [==============================] - 1s 110us/step - loss: 0.1382 - val_loss: 0.1387\n",
      "Epoch 37/150\n",
      "11412/11412 [==============================] - 1s 107us/step - loss: 0.1353 - val_loss: 0.1405\n",
      "Epoch 38/150\n",
      "11412/11412 [==============================] - 1s 112us/step - loss: 0.1335 - val_loss: 0.1321\n",
      "Epoch 39/150\n",
      "11412/11412 [==============================] - 1s 116us/step - loss: 0.1308 - val_loss: 0.1354\n",
      "Epoch 40/150\n",
      "11412/11412 [==============================] - 1s 116us/step - loss: 0.1314 - val_loss: 0.1329\n",
      "Epoch 41/150\n",
      "11412/11412 [==============================] - 1s 112us/step - loss: 0.1289 - val_loss: 0.1360\n",
      "Epoch 42/150\n",
      "11412/11412 [==============================] - 1s 116us/step - loss: 0.1270 - val_loss: 0.1364\n",
      "Evaluating model with testing data...\n",
      "2424/2424 [==============================] - 0s 15us/step\n",
      "Getting distribution of predictions and covariance matrix...\n",
      "      1 of 20\n",
      "      2 of 20\n",
      "      3 of 20\n",
      "      4 of 20\n",
      "      5 of 20\n",
      "      6 of 20\n",
      "      7 of 20\n",
      "      8 of 20\n",
      "      9 of 20\n",
      "      10 of 20\n",
      "      11 of 20\n",
      "      12 of 20\n",
      "      13 of 20\n",
      "      14 of 20\n",
      "      15 of 20\n",
      "      16 of 20\n",
      "      17 of 20\n",
      "      18 of 20\n",
      "      19 of 20\n",
      "      20 of 20\n",
      "Computing ensemble means...\n",
      "Computing mean squared error...\n",
      "Iteration 79\n",
      "Train on 11552 samples, validate on 2454 samples\n",
      "Epoch 1/150\n",
      "11552/11552 [==============================] - 1s 112us/step - loss: 0.5329 - val_loss: 0.4166\n",
      "Epoch 2/150\n",
      "11552/11552 [==============================] - 1s 109us/step - loss: 0.3694 - val_loss: 0.3420\n",
      "Epoch 3/150\n",
      "11552/11552 [==============================] - 1s 112us/step - loss: 0.3325 - val_loss: 0.3216\n",
      "Epoch 4/150\n",
      "11552/11552 [==============================] - 1s 110us/step - loss: 0.3144 - val_loss: 0.3116\n",
      "Epoch 5/150\n",
      "11552/11552 [==============================] - 1s 116us/step - loss: 0.3041 - val_loss: 0.2987\n",
      "Epoch 6/150\n",
      "11552/11552 [==============================] - 1s 106us/step - loss: 0.2912 - val_loss: 0.2848\n",
      "Epoch 7/150\n",
      "11552/11552 [==============================] - 1s 114us/step - loss: 0.2728 - val_loss: 0.2485\n",
      "Epoch 8/150\n",
      "11552/11552 [==============================] - 1s 111us/step - loss: 0.2331 - val_loss: 0.2265\n",
      "Epoch 9/150\n",
      "11552/11552 [==============================] - 1s 108us/step - loss: 0.2212 - val_loss: 0.2175\n",
      "Epoch 10/150\n",
      "11552/11552 [==============================] - 1s 111us/step - loss: 0.2141 - val_loss: 0.2080\n",
      "Epoch 11/150\n",
      "11552/11552 [==============================] - 1s 110us/step - loss: 0.2028 - val_loss: 0.2048\n",
      "Epoch 12/150\n",
      "11552/11552 [==============================] - 1s 112us/step - loss: 0.1985 - val_loss: 0.1952\n",
      "Epoch 13/150\n",
      "11552/11552 [==============================] - 1s 107us/step - loss: 0.1963 - val_loss: 0.1982\n",
      "Epoch 14/150\n",
      "11552/11552 [==============================] - 1s 105us/step - loss: 0.1940 - val_loss: 0.1940\n",
      "Epoch 15/150\n",
      "11552/11552 [==============================] - 1s 112us/step - loss: 0.1940 - val_loss: 0.1911\n",
      "Epoch 16/150\n",
      "11552/11552 [==============================] - 1s 102us/step - loss: 0.1879 - val_loss: 0.1857\n",
      "Epoch 17/150\n",
      "11552/11552 [==============================] - 1s 114us/step - loss: 0.1871 - val_loss: 0.1827\n",
      "Epoch 18/150\n",
      "11552/11552 [==============================] - 1s 111us/step - loss: 0.1823 - val_loss: 0.1866\n",
      "Epoch 19/150\n",
      "11552/11552 [==============================] - 1s 105us/step - loss: 0.1821 - val_loss: 0.1883\n",
      "Epoch 20/150\n",
      "11552/11552 [==============================] - 1s 105us/step - loss: 0.1829 - val_loss: 0.1868\n",
      "Epoch 21/150\n",
      "11552/11552 [==============================] - 1s 102us/step - loss: 0.1797 - val_loss: 0.1842\n",
      "Evaluating model with testing data...\n",
      "2454/2454 [==============================] - 0s 15us/step\n",
      "Getting distribution of predictions and covariance matrix...\n",
      "      1 of 20\n",
      "      2 of 20\n",
      "      3 of 20\n",
      "      4 of 20\n",
      "      5 of 20\n",
      "      6 of 20\n",
      "      7 of 20\n",
      "      8 of 20\n",
      "      9 of 20\n",
      "      10 of 20\n",
      "      11 of 20\n",
      "      12 of 20\n",
      "      13 of 20\n",
      "      14 of 20\n",
      "      15 of 20\n",
      "      16 of 20\n",
      "      17 of 20\n",
      "      18 of 20\n",
      "      19 of 20\n",
      "      20 of 20\n",
      "Computing ensemble means...\n",
      "Computing mean squared error...\n",
      "Iteration 80\n",
      "Train on 11692 samples, validate on 2484 samples\n",
      "Epoch 1/150\n",
      "11692/11692 [==============================] - 1s 109us/step - loss: 0.5331 - val_loss: 0.4120\n",
      "Epoch 2/150\n",
      "11692/11692 [==============================] - 1s 105us/step - loss: 0.3697 - val_loss: 0.3370\n",
      "Epoch 3/150\n",
      "11692/11692 [==============================] - 1s 111us/step - loss: 0.3118 - val_loss: 0.2924\n",
      "Epoch 4/150\n",
      "11692/11692 [==============================] - 1s 104us/step - loss: 0.2740 - val_loss: 0.2643\n",
      "Epoch 5/150\n",
      "11692/11692 [==============================] - 1s 110us/step - loss: 0.2499 - val_loss: 0.2482\n",
      "Epoch 6/150\n",
      "11692/11692 [==============================] - 1s 114us/step - loss: 0.2356 - val_loss: 0.2308\n",
      "Epoch 7/150\n",
      "11692/11692 [==============================] - 1s 111us/step - loss: 0.2238 - val_loss: 0.2212\n",
      "Epoch 8/150\n",
      "11692/11692 [==============================] - 1s 108us/step - loss: 0.2189 - val_loss: 0.2195\n",
      "Epoch 9/150\n",
      "11692/11692 [==============================] - 1s 99us/step - loss: 0.2134 - val_loss: 0.2186\n",
      "Epoch 10/150\n",
      "11692/11692 [==============================] - 1s 104us/step - loss: 0.2099 - val_loss: 0.2138\n",
      "Epoch 11/150\n",
      "11692/11692 [==============================] - 1s 105us/step - loss: 0.2039 - val_loss: 0.2026\n",
      "Epoch 12/150\n",
      "11692/11692 [==============================] - 1s 112us/step - loss: 0.1985 - val_loss: 0.1992\n",
      "Epoch 13/150\n",
      "11692/11692 [==============================] - 1s 100us/step - loss: 0.1957 - val_loss: 0.2004\n",
      "Epoch 14/150\n",
      "11692/11692 [==============================] - 1s 109us/step - loss: 0.1951 - val_loss: 0.1976\n",
      "Epoch 15/150\n",
      "11692/11692 [==============================] - 1s 102us/step - loss: 0.1934 - val_loss: 0.1952\n",
      "Epoch 16/150\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11692/11692 [==============================] - 1s 110us/step - loss: 0.1881 - val_loss: 0.1914\n",
      "Epoch 17/150\n",
      "11692/11692 [==============================] - 1s 115us/step - loss: 0.1885 - val_loss: 0.1914\n",
      "Epoch 18/150\n",
      "11692/11692 [==============================] - 1s 112us/step - loss: 0.1816 - val_loss: 0.1893\n",
      "Epoch 19/150\n",
      "11692/11692 [==============================] - 1s 115us/step - loss: 0.1823 - val_loss: 0.1901\n",
      "Epoch 20/150\n",
      "11692/11692 [==============================] - 1s 112us/step - loss: 0.1820 - val_loss: 0.1882\n",
      "Epoch 21/150\n",
      "11692/11692 [==============================] - 1s 111us/step - loss: 0.1828 - val_loss: 0.1840\n",
      "Epoch 22/150\n",
      "11692/11692 [==============================] - 1s 114us/step - loss: 0.1832 - val_loss: 0.1858\n",
      "Epoch 23/150\n",
      "11692/11692 [==============================] - 1s 109us/step - loss: 0.1815 - val_loss: 0.1882\n",
      "Epoch 24/150\n",
      "11692/11692 [==============================] - 1s 114us/step - loss: 0.1800 - val_loss: 0.1913\n",
      "Epoch 25/150\n",
      "11692/11692 [==============================] - 1s 111us/step - loss: 0.1785 - val_loss: 0.1772\n",
      "Epoch 26/150\n",
      "11692/11692 [==============================] - 1s 116us/step - loss: 0.1774 - val_loss: 0.1785\n",
      "Epoch 27/150\n",
      "11692/11692 [==============================] - 1s 112us/step - loss: 0.1796 - val_loss: 0.1844\n",
      "Epoch 28/150\n",
      "11692/11692 [==============================] - 1s 114us/step - loss: 0.1800 - val_loss: 0.1842\n",
      "Epoch 29/150\n",
      "11692/11692 [==============================] - 1s 111us/step - loss: 0.1748 - val_loss: 0.1761\n",
      "Epoch 30/150\n",
      "11692/11692 [==============================] - 1s 112us/step - loss: 0.1736 - val_loss: 0.1776\n",
      "Epoch 31/150\n",
      "11692/11692 [==============================] - 1s 114us/step - loss: 0.1714 - val_loss: 0.1756\n",
      "Epoch 32/150\n",
      "11692/11692 [==============================] - 1s 114us/step - loss: 0.1692 - val_loss: 0.1725\n",
      "Epoch 33/150\n",
      "11692/11692 [==============================] - 1s 111us/step - loss: 0.1687 - val_loss: 0.1731\n",
      "Epoch 34/150\n",
      "11692/11692 [==============================] - 1s 79us/step - loss: 0.1689 - val_loss: 0.1788\n",
      "Epoch 35/150\n",
      "11692/11692 [==============================] - 1s 59us/step - loss: 0.1677 - val_loss: 0.1674\n",
      "Epoch 36/150\n",
      "11692/11692 [==============================] - 1s 77us/step - loss: 0.1633 - val_loss: 0.1641\n",
      "Epoch 37/150\n",
      "11692/11692 [==============================] - 1s 114us/step - loss: 0.1615 - val_loss: 0.1644\n",
      "Epoch 38/150\n",
      "11692/11692 [==============================] - 1s 105us/step - loss: 0.1568 - val_loss: 0.1609\n",
      "Epoch 39/150\n",
      "11692/11692 [==============================] - 1s 106us/step - loss: 0.1534 - val_loss: 0.1561\n",
      "Epoch 40/150\n",
      "11692/11692 [==============================] - 1s 114us/step - loss: 0.1538 - val_loss: 0.1534\n",
      "Epoch 41/150\n",
      "11692/11692 [==============================] - 1s 115us/step - loss: 0.1515 - val_loss: 0.1555\n",
      "Epoch 42/150\n",
      "11692/11692 [==============================] - 1s 114us/step - loss: 0.1515 - val_loss: 0.1538\n",
      "Epoch 43/150\n",
      "11692/11692 [==============================] - 1s 111us/step - loss: 0.1501 - val_loss: 0.1556\n",
      "Epoch 44/150\n",
      "11692/11692 [==============================] - 1s 110us/step - loss: 0.1476 - val_loss: 0.1513\n",
      "Epoch 45/150\n",
      "11692/11692 [==============================] - 1s 112us/step - loss: 0.1468 - val_loss: 0.1514\n",
      "Epoch 46/150\n",
      "11692/11692 [==============================] - 1s 115us/step - loss: 0.1465 - val_loss: 0.1456\n",
      "Epoch 47/150\n",
      "11692/11692 [==============================] - 1s 111us/step - loss: 0.1457 - val_loss: 0.1517\n",
      "Epoch 48/150\n",
      "11692/11692 [==============================] - 1s 114us/step - loss: 0.1478 - val_loss: 0.1466\n",
      "Epoch 49/150\n",
      "11692/11692 [==============================] - 1s 110us/step - loss: 0.1444 - val_loss: 0.1545\n",
      "Epoch 50/150\n",
      "11692/11692 [==============================] - 1s 115us/step - loss: 0.1444 - val_loss: 0.1494\n",
      "Evaluating model with testing data...\n",
      "2484/2484 [==============================] - 0s 15us/step\n",
      "Getting distribution of predictions and covariance matrix...\n",
      "      1 of 20\n",
      "      2 of 20\n",
      "      3 of 20\n",
      "      4 of 20\n",
      "      5 of 20\n",
      "      6 of 20\n",
      "      7 of 20\n",
      "      8 of 20\n",
      "      9 of 20\n",
      "      10 of 20\n",
      "      11 of 20\n",
      "      12 of 20\n",
      "      13 of 20\n",
      "      14 of 20\n",
      "      15 of 20\n",
      "      16 of 20\n",
      "      17 of 20\n",
      "      18 of 20\n",
      "      19 of 20\n",
      "      20 of 20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|          | 0/20 [00:00<?, ?it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing ensemble means...\n",
      "Computing mean squared error...\n",
      "Getting distribution of predictions...\n",
      "      1 of 20\n",
      "1600/1600 [==============================] - 0s 27us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  5%|▌         | 1/20 [00:29<09:14, 29.16s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      2 of 20\n",
      "1600/1600 [==============================] - 0s 28us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 10%|█         | 2/20 [00:58<08:47, 29.33s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      3 of 20\n",
      "1600/1600 [==============================] - 0s 30us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 15%|█▌        | 3/20 [01:28<08:20, 29.45s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      4 of 20\n",
      "1600/1600 [==============================] - 0s 29us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 20%|██        | 4/20 [01:57<07:50, 29.38s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      5 of 20\n",
      "1600/1600 [==============================] - 0s 29us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 25%|██▌       | 5/20 [02:27<07:20, 29.40s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      6 of 20\n",
      "1600/1600 [==============================] - 0s 30us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 30%|███       | 6/20 [02:56<06:52, 29.49s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      7 of 20\n",
      "1600/1600 [==============================] - 0s 29us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 35%|███▌      | 7/20 [03:26<06:23, 29.51s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      8 of 20\n",
      "1600/1600 [==============================] - 0s 29us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 40%|████      | 8/20 [03:56<05:54, 29.50s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      9 of 20\n",
      "1600/1600 [==============================] - 0s 30us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 45%|████▌     | 9/20 [04:25<05:24, 29.51s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      10 of 20\n",
      "1600/1600 [==============================] - 0s 29us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 50%|█████     | 10/20 [04:55<04:55, 29.56s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      11 of 20\n",
      "1600/1600 [==============================] - 0s 28us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 55%|█████▌    | 11/20 [05:24<04:26, 29.57s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      12 of 20\n",
      "1600/1600 [==============================] - 0s 28us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 60%|██████    | 12/20 [05:54<03:55, 29.46s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      13 of 20\n",
      "1600/1600 [==============================] - 0s 29us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 65%|██████▌   | 13/20 [06:23<03:25, 29.42s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      14 of 20\n",
      "1600/1600 [==============================] - 0s 29us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 70%|███████   | 14/20 [06:53<02:56, 29.49s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      15 of 20\n",
      "1600/1600 [==============================] - 0s 29us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 75%|███████▌  | 15/20 [07:22<02:27, 29.54s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      16 of 20\n",
      "1600/1600 [==============================] - 0s 30us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 80%|████████  | 16/20 [07:52<01:58, 29.51s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      17 of 20\n",
      "1600/1600 [==============================] - 0s 30us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 85%|████████▌ | 17/20 [08:21<01:28, 29.60s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      18 of 20\n",
      "1600/1600 [==============================] - 0s 30us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 90%|█████████ | 18/20 [08:51<00:59, 29.60s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      19 of 20\n",
      "1600/1600 [==============================] - 0s 29us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 95%|█████████▌| 19/20 [09:20<00:29, 29.56s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      20 of 20\n",
      "1600/1600 [==============================] - 0s 29us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 20/20 [09:50<00:00, 29.51s/it]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing ensemble predictions...\n",
      "Iteration 81\n",
      "Train on 11832 samples, validate on 2514 samples\n",
      "Epoch 1/150\n",
      "11832/11832 [==============================] - 1s 107us/step - loss: 0.5244 - val_loss: 0.4241\n",
      "Epoch 2/150\n",
      "11832/11832 [==============================] - 1s 106us/step - loss: 0.3496 - val_loss: 0.2954\n",
      "Epoch 3/150\n",
      "11832/11832 [==============================] - 1s 115us/step - loss: 0.2614 - val_loss: 0.2331\n",
      "Epoch 4/150\n",
      "11832/11832 [==============================] - 1s 115us/step - loss: 0.2176 - val_loss: 0.2151\n",
      "Epoch 5/150\n",
      "11832/11832 [==============================] - 1s 115us/step - loss: 0.2041 - val_loss: 0.2012\n",
      "Epoch 6/150\n",
      "11832/11832 [==============================] - 1s 113us/step - loss: 0.1913 - val_loss: 0.1929\n",
      "Epoch 7/150\n",
      "11832/11832 [==============================] - 1s 117us/step - loss: 0.1827 - val_loss: 0.1797\n",
      "Epoch 8/150\n",
      "11832/11832 [==============================] - 1s 115us/step - loss: 0.1741 - val_loss: 0.1748\n",
      "Epoch 9/150\n",
      "11832/11832 [==============================] - 1s 114us/step - loss: 0.1716 - val_loss: 0.1689\n",
      "Epoch 10/150\n",
      "11832/11832 [==============================] - 1s 115us/step - loss: 0.1698 - val_loss: 0.1697\n",
      "Epoch 11/150\n",
      "11832/11832 [==============================] - 1s 115us/step - loss: 0.1629 - val_loss: 0.1592\n",
      "Epoch 12/150\n",
      "11832/11832 [==============================] - 1s 115us/step - loss: 0.1587 - val_loss: 0.1591\n",
      "Epoch 13/150\n",
      "11832/11832 [==============================] - 1s 116us/step - loss: 0.1577 - val_loss: 0.1601\n",
      "Epoch 14/150\n",
      "11832/11832 [==============================] - 1s 114us/step - loss: 0.1526 - val_loss: 0.1583\n",
      "Epoch 15/150\n",
      "11832/11832 [==============================] - 1s 115us/step - loss: 0.1509 - val_loss: 0.1514\n",
      "Epoch 16/150\n",
      "11832/11832 [==============================] - 1s 112us/step - loss: 0.1512 - val_loss: 0.1527\n",
      "Epoch 17/150\n",
      "11832/11832 [==============================] - 1s 116us/step - loss: 0.1460 - val_loss: 0.1460\n",
      "Epoch 18/150\n",
      "11832/11832 [==============================] - 1s 115us/step - loss: 0.1458 - val_loss: 0.1449\n",
      "Epoch 19/150\n",
      "11832/11832 [==============================] - 1s 113us/step - loss: 0.1457 - val_loss: 0.1497\n",
      "Epoch 20/150\n",
      "11832/11832 [==============================] - 1s 111us/step - loss: 0.1431 - val_loss: 0.1464\n",
      "Epoch 21/150\n",
      "11832/11832 [==============================] - 1s 113us/step - loss: 0.1420 - val_loss: 0.1434\n",
      "Epoch 22/150\n",
      "11832/11832 [==============================] - 1s 115us/step - loss: 0.1419 - val_loss: 0.1472\n",
      "Epoch 23/150\n",
      "11832/11832 [==============================] - 1s 115us/step - loss: 0.1431 - val_loss: 0.1389\n",
      "Epoch 24/150\n",
      "11832/11832 [==============================] - 1s 113us/step - loss: 0.1399 - val_loss: 0.1378\n",
      "Epoch 25/150\n",
      "11832/11832 [==============================] - 1s 112us/step - loss: 0.1391 - val_loss: 0.1436\n",
      "Epoch 26/150\n",
      "11832/11832 [==============================] - 1s 116us/step - loss: 0.1402 - val_loss: 0.1407\n",
      "Epoch 27/150\n",
      "11832/11832 [==============================] - 1s 115us/step - loss: 0.1400 - val_loss: 0.1438\n",
      "Epoch 28/150\n",
      "11832/11832 [==============================] - 1s 90us/step - loss: 0.1384 - val_loss: 0.1439\n",
      "Evaluating model with testing data...\n",
      "2514/2514 [==============================] - 0s 15us/step\n",
      "Getting distribution of predictions and covariance matrix...\n",
      "      1 of 20\n",
      "      2 of 20\n",
      "      3 of 20\n",
      "      4 of 20\n",
      "      5 of 20\n",
      "      6 of 20\n",
      "      7 of 20\n",
      "      8 of 20\n",
      "      9 of 20\n",
      "      10 of 20\n",
      "      11 of 20\n",
      "      12 of 20\n",
      "      13 of 20\n",
      "      14 of 20\n",
      "      15 of 20\n",
      "      16 of 20\n",
      "      17 of 20\n",
      "      18 of 20\n",
      "      19 of 20\n",
      "      20 of 20\n",
      "Computing ensemble means...\n",
      "Computing mean squared error...\n",
      "Iteration 82\n",
      "Train on 11972 samples, validate on 2544 samples\n",
      "Epoch 1/150\n",
      "11972/11972 [==============================] - 1s 107us/step - loss: 0.3713 - val_loss: 0.2469\n",
      "Epoch 2/150\n",
      "11972/11972 [==============================] - 1s 99us/step - loss: 0.2120 - val_loss: 0.1925\n",
      "Epoch 3/150\n",
      "11972/11972 [==============================] - 1s 106us/step - loss: 0.1800 - val_loss: 0.1778\n",
      "Epoch 4/150\n",
      "11972/11972 [==============================] - 1s 112us/step - loss: 0.1670 - val_loss: 0.1641\n",
      "Epoch 5/150\n",
      "11972/11972 [==============================] - 1s 114us/step - loss: 0.1575 - val_loss: 0.1578\n",
      "Epoch 6/150\n",
      "11972/11972 [==============================] - 1s 113us/step - loss: 0.1500 - val_loss: 0.1463\n",
      "Epoch 7/150\n",
      "11972/11972 [==============================] - 1s 107us/step - loss: 0.1453 - val_loss: 0.1480\n",
      "Epoch 8/150\n",
      "11972/11972 [==============================] - 1s 113us/step - loss: 0.1400 - val_loss: 0.1458\n",
      "Epoch 9/150\n",
      "11972/11972 [==============================] - 1s 111us/step - loss: 0.1347 - val_loss: 0.1415\n",
      "Epoch 10/150\n",
      "11972/11972 [==============================] - 1s 111us/step - loss: 0.1320 - val_loss: 0.1335\n",
      "Epoch 11/150\n",
      "11972/11972 [==============================] - 1s 107us/step - loss: 0.1294 - val_loss: 0.1335\n",
      "Epoch 12/150\n",
      "11972/11972 [==============================] - 1s 105us/step - loss: 0.1274 - val_loss: 0.1303\n",
      "Epoch 13/150\n",
      "11972/11972 [==============================] - 1s 113us/step - loss: 0.1257 - val_loss: 0.1259\n",
      "Epoch 14/150\n",
      "11972/11972 [==============================] - 1s 111us/step - loss: 0.1228 - val_loss: 0.1250\n",
      "Epoch 15/150\n",
      "11972/11972 [==============================] - 1s 112us/step - loss: 0.1209 - val_loss: 0.1265\n",
      "Epoch 16/150\n",
      "11972/11972 [==============================] - 1s 111us/step - loss: 0.1207 - val_loss: 0.1253\n",
      "Epoch 17/150\n",
      "11972/11972 [==============================] - 1s 107us/step - loss: 0.1197 - val_loss: 0.1185\n",
      "Epoch 18/150\n",
      "11972/11972 [==============================] - 1s 104us/step - loss: 0.1155 - val_loss: 0.1176\n",
      "Epoch 19/150\n",
      "11972/11972 [==============================] - 1s 110us/step - loss: 0.1139 - val_loss: 0.1254\n",
      "Epoch 20/150\n",
      "11972/11972 [==============================] - 1s 108us/step - loss: 0.1131 - val_loss: 0.1173\n",
      "Epoch 21/150\n",
      "11972/11972 [==============================] - 1s 98us/step - loss: 0.1132 - val_loss: 0.1166\n",
      "Epoch 22/150\n",
      "11972/11972 [==============================] - 1s 109us/step - loss: 0.1107 - val_loss: 0.1153\n",
      "Epoch 23/150\n",
      "11972/11972 [==============================] - 1s 108us/step - loss: 0.1094 - val_loss: 0.1118\n",
      "Epoch 24/150\n",
      "11972/11972 [==============================] - 1s 106us/step - loss: 0.1080 - val_loss: 0.1131\n",
      "Epoch 25/150\n",
      "11972/11972 [==============================] - 1s 110us/step - loss: 0.1078 - val_loss: 0.1085\n",
      "Epoch 26/150\n",
      "11972/11972 [==============================] - 1s 108us/step - loss: 0.1077 - val_loss: 0.1104\n",
      "Epoch 27/150\n",
      "11972/11972 [==============================] - 1s 109us/step - loss: 0.1050 - val_loss: 0.1071\n",
      "Epoch 28/150\n",
      "11972/11972 [==============================] - 1s 109us/step - loss: 0.1034 - val_loss: 0.1060\n",
      "Epoch 29/150\n",
      "11972/11972 [==============================] - 1s 101us/step - loss: 0.1029 - val_loss: 0.1084\n",
      "Epoch 30/150\n",
      "11972/11972 [==============================] - 1s 109us/step - loss: 0.1027 - val_loss: 0.1075\n",
      "Epoch 31/150\n",
      "11972/11972 [==============================] - 1s 107us/step - loss: 0.1036 - val_loss: 0.1049\n",
      "Epoch 32/150\n",
      "11972/11972 [==============================] - 1s 101us/step - loss: 0.1017 - val_loss: 0.1089\n",
      "Epoch 33/150\n",
      "11972/11972 [==============================] - 1s 106us/step - loss: 0.0996 - val_loss: 0.1054\n",
      "Epoch 34/150\n",
      "11972/11972 [==============================] - 1s 102us/step - loss: 0.1009 - val_loss: 0.1027\n",
      "Epoch 35/150\n",
      "11972/11972 [==============================] - 1s 110us/step - loss: 0.1008 - val_loss: 0.1028\n",
      "Epoch 36/150\n",
      "11972/11972 [==============================] - 1s 106us/step - loss: 0.0998 - val_loss: 0.0982\n",
      "Epoch 37/150\n",
      "11972/11972 [==============================] - 1s 105us/step - loss: 0.1003 - val_loss: 0.1006\n",
      "Epoch 38/150\n",
      "11972/11972 [==============================] - 1s 110us/step - loss: 0.0992 - val_loss: 0.1020\n",
      "Epoch 39/150\n",
      "11972/11972 [==============================] - 1s 111us/step - loss: 0.0969 - val_loss: 0.1002\n",
      "Epoch 40/150\n",
      "11972/11972 [==============================] - 1s 107us/step - loss: 0.0966 - val_loss: 0.0986\n",
      "Evaluating model with testing data...\n",
      "2544/2544 [==============================] - 0s 15us/step\n",
      "Getting distribution of predictions and covariance matrix...\n",
      "      1 of 20\n",
      "      2 of 20\n",
      "      3 of 20\n",
      "      4 of 20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      5 of 20\n",
      "      6 of 20\n",
      "      7 of 20\n",
      "      8 of 20\n",
      "      9 of 20\n",
      "      10 of 20\n",
      "      11 of 20\n",
      "      12 of 20\n",
      "      13 of 20\n",
      "      14 of 20\n",
      "      15 of 20\n",
      "      16 of 20\n",
      "      17 of 20\n",
      "      18 of 20\n",
      "      19 of 20\n",
      "      20 of 20\n",
      "Computing ensemble means...\n",
      "Computing mean squared error...\n",
      "Iteration 83\n",
      "Train on 12112 samples, validate on 2574 samples\n",
      "Epoch 1/150\n",
      "12112/12112 [==============================] - 1s 105us/step - loss: 0.5823 - val_loss: 0.4209\n",
      "Epoch 2/150\n",
      "12112/12112 [==============================] - 1s 110us/step - loss: 0.3827 - val_loss: 0.3695\n",
      "Epoch 3/150\n",
      "12112/12112 [==============================] - 1s 116us/step - loss: 0.3579 - val_loss: 0.3437\n",
      "Epoch 4/150\n",
      "12112/12112 [==============================] - 1s 110us/step - loss: 0.3256 - val_loss: 0.3152\n",
      "Epoch 5/150\n",
      "12112/12112 [==============================] - 1s 115us/step - loss: 0.3059 - val_loss: 0.3023\n",
      "Epoch 6/150\n",
      "12112/12112 [==============================] - 1s 113us/step - loss: 0.2944 - val_loss: 0.2970\n",
      "Epoch 7/150\n",
      "12112/12112 [==============================] - 1s 114us/step - loss: 0.2841 - val_loss: 0.2796\n",
      "Epoch 8/150\n",
      "12112/12112 [==============================] - 1s 116us/step - loss: 0.2699 - val_loss: 0.2651\n",
      "Epoch 9/150\n",
      "12112/12112 [==============================] - 1s 111us/step - loss: 0.2578 - val_loss: 0.2583\n",
      "Epoch 10/150\n",
      "12112/12112 [==============================] - 1s 116us/step - loss: 0.2532 - val_loss: 0.2549\n",
      "Epoch 11/150\n",
      "12112/12112 [==============================] - 1s 108us/step - loss: 0.2470 - val_loss: 0.2471\n",
      "Epoch 12/150\n",
      "12112/12112 [==============================] - 1s 59us/step - loss: 0.2440 - val_loss: 0.2478\n",
      "Epoch 13/150\n",
      "12112/12112 [==============================] - 1s 61us/step - loss: 0.2431 - val_loss: 0.2441\n",
      "Epoch 14/150\n",
      "12112/12112 [==============================] - 1s 109us/step - loss: 0.2424 - val_loss: 0.2425\n",
      "Epoch 15/150\n",
      "12112/12112 [==============================] - 1s 106us/step - loss: 0.2398 - val_loss: 0.2447\n",
      "Epoch 16/150\n",
      "12112/12112 [==============================] - 1s 110us/step - loss: 0.2382 - val_loss: 0.2418\n",
      "Epoch 17/150\n",
      "12112/12112 [==============================] - 1s 114us/step - loss: 0.2397 - val_loss: 0.2390\n",
      "Epoch 18/150\n",
      "12112/12112 [==============================] - 1s 114us/step - loss: 0.2385 - val_loss: 0.2443\n",
      "Epoch 19/150\n",
      "12112/12112 [==============================] - 1s 111us/step - loss: 0.2382 - val_loss: 0.2441\n",
      "Epoch 20/150\n",
      "12112/12112 [==============================] - 1s 107us/step - loss: 0.2371 - val_loss: 0.2369\n",
      "Epoch 21/150\n",
      "12112/12112 [==============================] - 1s 110us/step - loss: 0.2364 - val_loss: 0.2392\n",
      "Epoch 22/150\n",
      "12112/12112 [==============================] - 1s 113us/step - loss: 0.2367 - val_loss: 0.2404\n",
      "Epoch 23/150\n",
      "12112/12112 [==============================] - 1s 109us/step - loss: 0.2369 - val_loss: 0.2433\n",
      "Epoch 24/150\n",
      "12112/12112 [==============================] - 1s 114us/step - loss: 0.2366 - val_loss: 0.2393\n",
      "Evaluating model with testing data...\n",
      "2574/2574 [==============================] - 0s 16us/step\n",
      "Getting distribution of predictions and covariance matrix...\n",
      "      1 of 20\n",
      "      2 of 20\n",
      "      3 of 20\n",
      "      4 of 20\n",
      "      5 of 20\n",
      "      6 of 20\n",
      "      7 of 20\n",
      "      8 of 20\n",
      "      9 of 20\n",
      "      10 of 20\n",
      "      11 of 20\n",
      "      12 of 20\n",
      "      13 of 20\n",
      "      14 of 20\n",
      "      15 of 20\n",
      "      16 of 20\n",
      "      17 of 20\n",
      "      18 of 20\n",
      "      19 of 20\n",
      "      20 of 20\n",
      "Computing ensemble means...\n",
      "Computing mean squared error...\n",
      "Iteration 84\n",
      "Train on 12252 samples, validate on 2604 samples\n",
      "Epoch 1/150\n",
      "12252/12252 [==============================] - 1s 100us/step - loss: 0.4952 - val_loss: 0.3773\n",
      "Epoch 2/150\n",
      "12252/12252 [==============================] - 1s 105us/step - loss: 0.3146 - val_loss: 0.2746\n",
      "Epoch 3/150\n",
      "12252/12252 [==============================] - 1s 109us/step - loss: 0.2460 - val_loss: 0.2312\n",
      "Epoch 4/150\n",
      "12252/12252 [==============================] - 1s 110us/step - loss: 0.2194 - val_loss: 0.2103\n",
      "Epoch 5/150\n",
      "12252/12252 [==============================] - 1s 111us/step - loss: 0.2036 - val_loss: 0.2023\n",
      "Epoch 6/150\n",
      "12252/12252 [==============================] - 1s 112us/step - loss: 0.1943 - val_loss: 0.1872\n",
      "Epoch 7/150\n",
      "12252/12252 [==============================] - 1s 109us/step - loss: 0.1873 - val_loss: 0.1879\n",
      "Epoch 8/150\n",
      "12252/12252 [==============================] - 1s 114us/step - loss: 0.1808 - val_loss: 0.1832\n",
      "Epoch 9/150\n",
      "12252/12252 [==============================] - 1s 108us/step - loss: 0.1769 - val_loss: 0.1777\n",
      "Epoch 10/150\n",
      "12252/12252 [==============================] - 1s 108us/step - loss: 0.1727 - val_loss: 0.1748\n",
      "Epoch 11/150\n",
      "12252/12252 [==============================] - 1s 105us/step - loss: 0.1676 - val_loss: 0.1656\n",
      "Epoch 12/150\n",
      "12252/12252 [==============================] - 1s 105us/step - loss: 0.1655 - val_loss: 0.1605\n",
      "Epoch 13/150\n",
      "12252/12252 [==============================] - 1s 111us/step - loss: 0.1596 - val_loss: 0.1581\n",
      "Epoch 14/150\n",
      "12252/12252 [==============================] - 1s 108us/step - loss: 0.1537 - val_loss: 0.1613\n",
      "Epoch 15/150\n",
      "12252/12252 [==============================] - 1s 110us/step - loss: 0.1536 - val_loss: 0.1554\n",
      "Epoch 16/150\n",
      "12252/12252 [==============================] - 1s 110us/step - loss: 0.1519 - val_loss: 0.1500\n",
      "Epoch 17/150\n",
      "12252/12252 [==============================] - 1s 110us/step - loss: 0.1502 - val_loss: 0.1519\n",
      "Epoch 18/150\n",
      "12252/12252 [==============================] - 1s 110us/step - loss: 0.1506 - val_loss: 0.1545\n",
      "Epoch 19/150\n",
      "12252/12252 [==============================] - 1s 107us/step - loss: 0.1469 - val_loss: 0.1530\n",
      "Epoch 20/150\n",
      "12252/12252 [==============================] - 1s 109us/step - loss: 0.1440 - val_loss: 0.1453\n",
      "Epoch 21/150\n",
      "12252/12252 [==============================] - 1s 108us/step - loss: 0.1412 - val_loss: 0.1470\n",
      "Epoch 22/150\n",
      "12252/12252 [==============================] - 1s 106us/step - loss: 0.1441 - val_loss: 0.1413\n",
      "Epoch 23/150\n",
      "12252/12252 [==============================] - 1s 105us/step - loss: 0.1410 - val_loss: 0.1448\n",
      "Epoch 24/150\n",
      "12252/12252 [==============================] - 1s 106us/step - loss: 0.1387 - val_loss: 0.1396\n",
      "Epoch 25/150\n",
      "12252/12252 [==============================] - 1s 98us/step - loss: 0.1359 - val_loss: 0.1396\n",
      "Epoch 26/150\n",
      "12252/12252 [==============================] - 1s 109us/step - loss: 0.1337 - val_loss: 0.1348\n",
      "Epoch 27/150\n",
      "12252/12252 [==============================] - 1s 105us/step - loss: 0.1330 - val_loss: 0.1340\n",
      "Epoch 28/150\n",
      "12252/12252 [==============================] - 1s 111us/step - loss: 0.1325 - val_loss: 0.1333\n",
      "Epoch 29/150\n",
      "12252/12252 [==============================] - 1s 107us/step - loss: 0.1305 - val_loss: 0.1347\n",
      "Epoch 30/150\n",
      "12252/12252 [==============================] - 1s 102us/step - loss: 0.1296 - val_loss: 0.1297\n",
      "Epoch 31/150\n",
      "12252/12252 [==============================] - 1s 105us/step - loss: 0.1280 - val_loss: 0.1346\n",
      "Epoch 32/150\n",
      "12252/12252 [==============================] - 1s 109us/step - loss: 0.1273 - val_loss: 0.1268\n",
      "Epoch 33/150\n",
      "12252/12252 [==============================] - 1s 110us/step - loss: 0.1248 - val_loss: 0.1248\n",
      "Epoch 34/150\n",
      "12252/12252 [==============================] - 1s 105us/step - loss: 0.1254 - val_loss: 0.1268\n",
      "Epoch 35/150\n",
      "12252/12252 [==============================] - 1s 103us/step - loss: 0.1245 - val_loss: 0.1249\n",
      "Epoch 36/150\n",
      "12252/12252 [==============================] - 1s 107us/step - loss: 0.1214 - val_loss: 0.1257\n",
      "Epoch 37/150\n",
      "12252/12252 [==============================] - 1s 109us/step - loss: 0.1215 - val_loss: 0.1244\n",
      "Epoch 38/150\n",
      "12252/12252 [==============================] - 1s 108us/step - loss: 0.1218 - val_loss: 0.1260\n",
      "Epoch 39/150\n",
      "12252/12252 [==============================] - 1s 107us/step - loss: 0.1203 - val_loss: 0.1263\n",
      "Epoch 40/150\n",
      "12252/12252 [==============================] - 1s 109us/step - loss: 0.1195 - val_loss: 0.1202\n",
      "Epoch 41/150\n",
      "12252/12252 [==============================] - 1s 102us/step - loss: 0.1194 - val_loss: 0.1252\n",
      "Epoch 42/150\n",
      "12252/12252 [==============================] - 1s 107us/step - loss: 0.1192 - val_loss: 0.1231\n",
      "Epoch 43/150\n",
      "12252/12252 [==============================] - 1s 107us/step - loss: 0.1188 - val_loss: 0.1240\n",
      "Epoch 44/150\n",
      "12252/12252 [==============================] - 1s 112us/step - loss: 0.1177 - val_loss: 0.1181\n",
      "Epoch 45/150\n",
      "12252/12252 [==============================] - 1s 113us/step - loss: 0.1177 - val_loss: 0.1219\n",
      "Epoch 46/150\n",
      "12252/12252 [==============================] - 1s 114us/step - loss: 0.1163 - val_loss: 0.1203\n",
      "Epoch 47/150\n",
      "12252/12252 [==============================] - 1s 114us/step - loss: 0.1177 - val_loss: 0.1193\n",
      "Epoch 48/150\n",
      "12252/12252 [==============================] - 1s 115us/step - loss: 0.1153 - val_loss: 0.1152\n",
      "Epoch 49/150\n",
      "12252/12252 [==============================] - 1s 114us/step - loss: 0.1152 - val_loss: 0.1207\n",
      "Epoch 50/150\n",
      "12252/12252 [==============================] - 1s 114us/step - loss: 0.1153 - val_loss: 0.1209\n",
      "Epoch 51/150\n",
      "12252/12252 [==============================] - 1s 112us/step - loss: 0.1141 - val_loss: 0.1215\n",
      "Epoch 52/150\n",
      "12252/12252 [==============================] - 1s 114us/step - loss: 0.1144 - val_loss: 0.1152\n",
      "Epoch 53/150\n",
      "12252/12252 [==============================] - 1s 114us/step - loss: 0.1144 - val_loss: 0.1145\n",
      "Epoch 54/150\n",
      "12252/12252 [==============================] - 1s 111us/step - loss: 0.1143 - val_loss: 0.1165\n",
      "Epoch 55/150\n",
      "12252/12252 [==============================] - 1s 113us/step - loss: 0.1125 - val_loss: 0.1201\n",
      "Epoch 56/150\n",
      "12252/12252 [==============================] - 1s 114us/step - loss: 0.1134 - val_loss: 0.1155\n",
      "Epoch 57/150\n",
      "12252/12252 [==============================] - 1s 111us/step - loss: 0.1109 - val_loss: 0.1140\n",
      "Epoch 58/150\n",
      "12252/12252 [==============================] - 1s 112us/step - loss: 0.1114 - val_loss: 0.1159\n",
      "Epoch 59/150\n",
      "12252/12252 [==============================] - 1s 114us/step - loss: 0.1114 - val_loss: 0.1156\n",
      "Epoch 60/150\n",
      "12252/12252 [==============================] - 1s 110us/step - loss: 0.1121 - val_loss: 0.1145\n",
      "Epoch 61/150\n",
      "12252/12252 [==============================] - 1s 114us/step - loss: 0.1103 - val_loss: 0.1111\n",
      "Epoch 62/150\n",
      "12252/12252 [==============================] - 1s 115us/step - loss: 0.1105 - val_loss: 0.1149\n",
      "Epoch 63/150\n",
      "12252/12252 [==============================] - 1s 111us/step - loss: 0.1117 - val_loss: 0.1136\n",
      "Epoch 64/150\n",
      "12252/12252 [==============================] - 1s 111us/step - loss: 0.1107 - val_loss: 0.1127\n",
      "Epoch 65/150\n",
      "12252/12252 [==============================] - 1s 114us/step - loss: 0.1108 - val_loss: 0.1156\n",
      "Evaluating model with testing data...\n",
      "2604/2604 [==============================] - 0s 16us/step\n",
      "Getting distribution of predictions and covariance matrix...\n",
      "      1 of 20\n",
      "      2 of 20\n",
      "      3 of 20\n",
      "      4 of 20\n",
      "      5 of 20\n",
      "      6 of 20\n",
      "      7 of 20\n",
      "      8 of 20\n",
      "      9 of 20\n",
      "      10 of 20\n",
      "      11 of 20\n",
      "      12 of 20\n",
      "      13 of 20\n",
      "      14 of 20\n",
      "      15 of 20\n",
      "      16 of 20\n",
      "      17 of 20\n",
      "      18 of 20\n",
      "      19 of 20\n",
      "      20 of 20\n",
      "Computing ensemble means...\n",
      "Computing mean squared error...\n",
      "Iteration 85\n",
      "Train on 12392 samples, validate on 2634 samples\n",
      "Epoch 1/150\n",
      "12392/12392 [==============================] - 1s 116us/step - loss: 0.4834 - val_loss: 0.3470\n",
      "Epoch 2/150\n",
      "12392/12392 [==============================] - 1s 107us/step - loss: 0.3079 - val_loss: 0.2774\n",
      "Epoch 3/150\n",
      "12392/12392 [==============================] - 1s 109us/step - loss: 0.2631 - val_loss: 0.2448\n",
      "Epoch 4/150\n",
      "12392/12392 [==============================] - 1s 117us/step - loss: 0.2301 - val_loss: 0.2209\n",
      "Epoch 5/150\n",
      "12392/12392 [==============================] - 1s 116us/step - loss: 0.2145 - val_loss: 0.2114\n",
      "Epoch 6/150\n",
      "12392/12392 [==============================] - 1s 116us/step - loss: 0.2032 - val_loss: 0.1974\n",
      "Epoch 7/150\n",
      "12392/12392 [==============================] - 1s 116us/step - loss: 0.1970 - val_loss: 0.1946\n",
      "Epoch 8/150\n",
      "12392/12392 [==============================] - 1s 115us/step - loss: 0.1884 - val_loss: 0.1932\n",
      "Epoch 9/150\n",
      "12392/12392 [==============================] - 1s 116us/step - loss: 0.1835 - val_loss: 0.1795\n",
      "Epoch 10/150\n",
      "12392/12392 [==============================] - 1s 65us/step - loss: 0.1759 - val_loss: 0.1800\n",
      "Epoch 11/150\n",
      "12392/12392 [==============================] - 1s 59us/step - loss: 0.1714 - val_loss: 0.1700\n",
      "Epoch 12/150\n",
      "12392/12392 [==============================] - 1s 90us/step - loss: 0.1695 - val_loss: 0.1701\n",
      "Epoch 13/150\n",
      "12392/12392 [==============================] - 1s 112us/step - loss: 0.1681 - val_loss: 0.1691\n",
      "Epoch 14/150\n",
      "12392/12392 [==============================] - 1s 113us/step - loss: 0.1655 - val_loss: 0.1627\n",
      "Epoch 15/150\n",
      "12392/12392 [==============================] - 1s 101us/step - loss: 0.1651 - val_loss: 0.1674\n",
      "Epoch 16/150\n",
      "12392/12392 [==============================] - 1s 116us/step - loss: 0.1640 - val_loss: 0.1677\n",
      "Epoch 17/150\n",
      "12392/12392 [==============================] - 1s 113us/step - loss: 0.1628 - val_loss: 0.1639\n",
      "Epoch 18/150\n",
      "12392/12392 [==============================] - 1s 109us/step - loss: 0.1635 - val_loss: 0.1633\n",
      "Evaluating model with testing data...\n",
      "2634/2634 [==============================] - 0s 15us/step\n",
      "Getting distribution of predictions and covariance matrix...\n",
      "      1 of 20\n",
      "      2 of 20\n",
      "      3 of 20\n",
      "      4 of 20\n",
      "      5 of 20\n",
      "      6 of 20\n",
      "      7 of 20\n",
      "      8 of 20\n",
      "      9 of 20\n",
      "      10 of 20\n",
      "      11 of 20\n",
      "      12 of 20\n",
      "      13 of 20\n",
      "      14 of 20\n",
      "      15 of 20\n",
      "      16 of 20\n",
      "      17 of 20\n",
      "      18 of 20\n",
      "      19 of 20\n",
      "      20 of 20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|          | 0/20 [00:00<?, ?it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing ensemble means...\n",
      "Computing mean squared error...\n",
      "Getting distribution of predictions...\n",
      "      1 of 20\n",
      "1600/1600 [==============================] - 0s 28us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  5%|▌         | 1/20 [00:29<09:18, 29.39s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      2 of 20\n",
      "1600/1600 [==============================] - 0s 28us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 10%|█         | 2/20 [00:58<08:48, 29.38s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      3 of 20\n",
      "1600/1600 [==============================] - 0s 36us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 15%|█▌        | 3/20 [01:28<08:21, 29.51s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      4 of 20\n",
      "1600/1600 [==============================] - 0s 29us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 20%|██        | 4/20 [01:58<07:52, 29.50s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      5 of 20\n",
      "1600/1600 [==============================] - 0s 30us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 25%|██▌       | 5/20 [02:27<07:23, 29.56s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      6 of 20\n",
      "1600/1600 [==============================] - 0s 29us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 30%|███       | 6/20 [02:57<06:53, 29.52s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      7 of 20\n",
      "1600/1600 [==============================] - 0s 29us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 35%|███▌      | 7/20 [03:27<06:25, 29.62s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      8 of 20\n",
      "1600/1600 [==============================] - 0s 29us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 40%|████      | 8/20 [03:56<05:54, 29.54s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      9 of 20\n",
      "1600/1600 [==============================] - 0s 29us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 45%|████▌     | 9/20 [04:26<05:25, 29.58s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      10 of 20\n",
      "1600/1600 [==============================] - 0s 29us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 50%|█████     | 10/20 [04:55<04:55, 29.60s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      11 of 20\n",
      "1600/1600 [==============================] - 0s 29us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 55%|█████▌    | 11/20 [05:25<04:26, 29.62s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      12 of 20\n",
      "1600/1600 [==============================] - 0s 30us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 60%|██████    | 12/20 [05:54<03:56, 29.57s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      13 of 20\n",
      "1600/1600 [==============================] - 0s 28us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 65%|██████▌   | 13/20 [06:24<03:26, 29.57s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      14 of 20\n",
      "1600/1600 [==============================] - 0s 30us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 70%|███████   | 14/20 [06:53<02:57, 29.57s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      15 of 20\n",
      "1600/1600 [==============================] - 0s 30us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 75%|███████▌  | 15/20 [07:23<02:28, 29.62s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      16 of 20\n",
      "1600/1600 [==============================] - 0s 29us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 80%|████████  | 16/20 [07:53<01:58, 29.55s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      17 of 20\n",
      "1600/1600 [==============================] - 0s 29us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 85%|████████▌ | 17/20 [08:22<01:28, 29.59s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      18 of 20\n",
      "1600/1600 [==============================] - 0s 29us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 90%|█████████ | 18/20 [08:52<00:59, 29.59s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      19 of 20\n",
      "1600/1600 [==============================] - 0s 29us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 95%|█████████▌| 19/20 [09:21<00:29, 29.56s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      20 of 20\n",
      "1600/1600 [==============================] - 0s 29us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 20/20 [09:51<00:00, 29.56s/it]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing ensemble predictions...\n",
      "Iteration 86\n",
      "Train on 12532 samples, validate on 2664 samples\n",
      "Epoch 1/150\n",
      "12532/12532 [==============================] - 1s 113us/step - loss: 0.4383 - val_loss: 0.2963\n",
      "Epoch 2/150\n",
      "12532/12532 [==============================] - 1s 116us/step - loss: 0.2698 - val_loss: 0.2439\n",
      "Epoch 3/150\n",
      "12532/12532 [==============================] - 1s 117us/step - loss: 0.2294 - val_loss: 0.2259\n",
      "Epoch 4/150\n",
      "12532/12532 [==============================] - 1s 115us/step - loss: 0.2122 - val_loss: 0.2050\n",
      "Epoch 5/150\n",
      "12532/12532 [==============================] - 1s 116us/step - loss: 0.1991 - val_loss: 0.1957\n",
      "Epoch 6/150\n",
      "12532/12532 [==============================] - 1s 114us/step - loss: 0.1896 - val_loss: 0.1848\n",
      "Epoch 7/150\n",
      "12532/12532 [==============================] - 1s 115us/step - loss: 0.1773 - val_loss: 0.1752\n",
      "Epoch 8/150\n",
      "12532/12532 [==============================] - 1s 115us/step - loss: 0.1731 - val_loss: 0.1745\n",
      "Epoch 9/150\n",
      "12532/12532 [==============================] - 1s 115us/step - loss: 0.1636 - val_loss: 0.1645\n",
      "Epoch 10/150\n",
      "12532/12532 [==============================] - 1s 108us/step - loss: 0.1621 - val_loss: 0.1615\n",
      "Epoch 11/150\n",
      "12532/12532 [==============================] - 1s 110us/step - loss: 0.1606 - val_loss: 0.1629\n",
      "Epoch 12/150\n",
      "12532/12532 [==============================] - 1s 116us/step - loss: 0.1557 - val_loss: 0.1611\n",
      "Epoch 13/150\n",
      "12532/12532 [==============================] - 1s 115us/step - loss: 0.1532 - val_loss: 0.1548\n",
      "Epoch 14/150\n",
      "12532/12532 [==============================] - 1s 112us/step - loss: 0.1511 - val_loss: 0.1522\n",
      "Epoch 15/150\n",
      "12532/12532 [==============================] - 1s 115us/step - loss: 0.1486 - val_loss: 0.1509\n",
      "Epoch 16/150\n",
      "12532/12532 [==============================] - 1s 109us/step - loss: 0.1480 - val_loss: 0.1495\n",
      "Epoch 17/150\n",
      "12532/12532 [==============================] - 1s 115us/step - loss: 0.1476 - val_loss: 0.1499\n",
      "Epoch 18/150\n",
      "12532/12532 [==============================] - 1s 115us/step - loss: 0.1459 - val_loss: 0.1432\n",
      "Epoch 19/150\n",
      "12532/12532 [==============================] - 1s 113us/step - loss: 0.1435 - val_loss: 0.1425\n",
      "Epoch 20/150\n",
      "12532/12532 [==============================] - 1s 112us/step - loss: 0.1431 - val_loss: 0.1484\n",
      "Epoch 21/150\n",
      "12532/12532 [==============================] - 1s 115us/step - loss: 0.1425 - val_loss: 0.1449\n",
      "Epoch 22/150\n",
      "12532/12532 [==============================] - 1s 112us/step - loss: 0.1435 - val_loss: 0.1453\n",
      "Epoch 23/150\n",
      "12532/12532 [==============================] - 1s 112us/step - loss: 0.1421 - val_loss: 0.1443\n",
      "Evaluating model with testing data...\n",
      "2664/2664 [==============================] - 0s 15us/step\n",
      "Getting distribution of predictions and covariance matrix...\n",
      "      1 of 20\n",
      "      2 of 20\n",
      "      3 of 20\n",
      "      4 of 20\n",
      "      5 of 20\n",
      "      6 of 20\n",
      "      7 of 20\n",
      "      8 of 20\n",
      "      9 of 20\n",
      "      10 of 20\n",
      "      11 of 20\n",
      "      12 of 20\n",
      "      13 of 20\n",
      "      14 of 20\n",
      "      15 of 20\n",
      "      16 of 20\n",
      "      17 of 20\n",
      "      18 of 20\n",
      "      19 of 20\n",
      "      20 of 20\n",
      "Computing ensemble means...\n",
      "Computing mean squared error...\n",
      "Iteration 87\n",
      "Train on 12672 samples, validate on 2694 samples\n",
      "Epoch 1/150\n",
      "12672/12672 [==============================] - 1s 113us/step - loss: 0.5069 - val_loss: 0.3505\n",
      "Epoch 2/150\n",
      "12672/12672 [==============================] - 1s 113us/step - loss: 0.3092 - val_loss: 0.2748\n",
      "Epoch 3/150\n",
      "12672/12672 [==============================] - 1s 113us/step - loss: 0.2551 - val_loss: 0.2436\n",
      "Epoch 4/150\n",
      "12672/12672 [==============================] - 1s 112us/step - loss: 0.2373 - val_loss: 0.2294\n",
      "Epoch 5/150\n",
      "12672/12672 [==============================] - 1s 116us/step - loss: 0.2235 - val_loss: 0.2232\n",
      "Epoch 6/150\n",
      "12672/12672 [==============================] - 1s 113us/step - loss: 0.2133 - val_loss: 0.2126\n",
      "Epoch 7/150\n",
      "12672/12672 [==============================] - 1s 113us/step - loss: 0.2056 - val_loss: 0.2087\n",
      "Epoch 8/150\n",
      "12672/12672 [==============================] - 1s 112us/step - loss: 0.2017 - val_loss: 0.2080\n",
      "Epoch 9/150\n",
      "12672/12672 [==============================] - 1s 108us/step - loss: 0.1965 - val_loss: 0.1985\n",
      "Epoch 10/150\n",
      "12672/12672 [==============================] - 1s 109us/step - loss: 0.1944 - val_loss: 0.1972\n",
      "Epoch 11/150\n",
      "12672/12672 [==============================] - 1s 116us/step - loss: 0.1912 - val_loss: 0.1889\n",
      "Epoch 12/150\n",
      "12672/12672 [==============================] - 1s 114us/step - loss: 0.1875 - val_loss: 0.1921\n",
      "Epoch 13/150\n",
      "12672/12672 [==============================] - 1s 116us/step - loss: 0.1841 - val_loss: 0.1838\n",
      "Epoch 14/150\n",
      "12672/12672 [==============================] - 1s 116us/step - loss: 0.1797 - val_loss: 0.1847\n",
      "Epoch 15/150\n",
      "12672/12672 [==============================] - 1s 111us/step - loss: 0.1767 - val_loss: 0.1797\n",
      "Epoch 16/150\n",
      "12672/12672 [==============================] - 1s 115us/step - loss: 0.1735 - val_loss: 0.1791\n",
      "Epoch 17/150\n",
      "12672/12672 [==============================] - 1s 106us/step - loss: 0.1746 - val_loss: 0.1762\n",
      "Epoch 18/150\n",
      "12672/12672 [==============================] - 1s 114us/step - loss: 0.1726 - val_loss: 0.1743\n",
      "Epoch 19/150\n",
      "12672/12672 [==============================] - 1s 110us/step - loss: 0.1699 - val_loss: 0.1746\n",
      "Epoch 20/150\n",
      "12672/12672 [==============================] - 1s 110us/step - loss: 0.1722 - val_loss: 0.1766\n",
      "Epoch 21/150\n",
      "12672/12672 [==============================] - 1s 109us/step - loss: 0.1706 - val_loss: 0.1700\n",
      "Epoch 22/150\n",
      "12672/12672 [==============================] - 1s 115us/step - loss: 0.1691 - val_loss: 0.1743\n",
      "Epoch 23/150\n",
      "12672/12672 [==============================] - 1s 106us/step - loss: 0.1696 - val_loss: 0.1708\n",
      "Epoch 24/150\n",
      "12672/12672 [==============================] - 1s 110us/step - loss: 0.1665 - val_loss: 0.1701\n",
      "Epoch 25/150\n",
      "12672/12672 [==============================] - 1s 111us/step - loss: 0.1674 - val_loss: 0.1704\n",
      "Evaluating model with testing data...\n",
      "2694/2694 [==============================] - 0s 15us/step\n",
      "Getting distribution of predictions and covariance matrix...\n",
      "      1 of 20\n",
      "      2 of 20\n",
      "      3 of 20\n",
      "      4 of 20\n",
      "      5 of 20\n",
      "      6 of 20\n",
      "      7 of 20\n",
      "      8 of 20\n",
      "      9 of 20\n",
      "      10 of 20\n",
      "      11 of 20\n",
      "      12 of 20\n",
      "      13 of 20\n",
      "      14 of 20\n",
      "      15 of 20\n",
      "      16 of 20\n",
      "      17 of 20\n",
      "      18 of 20\n",
      "      19 of 20\n",
      "      20 of 20\n",
      "Computing ensemble means...\n",
      "Computing mean squared error...\n",
      "Iteration 88\n",
      "Train on 12812 samples, validate on 2724 samples\n",
      "Epoch 1/150\n",
      "12812/12812 [==============================] - 1s 107us/step - loss: 0.5891 - val_loss: 0.4563\n",
      "Epoch 2/150\n",
      "12812/12812 [==============================] - 1s 97us/step - loss: 0.4324 - val_loss: 0.4103\n",
      "Epoch 3/150\n",
      "12812/12812 [==============================] - 1s 103us/step - loss: 0.3917 - val_loss: 0.3757\n",
      "Epoch 4/150\n",
      "12812/12812 [==============================] - 1s 101us/step - loss: 0.3621 - val_loss: 0.3514\n",
      "Epoch 5/150\n",
      "12812/12812 [==============================] - 1s 99us/step - loss: 0.3420 - val_loss: 0.3354\n",
      "Epoch 6/150\n",
      "12812/12812 [==============================] - 1s 109us/step - loss: 0.3257 - val_loss: 0.3135\n",
      "Epoch 7/150\n",
      "12812/12812 [==============================] - 1s 111us/step - loss: 0.2983 - val_loss: 0.2984\n",
      "Epoch 8/150\n",
      "12812/12812 [==============================] - 1s 106us/step - loss: 0.2747 - val_loss: 0.2600\n",
      "Epoch 9/150\n",
      "12812/12812 [==============================] - 1s 107us/step - loss: 0.2564 - val_loss: 0.2471\n",
      "Epoch 10/150\n",
      "12812/12812 [==============================] - 1s 107us/step - loss: 0.2440 - val_loss: 0.2444\n",
      "Epoch 11/150\n",
      "12812/12812 [==============================] - 1s 103us/step - loss: 0.2338 - val_loss: 0.2303\n",
      "Epoch 12/150\n",
      "12812/12812 [==============================] - 1s 106us/step - loss: 0.2281 - val_loss: 0.2329\n",
      "Epoch 13/150\n",
      "12812/12812 [==============================] - 1s 109us/step - loss: 0.2314 - val_loss: 0.2299\n",
      "Epoch 14/150\n",
      "12812/12812 [==============================] - 1s 101us/step - loss: 0.2284 - val_loss: 0.2345\n",
      "Epoch 15/150\n",
      "12812/12812 [==============================] - 1s 106us/step - loss: 0.2269 - val_loss: 0.2257\n",
      "Epoch 16/150\n",
      "12812/12812 [==============================] - 1s 104us/step - loss: 0.2253 - val_loss: 0.2335\n",
      "Epoch 17/150\n",
      "12812/12812 [==============================] - 1s 107us/step - loss: 0.2235 - val_loss: 0.2270\n",
      "Epoch 18/150\n",
      "12812/12812 [==============================] - 1s 115us/step - loss: 0.2203 - val_loss: 0.2217\n",
      "Epoch 19/150\n",
      "12812/12812 [==============================] - 1s 110us/step - loss: 0.2256 - val_loss: 0.2239\n",
      "Epoch 20/150\n",
      "12812/12812 [==============================] - 1s 117us/step - loss: 0.2223 - val_loss: 0.2238\n",
      "Epoch 21/150\n",
      "12812/12812 [==============================] - 1s 117us/step - loss: 0.2236 - val_loss: 0.2294\n",
      "Epoch 22/150\n",
      "12812/12812 [==============================] - 1s 117us/step - loss: 0.2188 - val_loss: 0.2222\n",
      "Evaluating model with testing data...\n",
      "2724/2724 [==============================] - 0s 15us/step\n",
      "Getting distribution of predictions and covariance matrix...\n",
      "      1 of 20\n",
      "      2 of 20\n",
      "      3 of 20\n",
      "      4 of 20\n",
      "      5 of 20\n",
      "      6 of 20\n",
      "      7 of 20\n",
      "      8 of 20\n",
      "      9 of 20\n",
      "      10 of 20\n",
      "      11 of 20\n",
      "      12 of 20\n",
      "      13 of 20\n",
      "      14 of 20\n",
      "      15 of 20\n",
      "      16 of 20\n",
      "      17 of 20\n",
      "      18 of 20\n",
      "      19 of 20\n",
      "      20 of 20\n",
      "Computing ensemble means...\n",
      "Computing mean squared error...\n",
      "Iteration 89\n",
      "Train on 12952 samples, validate on 2754 samples\n",
      "Epoch 1/150\n",
      "12952/12952 [==============================] - 1s 112us/step - loss: 0.4600 - val_loss: 0.3173\n",
      "Epoch 2/150\n",
      "12952/12952 [==============================] - 1s 108us/step - loss: 0.2923 - val_loss: 0.2658\n",
      "Epoch 3/150\n",
      "12952/12952 [==============================] - 1s 115us/step - loss: 0.2521 - val_loss: 0.2356\n",
      "Epoch 4/150\n",
      "12952/12952 [==============================] - 2s 116us/step - loss: 0.2247 - val_loss: 0.2158\n",
      "Epoch 5/150\n",
      "12952/12952 [==============================] - 1s 113us/step - loss: 0.2068 - val_loss: 0.1999\n",
      "Epoch 6/150\n",
      "12952/12952 [==============================] - 1s 114us/step - loss: 0.1942 - val_loss: 0.1929\n",
      "Epoch 7/150\n",
      "12952/12952 [==============================] - 2s 116us/step - loss: 0.1844 - val_loss: 0.1804\n",
      "Epoch 8/150\n",
      "12952/12952 [==============================] - 1s 112us/step - loss: 0.1774 - val_loss: 0.1795\n",
      "Epoch 9/150\n",
      "12952/12952 [==============================] - 1s 71us/step - loss: 0.1685 - val_loss: 0.1722\n",
      "Epoch 10/150\n",
      "12952/12952 [==============================] - 1s 60us/step - loss: 0.1638 - val_loss: 0.1631\n",
      "Epoch 11/150\n",
      "12952/12952 [==============================] - 1s 102us/step - loss: 0.1587 - val_loss: 0.1580\n",
      "Epoch 12/150\n",
      "12952/12952 [==============================] - 1s 108us/step - loss: 0.1567 - val_loss: 0.1576\n",
      "Epoch 13/150\n",
      "12952/12952 [==============================] - 1s 112us/step - loss: 0.1555 - val_loss: 0.1541\n",
      "Epoch 14/150\n",
      "12952/12952 [==============================] - 1s 113us/step - loss: 0.1490 - val_loss: 0.1519\n",
      "Epoch 15/150\n",
      "12952/12952 [==============================] - 1s 116us/step - loss: 0.1490 - val_loss: 0.1519\n",
      "Epoch 16/150\n",
      "12952/12952 [==============================] - 1s 109us/step - loss: 0.1477 - val_loss: 0.1521\n",
      "Epoch 17/150\n",
      "12952/12952 [==============================] - 1s 113us/step - loss: 0.1475 - val_loss: 0.1484\n",
      "Epoch 18/150\n",
      "12952/12952 [==============================] - 1s 110us/step - loss: 0.1463 - val_loss: 0.1453\n",
      "Epoch 19/150\n",
      "12952/12952 [==============================] - 1s 113us/step - loss: 0.1449 - val_loss: 0.1518\n",
      "Epoch 20/150\n",
      "12952/12952 [==============================] - 1s 112us/step - loss: 0.1438 - val_loss: 0.1484\n",
      "Epoch 21/150\n",
      "12952/12952 [==============================] - 1s 113us/step - loss: 0.1440 - val_loss: 0.1495\n",
      "Epoch 22/150\n",
      "12952/12952 [==============================] - 2s 116us/step - loss: 0.1426 - val_loss: 0.1446\n",
      "Epoch 23/150\n",
      "12952/12952 [==============================] - 1s 115us/step - loss: 0.1434 - val_loss: 0.1449\n",
      "Epoch 24/150\n",
      "12952/12952 [==============================] - 1s 115us/step - loss: 0.1408 - val_loss: 0.1498\n",
      "Epoch 25/150\n",
      "12952/12952 [==============================] - 1s 113us/step - loss: 0.1414 - val_loss: 0.1449\n",
      "Epoch 26/150\n",
      "12952/12952 [==============================] - 1s 115us/step - loss: 0.1399 - val_loss: 0.1457\n",
      "Evaluating model with testing data...\n",
      "2754/2754 [==============================] - 0s 16us/step\n",
      "Getting distribution of predictions and covariance matrix...\n",
      "      1 of 20\n",
      "      2 of 20\n",
      "      3 of 20\n",
      "      4 of 20\n",
      "      5 of 20\n",
      "      6 of 20\n",
      "      7 of 20\n",
      "      8 of 20\n",
      "      9 of 20\n",
      "      10 of 20\n",
      "      11 of 20\n",
      "      12 of 20\n",
      "      13 of 20\n",
      "      14 of 20\n",
      "      15 of 20\n",
      "      16 of 20\n",
      "      17 of 20\n",
      "      18 of 20\n",
      "      19 of 20\n",
      "      20 of 20\n",
      "Computing ensemble means...\n",
      "Computing mean squared error...\n",
      "Iteration 90\n",
      "Train on 13092 samples, validate on 2784 samples\n",
      "Epoch 1/150\n",
      "13092/13092 [==============================] - 1s 107us/step - loss: 0.5014 - val_loss: 0.3498\n",
      "Epoch 2/150\n",
      "13092/13092 [==============================] - 1s 107us/step - loss: 0.3271 - val_loss: 0.3154\n",
      "Epoch 3/150\n",
      "13092/13092 [==============================] - 1s 110us/step - loss: 0.3028 - val_loss: 0.2978\n",
      "Epoch 4/150\n",
      "13092/13092 [==============================] - 1s 109us/step - loss: 0.2814 - val_loss: 0.2768\n",
      "Epoch 5/150\n",
      "13092/13092 [==============================] - 1s 105us/step - loss: 0.2663 - val_loss: 0.2643\n",
      "Epoch 6/150\n",
      "13092/13092 [==============================] - 1s 105us/step - loss: 0.2535 - val_loss: 0.2484\n",
      "Epoch 7/150\n",
      "13092/13092 [==============================] - 1s 109us/step - loss: 0.2333 - val_loss: 0.2239\n",
      "Epoch 8/150\n",
      "13092/13092 [==============================] - 1s 110us/step - loss: 0.2218 - val_loss: 0.2189\n",
      "Epoch 9/150\n",
      "13092/13092 [==============================] - 1s 109us/step - loss: 0.2158 - val_loss: 0.2176\n",
      "Epoch 10/150\n",
      "13092/13092 [==============================] - 1s 111us/step - loss: 0.2112 - val_loss: 0.2125\n",
      "Epoch 11/150\n",
      "13092/13092 [==============================] - 1s 108us/step - loss: 0.2087 - val_loss: 0.2092\n",
      "Epoch 12/150\n",
      "13092/13092 [==============================] - 1s 111us/step - loss: 0.2071 - val_loss: 0.2043\n",
      "Epoch 13/150\n",
      "13092/13092 [==============================] - 1s 109us/step - loss: 0.2053 - val_loss: 0.2083\n",
      "Epoch 14/150\n",
      "13092/13092 [==============================] - 1s 104us/step - loss: 0.2021 - val_loss: 0.2040\n",
      "Epoch 15/150\n",
      "13092/13092 [==============================] - 1s 101us/step - loss: 0.2024 - val_loss: 0.2058\n",
      "Epoch 16/150\n",
      "13092/13092 [==============================] - 1s 109us/step - loss: 0.1995 - val_loss: 0.2055\n",
      "Epoch 17/150\n",
      "13092/13092 [==============================] - 1s 109us/step - loss: 0.2008 - val_loss: 0.2037\n",
      "Epoch 18/150\n",
      "13092/13092 [==============================] - 1s 110us/step - loss: 0.1989 - val_loss: 0.1969\n",
      "Epoch 19/150\n",
      "13092/13092 [==============================] - 1s 102us/step - loss: 0.1958 - val_loss: 0.1945\n",
      "Epoch 20/150\n",
      "13092/13092 [==============================] - 1s 105us/step - loss: 0.1911 - val_loss: 0.1907\n",
      "Epoch 21/150\n",
      "13092/13092 [==============================] - 1s 103us/step - loss: 0.1904 - val_loss: 0.1864\n",
      "Epoch 22/150\n",
      "13092/13092 [==============================] - 1s 101us/step - loss: 0.1888 - val_loss: 0.1876\n",
      "Epoch 23/150\n",
      "13092/13092 [==============================] - 1s 108us/step - loss: 0.1856 - val_loss: 0.1813\n",
      "Epoch 24/150\n",
      "13092/13092 [==============================] - 1s 104us/step - loss: 0.1819 - val_loss: 0.1800\n",
      "Epoch 25/150\n",
      "13092/13092 [==============================] - 1s 108us/step - loss: 0.1783 - val_loss: 0.1825\n",
      "Epoch 26/150\n",
      "13092/13092 [==============================] - 1s 104us/step - loss: 0.1766 - val_loss: 0.1751\n",
      "Epoch 27/150\n",
      "13092/13092 [==============================] - 1s 102us/step - loss: 0.1760 - val_loss: 0.1739\n",
      "Epoch 28/150\n",
      "13092/13092 [==============================] - 1s 99us/step - loss: 0.1739 - val_loss: 0.1760\n",
      "Epoch 29/150\n",
      "13092/13092 [==============================] - 1s 106us/step - loss: 0.1718 - val_loss: 0.1681\n",
      "Epoch 30/150\n",
      "13092/13092 [==============================] - 1s 99us/step - loss: 0.1732 - val_loss: 0.1742\n",
      "Epoch 31/150\n",
      "13092/13092 [==============================] - 1s 109us/step - loss: 0.1728 - val_loss: 0.1747\n",
      "Epoch 32/150\n",
      "13092/13092 [==============================] - 1s 101us/step - loss: 0.1722 - val_loss: 0.1720\n",
      "Epoch 33/150\n",
      "13092/13092 [==============================] - 1s 101us/step - loss: 0.1716 - val_loss: 0.1694\n",
      "Evaluating model with testing data...\n",
      "2784/2784 [==============================] - 0s 15us/step\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Getting distribution of predictions and covariance matrix...\n",
      "      1 of 20\n",
      "      2 of 20\n",
      "      3 of 20\n",
      "      4 of 20\n",
      "      5 of 20\n",
      "      6 of 20\n",
      "      7 of 20\n",
      "      8 of 20\n",
      "      9 of 20\n",
      "      10 of 20\n",
      "      11 of 20\n",
      "      12 of 20\n",
      "      13 of 20\n",
      "      14 of 20\n",
      "      15 of 20\n",
      "      16 of 20\n",
      "      17 of 20\n",
      "      18 of 20\n",
      "      19 of 20\n",
      "      20 of 20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|          | 0/20 [00:00<?, ?it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing ensemble means...\n",
      "Computing mean squared error...\n",
      "Getting distribution of predictions...\n",
      "      1 of 20\n",
      "1600/1600 [==============================] - 0s 28us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  5%|▌         | 1/20 [00:29<09:26, 29.80s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      2 of 20\n",
      "1600/1600 [==============================] - 0s 28us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 10%|█         | 2/20 [00:59<08:54, 29.67s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      3 of 20\n",
      "1600/1600 [==============================] - 0s 32us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 15%|█▌        | 3/20 [01:28<08:24, 29.68s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      4 of 20\n",
      "1600/1600 [==============================] - 0s 29us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 20%|██        | 4/20 [01:58<07:55, 29.69s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      5 of 20\n",
      "1600/1600 [==============================] - 0s 29us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 25%|██▌       | 5/20 [02:28<07:25, 29.70s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      6 of 20\n",
      "1600/1600 [==============================] - 0s 30us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 30%|███       | 6/20 [02:57<06:54, 29.64s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      7 of 20\n",
      "1600/1600 [==============================] - 0s 29us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 35%|███▌      | 7/20 [03:27<06:24, 29.60s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      8 of 20\n",
      "1600/1600 [==============================] - 0s 29us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 40%|████      | 8/20 [03:57<05:56, 29.67s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      9 of 20\n",
      "1600/1600 [==============================] - 0s 29us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 45%|████▌     | 9/20 [04:26<05:26, 29.70s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      10 of 20\n",
      "1600/1600 [==============================] - 0s 30us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 50%|█████     | 10/20 [04:56<04:56, 29.64s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      11 of 20\n",
      "1600/1600 [==============================] - 0s 30us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 55%|█████▌    | 11/20 [05:26<04:27, 29.71s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      12 of 20\n",
      "1600/1600 [==============================] - 0s 28us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 60%|██████    | 12/20 [05:56<03:58, 29.78s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      13 of 20\n",
      "1600/1600 [==============================] - 0s 28us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 65%|██████▌   | 13/20 [06:25<03:28, 29.76s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      14 of 20\n",
      "1600/1600 [==============================] - 0s 28us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 70%|███████   | 14/20 [06:55<02:58, 29.71s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      15 of 20\n",
      "1600/1600 [==============================] - 0s 29us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 75%|███████▌  | 15/20 [07:25<02:28, 29.78s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      16 of 20\n",
      "1600/1600 [==============================] - 0s 30us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 80%|████████  | 16/20 [07:54<01:58, 29.69s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      17 of 20\n",
      "1600/1600 [==============================] - 0s 30us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 85%|████████▌ | 17/20 [08:24<01:28, 29.64s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      18 of 20\n",
      "1600/1600 [==============================] - 0s 29us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 90%|█████████ | 18/20 [08:54<00:59, 29.63s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      19 of 20\n",
      "1600/1600 [==============================] - 0s 29us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 95%|█████████▌| 19/20 [09:23<00:29, 29.63s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      20 of 20\n",
      "1600/1600 [==============================] - 0s 29us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 20/20 [09:53<00:00, 29.67s/it]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing ensemble predictions...\n",
      "Iteration 91\n",
      "Train on 13232 samples, validate on 2814 samples\n",
      "Epoch 1/150\n",
      "13232/13232 [==============================] - 1s 110us/step - loss: 0.4999 - val_loss: 0.3956\n",
      "Epoch 2/150\n",
      "13232/13232 [==============================] - 1s 108us/step - loss: 0.3607 - val_loss: 0.3254\n",
      "Epoch 3/150\n",
      "13232/13232 [==============================] - 2s 113us/step - loss: 0.2968 - val_loss: 0.2754\n",
      "Epoch 4/150\n",
      "13232/13232 [==============================] - 1s 113us/step - loss: 0.2590 - val_loss: 0.2508\n",
      "Epoch 5/150\n",
      "13232/13232 [==============================] - 1s 113us/step - loss: 0.2405 - val_loss: 0.2352\n",
      "Epoch 6/150\n",
      "13232/13232 [==============================] - 2s 114us/step - loss: 0.2291 - val_loss: 0.2246\n",
      "Epoch 7/150\n",
      "13232/13232 [==============================] - 1s 112us/step - loss: 0.2225 - val_loss: 0.2191\n",
      "Epoch 8/150\n",
      "13232/13232 [==============================] - 1s 111us/step - loss: 0.2167 - val_loss: 0.2150\n",
      "Epoch 9/150\n",
      "13232/13232 [==============================] - 2s 114us/step - loss: 0.2120 - val_loss: 0.2161\n",
      "Epoch 10/150\n",
      "13232/13232 [==============================] - 1s 112us/step - loss: 0.2090 - val_loss: 0.2066\n",
      "Epoch 11/150\n",
      "13232/13232 [==============================] - 1s 113us/step - loss: 0.2053 - val_loss: 0.2018\n",
      "Epoch 12/150\n",
      "13232/13232 [==============================] - 2s 113us/step - loss: 0.2058 - val_loss: 0.2051\n",
      "Epoch 13/150\n",
      "13232/13232 [==============================] - 1s 112us/step - loss: 0.2027 - val_loss: 0.1989\n",
      "Epoch 14/150\n",
      "13232/13232 [==============================] - 1s 113us/step - loss: 0.2014 - val_loss: 0.1991\n",
      "Epoch 15/150\n",
      "13232/13232 [==============================] - 1s 111us/step - loss: 0.2012 - val_loss: 0.2017\n",
      "Epoch 16/150\n",
      "13232/13232 [==============================] - 2s 113us/step - loss: 0.1991 - val_loss: 0.2008\n",
      "Epoch 17/150\n",
      "13232/13232 [==============================] - 2s 113us/step - loss: 0.1990 - val_loss: 0.1971\n",
      "Epoch 18/150\n",
      "13232/13232 [==============================] - 1s 113us/step - loss: 0.1970 - val_loss: 0.1968\n",
      "Epoch 19/150\n",
      "13232/13232 [==============================] - 1s 113us/step - loss: 0.1994 - val_loss: 0.1945\n",
      "Epoch 20/150\n",
      "13232/13232 [==============================] - 1s 113us/step - loss: 0.1974 - val_loss: 0.1971\n",
      "Epoch 21/150\n",
      "13232/13232 [==============================] - 1s 110us/step - loss: 0.1937 - val_loss: 0.1924\n",
      "Epoch 22/150\n",
      "13232/13232 [==============================] - 1s 113us/step - loss: 0.1949 - val_loss: 0.1974\n",
      "Epoch 23/150\n",
      "13232/13232 [==============================] - 2s 114us/step - loss: 0.1965 - val_loss: 0.1923\n",
      "Epoch 24/150\n",
      "13232/13232 [==============================] - 1s 110us/step - loss: 0.1964 - val_loss: 0.1909\n",
      "Epoch 25/150\n",
      "13232/13232 [==============================] - 1s 109us/step - loss: 0.1962 - val_loss: 0.1941\n",
      "Epoch 26/150\n",
      "13232/13232 [==============================] - 1s 111us/step - loss: 0.1930 - val_loss: 0.1938\n",
      "Epoch 27/150\n",
      "13232/13232 [==============================] - 1s 112us/step - loss: 0.1939 - val_loss: 0.1892\n",
      "Epoch 28/150\n",
      "13232/13232 [==============================] - 1s 105us/step - loss: 0.1948 - val_loss: 0.1952\n",
      "Epoch 29/150\n",
      "13232/13232 [==============================] - 1s 107us/step - loss: 0.1941 - val_loss: 0.1927\n",
      "Epoch 30/150\n",
      "13232/13232 [==============================] - 1s 113us/step - loss: 0.1930 - val_loss: 0.1920\n",
      "Epoch 31/150\n",
      "13232/13232 [==============================] - 1s 113us/step - loss: 0.1915 - val_loss: 0.1889\n",
      "Epoch 32/150\n",
      "13232/13232 [==============================] - 1s 107us/step - loss: 0.1862 - val_loss: 0.1837\n",
      "Epoch 33/150\n",
      "13232/13232 [==============================] - 1s 112us/step - loss: 0.1843 - val_loss: 0.1810\n",
      "Epoch 34/150\n",
      "13232/13232 [==============================] - 1s 113us/step - loss: 0.1840 - val_loss: 0.1770\n",
      "Epoch 35/150\n",
      "13232/13232 [==============================] - 1s 110us/step - loss: 0.1843 - val_loss: 0.1788\n",
      "Epoch 36/150\n",
      "13232/13232 [==============================] - 1s 80us/step - loss: 0.1816 - val_loss: 0.1834\n",
      "Epoch 37/150\n",
      "13232/13232 [==============================] - 1s 58us/step - loss: 0.1806 - val_loss: 0.1756\n",
      "Epoch 38/150\n",
      "13232/13232 [==============================] - 1s 95us/step - loss: 0.1816 - val_loss: 0.1814\n",
      "Epoch 39/150\n",
      "13232/13232 [==============================] - 1s 100us/step - loss: 0.1810 - val_loss: 0.1808\n",
      "Epoch 40/150\n",
      "13232/13232 [==============================] - 1s 109us/step - loss: 0.1809 - val_loss: 0.1784\n",
      "Epoch 41/150\n",
      "13232/13232 [==============================] - 1s 110us/step - loss: 0.1814 - val_loss: 0.1814\n",
      "Evaluating model with testing data...\n",
      "2814/2814 [==============================] - 0s 15us/step\n",
      "Getting distribution of predictions and covariance matrix...\n",
      "      1 of 20\n",
      "      2 of 20\n",
      "      3 of 20\n",
      "      4 of 20\n",
      "      5 of 20\n",
      "      6 of 20\n",
      "      7 of 20\n",
      "      8 of 20\n",
      "      9 of 20\n",
      "      10 of 20\n",
      "      11 of 20\n",
      "      12 of 20\n",
      "      13 of 20\n",
      "      14 of 20\n",
      "      15 of 20\n",
      "      16 of 20\n",
      "      17 of 20\n",
      "      18 of 20\n",
      "      19 of 20\n",
      "      20 of 20\n",
      "Computing ensemble means...\n",
      "Computing mean squared error...\n",
      "Iteration 92\n",
      "Train on 13372 samples, validate on 2844 samples\n",
      "Epoch 1/150\n",
      "13372/13372 [==============================] - 1s 101us/step - loss: 0.5698 - val_loss: 0.4527\n",
      "Epoch 2/150\n",
      "13372/13372 [==============================] - 1s 107us/step - loss: 0.4279 - val_loss: 0.3987\n",
      "Epoch 3/150\n",
      "13372/13372 [==============================] - 1s 106us/step - loss: 0.3633 - val_loss: 0.3373\n",
      "Epoch 4/150\n",
      "13372/13372 [==============================] - 1s 106us/step - loss: 0.3217 - val_loss: 0.3110\n",
      "Epoch 5/150\n",
      "13372/13372 [==============================] - 1s 107us/step - loss: 0.3019 - val_loss: 0.2950\n",
      "Epoch 6/150\n",
      "13372/13372 [==============================] - 1s 105us/step - loss: 0.2884 - val_loss: 0.2788\n",
      "Epoch 7/150\n",
      "13372/13372 [==============================] - 1s 109us/step - loss: 0.2694 - val_loss: 0.2606\n",
      "Epoch 8/150\n",
      "13372/13372 [==============================] - 1s 110us/step - loss: 0.2592 - val_loss: 0.2552\n",
      "Epoch 9/150\n",
      "13372/13372 [==============================] - 1s 102us/step - loss: 0.2506 - val_loss: 0.2467\n",
      "Epoch 10/150\n",
      "13372/13372 [==============================] - 1s 102us/step - loss: 0.2480 - val_loss: 0.2454\n",
      "Epoch 11/150\n",
      "13372/13372 [==============================] - 1s 109us/step - loss: 0.2458 - val_loss: 0.2485\n",
      "Epoch 12/150\n",
      "13372/13372 [==============================] - 1s 109us/step - loss: 0.2470 - val_loss: 0.2394\n",
      "Epoch 13/150\n",
      "13372/13372 [==============================] - 1s 108us/step - loss: 0.2447 - val_loss: 0.2460\n",
      "Epoch 14/150\n",
      "13372/13372 [==============================] - 1s 106us/step - loss: 0.2442 - val_loss: 0.2437\n",
      "Epoch 15/150\n",
      "13372/13372 [==============================] - 1s 105us/step - loss: 0.2408 - val_loss: 0.2275\n",
      "Epoch 16/150\n",
      "13372/13372 [==============================] - 1s 102us/step - loss: 0.2278 - val_loss: 0.2306\n",
      "Epoch 17/150\n",
      "13372/13372 [==============================] - 1s 107us/step - loss: 0.2271 - val_loss: 0.2251\n",
      "Epoch 18/150\n",
      "13372/13372 [==============================] - 1s 104us/step - loss: 0.2253 - val_loss: 0.2293\n",
      "Epoch 19/150\n",
      "13372/13372 [==============================] - 1s 107us/step - loss: 0.2217 - val_loss: 0.2220\n",
      "Epoch 20/150\n",
      "13372/13372 [==============================] - 1s 109us/step - loss: 0.2208 - val_loss: 0.2228\n",
      "Epoch 21/150\n",
      "13372/13372 [==============================] - 1s 102us/step - loss: 0.2191 - val_loss: 0.2254\n",
      "Epoch 22/150\n",
      "13372/13372 [==============================] - 1s 105us/step - loss: 0.2187 - val_loss: 0.2166\n",
      "Epoch 23/150\n",
      "13372/13372 [==============================] - 1s 107us/step - loss: 0.2156 - val_loss: 0.2079\n",
      "Epoch 24/150\n",
      "13372/13372 [==============================] - 1s 98us/step - loss: 0.2048 - val_loss: 0.2043\n",
      "Epoch 25/150\n",
      "13372/13372 [==============================] - 1s 105us/step - loss: 0.2006 - val_loss: 0.1986\n",
      "Epoch 26/150\n",
      "13372/13372 [==============================] - 1s 110us/step - loss: 0.1995 - val_loss: 0.1995\n",
      "Epoch 27/150\n",
      "13372/13372 [==============================] - 1s 106us/step - loss: 0.1963 - val_loss: 0.1988\n",
      "Epoch 28/150\n",
      "13372/13372 [==============================] - 1s 100us/step - loss: 0.1960 - val_loss: 0.1975\n",
      "Epoch 29/150\n",
      "13372/13372 [==============================] - 1s 106us/step - loss: 0.1969 - val_loss: 0.1995\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 30/150\n",
      "13372/13372 [==============================] - 1s 110us/step - loss: 0.1958 - val_loss: 0.2010\n",
      "Epoch 31/150\n",
      "13372/13372 [==============================] - 1s 111us/step - loss: 0.1937 - val_loss: 0.1941\n",
      "Epoch 32/150\n",
      "13372/13372 [==============================] - 2s 114us/step - loss: 0.1936 - val_loss: 0.1898\n",
      "Epoch 33/150\n",
      "13372/13372 [==============================] - 2s 114us/step - loss: 0.1953 - val_loss: 0.1966\n",
      "Epoch 34/150\n",
      "13372/13372 [==============================] - 2s 114us/step - loss: 0.1927 - val_loss: 0.1885\n",
      "Epoch 35/150\n",
      "13372/13372 [==============================] - 1s 111us/step - loss: 0.1923 - val_loss: 0.1960\n",
      "Epoch 36/150\n",
      "13372/13372 [==============================] - 1s 109us/step - loss: 0.1922 - val_loss: 0.1963\n",
      "Epoch 37/150\n",
      "13372/13372 [==============================] - 1s 111us/step - loss: 0.1903 - val_loss: 0.1934\n",
      "Epoch 38/150\n",
      "13372/13372 [==============================] - 2s 112us/step - loss: 0.1909 - val_loss: 0.1878\n",
      "Epoch 39/150\n",
      "13372/13372 [==============================] - 1s 111us/step - loss: 0.1895 - val_loss: 0.1937\n",
      "Epoch 40/150\n",
      "13372/13372 [==============================] - 2s 113us/step - loss: 0.1912 - val_loss: 0.1914\n",
      "Epoch 41/150\n",
      "13372/13372 [==============================] - 2s 114us/step - loss: 0.1900 - val_loss: 0.1966\n",
      "Epoch 42/150\n",
      "13372/13372 [==============================] - 2s 113us/step - loss: 0.1907 - val_loss: 0.1896\n",
      "Evaluating model with testing data...\n",
      "2844/2844 [==============================] - 0s 15us/step\n",
      "Getting distribution of predictions and covariance matrix...\n",
      "      1 of 20\n",
      "      2 of 20\n",
      "      3 of 20\n",
      "      4 of 20\n",
      "      5 of 20\n",
      "      6 of 20\n",
      "      7 of 20\n",
      "      8 of 20\n",
      "      9 of 20\n",
      "      10 of 20\n",
      "      11 of 20\n",
      "      12 of 20\n",
      "      13 of 20\n",
      "      14 of 20\n",
      "      15 of 20\n",
      "      16 of 20\n",
      "      17 of 20\n",
      "      18 of 20\n",
      "      19 of 20\n",
      "      20 of 20\n",
      "Computing ensemble means...\n",
      "Computing mean squared error...\n",
      "Iteration 93\n",
      "Train on 13512 samples, validate on 2874 samples\n",
      "Epoch 1/150\n",
      "13512/13512 [==============================] - 1s 102us/step - loss: 0.4883 - val_loss: 0.3399\n",
      "Epoch 2/150\n",
      "13512/13512 [==============================] - 2s 113us/step - loss: 0.2945 - val_loss: 0.2685\n",
      "Epoch 3/150\n",
      "13512/13512 [==============================] - 2s 116us/step - loss: 0.2489 - val_loss: 0.2382\n",
      "Epoch 4/150\n",
      "13512/13512 [==============================] - 2s 116us/step - loss: 0.2290 - val_loss: 0.2250\n",
      "Epoch 5/150\n",
      "13512/13512 [==============================] - 2s 116us/step - loss: 0.2146 - val_loss: 0.2120\n",
      "Epoch 6/150\n",
      "13512/13512 [==============================] - 2s 113us/step - loss: 0.2061 - val_loss: 0.2046\n",
      "Epoch 7/150\n",
      "13512/13512 [==============================] - 2s 116us/step - loss: 0.2010 - val_loss: 0.2014\n",
      "Epoch 8/150\n",
      "13512/13512 [==============================] - 1s 108us/step - loss: 0.1953 - val_loss: 0.1936\n",
      "Epoch 9/150\n",
      "13512/13512 [==============================] - 2s 112us/step - loss: 0.1916 - val_loss: 0.1909\n",
      "Epoch 10/150\n",
      "13512/13512 [==============================] - 2s 114us/step - loss: 0.1889 - val_loss: 0.1866\n",
      "Epoch 11/150\n",
      "13512/13512 [==============================] - 2s 114us/step - loss: 0.1883 - val_loss: 0.1905\n",
      "Epoch 12/150\n",
      "13512/13512 [==============================] - 1s 102us/step - loss: 0.1859 - val_loss: 0.1900\n",
      "Epoch 13/150\n",
      "13512/13512 [==============================] - 1s 110us/step - loss: 0.1869 - val_loss: 0.1903\n",
      "Epoch 14/150\n",
      "13512/13512 [==============================] - 2s 112us/step - loss: 0.1868 - val_loss: 0.1845\n",
      "Epoch 15/150\n",
      "13512/13512 [==============================] - 1s 107us/step - loss: 0.1866 - val_loss: 0.1881\n",
      "Epoch 16/150\n",
      "13512/13512 [==============================] - 1s 108us/step - loss: 0.1857 - val_loss: 0.1843\n",
      "Epoch 17/150\n",
      "13512/13512 [==============================] - 2s 116us/step - loss: 0.1822 - val_loss: 0.1817\n",
      "Epoch 18/150\n",
      "13512/13512 [==============================] - 2s 114us/step - loss: 0.1835 - val_loss: 0.1854\n",
      "Epoch 19/150\n",
      "13512/13512 [==============================] - 2s 112us/step - loss: 0.1842 - val_loss: 0.1845\n",
      "Epoch 20/150\n",
      "13512/13512 [==============================] - 1s 108us/step - loss: 0.1833 - val_loss: 0.1813\n",
      "Epoch 21/150\n",
      "13512/13512 [==============================] - 1s 109us/step - loss: 0.1815 - val_loss: 0.1781\n",
      "Epoch 22/150\n",
      "13512/13512 [==============================] - 1s 110us/step - loss: 0.1824 - val_loss: 0.1824\n",
      "Epoch 23/150\n",
      "13512/13512 [==============================] - 1s 108us/step - loss: 0.1822 - val_loss: 0.1876\n",
      "Epoch 24/150\n",
      "13512/13512 [==============================] - 2s 117us/step - loss: 0.1813 - val_loss: 0.1814\n",
      "Epoch 25/150\n",
      "13512/13512 [==============================] - 2s 112us/step - loss: 0.1813 - val_loss: 0.1817\n",
      "Evaluating model with testing data...\n",
      "2874/2874 [==============================] - 0s 15us/step\n",
      "Getting distribution of predictions and covariance matrix...\n",
      "      1 of 20\n",
      "      2 of 20\n",
      "      3 of 20\n",
      "      4 of 20\n",
      "      5 of 20\n",
      "      6 of 20\n",
      "      7 of 20\n",
      "      8 of 20\n",
      "      9 of 20\n",
      "      10 of 20\n",
      "      11 of 20\n",
      "      12 of 20\n",
      "      13 of 20\n",
      "      14 of 20\n",
      "      15 of 20\n",
      "      16 of 20\n",
      "      17 of 20\n",
      "      18 of 20\n",
      "      19 of 20\n",
      "      20 of 20\n",
      "Computing ensemble means...\n",
      "Computing mean squared error...\n",
      "Iteration 94\n",
      "Train on 13652 samples, validate on 2904 samples\n",
      "Epoch 1/150\n",
      "13652/13652 [==============================] - 1s 108us/step - loss: 0.4113 - val_loss: 0.2657\n",
      "Epoch 2/150\n",
      "13652/13652 [==============================] - 1s 109us/step - loss: 0.2290 - val_loss: 0.2070\n",
      "Epoch 3/150\n",
      "13652/13652 [==============================] - 1s 110us/step - loss: 0.1969 - val_loss: 0.1876\n",
      "Epoch 4/150\n",
      "13652/13652 [==============================] - 1s 109us/step - loss: 0.1834 - val_loss: 0.1818\n",
      "Epoch 5/150\n",
      "13652/13652 [==============================] - 2s 110us/step - loss: 0.1740 - val_loss: 0.1723\n",
      "Epoch 6/150\n",
      "13652/13652 [==============================] - 2s 111us/step - loss: 0.1638 - val_loss: 0.1610\n",
      "Epoch 7/150\n",
      "13652/13652 [==============================] - 1s 72us/step - loss: 0.1592 - val_loss: 0.1579\n",
      "Epoch 8/150\n",
      "13652/13652 [==============================] - 1s 59us/step - loss: 0.1548 - val_loss: 0.1572\n",
      "Epoch 9/150\n",
      "13652/13652 [==============================] - 1s 102us/step - loss: 0.1504 - val_loss: 0.1521\n",
      "Epoch 10/150\n",
      "13652/13652 [==============================] - 1s 98us/step - loss: 0.1461 - val_loss: 0.1464\n",
      "Epoch 11/150\n",
      "13652/13652 [==============================] - 1s 110us/step - loss: 0.1432 - val_loss: 0.1448\n",
      "Epoch 12/150\n",
      "13652/13652 [==============================] - 1s 107us/step - loss: 0.1393 - val_loss: 0.1399\n",
      "Epoch 13/150\n",
      "13652/13652 [==============================] - 1s 103us/step - loss: 0.1352 - val_loss: 0.1327\n",
      "Epoch 14/150\n",
      "13652/13652 [==============================] - 1s 106us/step - loss: 0.1326 - val_loss: 0.1316\n",
      "Epoch 15/150\n",
      "13652/13652 [==============================] - 1s 106us/step - loss: 0.1304 - val_loss: 0.1300\n",
      "Epoch 16/150\n",
      "13652/13652 [==============================] - 2s 112us/step - loss: 0.1289 - val_loss: 0.1310\n",
      "Epoch 17/150\n",
      "13652/13652 [==============================] - 1s 107us/step - loss: 0.1272 - val_loss: 0.1244\n",
      "Epoch 18/150\n",
      "13652/13652 [==============================] - 1s 107us/step - loss: 0.1237 - val_loss: 0.1251\n",
      "Epoch 19/150\n",
      "13652/13652 [==============================] - 2s 113us/step - loss: 0.1224 - val_loss: 0.1231\n",
      "Epoch 20/150\n",
      "13652/13652 [==============================] - 1s 103us/step - loss: 0.1226 - val_loss: 0.1224\n",
      "Epoch 21/150\n",
      "13652/13652 [==============================] - 1s 108us/step - loss: 0.1213 - val_loss: 0.1200\n",
      "Epoch 22/150\n",
      "13652/13652 [==============================] - 1s 104us/step - loss: 0.1177 - val_loss: 0.1181\n",
      "Epoch 23/150\n",
      "13652/13652 [==============================] - 1s 105us/step - loss: 0.1169 - val_loss: 0.1178\n",
      "Epoch 24/150\n",
      "13652/13652 [==============================] - 1s 106us/step - loss: 0.1154 - val_loss: 0.1165\n",
      "Epoch 25/150\n",
      "13652/13652 [==============================] - 1s 104us/step - loss: 0.1155 - val_loss: 0.1157\n",
      "Epoch 26/150\n",
      "13652/13652 [==============================] - 2s 113us/step - loss: 0.1141 - val_loss: 0.1166\n",
      "Epoch 27/150\n",
      "13652/13652 [==============================] - 1s 99us/step - loss: 0.1125 - val_loss: 0.1123\n",
      "Epoch 28/150\n",
      "13652/13652 [==============================] - 2s 112us/step - loss: 0.1125 - val_loss: 0.1139\n",
      "Epoch 29/150\n",
      "13652/13652 [==============================] - 2s 116us/step - loss: 0.1116 - val_loss: 0.1110\n",
      "Epoch 30/150\n",
      "13652/13652 [==============================] - 2s 115us/step - loss: 0.1097 - val_loss: 0.1143\n",
      "Epoch 31/150\n",
      "13652/13652 [==============================] - 2s 116us/step - loss: 0.1104 - val_loss: 0.1106\n",
      "Epoch 32/150\n",
      "13652/13652 [==============================] - 2s 110us/step - loss: 0.1071 - val_loss: 0.1082\n",
      "Epoch 33/150\n",
      "13652/13652 [==============================] - 2s 116us/step - loss: 0.1063 - val_loss: 0.1118\n",
      "Epoch 34/150\n",
      "13652/13652 [==============================] - 2s 115us/step - loss: 0.1061 - val_loss: 0.1073\n",
      "Epoch 35/150\n",
      "13652/13652 [==============================] - 2s 114us/step - loss: 0.1043 - val_loss: 0.1084\n",
      "Epoch 36/150\n",
      "13652/13652 [==============================] - 2s 116us/step - loss: 0.1046 - val_loss: 0.1045\n",
      "Epoch 37/150\n",
      "13652/13652 [==============================] - 2s 116us/step - loss: 0.1026 - val_loss: 0.1039\n",
      "Epoch 38/150\n",
      "13652/13652 [==============================] - 2s 112us/step - loss: 0.1023 - val_loss: 0.1009\n",
      "Epoch 39/150\n",
      "13652/13652 [==============================] - 2s 116us/step - loss: 0.1013 - val_loss: 0.1023\n",
      "Epoch 40/150\n",
      "13652/13652 [==============================] - 1s 108us/step - loss: 0.0991 - val_loss: 0.1003\n",
      "Epoch 41/150\n",
      "13652/13652 [==============================] - 1s 104us/step - loss: 0.0993 - val_loss: 0.1018\n",
      "Epoch 42/150\n",
      "13652/13652 [==============================] - 2s 116us/step - loss: 0.0997 - val_loss: 0.0996\n",
      "Epoch 43/150\n",
      "13652/13652 [==============================] - 2s 116us/step - loss: 0.0982 - val_loss: 0.1014\n",
      "Epoch 44/150\n",
      "13652/13652 [==============================] - 2s 110us/step - loss: 0.0972 - val_loss: 0.1008\n",
      "Epoch 45/150\n",
      "13652/13652 [==============================] - 2s 116us/step - loss: 0.0965 - val_loss: 0.0982\n",
      "Epoch 46/150\n",
      "13652/13652 [==============================] - 2s 116us/step - loss: 0.0966 - val_loss: 0.0980\n",
      "Epoch 47/150\n",
      "13652/13652 [==============================] - 1s 109us/step - loss: 0.0961 - val_loss: 0.0967\n",
      "Epoch 48/150\n",
      "13652/13652 [==============================] - 2s 116us/step - loss: 0.0967 - val_loss: 0.0958\n",
      "Epoch 49/150\n",
      "13652/13652 [==============================] - 2s 112us/step - loss: 0.0938 - val_loss: 0.0974\n",
      "Epoch 50/150\n",
      "13652/13652 [==============================] - 2s 113us/step - loss: 0.0961 - val_loss: 0.0962\n",
      "Epoch 51/150\n",
      "13652/13652 [==============================] - 2s 113us/step - loss: 0.0953 - val_loss: 0.0960\n",
      "Epoch 52/150\n",
      "13652/13652 [==============================] - 2s 114us/step - loss: 0.0956 - val_loss: 0.0964\n",
      "Evaluating model with testing data...\n",
      "2904/2904 [==============================] - 0s 15us/step\n",
      "Getting distribution of predictions and covariance matrix...\n",
      "      1 of 20\n",
      "      2 of 20\n",
      "      3 of 20\n",
      "      4 of 20\n",
      "      5 of 20\n",
      "      6 of 20\n",
      "      7 of 20\n",
      "      8 of 20\n",
      "      9 of 20\n",
      "      10 of 20\n",
      "      11 of 20\n",
      "      12 of 20\n",
      "      13 of 20\n",
      "      14 of 20\n",
      "      15 of 20\n",
      "      16 of 20\n",
      "      17 of 20\n",
      "      18 of 20\n",
      "      19 of 20\n",
      "      20 of 20\n",
      "Computing ensemble means...\n",
      "Computing mean squared error...\n",
      "Iteration 95\n",
      "Train on 13792 samples, validate on 2934 samples\n",
      "Epoch 1/150\n",
      "13792/13792 [==============================] - 1s 107us/step - loss: 0.5141 - val_loss: 0.4062\n",
      "Epoch 2/150\n",
      "13792/13792 [==============================] - 2s 109us/step - loss: 0.3769 - val_loss: 0.3596\n",
      "Epoch 3/150\n",
      "13792/13792 [==============================] - 1s 105us/step - loss: 0.3519 - val_loss: 0.3456\n",
      "Epoch 4/150\n",
      "13792/13792 [==============================] - 2s 109us/step - loss: 0.3396 - val_loss: 0.3344\n",
      "Epoch 5/150\n",
      "13792/13792 [==============================] - 1s 103us/step - loss: 0.3288 - val_loss: 0.3243\n",
      "Epoch 6/150\n",
      "13792/13792 [==============================] - 2s 110us/step - loss: 0.3207 - val_loss: 0.3170\n",
      "Epoch 7/150\n",
      "13792/13792 [==============================] - 2s 112us/step - loss: 0.3136 - val_loss: 0.3106\n",
      "Epoch 8/150\n",
      "13792/13792 [==============================] - 2s 111us/step - loss: 0.2899 - val_loss: 0.2755\n",
      "Epoch 9/150\n",
      "13792/13792 [==============================] - 2s 111us/step - loss: 0.2611 - val_loss: 0.2447\n",
      "Epoch 10/150\n",
      "13792/13792 [==============================] - 1s 106us/step - loss: 0.2342 - val_loss: 0.2379\n",
      "Epoch 11/150\n",
      "13792/13792 [==============================] - 1s 96us/step - loss: 0.2310 - val_loss: 0.2298\n",
      "Epoch 12/150\n",
      "13792/13792 [==============================] - 2s 110us/step - loss: 0.2281 - val_loss: 0.2301\n",
      "Epoch 13/150\n",
      "13792/13792 [==============================] - 1s 104us/step - loss: 0.2248 - val_loss: 0.2318\n",
      "Epoch 14/150\n",
      "13792/13792 [==============================] - 1s 104us/step - loss: 0.2253 - val_loss: 0.2266\n",
      "Epoch 15/150\n",
      "13792/13792 [==============================] - 2s 110us/step - loss: 0.2227 - val_loss: 0.2265\n",
      "Epoch 16/150\n",
      "13792/13792 [==============================] - 1s 106us/step - loss: 0.2216 - val_loss: 0.2219\n",
      "Epoch 17/150\n",
      "13792/13792 [==============================] - 1s 104us/step - loss: 0.2152 - val_loss: 0.2120\n",
      "Epoch 18/150\n",
      "13792/13792 [==============================] - 1s 108us/step - loss: 0.2002 - val_loss: 0.1970\n",
      "Epoch 19/150\n",
      "13792/13792 [==============================] - 2s 111us/step - loss: 0.1949 - val_loss: 0.1895\n",
      "Epoch 20/150\n",
      "13792/13792 [==============================] - 1s 107us/step - loss: 0.1932 - val_loss: 0.1934\n",
      "Epoch 21/150\n",
      "13792/13792 [==============================] - 2s 109us/step - loss: 0.1880 - val_loss: 0.1943\n",
      "Epoch 22/150\n",
      "13792/13792 [==============================] - 2s 109us/step - loss: 0.1888 - val_loss: 0.1921\n",
      "Epoch 23/150\n",
      "13792/13792 [==============================] - 1s 107us/step - loss: 0.1886 - val_loss: 0.1920\n",
      "Evaluating model with testing data...\n",
      "2934/2934 [==============================] - 0s 15us/step\n",
      "Getting distribution of predictions and covariance matrix...\n",
      "      1 of 20\n",
      "      2 of 20\n",
      "      3 of 20\n",
      "      4 of 20\n",
      "      5 of 20\n",
      "      6 of 20\n",
      "      7 of 20\n",
      "      8 of 20\n",
      "      9 of 20\n",
      "      10 of 20\n",
      "      11 of 20\n",
      "      12 of 20\n",
      "      13 of 20\n",
      "      14 of 20\n",
      "      15 of 20\n",
      "      16 of 20\n",
      "      17 of 20\n",
      "      18 of 20\n",
      "      19 of 20\n",
      "      20 of 20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|          | 0/20 [00:00<?, ?it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing ensemble means...\n",
      "Computing mean squared error...\n",
      "Getting distribution of predictions...\n",
      "      1 of 20\n",
      "1600/1600 [==============================] - 0s 27us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  5%|▌         | 1/20 [00:29<09:21, 29.54s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      2 of 20\n",
      "1600/1600 [==============================] - 0s 29us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 10%|█         | 2/20 [00:58<08:51, 29.50s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      3 of 20\n",
      "1600/1600 [==============================] - 0s 29us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 15%|█▌        | 3/20 [01:28<08:23, 29.60s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      4 of 20\n",
      "1600/1600 [==============================] - 0s 29us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 20%|██        | 4/20 [01:58<07:53, 29.59s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      5 of 20\n",
      "1600/1600 [==============================] - 0s 29us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 25%|██▌       | 5/20 [02:27<07:22, 29.52s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      6 of 20\n",
      "1600/1600 [==============================] - 0s 28us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 30%|███       | 6/20 [02:57<06:52, 29.49s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      7 of 20\n",
      "1600/1600 [==============================] - 0s 29us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 35%|███▌      | 7/20 [03:26<06:24, 29.55s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      8 of 20\n",
      "1600/1600 [==============================] - 0s 29us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 40%|████      | 8/20 [03:56<05:55, 29.58s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      9 of 20\n",
      "1600/1600 [==============================] - 0s 28us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 45%|████▌     | 9/20 [04:25<05:25, 29.55s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      10 of 20\n",
      "1600/1600 [==============================] - 0s 30us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 50%|█████     | 10/20 [04:55<04:55, 29.54s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      11 of 20\n",
      "1600/1600 [==============================] - 0s 29us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 55%|█████▌    | 11/20 [05:25<04:27, 29.67s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      12 of 20\n",
      "1600/1600 [==============================] - 0s 28us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 60%|██████    | 12/20 [05:55<03:57, 29.74s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      13 of 20\n",
      "1600/1600 [==============================] - 0s 29us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 65%|██████▌   | 13/20 [06:24<03:27, 29.61s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      14 of 20\n",
      "1600/1600 [==============================] - 0s 29us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 70%|███████   | 14/20 [06:54<02:57, 29.55s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      15 of 20\n",
      "1600/1600 [==============================] - 0s 29us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 75%|███████▌  | 15/20 [07:23<02:27, 29.47s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      16 of 20\n",
      "1600/1600 [==============================] - 0s 29us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 80%|████████  | 16/20 [07:53<01:58, 29.57s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      17 of 20\n",
      "1600/1600 [==============================] - 0s 28us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 85%|████████▌ | 17/20 [08:22<01:28, 29.53s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      18 of 20\n",
      "1600/1600 [==============================] - 0s 29us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 90%|█████████ | 18/20 [08:52<00:59, 29.62s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      19 of 20\n",
      "1600/1600 [==============================] - 0s 29us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 95%|█████████▌| 19/20 [09:21<00:29, 29.59s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      20 of 20\n",
      "1600/1600 [==============================] - 0s 30us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 20/20 [09:51<00:00, 29.59s/it]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing ensemble predictions...\n",
      "Iteration 96\n",
      "Train on 13932 samples, validate on 2964 samples\n",
      "Epoch 1/150\n",
      "13932/13932 [==============================] - 2s 111us/step - loss: 0.3625 - val_loss: 0.2477\n",
      "Epoch 2/150\n",
      "13932/13932 [==============================] - 2s 112us/step - loss: 0.2132 - val_loss: 0.1905\n",
      "Epoch 3/150\n",
      "13932/13932 [==============================] - 2s 113us/step - loss: 0.1816 - val_loss: 0.1747\n",
      "Epoch 4/150\n",
      "13932/13932 [==============================] - 2s 113us/step - loss: 0.1685 - val_loss: 0.1658\n",
      "Epoch 5/150\n",
      "13932/13932 [==============================] - 1s 104us/step - loss: 0.1565 - val_loss: 0.1513\n",
      "Epoch 6/150\n",
      "13932/13932 [==============================] - 1s 103us/step - loss: 0.1492 - val_loss: 0.1464\n",
      "Epoch 7/150\n",
      "13932/13932 [==============================] - 2s 114us/step - loss: 0.1394 - val_loss: 0.1421\n",
      "Epoch 8/150\n",
      "13932/13932 [==============================] - 2s 112us/step - loss: 0.1372 - val_loss: 0.1366\n",
      "Epoch 9/150\n",
      "13932/13932 [==============================] - 1s 103us/step - loss: 0.1310 - val_loss: 0.1333\n",
      "Epoch 10/150\n",
      "13932/13932 [==============================] - 2s 112us/step - loss: 0.1286 - val_loss: 0.1247\n",
      "Epoch 11/150\n",
      "13932/13932 [==============================] - 1s 107us/step - loss: 0.1237 - val_loss: 0.1261\n",
      "Epoch 12/150\n",
      "13932/13932 [==============================] - 2s 114us/step - loss: 0.1232 - val_loss: 0.1233\n",
      "Epoch 13/150\n",
      "13932/13932 [==============================] - 2s 108us/step - loss: 0.1217 - val_loss: 0.1249\n",
      "Epoch 14/150\n",
      "13932/13932 [==============================] - 2s 112us/step - loss: 0.1208 - val_loss: 0.1246\n",
      "Epoch 15/150\n",
      "13932/13932 [==============================] - 1s 92us/step - loss: 0.1183 - val_loss: 0.1229\n",
      "Epoch 16/150\n",
      "13932/13932 [==============================] - 1s 59us/step - loss: 0.1167 - val_loss: 0.1178\n",
      "Epoch 17/150\n",
      "13932/13932 [==============================] - 1s 79us/step - loss: 0.1185 - val_loss: 0.1212\n",
      "Epoch 18/150\n",
      "13932/13932 [==============================] - 2s 108us/step - loss: 0.1147 - val_loss: 0.1188\n",
      "Epoch 19/150\n",
      "13932/13932 [==============================] - 2s 109us/step - loss: 0.1158 - val_loss: 0.1155\n",
      "Epoch 20/150\n",
      "13932/13932 [==============================] - 2s 111us/step - loss: 0.1129 - val_loss: 0.1162\n",
      "Epoch 21/150\n",
      "13932/13932 [==============================] - 2s 112us/step - loss: 0.1114 - val_loss: 0.1144\n",
      "Epoch 22/150\n",
      "13932/13932 [==============================] - 2s 111us/step - loss: 0.1111 - val_loss: 0.1162\n",
      "Epoch 23/150\n",
      "13932/13932 [==============================] - 1s 103us/step - loss: 0.1092 - val_loss: 0.1133\n",
      "Epoch 24/150\n",
      "13932/13932 [==============================] - 2s 109us/step - loss: 0.1090 - val_loss: 0.1140\n",
      "Epoch 25/150\n",
      "13932/13932 [==============================] - 2s 114us/step - loss: 0.1092 - val_loss: 0.1094\n",
      "Epoch 26/150\n",
      "13932/13932 [==============================] - 2s 114us/step - loss: 0.1061 - val_loss: 0.1077\n",
      "Epoch 27/150\n",
      "13932/13932 [==============================] - 2s 109us/step - loss: 0.1062 - val_loss: 0.1084\n",
      "Epoch 28/150\n",
      "13932/13932 [==============================] - 2s 111us/step - loss: 0.1052 - val_loss: 0.1064\n",
      "Epoch 29/150\n",
      "13932/13932 [==============================] - 2s 112us/step - loss: 0.1052 - val_loss: 0.1101\n",
      "Epoch 30/150\n",
      "13932/13932 [==============================] - 2s 114us/step - loss: 0.1046 - val_loss: 0.1078\n",
      "Epoch 31/150\n",
      "13932/13932 [==============================] - 1s 105us/step - loss: 0.1034 - val_loss: 0.1046\n",
      "Epoch 32/150\n",
      "13932/13932 [==============================] - 2s 109us/step - loss: 0.1043 - val_loss: 0.1090\n",
      "Epoch 33/150\n",
      "13932/13932 [==============================] - 1s 107us/step - loss: 0.1024 - val_loss: 0.1087\n",
      "Epoch 34/150\n",
      "13932/13932 [==============================] - 2s 113us/step - loss: 0.1028 - val_loss: 0.1068\n",
      "Epoch 35/150\n",
      "13932/13932 [==============================] - 1s 106us/step - loss: 0.1001 - val_loss: 0.1031\n",
      "Epoch 36/150\n",
      "13932/13932 [==============================] - 2s 110us/step - loss: 0.1020 - val_loss: 0.1045\n",
      "Epoch 37/150\n",
      "13932/13932 [==============================] - 2s 109us/step - loss: 0.1014 - val_loss: 0.1016\n",
      "Epoch 38/150\n",
      "13932/13932 [==============================] - 2s 110us/step - loss: 0.1007 - val_loss: 0.1035\n",
      "Epoch 39/150\n",
      "13932/13932 [==============================] - 1s 106us/step - loss: 0.0998 - val_loss: 0.1026\n",
      "Epoch 40/150\n",
      "13932/13932 [==============================] - 1s 107us/step - loss: 0.1003 - val_loss: 0.1052\n",
      "Epoch 41/150\n",
      "13932/13932 [==============================] - 1s 107us/step - loss: 0.0997 - val_loss: 0.1030\n",
      "Evaluating model with testing data...\n",
      "2964/2964 [==============================] - 0s 15us/step\n",
      "Getting distribution of predictions and covariance matrix...\n",
      "      1 of 20\n",
      "      2 of 20\n",
      "      3 of 20\n",
      "      4 of 20\n",
      "      5 of 20\n",
      "      6 of 20\n",
      "      7 of 20\n",
      "      8 of 20\n",
      "      9 of 20\n",
      "      10 of 20\n",
      "      11 of 20\n",
      "      12 of 20\n",
      "      13 of 20\n",
      "      14 of 20\n",
      "      15 of 20\n",
      "      16 of 20\n",
      "      17 of 20\n",
      "      18 of 20\n",
      "      19 of 20\n",
      "      20 of 20\n",
      "Computing ensemble means...\n",
      "Computing mean squared error...\n",
      "Iteration 97\n",
      "Train on 14072 samples, validate on 2994 samples\n",
      "Epoch 1/150\n",
      "14072/14072 [==============================] - 2s 109us/step - loss: 0.4144 - val_loss: 0.2855\n",
      "Epoch 2/150\n",
      "14072/14072 [==============================] - 2s 113us/step - loss: 0.2505 - val_loss: 0.2319\n",
      "Epoch 3/150\n",
      "14072/14072 [==============================] - 2s 107us/step - loss: 0.2178 - val_loss: 0.2068\n",
      "Epoch 4/150\n",
      "14072/14072 [==============================] - 2s 108us/step - loss: 0.1989 - val_loss: 0.1966\n",
      "Epoch 5/150\n",
      "14072/14072 [==============================] - 2s 107us/step - loss: 0.1902 - val_loss: 0.1908\n",
      "Epoch 6/150\n",
      "14072/14072 [==============================] - 2s 108us/step - loss: 0.1838 - val_loss: 0.1819\n",
      "Epoch 7/150\n",
      "14072/14072 [==============================] - 2s 110us/step - loss: 0.1769 - val_loss: 0.1768\n",
      "Epoch 8/150\n",
      "14072/14072 [==============================] - 1s 105us/step - loss: 0.1718 - val_loss: 0.1712\n",
      "Epoch 9/150\n",
      "14072/14072 [==============================] - 2s 109us/step - loss: 0.1677 - val_loss: 0.1683\n",
      "Epoch 10/150\n",
      "14072/14072 [==============================] - 2s 108us/step - loss: 0.1631 - val_loss: 0.1647\n",
      "Epoch 11/150\n",
      "14072/14072 [==============================] - 2s 109us/step - loss: 0.1595 - val_loss: 0.1651\n",
      "Epoch 12/150\n",
      "14072/14072 [==============================] - 1s 106us/step - loss: 0.1591 - val_loss: 0.1676\n",
      "Epoch 13/150\n",
      "14072/14072 [==============================] - 1s 105us/step - loss: 0.1551 - val_loss: 0.1568\n",
      "Epoch 14/150\n",
      "14072/14072 [==============================] - 2s 110us/step - loss: 0.1558 - val_loss: 0.1576\n",
      "Epoch 15/150\n",
      "14072/14072 [==============================] - 2s 108us/step - loss: 0.1546 - val_loss: 0.1573\n",
      "Epoch 16/150\n",
      "14072/14072 [==============================] - 1s 103us/step - loss: 0.1530 - val_loss: 0.1557\n",
      "Epoch 17/150\n",
      "14072/14072 [==============================] - 1s 103us/step - loss: 0.1501 - val_loss: 0.1585\n",
      "Epoch 18/150\n",
      "14072/14072 [==============================] - 1s 103us/step - loss: 0.1517 - val_loss: 0.1563\n",
      "Epoch 19/150\n",
      "14072/14072 [==============================] - 1s 106us/step - loss: 0.1493 - val_loss: 0.1548\n",
      "Epoch 20/150\n",
      "14072/14072 [==============================] - 1s 105us/step - loss: 0.1496 - val_loss: 0.1498\n",
      "Epoch 21/150\n",
      "14072/14072 [==============================] - 2s 110us/step - loss: 0.1464 - val_loss: 0.1504\n",
      "Epoch 22/150\n",
      "14072/14072 [==============================] - 1s 100us/step - loss: 0.1457 - val_loss: 0.1490\n",
      "Epoch 23/150\n",
      "14072/14072 [==============================] - 1s 101us/step - loss: 0.1465 - val_loss: 0.1460\n",
      "Epoch 24/150\n",
      "14072/14072 [==============================] - 1s 103us/step - loss: 0.1440 - val_loss: 0.1480\n",
      "Epoch 25/150\n",
      "14072/14072 [==============================] - 1s 101us/step - loss: 0.1436 - val_loss: 0.1485\n",
      "Epoch 26/150\n",
      "14072/14072 [==============================] - 1s 105us/step - loss: 0.1440 - val_loss: 0.1462\n",
      "Epoch 27/150\n",
      "14072/14072 [==============================] - 1s 105us/step - loss: 0.1425 - val_loss: 0.1423\n",
      "Epoch 28/150\n",
      "14072/14072 [==============================] - 1s 103us/step - loss: 0.1426 - val_loss: 0.1489\n",
      "Epoch 29/150\n",
      "14072/14072 [==============================] - 1s 105us/step - loss: 0.1416 - val_loss: 0.1447\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 30/150\n",
      "14072/14072 [==============================] - 2s 109us/step - loss: 0.1432 - val_loss: 0.1492\n",
      "Epoch 31/150\n",
      "14072/14072 [==============================] - 2s 113us/step - loss: 0.1404 - val_loss: 0.1476\n",
      "Evaluating model with testing data...\n",
      "2994/2994 [==============================] - 0s 15us/step\n",
      "Getting distribution of predictions and covariance matrix...\n",
      "      1 of 20\n",
      "      2 of 20\n",
      "      3 of 20\n",
      "      4 of 20\n",
      "      5 of 20\n",
      "      6 of 20\n",
      "      7 of 20\n",
      "      8 of 20\n",
      "      9 of 20\n",
      "      10 of 20\n",
      "      11 of 20\n",
      "      12 of 20\n",
      "      13 of 20\n",
      "      14 of 20\n",
      "      15 of 20\n",
      "      16 of 20\n",
      "      17 of 20\n",
      "      18 of 20\n",
      "      19 of 20\n",
      "      20 of 20\n",
      "Computing ensemble means...\n",
      "Computing mean squared error...\n",
      "Iteration 98\n",
      "Train on 14212 samples, validate on 3024 samples\n",
      "Epoch 1/150\n",
      "14212/14212 [==============================] - 2s 114us/step - loss: 0.4280 - val_loss: 0.3003\n",
      "Epoch 2/150\n",
      "14212/14212 [==============================] - 2s 111us/step - loss: 0.2663 - val_loss: 0.2434\n",
      "Epoch 3/150\n",
      "14212/14212 [==============================] - 2s 114us/step - loss: 0.2364 - val_loss: 0.2265\n",
      "Epoch 4/150\n",
      "14212/14212 [==============================] - 2s 109us/step - loss: 0.2233 - val_loss: 0.2144\n",
      "Epoch 5/150\n",
      "14212/14212 [==============================] - 2s 111us/step - loss: 0.2099 - val_loss: 0.2131\n",
      "Epoch 6/150\n",
      "14212/14212 [==============================] - 2s 114us/step - loss: 0.2057 - val_loss: 0.2079\n",
      "Epoch 7/150\n",
      "14212/14212 [==============================] - 2s 114us/step - loss: 0.1944 - val_loss: 0.1949\n",
      "Epoch 8/150\n",
      "14212/14212 [==============================] - 2s 114us/step - loss: 0.1858 - val_loss: 0.1879\n",
      "Epoch 9/150\n",
      "14212/14212 [==============================] - 2s 114us/step - loss: 0.1826 - val_loss: 0.1814\n",
      "Epoch 10/150\n",
      "14212/14212 [==============================] - 2s 114us/step - loss: 0.1786 - val_loss: 0.1763\n",
      "Epoch 11/150\n",
      "14212/14212 [==============================] - 2s 112us/step - loss: 0.1735 - val_loss: 0.1742\n",
      "Epoch 12/150\n",
      "14212/14212 [==============================] - 2s 114us/step - loss: 0.1709 - val_loss: 0.1690\n",
      "Epoch 13/150\n",
      "14212/14212 [==============================] - 2s 114us/step - loss: 0.1658 - val_loss: 0.1691\n",
      "Epoch 14/150\n",
      "14212/14212 [==============================] - 1s 103us/step - loss: 0.1641 - val_loss: 0.1601\n",
      "Epoch 15/150\n",
      "14212/14212 [==============================] - 2s 114us/step - loss: 0.1604 - val_loss: 0.1600\n",
      "Epoch 16/150\n",
      "14212/14212 [==============================] - 2s 114us/step - loss: 0.1583 - val_loss: 0.1624\n",
      "Epoch 17/150\n",
      "14212/14212 [==============================] - 2s 113us/step - loss: 0.1587 - val_loss: 0.1604\n",
      "Epoch 18/150\n",
      "14212/14212 [==============================] - 2s 112us/step - loss: 0.1554 - val_loss: 0.1601\n",
      "Epoch 19/150\n",
      "14212/14212 [==============================] - 2s 113us/step - loss: 0.1584 - val_loss: 0.1608\n",
      "Evaluating model with testing data...\n",
      "3024/3024 [==============================] - 0s 15us/step\n",
      "Getting distribution of predictions and covariance matrix...\n",
      "      1 of 20\n",
      "      2 of 20\n",
      "      3 of 20\n",
      "      4 of 20\n",
      "      5 of 20\n",
      "      6 of 20\n",
      "      7 of 20\n",
      "      8 of 20\n",
      "      9 of 20\n",
      "      10 of 20\n",
      "      11 of 20\n",
      "      12 of 20\n",
      "      13 of 20\n",
      "      14 of 20\n",
      "      15 of 20\n",
      "      16 of 20\n",
      "      17 of 20\n",
      "      18 of 20\n",
      "      19 of 20\n",
      "      20 of 20\n",
      "Computing ensemble means...\n",
      "Computing mean squared error...\n",
      "Iteration 99\n",
      "Train on 14352 samples, validate on 3054 samples\n",
      "Epoch 1/150\n",
      "14352/14352 [==============================] - 1s 98us/step - loss: 0.4600 - val_loss: 0.3048\n",
      "Epoch 2/150\n",
      "14352/14352 [==============================] - 2s 109us/step - loss: 0.2716 - val_loss: 0.2475\n",
      "Epoch 3/150\n",
      "14352/14352 [==============================] - 2s 108us/step - loss: 0.2330 - val_loss: 0.2179\n",
      "Epoch 4/150\n",
      "14352/14352 [==============================] - 2s 111us/step - loss: 0.2132 - val_loss: 0.2097\n",
      "Epoch 5/150\n",
      "14352/14352 [==============================] - 2s 111us/step - loss: 0.1973 - val_loss: 0.1923\n",
      "Epoch 6/150\n",
      "14352/14352 [==============================] - 2s 112us/step - loss: 0.1872 - val_loss: 0.1892\n",
      "Epoch 7/150\n",
      "14352/14352 [==============================] - 2s 115us/step - loss: 0.1775 - val_loss: 0.1722\n",
      "Epoch 8/150\n",
      "14352/14352 [==============================] - 2s 113us/step - loss: 0.1693 - val_loss: 0.1681\n",
      "Epoch 9/150\n",
      "14352/14352 [==============================] - 2s 112us/step - loss: 0.1622 - val_loss: 0.1611\n",
      "Epoch 10/150\n",
      "14352/14352 [==============================] - 2s 112us/step - loss: 0.1583 - val_loss: 0.1572\n",
      "Epoch 11/150\n",
      "14352/14352 [==============================] - 2s 113us/step - loss: 0.1529 - val_loss: 0.1554\n",
      "Epoch 12/150\n",
      "14352/14352 [==============================] - 2s 111us/step - loss: 0.1499 - val_loss: 0.1498\n",
      "Epoch 13/150\n",
      "14352/14352 [==============================] - 2s 110us/step - loss: 0.1464 - val_loss: 0.1509\n",
      "Epoch 14/150\n",
      "14352/14352 [==============================] - 1s 104us/step - loss: 0.1469 - val_loss: 0.1447\n",
      "Epoch 15/150\n",
      "14352/14352 [==============================] - 2s 109us/step - loss: 0.1425 - val_loss: 0.1460\n",
      "Epoch 16/150\n",
      "14352/14352 [==============================] - 2s 108us/step - loss: 0.1434 - val_loss: 0.1490\n",
      "Epoch 17/150\n",
      "14352/14352 [==============================] - 2s 108us/step - loss: 0.1431 - val_loss: 0.1437\n",
      "Epoch 18/150\n",
      "14352/14352 [==============================] - 1s 100us/step - loss: 0.1415 - val_loss: 0.1425\n",
      "Epoch 19/150\n",
      "14352/14352 [==============================] - 2s 107us/step - loss: 0.1398 - val_loss: 0.1418\n",
      "Epoch 20/150\n",
      "14352/14352 [==============================] - 2s 110us/step - loss: 0.1393 - val_loss: 0.1424\n",
      "Epoch 21/150\n",
      "14352/14352 [==============================] - 2s 107us/step - loss: 0.1391 - val_loss: 0.1393\n",
      "Epoch 22/150\n",
      "14352/14352 [==============================] - 2s 105us/step - loss: 0.1399 - val_loss: 0.1381\n",
      "Epoch 23/150\n",
      "14352/14352 [==============================] - 1s 104us/step - loss: 0.1367 - val_loss: 0.1423\n",
      "Epoch 24/150\n",
      "14352/14352 [==============================] - 2s 108us/step - loss: 0.1364 - val_loss: 0.1376\n",
      "Epoch 25/150\n",
      "14352/14352 [==============================] - 1s 104us/step - loss: 0.1380 - val_loss: 0.1384\n",
      "Epoch 26/150\n",
      "14352/14352 [==============================] - 2s 109us/step - loss: 0.1370 - val_loss: 0.1396\n",
      "Epoch 27/150\n",
      "14352/14352 [==============================] - 2s 108us/step - loss: 0.1356 - val_loss: 0.1368\n",
      "Epoch 28/150\n",
      "14352/14352 [==============================] - 1s 102us/step - loss: 0.1333 - val_loss: 0.1343\n",
      "Epoch 29/150\n",
      "14352/14352 [==============================] - 2s 109us/step - loss: 0.1341 - val_loss: 0.1373\n",
      "Epoch 30/150\n",
      "14352/14352 [==============================] - 2s 110us/step - loss: 0.1312 - val_loss: 0.1320\n",
      "Epoch 31/150\n",
      "14352/14352 [==============================] - 1s 104us/step - loss: 0.1307 - val_loss: 0.1334\n",
      "Epoch 32/150\n",
      "14352/14352 [==============================] - 1s 104us/step - loss: 0.1320 - val_loss: 0.1314\n",
      "Epoch 33/150\n",
      "14352/14352 [==============================] - 1s 101us/step - loss: 0.1301 - val_loss: 0.1303\n",
      "Epoch 34/150\n",
      "14352/14352 [==============================] - 1s 103us/step - loss: 0.1296 - val_loss: 0.1288\n",
      "Epoch 35/150\n",
      "14352/14352 [==============================] - 2s 105us/step - loss: 0.1291 - val_loss: 0.1283\n",
      "Epoch 36/150\n",
      "14352/14352 [==============================] - 1s 101us/step - loss: 0.1264 - val_loss: 0.1310\n",
      "Epoch 37/150\n",
      "14352/14352 [==============================] - 2s 107us/step - loss: 0.1277 - val_loss: 0.1299\n",
      "Epoch 38/150\n",
      "14352/14352 [==============================] - 1s 104us/step - loss: 0.1280 - val_loss: 0.1285\n",
      "Epoch 39/150\n",
      "14352/14352 [==============================] - 2s 105us/step - loss: 0.1276 - val_loss: 0.1293\n",
      "Evaluating model with testing data...\n",
      "3054/3054 [==============================] - 0s 15us/step\n",
      "Getting distribution of predictions and covariance matrix...\n",
      "      1 of 20\n",
      "      2 of 20\n",
      "      3 of 20\n",
      "      4 of 20\n",
      "      5 of 20\n",
      "      6 of 20\n",
      "      7 of 20\n",
      "      8 of 20\n",
      "      9 of 20\n",
      "      10 of 20\n",
      "      11 of 20\n",
      "      12 of 20\n",
      "      13 of 20\n",
      "      14 of 20\n",
      "      15 of 20\n",
      "      16 of 20\n",
      "      17 of 20\n",
      "      18 of 20\n",
      "      19 of 20\n",
      "      20 of 20\n",
      "Computing ensemble means...\n",
      "Computing mean squared error...\n",
      "Iteration 100\n",
      "Train on 14492 samples, validate on 3084 samples\n",
      "Epoch 1/150\n",
      "14492/14492 [==============================] - 2s 110us/step - loss: 0.4602 - val_loss: 0.3418\n",
      "Epoch 2/150\n",
      "14492/14492 [==============================] - 2s 110us/step - loss: 0.3033 - val_loss: 0.2683\n",
      "Epoch 3/150\n",
      "14492/14492 [==============================] - 2s 113us/step - loss: 0.2470 - val_loss: 0.2352\n",
      "Epoch 4/150\n",
      "14492/14492 [==============================] - 2s 113us/step - loss: 0.2235 - val_loss: 0.2185\n",
      "Epoch 5/150\n",
      "14492/14492 [==============================] - 2s 111us/step - loss: 0.2096 - val_loss: 0.2047\n",
      "Epoch 6/150\n",
      "14492/14492 [==============================] - 2s 109us/step - loss: 0.1949 - val_loss: 0.1920\n",
      "Epoch 7/150\n",
      "14492/14492 [==============================] - 2s 111us/step - loss: 0.1830 - val_loss: 0.1799\n",
      "Epoch 8/150\n",
      "14492/14492 [==============================] - 1s 101us/step - loss: 0.1808 - val_loss: 0.1732\n",
      "Epoch 9/150\n",
      "14492/14492 [==============================] - 1s 103us/step - loss: 0.1725 - val_loss: 0.1648\n",
      "Epoch 10/150\n",
      "14492/14492 [==============================] - 2s 116us/step - loss: 0.1700 - val_loss: 0.1721\n",
      "Epoch 11/150\n",
      "14492/14492 [==============================] - 2s 115us/step - loss: 0.1630 - val_loss: 0.1657\n",
      "Epoch 12/150\n",
      "14492/14492 [==============================] - 2s 107us/step - loss: 0.1614 - val_loss: 0.1581\n",
      "Epoch 13/150\n",
      "14492/14492 [==============================] - 2s 115us/step - loss: 0.1589 - val_loss: 0.1625\n",
      "Epoch 14/150\n",
      "14492/14492 [==============================] - 2s 115us/step - loss: 0.1586 - val_loss: 0.1557\n",
      "Epoch 15/150\n",
      "14492/14492 [==============================] - 2s 111us/step - loss: 0.1551 - val_loss: 0.1588\n",
      "Epoch 16/150\n",
      "14492/14492 [==============================] - 2s 115us/step - loss: 0.1544 - val_loss: 0.1550\n",
      "Epoch 17/150\n",
      "14492/14492 [==============================] - 2s 111us/step - loss: 0.1534 - val_loss: 0.1542\n",
      "Epoch 18/150\n",
      "14492/14492 [==============================] - 2s 113us/step - loss: 0.1523 - val_loss: 0.1532\n",
      "Epoch 19/150\n",
      "14492/14492 [==============================] - 2s 115us/step - loss: 0.1534 - val_loss: 0.1479\n",
      "Epoch 20/150\n",
      "14492/14492 [==============================] - 2s 111us/step - loss: 0.1500 - val_loss: 0.1502\n",
      "Epoch 21/150\n",
      "14492/14492 [==============================] - 2s 113us/step - loss: 0.1471 - val_loss: 0.1425\n",
      "Epoch 22/150\n",
      "14492/14492 [==============================] - 2s 115us/step - loss: 0.1452 - val_loss: 0.1482\n",
      "Epoch 23/150\n",
      "14492/14492 [==============================] - 2s 115us/step - loss: 0.1464 - val_loss: 0.1464\n",
      "Epoch 24/150\n",
      "14492/14492 [==============================] - 2s 106us/step - loss: 0.1446 - val_loss: 0.1432\n",
      "Epoch 25/150\n",
      "14492/14492 [==============================] - 2s 110us/step - loss: 0.1423 - val_loss: 0.1415\n",
      "Epoch 26/150\n",
      "14492/14492 [==============================] - 2s 107us/step - loss: 0.1431 - val_loss: 0.1424\n",
      "Epoch 27/150\n",
      "14492/14492 [==============================] - 2s 115us/step - loss: 0.1423 - val_loss: 0.1376\n",
      "Epoch 28/150\n",
      "14492/14492 [==============================] - 2s 109us/step - loss: 0.1399 - val_loss: 0.1424\n",
      "Epoch 29/150\n",
      "14492/14492 [==============================] - 1s 102us/step - loss: 0.1416 - val_loss: 0.1415\n",
      "Epoch 30/150\n",
      "14492/14492 [==============================] - 2s 112us/step - loss: 0.1398 - val_loss: 0.1453\n",
      "Epoch 31/150\n",
      "14492/14492 [==============================] - 2s 114us/step - loss: 0.1398 - val_loss: 0.1405\n",
      "Evaluating model with testing data...\n",
      "3084/3084 [==============================] - 0s 15us/step\n",
      "Getting distribution of predictions and covariance matrix...\n",
      "      1 of 20\n",
      "      2 of 20\n",
      "      3 of 20\n",
      "      4 of 20\n",
      "      5 of 20\n",
      "      6 of 20\n",
      "      7 of 20\n",
      "      8 of 20\n",
      "      9 of 20\n",
      "      10 of 20\n",
      "      11 of 20\n",
      "      12 of 20\n",
      "      13 of 20\n",
      "      14 of 20\n",
      "      15 of 20\n",
      "      16 of 20\n",
      "      17 of 20\n",
      "      18 of 20\n",
      "      19 of 20\n",
      "      20 of 20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|          | 0/20 [00:00<?, ?it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing ensemble means...\n",
      "Computing mean squared error...\n",
      "Getting distribution of predictions...\n",
      "      1 of 20\n",
      "1600/1600 [==============================] - 0s 27us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  5%|▌         | 1/20 [00:29<09:17, 29.35s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      2 of 20\n",
      "1600/1600 [==============================] - 0s 29us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 10%|█         | 2/20 [00:58<08:48, 29.37s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      3 of 20\n",
      "1600/1600 [==============================] - 0s 29us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 15%|█▌        | 3/20 [01:28<08:22, 29.53s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      4 of 20\n",
      "1600/1600 [==============================] - 0s 29us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 20%|██        | 4/20 [01:58<07:54, 29.63s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      5 of 20\n",
      "1600/1600 [==============================] - 0s 28us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 25%|██▌       | 5/20 [02:27<07:22, 29.50s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      6 of 20\n",
      "1600/1600 [==============================] - 0s 36us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 30%|███       | 6/20 [02:57<06:54, 29.62s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      7 of 20\n",
      "1600/1600 [==============================] - 0s 28us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 35%|███▌      | 7/20 [03:27<06:26, 29.70s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      8 of 20\n",
      "1600/1600 [==============================] - 0s 28us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 40%|████      | 8/20 [03:57<05:56, 29.74s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      9 of 20\n",
      "1600/1600 [==============================] - 0s 29us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 45%|████▌     | 9/20 [04:26<05:25, 29.62s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      10 of 20\n",
      "1600/1600 [==============================] - 0s 29us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 50%|█████     | 10/20 [04:56<04:56, 29.62s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      11 of 20\n",
      "1600/1600 [==============================] - 0s 29us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 55%|█████▌    | 11/20 [05:26<04:26, 29.64s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      12 of 20\n",
      "1600/1600 [==============================] - 0s 30us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 60%|██████    | 12/20 [05:55<03:57, 29.69s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      13 of 20\n",
      "1600/1600 [==============================] - 0s 29us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 65%|██████▌   | 13/20 [06:25<03:26, 29.57s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      14 of 20\n",
      "1600/1600 [==============================] - 0s 28us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 70%|███████   | 14/20 [06:54<02:57, 29.64s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      15 of 20\n",
      "1600/1600 [==============================] - 0s 30us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 75%|███████▌  | 15/20 [07:24<02:28, 29.71s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      16 of 20\n",
      "1600/1600 [==============================] - 0s 29us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 80%|████████  | 16/20 [07:54<01:58, 29.66s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      17 of 20\n",
      "1600/1600 [==============================] - 0s 28us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 85%|████████▌ | 17/20 [08:23<01:28, 29.56s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      18 of 20\n",
      "1600/1600 [==============================] - 0s 29us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 90%|█████████ | 18/20 [08:53<00:59, 29.58s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      19 of 20\n",
      "1600/1600 [==============================] - 0s 30us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 95%|█████████▌| 19/20 [09:22<00:29, 29.58s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      20 of 20\n",
      "1600/1600 [==============================] - 0s 28us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 20/20 [09:52<00:00, 29.63s/it]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing ensemble predictions...\n",
      "Iteration 101\n",
      "Train on 14632 samples, validate on 3114 samples\n",
      "Epoch 1/150\n",
      "14632/14632 [==============================] - 2s 108us/step - loss: 0.4522 - val_loss: 0.3149\n",
      "Epoch 2/150\n",
      "14632/14632 [==============================] - 2s 111us/step - loss: 0.2813 - val_loss: 0.2610\n",
      "Epoch 3/150\n",
      "14632/14632 [==============================] - 2s 110us/step - loss: 0.2410 - val_loss: 0.2202\n",
      "Epoch 4/150\n",
      "14632/14632 [==============================] - 2s 114us/step - loss: 0.2046 - val_loss: 0.1976\n",
      "Epoch 5/150\n",
      "14632/14632 [==============================] - 2s 114us/step - loss: 0.1896 - val_loss: 0.1871\n",
      "Epoch 6/150\n",
      "14632/14632 [==============================] - 2s 111us/step - loss: 0.1824 - val_loss: 0.1847\n",
      "Epoch 7/150\n",
      "14632/14632 [==============================] - 2s 115us/step - loss: 0.1769 - val_loss: 0.1791\n",
      "Epoch 8/150\n",
      "14632/14632 [==============================] - 1s 65us/step - loss: 0.1726 - val_loss: 0.1709\n",
      "Epoch 9/150\n",
      "14632/14632 [==============================] - 1s 63us/step - loss: 0.1701 - val_loss: 0.1640\n",
      "Epoch 10/150\n",
      "14632/14632 [==============================] - 2s 112us/step - loss: 0.1653 - val_loss: 0.1681\n",
      "Epoch 11/150\n",
      "14632/14632 [==============================] - 2s 106us/step - loss: 0.1645 - val_loss: 0.1692\n",
      "Epoch 12/150\n",
      "14632/14632 [==============================] - 2s 115us/step - loss: 0.1634 - val_loss: 0.1655\n",
      "Epoch 13/150\n",
      "14632/14632 [==============================] - 2s 115us/step - loss: 0.1619 - val_loss: 0.1632\n",
      "Epoch 14/150\n",
      "14632/14632 [==============================] - 2s 114us/step - loss: 0.1622 - val_loss: 0.1597\n",
      "Epoch 15/150\n",
      "14632/14632 [==============================] - 2s 113us/step - loss: 0.1598 - val_loss: 0.1595\n",
      "Epoch 16/150\n",
      "14632/14632 [==============================] - 2s 115us/step - loss: 0.1617 - val_loss: 0.1576\n",
      "Epoch 17/150\n",
      "14632/14632 [==============================] - 2s 109us/step - loss: 0.1593 - val_loss: 0.1567\n",
      "Epoch 18/150\n",
      "14632/14632 [==============================] - 2s 111us/step - loss: 0.1599 - val_loss: 0.1619\n",
      "Epoch 19/150\n",
      "14632/14632 [==============================] - 2s 112us/step - loss: 0.1587 - val_loss: 0.1600\n",
      "Epoch 20/150\n",
      "14632/14632 [==============================] - 2s 114us/step - loss: 0.1577 - val_loss: 0.1581\n",
      "Epoch 21/150\n",
      "14632/14632 [==============================] - 2s 111us/step - loss: 0.1590 - val_loss: 0.1537\n",
      "Epoch 22/150\n",
      "14632/14632 [==============================] - 2s 112us/step - loss: 0.1548 - val_loss: 0.1584\n",
      "Epoch 23/150\n",
      "14632/14632 [==============================] - 2s 113us/step - loss: 0.1557 - val_loss: 0.1595\n",
      "Epoch 24/150\n",
      "14632/14632 [==============================] - 2s 112us/step - loss: 0.1535 - val_loss: 0.1574\n",
      "Epoch 25/150\n",
      "14632/14632 [==============================] - 2s 114us/step - loss: 0.1557 - val_loss: 0.1572\n",
      "Evaluating model with testing data...\n",
      "3114/3114 [==============================] - 0s 17us/step\n",
      "Getting distribution of predictions and covariance matrix...\n",
      "      1 of 20\n",
      "      2 of 20\n",
      "      3 of 20\n",
      "      4 of 20\n",
      "      5 of 20\n",
      "      6 of 20\n",
      "      7 of 20\n",
      "      8 of 20\n",
      "      9 of 20\n",
      "      10 of 20\n",
      "      11 of 20\n",
      "      12 of 20\n",
      "      13 of 20\n",
      "      14 of 20\n",
      "      15 of 20\n",
      "      16 of 20\n",
      "      17 of 20\n",
      "      18 of 20\n",
      "      19 of 20\n",
      "      20 of 20\n",
      "Computing ensemble means...\n",
      "Computing mean squared error...\n",
      "Iteration 102\n",
      "Train on 14772 samples, validate on 3144 samples\n",
      "Epoch 1/150\n",
      "14772/14772 [==============================] - 2s 104us/step - loss: 0.4903 - val_loss: 0.3371\n",
      "Epoch 2/150\n",
      "14772/14772 [==============================] - 2s 105us/step - loss: 0.3046 - val_loss: 0.2915\n",
      "Epoch 3/150\n",
      "14772/14772 [==============================] - 2s 105us/step - loss: 0.2716 - val_loss: 0.2642\n",
      "Epoch 4/150\n",
      "14772/14772 [==============================] - 2s 106us/step - loss: 0.2512 - val_loss: 0.2453\n",
      "Epoch 5/150\n",
      "14772/14772 [==============================] - 2s 108us/step - loss: 0.2349 - val_loss: 0.2285\n",
      "Epoch 6/150\n",
      "14772/14772 [==============================] - 2s 105us/step - loss: 0.2207 - val_loss: 0.2170\n",
      "Epoch 7/150\n",
      "14772/14772 [==============================] - 2s 109us/step - loss: 0.2147 - val_loss: 0.2092\n",
      "Epoch 8/150\n",
      "14772/14772 [==============================] - 2s 106us/step - loss: 0.2057 - val_loss: 0.2011\n",
      "Epoch 9/150\n",
      "14772/14772 [==============================] - 2s 108us/step - loss: 0.2034 - val_loss: 0.2031\n",
      "Epoch 10/150\n",
      "14772/14772 [==============================] - 2s 108us/step - loss: 0.2020 - val_loss: 0.1992\n",
      "Epoch 11/150\n",
      "14772/14772 [==============================] - 2s 112us/step - loss: 0.1986 - val_loss: 0.2020\n",
      "Epoch 12/150\n",
      "14772/14772 [==============================] - 2s 111us/step - loss: 0.1992 - val_loss: 0.2001\n",
      "Epoch 13/150\n",
      "14772/14772 [==============================] - 2s 110us/step - loss: 0.1982 - val_loss: 0.1990\n",
      "Epoch 14/150\n",
      "14772/14772 [==============================] - 2s 107us/step - loss: 0.1970 - val_loss: 0.1969\n",
      "Epoch 15/150\n",
      "14772/14772 [==============================] - 2s 110us/step - loss: 0.1958 - val_loss: 0.2003\n",
      "Epoch 16/150\n",
      "14772/14772 [==============================] - 2s 113us/step - loss: 0.1947 - val_loss: 0.1955\n",
      "Epoch 17/150\n",
      "14772/14772 [==============================] - 2s 105us/step - loss: 0.1952 - val_loss: 0.1989\n",
      "Epoch 18/150\n",
      "14772/14772 [==============================] - 2s 106us/step - loss: 0.1959 - val_loss: 0.1970\n",
      "Epoch 19/150\n",
      "14772/14772 [==============================] - 2s 109us/step - loss: 0.1947 - val_loss: 0.1927\n",
      "Epoch 20/150\n",
      "14772/14772 [==============================] - 2s 111us/step - loss: 0.1928 - val_loss: 0.1929\n",
      "Epoch 21/150\n",
      "14772/14772 [==============================] - 2s 109us/step - loss: 0.1941 - val_loss: 0.1937\n",
      "Epoch 22/150\n",
      "14772/14772 [==============================] - 2s 109us/step - loss: 0.1938 - val_loss: 0.1975\n",
      "Epoch 23/150\n",
      "14772/14772 [==============================] - 2s 105us/step - loss: 0.1933 - val_loss: 0.1956\n",
      "Evaluating model with testing data...\n",
      "3144/3144 [==============================] - 0s 16us/step\n",
      "Getting distribution of predictions and covariance matrix...\n",
      "      1 of 20\n",
      "      2 of 20\n",
      "      3 of 20\n",
      "      4 of 20\n",
      "      5 of 20\n",
      "      6 of 20\n",
      "      7 of 20\n",
      "      8 of 20\n",
      "      9 of 20\n",
      "      10 of 20\n",
      "      11 of 20\n",
      "      12 of 20\n",
      "      13 of 20\n",
      "      14 of 20\n",
      "      15 of 20\n",
      "      16 of 20\n",
      "      17 of 20\n",
      "      18 of 20\n",
      "      19 of 20\n",
      "      20 of 20\n",
      "Computing ensemble means...\n",
      "Computing mean squared error...\n",
      "Iteration 103\n",
      "Train on 14912 samples, validate on 3174 samples\n",
      "Epoch 1/150\n",
      "14912/14912 [==============================] - 2s 106us/step - loss: 0.5077 - val_loss: 0.4101\n",
      "Epoch 2/150\n",
      "14912/14912 [==============================] - 2s 102us/step - loss: 0.3670 - val_loss: 0.3307\n",
      "Epoch 3/150\n",
      "14912/14912 [==============================] - 2s 104us/step - loss: 0.3162 - val_loss: 0.2998\n",
      "Epoch 4/150\n",
      "14912/14912 [==============================] - 2s 107us/step - loss: 0.2895 - val_loss: 0.2801\n",
      "Epoch 5/150\n",
      "14912/14912 [==============================] - 2s 105us/step - loss: 0.2725 - val_loss: 0.2635\n",
      "Epoch 6/150\n",
      "14912/14912 [==============================] - 2s 105us/step - loss: 0.2581 - val_loss: 0.2524\n",
      "Epoch 7/150\n",
      "14912/14912 [==============================] - 2s 106us/step - loss: 0.2405 - val_loss: 0.2294\n",
      "Epoch 8/150\n",
      "14912/14912 [==============================] - 2s 102us/step - loss: 0.2324 - val_loss: 0.2349\n",
      "Epoch 9/150\n",
      "14912/14912 [==============================] - 2s 102us/step - loss: 0.2266 - val_loss: 0.2274\n",
      "Epoch 10/150\n",
      "14912/14912 [==============================] - 1s 96us/step - loss: 0.2256 - val_loss: 0.2261\n",
      "Epoch 11/150\n",
      "14912/14912 [==============================] - 1s 100us/step - loss: 0.2219 - val_loss: 0.2275\n",
      "Epoch 12/150\n",
      "14912/14912 [==============================] - 2s 105us/step - loss: 0.2218 - val_loss: 0.2226\n",
      "Epoch 13/150\n",
      "14912/14912 [==============================] - 2s 106us/step - loss: 0.2214 - val_loss: 0.2272\n",
      "Epoch 14/150\n",
      "14912/14912 [==============================] - 2s 103us/step - loss: 0.2200 - val_loss: 0.2185\n",
      "Epoch 15/150\n",
      "14912/14912 [==============================] - 2s 101us/step - loss: 0.2189 - val_loss: 0.2265\n",
      "Epoch 16/150\n",
      "14912/14912 [==============================] - 2s 101us/step - loss: 0.2129 - val_loss: 0.2122\n",
      "Epoch 17/150\n",
      "14912/14912 [==============================] - 2s 108us/step - loss: 0.2007 - val_loss: 0.1973\n",
      "Epoch 18/150\n",
      "14912/14912 [==============================] - 2s 111us/step - loss: 0.1944 - val_loss: 0.1976\n",
      "Epoch 19/150\n",
      "14912/14912 [==============================] - 2s 112us/step - loss: 0.1920 - val_loss: 0.1939\n",
      "Epoch 20/150\n",
      "14912/14912 [==============================] - 2s 115us/step - loss: 0.1849 - val_loss: 0.1864\n",
      "Epoch 21/150\n",
      "14912/14912 [==============================] - 2s 109us/step - loss: 0.1801 - val_loss: 0.1802\n",
      "Epoch 22/150\n",
      "14912/14912 [==============================] - 2s 114us/step - loss: 0.1756 - val_loss: 0.1808\n",
      "Epoch 23/150\n",
      "14912/14912 [==============================] - 2s 115us/step - loss: 0.1755 - val_loss: 0.1735\n",
      "Epoch 24/150\n",
      "14912/14912 [==============================] - 2s 112us/step - loss: 0.1748 - val_loss: 0.1730\n",
      "Epoch 25/150\n",
      "14912/14912 [==============================] - 2s 115us/step - loss: 0.1745 - val_loss: 0.1802\n",
      "Epoch 26/150\n",
      "14912/14912 [==============================] - 2s 115us/step - loss: 0.1732 - val_loss: 0.1784\n",
      "Epoch 27/150\n",
      "14912/14912 [==============================] - 2s 114us/step - loss: 0.1734 - val_loss: 0.1773\n",
      "Epoch 28/150\n",
      "14912/14912 [==============================] - 2s 112us/step - loss: 0.1730 - val_loss: 0.1726\n",
      "Epoch 29/150\n",
      "14912/14912 [==============================] - 2s 115us/step - loss: 0.1703 - val_loss: 0.1726\n",
      "Epoch 30/150\n",
      "14912/14912 [==============================] - 2s 111us/step - loss: 0.1705 - val_loss: 0.1739\n",
      "Epoch 31/150\n",
      "14912/14912 [==============================] - 2s 113us/step - loss: 0.1693 - val_loss: 0.1711\n",
      "Epoch 32/150\n",
      "14912/14912 [==============================] - 1s 89us/step - loss: 0.1707 - val_loss: 0.1721\n",
      "Epoch 33/150\n",
      "14912/14912 [==============================] - 1s 59us/step - loss: 0.1692 - val_loss: 0.1681\n",
      "Epoch 34/150\n",
      "14912/14912 [==============================] - 1s 88us/step - loss: 0.1692 - val_loss: 0.1714\n",
      "Epoch 35/150\n",
      "14912/14912 [==============================] - 2s 110us/step - loss: 0.1651 - val_loss: 0.1606\n",
      "Epoch 36/150\n",
      "14912/14912 [==============================] - 2s 114us/step - loss: 0.1620 - val_loss: 0.1621\n",
      "Epoch 37/150\n",
      "14912/14912 [==============================] - 2s 108us/step - loss: 0.1581 - val_loss: 0.1595\n",
      "Epoch 38/150\n",
      "14912/14912 [==============================] - 2s 114us/step - loss: 0.1583 - val_loss: 0.1623\n",
      "Epoch 39/150\n",
      "14912/14912 [==============================] - 2s 110us/step - loss: 0.1582 - val_loss: 0.1621\n",
      "Epoch 40/150\n",
      "14912/14912 [==============================] - 2s 104us/step - loss: 0.1566 - val_loss: 0.1595\n",
      "Epoch 41/150\n",
      "14912/14912 [==============================] - 2s 107us/step - loss: 0.1577 - val_loss: 0.1550\n",
      "Epoch 42/150\n",
      "14912/14912 [==============================] - 2s 110us/step - loss: 0.1546 - val_loss: 0.1599\n",
      "Epoch 43/150\n",
      "14912/14912 [==============================] - 2s 112us/step - loss: 0.1546 - val_loss: 0.1607\n",
      "Epoch 44/150\n",
      "14912/14912 [==============================] - 2s 111us/step - loss: 0.1558 - val_loss: 0.1554\n",
      "Epoch 45/150\n",
      "14912/14912 [==============================] - 2s 106us/step - loss: 0.1547 - val_loss: 0.1570\n",
      "Evaluating model with testing data...\n",
      "3174/3174 [==============================] - 0s 16us/step\n",
      "Getting distribution of predictions and covariance matrix...\n",
      "      1 of 20\n",
      "      2 of 20\n",
      "      3 of 20\n",
      "      4 of 20\n",
      "      5 of 20\n",
      "      6 of 20\n",
      "      7 of 20\n",
      "      8 of 20\n",
      "      9 of 20\n",
      "      10 of 20\n",
      "      11 of 20\n",
      "      12 of 20\n",
      "      13 of 20\n",
      "      14 of 20\n",
      "      15 of 20\n",
      "      16 of 20\n",
      "      17 of 20\n",
      "      18 of 20\n",
      "      19 of 20\n",
      "      20 of 20\n",
      "Computing ensemble means...\n",
      "Computing mean squared error...\n",
      "Iteration 104\n",
      "Train on 15052 samples, validate on 3204 samples\n",
      "Epoch 1/150\n",
      "15052/15052 [==============================] - 2s 101us/step - loss: 0.4380 - val_loss: 0.2625\n",
      "Epoch 2/150\n",
      "15052/15052 [==============================] - 2s 110us/step - loss: 0.2366 - val_loss: 0.2118\n",
      "Epoch 3/150\n",
      "15052/15052 [==============================] - 2s 109us/step - loss: 0.2013 - val_loss: 0.1896\n",
      "Epoch 4/150\n",
      "15052/15052 [==============================] - 2s 113us/step - loss: 0.1813 - val_loss: 0.1751\n",
      "Epoch 5/150\n",
      "15052/15052 [==============================] - 2s 110us/step - loss: 0.1708 - val_loss: 0.1676\n",
      "Epoch 6/150\n",
      "15052/15052 [==============================] - 2s 105us/step - loss: 0.1622 - val_loss: 0.1597\n",
      "Epoch 7/150\n",
      "15052/15052 [==============================] - 2s 109us/step - loss: 0.1539 - val_loss: 0.1505\n",
      "Epoch 8/150\n",
      "15052/15052 [==============================] - 2s 109us/step - loss: 0.1459 - val_loss: 0.1438\n",
      "Epoch 9/150\n",
      "15052/15052 [==============================] - 2s 107us/step - loss: 0.1425 - val_loss: 0.1442\n",
      "Epoch 10/150\n",
      "15052/15052 [==============================] - 2s 110us/step - loss: 0.1382 - val_loss: 0.1481\n",
      "Epoch 11/150\n",
      "15052/15052 [==============================] - 2s 111us/step - loss: 0.1343 - val_loss: 0.1330\n",
      "Epoch 12/150\n",
      "15052/15052 [==============================] - 2s 107us/step - loss: 0.1307 - val_loss: 0.1303\n",
      "Epoch 13/150\n",
      "15052/15052 [==============================] - 2s 106us/step - loss: 0.1272 - val_loss: 0.1270\n",
      "Epoch 14/150\n",
      "15052/15052 [==============================] - 2s 113us/step - loss: 0.1237 - val_loss: 0.1292\n",
      "Epoch 15/150\n",
      "15052/15052 [==============================] - 2s 106us/step - loss: 0.1230 - val_loss: 0.1230\n",
      "Epoch 16/150\n",
      "15052/15052 [==============================] - 2s 110us/step - loss: 0.1214 - val_loss: 0.1205\n",
      "Epoch 17/150\n",
      "15052/15052 [==============================] - 2s 110us/step - loss: 0.1204 - val_loss: 0.1243\n",
      "Epoch 18/150\n",
      "15052/15052 [==============================] - 2s 108us/step - loss: 0.1179 - val_loss: 0.1204\n",
      "Epoch 19/150\n",
      "15052/15052 [==============================] - 2s 105us/step - loss: 0.1167 - val_loss: 0.1164\n",
      "Epoch 20/150\n",
      "15052/15052 [==============================] - 2s 110us/step - loss: 0.1150 - val_loss: 0.1172\n",
      "Epoch 21/150\n",
      "15052/15052 [==============================] - 2s 104us/step - loss: 0.1144 - val_loss: 0.1200\n",
      "Epoch 22/150\n",
      "15052/15052 [==============================] - 2s 108us/step - loss: 0.1135 - val_loss: 0.1117\n",
      "Epoch 23/150\n",
      "15052/15052 [==============================] - 2s 105us/step - loss: 0.1123 - val_loss: 0.1144\n",
      "Epoch 24/150\n",
      "15052/15052 [==============================] - 1s 99us/step - loss: 0.1114 - val_loss: 0.1134\n",
      "Epoch 25/150\n",
      "15052/15052 [==============================] - 2s 104us/step - loss: 0.1114 - val_loss: 0.1108\n",
      "Epoch 26/150\n",
      "15052/15052 [==============================] - 2s 107us/step - loss: 0.1116 - val_loss: 0.1137\n",
      "Epoch 27/150\n",
      "15052/15052 [==============================] - 2s 101us/step - loss: 0.1085 - val_loss: 0.1116\n",
      "Epoch 28/150\n",
      "15052/15052 [==============================] - 2s 111us/step - loss: 0.1096 - val_loss: 0.1136\n",
      "Epoch 29/150\n",
      "15052/15052 [==============================] - 2s 105us/step - loss: 0.1068 - val_loss: 0.1130\n",
      "Evaluating model with testing data...\n",
      "3204/3204 [==============================] - 0s 16us/step\n",
      "Getting distribution of predictions and covariance matrix...\n",
      "      1 of 20\n",
      "      2 of 20\n",
      "      3 of 20\n",
      "      4 of 20\n",
      "      5 of 20\n",
      "      6 of 20\n",
      "      7 of 20\n",
      "      8 of 20\n",
      "      9 of 20\n",
      "      10 of 20\n",
      "      11 of 20\n",
      "      12 of 20\n",
      "      13 of 20\n",
      "      14 of 20\n",
      "      15 of 20\n",
      "      16 of 20\n",
      "      17 of 20\n",
      "      18 of 20\n",
      "      19 of 20\n",
      "      20 of 20\n",
      "Computing ensemble means...\n",
      "Computing mean squared error...\n",
      "Iteration 105\n",
      "Train on 15192 samples, validate on 3234 samples\n",
      "Epoch 1/150\n",
      "15192/15192 [==============================] - 1s 97us/step - loss: 0.3845 - val_loss: 0.2579\n",
      "Epoch 2/150\n",
      "15192/15192 [==============================] - 1s 95us/step - loss: 0.2244 - val_loss: 0.2015\n",
      "Epoch 3/150\n",
      "15192/15192 [==============================] - 2s 100us/step - loss: 0.1919 - val_loss: 0.1836\n",
      "Epoch 4/150\n",
      "15192/15192 [==============================] - 1s 98us/step - loss: 0.1740 - val_loss: 0.1657\n",
      "Epoch 5/150\n",
      "15192/15192 [==============================] - 2s 101us/step - loss: 0.1621 - val_loss: 0.1507\n",
      "Epoch 6/150\n",
      "15192/15192 [==============================] - 1s 96us/step - loss: 0.1507 - val_loss: 0.1434\n",
      "Epoch 7/150\n",
      "15192/15192 [==============================] - 1s 98us/step - loss: 0.1426 - val_loss: 0.1467\n",
      "Epoch 8/150\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15192/15192 [==============================] - 2s 103us/step - loss: 0.1393 - val_loss: 0.1401\n",
      "Epoch 9/150\n",
      "15192/15192 [==============================] - 2s 104us/step - loss: 0.1362 - val_loss: 0.1337\n",
      "Epoch 10/150\n",
      "15192/15192 [==============================] - 2s 105us/step - loss: 0.1334 - val_loss: 0.1347\n",
      "Epoch 11/150\n",
      "15192/15192 [==============================] - 2s 109us/step - loss: 0.1301 - val_loss: 0.1322\n",
      "Epoch 12/150\n",
      "15192/15192 [==============================] - 2s 105us/step - loss: 0.1267 - val_loss: 0.1255\n",
      "Epoch 13/150\n",
      "15192/15192 [==============================] - 2s 107us/step - loss: 0.1253 - val_loss: 0.1232\n",
      "Epoch 14/150\n",
      "15192/15192 [==============================] - 2s 104us/step - loss: 0.1234 - val_loss: 0.1194\n",
      "Epoch 15/150\n",
      "15192/15192 [==============================] - 2s 110us/step - loss: 0.1225 - val_loss: 0.1200\n",
      "Epoch 16/150\n",
      "15192/15192 [==============================] - 2s 108us/step - loss: 0.1200 - val_loss: 0.1193\n",
      "Epoch 17/150\n",
      "15192/15192 [==============================] - 2s 104us/step - loss: 0.1190 - val_loss: 0.1185\n",
      "Epoch 18/150\n",
      "15192/15192 [==============================] - 2s 110us/step - loss: 0.1188 - val_loss: 0.1186\n",
      "Epoch 19/150\n",
      "15192/15192 [==============================] - 2s 111us/step - loss: 0.1159 - val_loss: 0.1162\n",
      "Epoch 20/150\n",
      "15192/15192 [==============================] - 2s 104us/step - loss: 0.1162 - val_loss: 0.1167\n",
      "Epoch 21/150\n",
      "15192/15192 [==============================] - 2s 106us/step - loss: 0.1147 - val_loss: 0.1194\n",
      "Epoch 22/150\n",
      "15192/15192 [==============================] - 2s 107us/step - loss: 0.1144 - val_loss: 0.1162\n",
      "Epoch 23/150\n",
      "15192/15192 [==============================] - 2s 106us/step - loss: 0.1118 - val_loss: 0.1125\n",
      "Epoch 24/150\n",
      "15192/15192 [==============================] - 2s 103us/step - loss: 0.1118 - val_loss: 0.1140\n",
      "Epoch 25/150\n",
      "15192/15192 [==============================] - 2s 111us/step - loss: 0.1095 - val_loss: 0.1087\n",
      "Epoch 26/150\n",
      "15192/15192 [==============================] - 2s 105us/step - loss: 0.1085 - val_loss: 0.1076\n",
      "Epoch 27/150\n",
      "15192/15192 [==============================] - 2s 108us/step - loss: 0.1062 - val_loss: 0.1045\n",
      "Epoch 28/150\n",
      "15192/15192 [==============================] - 2s 111us/step - loss: 0.1038 - val_loss: 0.1043\n",
      "Epoch 29/150\n",
      "15192/15192 [==============================] - 2s 105us/step - loss: 0.1032 - val_loss: 0.1018\n",
      "Epoch 30/150\n",
      "15192/15192 [==============================] - 2s 103us/step - loss: 0.1011 - val_loss: 0.1045\n",
      "Epoch 31/150\n",
      "15192/15192 [==============================] - 1s 72us/step - loss: 0.1020 - val_loss: 0.0996\n",
      "Epoch 32/150\n",
      "15192/15192 [==============================] - 1s 59us/step - loss: 0.0985 - val_loss: 0.1012\n",
      "Epoch 33/150\n",
      "15192/15192 [==============================] - 2s 108us/step - loss: 0.0990 - val_loss: 0.0987\n",
      "Epoch 34/150\n",
      "15192/15192 [==============================] - 2s 104us/step - loss: 0.0981 - val_loss: 0.0979\n",
      "Epoch 35/150\n",
      "15192/15192 [==============================] - 2s 109us/step - loss: 0.0983 - val_loss: 0.0985\n",
      "Epoch 36/150\n",
      "15192/15192 [==============================] - 2s 105us/step - loss: 0.0969 - val_loss: 0.0982\n",
      "Epoch 37/150\n",
      "15192/15192 [==============================] - 2s 103us/step - loss: 0.0969 - val_loss: 0.0976\n",
      "Epoch 38/150\n",
      "15192/15192 [==============================] - 2s 103us/step - loss: 0.0970 - val_loss: 0.0955\n",
      "Epoch 39/150\n",
      "15192/15192 [==============================] - 2s 104us/step - loss: 0.0940 - val_loss: 0.0950\n",
      "Epoch 40/150\n",
      "15192/15192 [==============================] - 2s 102us/step - loss: 0.0928 - val_loss: 0.0922\n",
      "Epoch 41/150\n",
      "15192/15192 [==============================] - 2s 105us/step - loss: 0.0928 - val_loss: 0.0935\n",
      "Epoch 42/150\n",
      "15192/15192 [==============================] - 2s 106us/step - loss: 0.0925 - val_loss: 0.0919\n",
      "Epoch 43/150\n",
      "15192/15192 [==============================] - 2s 102us/step - loss: 0.0919 - val_loss: 0.0922\n",
      "Epoch 44/150\n",
      "15192/15192 [==============================] - 2s 102us/step - loss: 0.0912 - val_loss: 0.0951\n",
      "Epoch 45/150\n",
      "15192/15192 [==============================] - 2s 110us/step - loss: 0.0913 - val_loss: 0.0914\n",
      "Epoch 46/150\n",
      "15192/15192 [==============================] - 2s 103us/step - loss: 0.0902 - val_loss: 0.0937\n",
      "Epoch 47/150\n",
      "15192/15192 [==============================] - 1s 98us/step - loss: 0.0908 - val_loss: 0.0893\n",
      "Epoch 48/150\n",
      "15192/15192 [==============================] - 2s 103us/step - loss: 0.0898 - val_loss: 0.0935\n",
      "Epoch 49/150\n",
      "15192/15192 [==============================] - 2s 104us/step - loss: 0.0906 - val_loss: 0.0912\n",
      "Epoch 50/150\n",
      "15192/15192 [==============================] - 2s 104us/step - loss: 0.0891 - val_loss: 0.0917\n",
      "Epoch 51/150\n",
      "15192/15192 [==============================] - 2s 101us/step - loss: 0.0896 - val_loss: 0.0912\n",
      "Evaluating model with testing data...\n",
      "3234/3234 [==============================] - 0s 15us/step\n",
      "Getting distribution of predictions and covariance matrix...\n",
      "      1 of 20\n",
      "      2 of 20\n",
      "      3 of 20\n",
      "      4 of 20\n",
      "      5 of 20\n",
      "      6 of 20\n",
      "      7 of 20\n",
      "      8 of 20\n",
      "      9 of 20\n",
      "      10 of 20\n",
      "      11 of 20\n",
      "      12 of 20\n",
      "      13 of 20\n",
      "      14 of 20\n",
      "      15 of 20\n",
      "      16 of 20\n",
      "      17 of 20\n",
      "      18 of 20\n",
      "      19 of 20\n",
      "      20 of 20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|          | 0/20 [00:00<?, ?it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing ensemble means...\n",
      "Computing mean squared error...\n",
      "Getting distribution of predictions...\n",
      "      1 of 20\n",
      "1600/1600 [==============================] - 0s 27us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  5%|▌         | 1/20 [00:29<09:18, 29.41s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      2 of 20\n",
      "1600/1600 [==============================] - 0s 29us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 10%|█         | 2/20 [00:58<08:48, 29.37s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      3 of 20\n",
      "1600/1600 [==============================] - 0s 29us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 15%|█▌        | 3/20 [01:28<08:19, 29.41s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      4 of 20\n",
      "1600/1600 [==============================] - 0s 29us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 20%|██        | 4/20 [01:57<07:50, 29.42s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      5 of 20\n",
      "1600/1600 [==============================] - 0s 30us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 25%|██▌       | 5/20 [02:27<07:22, 29.53s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      6 of 20\n",
      "1600/1600 [==============================] - 0s 29us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 30%|███       | 6/20 [02:57<06:54, 29.59s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      7 of 20\n",
      "1600/1600 [==============================] - 0s 29us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 35%|███▌      | 7/20 [03:26<06:24, 29.54s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      8 of 20\n",
      "1600/1600 [==============================] - 0s 29us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 40%|████      | 8/20 [03:55<05:52, 29.39s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      9 of 20\n",
      "1600/1600 [==============================] - 0s 29us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 45%|████▌     | 9/20 [04:25<05:24, 29.47s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      10 of 20\n",
      "1600/1600 [==============================] - 0s 30us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 50%|█████     | 10/20 [04:54<04:55, 29.52s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      11 of 20\n",
      "1600/1600 [==============================] - 0s 29us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 55%|█████▌    | 11/20 [05:24<04:25, 29.47s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      12 of 20\n",
      "1600/1600 [==============================] - 0s 29us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 60%|██████    | 12/20 [05:53<03:55, 29.49s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      13 of 20\n",
      "1600/1600 [==============================] - 0s 30us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 65%|██████▌   | 13/20 [06:23<03:26, 29.49s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      14 of 20\n",
      "1600/1600 [==============================] - 0s 30us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 70%|███████   | 14/20 [06:52<02:57, 29.54s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      15 of 20\n",
      "1600/1600 [==============================] - 0s 30us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 75%|███████▌  | 15/20 [07:22<02:27, 29.57s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      16 of 20\n",
      "1600/1600 [==============================] - 0s 29us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 80%|████████  | 16/20 [07:51<01:57, 29.43s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      17 of 20\n",
      "1600/1600 [==============================] - 0s 29us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 85%|████████▌ | 17/20 [08:21<01:28, 29.50s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      18 of 20\n",
      "1600/1600 [==============================] - 0s 29us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 90%|█████████ | 18/20 [08:51<00:59, 29.56s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      19 of 20\n",
      "1600/1600 [==============================] - 0s 29us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 95%|█████████▌| 19/20 [09:20<00:29, 29.51s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      20 of 20\n",
      "1600/1600 [==============================] - 0s 30us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 20/20 [09:49<00:00, 29.48s/it]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing ensemble predictions...\n",
      "Iteration 106\n",
      "Train on 15332 samples, validate on 3264 samples\n",
      "Epoch 1/150\n",
      "15332/15332 [==============================] - 2s 114us/step - loss: 0.4571 - val_loss: 0.3084\n",
      "Epoch 2/150\n",
      "15332/15332 [==============================] - 2s 112us/step - loss: 0.2585 - val_loss: 0.2289\n",
      "Epoch 3/150\n",
      "15332/15332 [==============================] - 2s 110us/step - loss: 0.2097 - val_loss: 0.1942\n",
      "Epoch 4/150\n",
      "15332/15332 [==============================] - 2s 110us/step - loss: 0.1848 - val_loss: 0.1776\n",
      "Epoch 5/150\n",
      "15332/15332 [==============================] - 2s 108us/step - loss: 0.1726 - val_loss: 0.1756\n",
      "Epoch 6/150\n",
      "15332/15332 [==============================] - 2s 115us/step - loss: 0.1652 - val_loss: 0.1582\n",
      "Epoch 7/150\n",
      "15332/15332 [==============================] - 2s 112us/step - loss: 0.1573 - val_loss: 0.1577\n",
      "Epoch 8/150\n",
      "15332/15332 [==============================] - 2s 112us/step - loss: 0.1539 - val_loss: 0.1519\n",
      "Epoch 9/150\n",
      "15332/15332 [==============================] - 2s 112us/step - loss: 0.1474 - val_loss: 0.1522\n",
      "Epoch 10/150\n",
      "15332/15332 [==============================] - 2s 110us/step - loss: 0.1466 - val_loss: 0.1467\n",
      "Epoch 11/150\n",
      "15332/15332 [==============================] - 2s 112us/step - loss: 0.1412 - val_loss: 0.1379\n",
      "Epoch 12/150\n",
      "15332/15332 [==============================] - 2s 112us/step - loss: 0.1371 - val_loss: 0.1369\n",
      "Epoch 13/150\n",
      "15332/15332 [==============================] - 2s 111us/step - loss: 0.1375 - val_loss: 0.1395\n",
      "Epoch 14/150\n",
      "15332/15332 [==============================] - 2s 111us/step - loss: 0.1342 - val_loss: 0.1361\n",
      "Epoch 15/150\n",
      "15332/15332 [==============================] - 2s 110us/step - loss: 0.1349 - val_loss: 0.1363\n",
      "Epoch 16/150\n",
      "15332/15332 [==============================] - 2s 99us/step - loss: 0.1322 - val_loss: 0.1357\n",
      "Epoch 17/150\n",
      "15332/15332 [==============================] - 2s 114us/step - loss: 0.1316 - val_loss: 0.1340\n",
      "Epoch 18/150\n",
      "15332/15332 [==============================] - 2s 113us/step - loss: 0.1284 - val_loss: 0.1275\n",
      "Epoch 19/150\n",
      "15332/15332 [==============================] - 2s 110us/step - loss: 0.1273 - val_loss: 0.1314\n",
      "Epoch 20/150\n",
      "15332/15332 [==============================] - 2s 111us/step - loss: 0.1264 - val_loss: 0.1249\n",
      "Epoch 21/150\n",
      "15332/15332 [==============================] - 2s 110us/step - loss: 0.1257 - val_loss: 0.1238\n",
      "Epoch 22/150\n",
      "15332/15332 [==============================] - 2s 108us/step - loss: 0.1245 - val_loss: 0.1214\n",
      "Epoch 23/150\n",
      "15332/15332 [==============================] - 2s 112us/step - loss: 0.1222 - val_loss: 0.1219\n",
      "Epoch 24/150\n",
      "15332/15332 [==============================] - 2s 106us/step - loss: 0.1219 - val_loss: 0.1234\n",
      "Epoch 25/150\n",
      "15332/15332 [==============================] - 2s 109us/step - loss: 0.1208 - val_loss: 0.1230\n",
      "Epoch 26/150\n",
      "15332/15332 [==============================] - 2s 110us/step - loss: 0.1222 - val_loss: 0.1251\n",
      "Evaluating model with testing data...\n",
      "3264/3264 [==============================] - 0s 16us/step\n",
      "Getting distribution of predictions and covariance matrix...\n",
      "      1 of 20\n",
      "      2 of 20\n",
      "      3 of 20\n",
      "      4 of 20\n",
      "      5 of 20\n",
      "      6 of 20\n",
      "      7 of 20\n",
      "      8 of 20\n",
      "      9 of 20\n",
      "      10 of 20\n",
      "      11 of 20\n",
      "      12 of 20\n",
      "      13 of 20\n",
      "      14 of 20\n",
      "      15 of 20\n",
      "      16 of 20\n",
      "      17 of 20\n",
      "      18 of 20\n",
      "      19 of 20\n",
      "      20 of 20\n",
      "Computing ensemble means...\n",
      "Computing mean squared error...\n",
      "Iteration 107\n",
      "Train on 15472 samples, validate on 3294 samples\n",
      "Epoch 1/150\n",
      "15472/15472 [==============================] - 2s 106us/step - loss: 0.4653 - val_loss: 0.2960\n",
      "Epoch 2/150\n",
      "15472/15472 [==============================] - 2s 106us/step - loss: 0.2645 - val_loss: 0.2451\n",
      "Epoch 3/150\n",
      "15472/15472 [==============================] - 2s 106us/step - loss: 0.2325 - val_loss: 0.2142\n",
      "Epoch 4/150\n",
      "15472/15472 [==============================] - 2s 102us/step - loss: 0.2112 - val_loss: 0.2047\n",
      "Epoch 5/150\n",
      "15472/15472 [==============================] - 2s 106us/step - loss: 0.2022 - val_loss: 0.1961\n",
      "Epoch 6/150\n",
      "15472/15472 [==============================] - 2s 109us/step - loss: 0.1926 - val_loss: 0.1896\n",
      "Epoch 7/150\n",
      "15472/15472 [==============================] - 2s 107us/step - loss: 0.1885 - val_loss: 0.1878\n",
      "Epoch 8/150\n",
      "15472/15472 [==============================] - 2s 103us/step - loss: 0.1832 - val_loss: 0.1832\n",
      "Epoch 9/150\n",
      "15472/15472 [==============================] - 2s 102us/step - loss: 0.1790 - val_loss: 0.1800\n",
      "Epoch 10/150\n",
      "15472/15472 [==============================] - 2s 108us/step - loss: 0.1766 - val_loss: 0.1719\n",
      "Epoch 11/150\n",
      "15472/15472 [==============================] - 2s 104us/step - loss: 0.1728 - val_loss: 0.1715\n",
      "Epoch 12/150\n",
      "15472/15472 [==============================] - 2s 113us/step - loss: 0.1699 - val_loss: 0.1689\n",
      "Epoch 13/150\n",
      "15472/15472 [==============================] - 2s 111us/step - loss: 0.1708 - val_loss: 0.1694\n",
      "Epoch 14/150\n",
      "15472/15472 [==============================] - 2s 109us/step - loss: 0.1684 - val_loss: 0.1639\n",
      "Epoch 15/150\n",
      "15472/15472 [==============================] - 2s 109us/step - loss: 0.1663 - val_loss: 0.1629\n",
      "Epoch 16/150\n",
      "15472/15472 [==============================] - 2s 101us/step - loss: 0.1612 - val_loss: 0.1659\n",
      "Epoch 17/150\n",
      "15472/15472 [==============================] - 2s 102us/step - loss: 0.1625 - val_loss: 0.1634\n",
      "Epoch 18/150\n",
      "15472/15472 [==============================] - 2s 107us/step - loss: 0.1598 - val_loss: 0.1551\n",
      "Epoch 19/150\n",
      "15472/15472 [==============================] - 2s 102us/step - loss: 0.1592 - val_loss: 0.1558\n",
      "Epoch 20/150\n",
      "15472/15472 [==============================] - 2s 105us/step - loss: 0.1589 - val_loss: 0.1579\n",
      "Epoch 21/150\n",
      "15472/15472 [==============================] - 2s 107us/step - loss: 0.1571 - val_loss: 0.1605\n",
      "Epoch 22/150\n",
      "15472/15472 [==============================] - 2s 105us/step - loss: 0.1572 - val_loss: 0.1569\n",
      "Evaluating model with testing data...\n",
      "3294/3294 [==============================] - 0s 16us/step\n",
      "Getting distribution of predictions and covariance matrix...\n",
      "      1 of 20\n",
      "      2 of 20\n",
      "      3 of 20\n",
      "      4 of 20\n",
      "      5 of 20\n",
      "      6 of 20\n",
      "      7 of 20\n",
      "      8 of 20\n",
      "      9 of 20\n",
      "      10 of 20\n",
      "      11 of 20\n",
      "      12 of 20\n",
      "      13 of 20\n",
      "      14 of 20\n",
      "      15 of 20\n",
      "      16 of 20\n",
      "      17 of 20\n",
      "      18 of 20\n",
      "      19 of 20\n",
      "      20 of 20\n",
      "Computing ensemble means...\n",
      "Computing mean squared error...\n",
      "Iteration 108\n",
      "Train on 15612 samples, validate on 3324 samples\n",
      "Epoch 1/150\n",
      "15612/15612 [==============================] - 2s 107us/step - loss: 0.4366 - val_loss: 0.2903\n",
      "Epoch 2/150\n",
      "15612/15612 [==============================] - 2s 102us/step - loss: 0.2508 - val_loss: 0.2300\n",
      "Epoch 3/150\n",
      "15612/15612 [==============================] - 2s 105us/step - loss: 0.2174 - val_loss: 0.2080\n",
      "Epoch 4/150\n",
      "15612/15612 [==============================] - 2s 111us/step - loss: 0.2047 - val_loss: 0.1918\n",
      "Epoch 5/150\n",
      "15612/15612 [==============================] - 2s 102us/step - loss: 0.1922 - val_loss: 0.1820\n",
      "Epoch 6/150\n",
      "15612/15612 [==============================] - 2s 107us/step - loss: 0.1812 - val_loss: 0.1788\n",
      "Epoch 7/150\n",
      "15612/15612 [==============================] - 2s 105us/step - loss: 0.1691 - val_loss: 0.1643\n",
      "Epoch 8/150\n",
      "15612/15612 [==============================] - 1s 71us/step - loss: 0.1632 - val_loss: 0.1596\n",
      "Epoch 9/150\n",
      "15612/15612 [==============================] - 1s 60us/step - loss: 0.1584 - val_loss: 0.1570\n",
      "Epoch 10/150\n",
      "15612/15612 [==============================] - 2s 105us/step - loss: 0.1559 - val_loss: 0.1537\n",
      "Epoch 11/150\n",
      "15612/15612 [==============================] - 2s 104us/step - loss: 0.1527 - val_loss: 0.1539\n",
      "Epoch 12/150\n",
      "15612/15612 [==============================] - 2s 100us/step - loss: 0.1496 - val_loss: 0.1505\n",
      "Epoch 13/150\n",
      "15612/15612 [==============================] - 2s 98us/step - loss: 0.1472 - val_loss: 0.1463\n",
      "Epoch 14/150\n",
      "15612/15612 [==============================] - 2s 106us/step - loss: 0.1460 - val_loss: 0.1429\n",
      "Epoch 15/150\n",
      "15612/15612 [==============================] - 2s 97us/step - loss: 0.1433 - val_loss: 0.1368\n",
      "Epoch 16/150\n",
      "15612/15612 [==============================] - 2s 104us/step - loss: 0.1413 - val_loss: 0.1398\n",
      "Epoch 17/150\n",
      "15612/15612 [==============================] - 2s 109us/step - loss: 0.1395 - val_loss: 0.1428\n",
      "Epoch 18/150\n",
      "15612/15612 [==============================] - 2s 112us/step - loss: 0.1381 - val_loss: 0.1369\n",
      "Epoch 19/150\n",
      "15612/15612 [==============================] - 2s 109us/step - loss: 0.1348 - val_loss: 0.1370\n",
      "Evaluating model with testing data...\n",
      "3324/3324 [==============================] - 0s 15us/step\n",
      "Getting distribution of predictions and covariance matrix...\n",
      "      1 of 20\n",
      "      2 of 20\n",
      "      3 of 20\n",
      "      4 of 20\n",
      "      5 of 20\n",
      "      6 of 20\n",
      "      7 of 20\n",
      "      8 of 20\n",
      "      9 of 20\n",
      "      10 of 20\n",
      "      11 of 20\n",
      "      12 of 20\n",
      "      13 of 20\n",
      "      14 of 20\n",
      "      15 of 20\n",
      "      16 of 20\n",
      "      17 of 20\n",
      "      18 of 20\n",
      "      19 of 20\n",
      "      20 of 20\n",
      "Computing ensemble means...\n",
      "Computing mean squared error...\n",
      "Iteration 109\n",
      "Train on 15752 samples, validate on 3354 samples\n",
      "Epoch 1/150\n",
      "15752/15752 [==============================] - 2s 107us/step - loss: 0.4571 - val_loss: 0.3153\n",
      "Epoch 2/150\n",
      "15752/15752 [==============================] - 2s 111us/step - loss: 0.2812 - val_loss: 0.2570\n",
      "Epoch 3/150\n",
      "15752/15752 [==============================] - 2s 111us/step - loss: 0.2438 - val_loss: 0.2313\n",
      "Epoch 4/150\n",
      "15752/15752 [==============================] - 2s 115us/step - loss: 0.2248 - val_loss: 0.2161\n",
      "Epoch 5/150\n",
      "15752/15752 [==============================] - 2s 112us/step - loss: 0.2061 - val_loss: 0.2033\n",
      "Epoch 6/150\n",
      "15752/15752 [==============================] - 2s 114us/step - loss: 0.1933 - val_loss: 0.1830\n",
      "Epoch 7/150\n",
      "15752/15752 [==============================] - 2s 115us/step - loss: 0.1840 - val_loss: 0.1789\n",
      "Epoch 8/150\n",
      "15752/15752 [==============================] - 2s 109us/step - loss: 0.1773 - val_loss: 0.1710\n",
      "Epoch 9/150\n",
      "15752/15752 [==============================] - 2s 108us/step - loss: 0.1691 - val_loss: 0.1688\n",
      "Epoch 10/150\n",
      "15752/15752 [==============================] - 2s 112us/step - loss: 0.1662 - val_loss: 0.1633\n",
      "Epoch 11/150\n",
      "15752/15752 [==============================] - 2s 117us/step - loss: 0.1568 - val_loss: 0.1553\n",
      "Epoch 12/150\n",
      "15752/15752 [==============================] - 2s 110us/step - loss: 0.1527 - val_loss: 0.1533\n",
      "Epoch 13/150\n",
      "15752/15752 [==============================] - 2s 112us/step - loss: 0.1526 - val_loss: 0.1544\n",
      "Epoch 14/150\n",
      "15752/15752 [==============================] - 2s 111us/step - loss: 0.1528 - val_loss: 0.1505\n",
      "Epoch 15/150\n",
      "15752/15752 [==============================] - 2s 111us/step - loss: 0.1479 - val_loss: 0.1473\n",
      "Epoch 16/150\n",
      "15752/15752 [==============================] - 2s 105us/step - loss: 0.1451 - val_loss: 0.1450\n",
      "Epoch 17/150\n",
      "15752/15752 [==============================] - 2s 115us/step - loss: 0.1461 - val_loss: 0.1429\n",
      "Epoch 18/150\n",
      "15752/15752 [==============================] - 2s 117us/step - loss: 0.1441 - val_loss: 0.1434\n",
      "Epoch 19/150\n",
      "15752/15752 [==============================] - 2s 112us/step - loss: 0.1431 - val_loss: 0.1439\n",
      "Epoch 20/150\n",
      "15752/15752 [==============================] - 2s 115us/step - loss: 0.1429 - val_loss: 0.1431\n",
      "Epoch 21/150\n",
      "15752/15752 [==============================] - 2s 115us/step - loss: 0.1420 - val_loss: 0.1419\n",
      "Epoch 22/150\n",
      "15752/15752 [==============================] - 2s 115us/step - loss: 0.1405 - val_loss: 0.1438\n",
      "Epoch 23/150\n",
      "15752/15752 [==============================] - 2s 112us/step - loss: 0.1410 - val_loss: 0.1403\n",
      "Epoch 24/150\n",
      "15752/15752 [==============================] - 2s 111us/step - loss: 0.1412 - val_loss: 0.1410\n",
      "Epoch 25/150\n",
      "15752/15752 [==============================] - 2s 114us/step - loss: 0.1413 - val_loss: 0.1407\n",
      "Epoch 26/150\n",
      "15752/15752 [==============================] - 2s 110us/step - loss: 0.1410 - val_loss: 0.1374\n",
      "Epoch 27/150\n",
      "15752/15752 [==============================] - 2s 112us/step - loss: 0.1378 - val_loss: 0.1413\n",
      "Epoch 28/150\n",
      "15752/15752 [==============================] - 2s 117us/step - loss: 0.1409 - val_loss: 0.1418\n",
      "Epoch 29/150\n",
      "15752/15752 [==============================] - 2s 98us/step - loss: 0.1408 - val_loss: 0.1379\n",
      "Epoch 30/150\n",
      "15752/15752 [==============================] - 2s 106us/step - loss: 0.1373 - val_loss: 0.1426\n",
      "Evaluating model with testing data...\n",
      "3354/3354 [==============================] - 0s 16us/step\n",
      "Getting distribution of predictions and covariance matrix...\n",
      "      1 of 20\n",
      "      2 of 20\n",
      "      3 of 20\n",
      "      4 of 20\n",
      "      5 of 20\n",
      "      6 of 20\n",
      "      7 of 20\n",
      "      8 of 20\n",
      "      9 of 20\n",
      "      10 of 20\n",
      "      11 of 20\n",
      "      12 of 20\n",
      "      13 of 20\n",
      "      14 of 20\n",
      "      15 of 20\n",
      "      16 of 20\n",
      "      17 of 20\n",
      "      18 of 20\n",
      "      19 of 20\n",
      "      20 of 20\n",
      "Computing ensemble means...\n",
      "Computing mean squared error...\n",
      "Iteration 110\n",
      "Train on 15892 samples, validate on 3384 samples\n",
      "Epoch 1/150\n",
      "15892/15892 [==============================] - 2s 107us/step - loss: 0.4130 - val_loss: 0.2673\n",
      "Epoch 2/150\n",
      "15892/15892 [==============================] - 2s 101us/step - loss: 0.2297 - val_loss: 0.2111\n",
      "Epoch 3/150\n",
      "15892/15892 [==============================] - 2s 106us/step - loss: 0.1971 - val_loss: 0.1898\n",
      "Epoch 4/150\n",
      "15892/15892 [==============================] - 2s 111us/step - loss: 0.1839 - val_loss: 0.1797\n",
      "Epoch 5/150\n",
      "15892/15892 [==============================] - 2s 107us/step - loss: 0.1726 - val_loss: 0.1698\n",
      "Epoch 6/150\n",
      "15892/15892 [==============================] - 2s 107us/step - loss: 0.1638 - val_loss: 0.1593\n",
      "Epoch 7/150\n",
      "15892/15892 [==============================] - 2s 108us/step - loss: 0.1545 - val_loss: 0.1547\n",
      "Epoch 8/150\n",
      "15892/15892 [==============================] - 2s 109us/step - loss: 0.1519 - val_loss: 0.1545\n",
      "Epoch 9/150\n",
      "15892/15892 [==============================] - 2s 108us/step - loss: 0.1468 - val_loss: 0.1471\n",
      "Epoch 10/150\n",
      "15892/15892 [==============================] - 2s 107us/step - loss: 0.1444 - val_loss: 0.1441\n",
      "Epoch 11/150\n",
      "15892/15892 [==============================] - 2s 110us/step - loss: 0.1389 - val_loss: 0.1386\n",
      "Epoch 12/150\n",
      "15892/15892 [==============================] - 2s 108us/step - loss: 0.1371 - val_loss: 0.1346\n",
      "Epoch 13/150\n",
      "15892/15892 [==============================] - 2s 108us/step - loss: 0.1357 - val_loss: 0.1391\n",
      "Epoch 14/150\n",
      "15892/15892 [==============================] - 2s 104us/step - loss: 0.1348 - val_loss: 0.1321\n",
      "Epoch 15/150\n",
      "15892/15892 [==============================] - 2s 107us/step - loss: 0.1333 - val_loss: 0.1347\n",
      "Epoch 16/150\n",
      "15892/15892 [==============================] - 2s 106us/step - loss: 0.1314 - val_loss: 0.1313\n",
      "Epoch 17/150\n",
      "15892/15892 [==============================] - 2s 107us/step - loss: 0.1306 - val_loss: 0.1328\n",
      "Epoch 18/150\n",
      "15892/15892 [==============================] - 2s 105us/step - loss: 0.1308 - val_loss: 0.1298\n",
      "Epoch 19/150\n",
      "15892/15892 [==============================] - 2s 108us/step - loss: 0.1283 - val_loss: 0.1253\n",
      "Epoch 20/150\n",
      "15892/15892 [==============================] - 2s 107us/step - loss: 0.1296 - val_loss: 0.1287\n",
      "Epoch 21/150\n",
      "15892/15892 [==============================] - 2s 103us/step - loss: 0.1266 - val_loss: 0.1262\n",
      "Epoch 22/150\n",
      "15892/15892 [==============================] - 2s 107us/step - loss: 0.1266 - val_loss: 0.1281\n",
      "Epoch 23/150\n",
      "15892/15892 [==============================] - 2s 108us/step - loss: 0.1250 - val_loss: 0.1304\n",
      "Evaluating model with testing data...\n",
      "3384/3384 [==============================] - 0s 15us/step\n",
      "Getting distribution of predictions and covariance matrix...\n",
      "      1 of 20\n",
      "      2 of 20\n",
      "      3 of 20\n",
      "      4 of 20\n",
      "      5 of 20\n",
      "      6 of 20\n",
      "      7 of 20\n",
      "      8 of 20\n",
      "      9 of 20\n",
      "      10 of 20\n",
      "      11 of 20\n",
      "      12 of 20\n",
      "      13 of 20\n",
      "      14 of 20\n",
      "      15 of 20\n",
      "      16 of 20\n",
      "      17 of 20\n",
      "      18 of 20\n",
      "      19 of 20\n",
      "      20 of 20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|          | 0/20 [00:00<?, ?it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing ensemble means...\n",
      "Computing mean squared error...\n",
      "Getting distribution of predictions...\n",
      "      1 of 20\n",
      "1600/1600 [==============================] - 0s 28us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  5%|▌         | 1/20 [00:29<09:13, 29.15s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      2 of 20\n",
      "1600/1600 [==============================] - 0s 29us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 10%|█         | 2/20 [00:58<08:47, 29.33s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      3 of 20\n",
      "1600/1600 [==============================] - 0s 28us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 15%|█▌        | 3/20 [01:28<08:19, 29.37s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      4 of 20\n",
      "1600/1600 [==============================] - 0s 31us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 20%|██        | 4/20 [01:57<07:49, 29.36s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      5 of 20\n",
      "1600/1600 [==============================] - 0s 36us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 25%|██▌       | 5/20 [02:27<07:21, 29.45s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      6 of 20\n",
      "1600/1600 [==============================] - 0s 29us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 30%|███       | 6/20 [02:56<06:53, 29.51s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      7 of 20\n",
      "1600/1600 [==============================] - 0s 30us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 35%|███▌      | 7/20 [03:26<06:23, 29.47s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      8 of 20\n",
      "1600/1600 [==============================] - 0s 29us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 40%|████      | 8/20 [03:56<05:54, 29.52s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      9 of 20\n",
      "1600/1600 [==============================] - 0s 29us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 45%|████▌     | 9/20 [04:25<05:24, 29.48s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      10 of 20\n",
      "1600/1600 [==============================] - 0s 29us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 50%|█████     | 10/20 [04:55<04:55, 29.53s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      11 of 20\n",
      "1600/1600 [==============================] - 0s 28us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 55%|█████▌    | 11/20 [05:24<04:26, 29.60s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      12 of 20\n",
      "1600/1600 [==============================] - 0s 29us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 60%|██████    | 12/20 [05:54<03:57, 29.70s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      13 of 20\n",
      "1600/1600 [==============================] - 0s 30us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 65%|██████▌   | 13/20 [06:24<03:27, 29.59s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      14 of 20\n",
      "1600/1600 [==============================] - 0s 29us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 70%|███████   | 14/20 [06:53<02:57, 29.59s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      15 of 20\n",
      "1600/1600 [==============================] - 0s 29us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 75%|███████▌  | 15/20 [07:23<02:27, 29.53s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      16 of 20\n",
      "1600/1600 [==============================] - 0s 29us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 80%|████████  | 16/20 [07:52<01:58, 29.54s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      17 of 20\n",
      "1600/1600 [==============================] - 0s 30us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 85%|████████▌ | 17/20 [08:22<01:28, 29.57s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      18 of 20\n",
      "1600/1600 [==============================] - 0s 29us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 90%|█████████ | 18/20 [08:52<00:59, 29.65s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      19 of 20\n",
      "1600/1600 [==============================] - 0s 29us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 95%|█████████▌| 19/20 [09:21<00:29, 29.70s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      20 of 20\n",
      "1600/1600 [==============================] - 0s 29us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 20/20 [09:51<00:00, 29.59s/it]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing ensemble predictions...\n",
      "Iteration 111\n",
      "Train on 16032 samples, validate on 3414 samples\n",
      "Epoch 1/150\n",
      "16032/16032 [==============================] - 2s 108us/step - loss: 0.4702 - val_loss: 0.3411\n",
      "Epoch 2/150\n",
      "16032/16032 [==============================] - 2s 109us/step - loss: 0.2968 - val_loss: 0.2667\n",
      "Epoch 3/150\n",
      "16032/16032 [==============================] - 2s 114us/step - loss: 0.2465 - val_loss: 0.2369\n",
      "Epoch 4/150\n",
      "16032/16032 [==============================] - 2s 101us/step - loss: 0.2261 - val_loss: 0.2241\n",
      "Epoch 5/150\n",
      "16032/16032 [==============================] - 2s 115us/step - loss: 0.2132 - val_loss: 0.2058\n",
      "Epoch 6/150\n",
      "16032/16032 [==============================] - 2s 99us/step - loss: 0.2033 - val_loss: 0.1965\n",
      "Epoch 7/150\n",
      "16032/16032 [==============================] - 2s 99us/step - loss: 0.1963 - val_loss: 0.1954\n",
      "Epoch 8/150\n",
      "16032/16032 [==============================] - 1s 59us/step - loss: 0.1935 - val_loss: 0.1925\n",
      "Epoch 9/150\n",
      "16032/16032 [==============================] - 1s 84us/step - loss: 0.1898 - val_loss: 0.1873\n",
      "Epoch 10/150\n",
      "16032/16032 [==============================] - 2s 105us/step - loss: 0.1883 - val_loss: 0.1875\n",
      "Epoch 11/150\n",
      "16032/16032 [==============================] - 2s 110us/step - loss: 0.1856 - val_loss: 0.1902\n",
      "Epoch 12/150\n",
      "16032/16032 [==============================] - 2s 112us/step - loss: 0.1857 - val_loss: 0.1846\n",
      "Epoch 13/150\n",
      "16032/16032 [==============================] - 2s 111us/step - loss: 0.1857 - val_loss: 0.1832\n",
      "Epoch 14/150\n",
      "16032/16032 [==============================] - 2s 112us/step - loss: 0.1814 - val_loss: 0.1789\n",
      "Epoch 15/150\n",
      "16032/16032 [==============================] - 2s 109us/step - loss: 0.1732 - val_loss: 0.1705\n",
      "Epoch 16/150\n",
      "16032/16032 [==============================] - 2s 110us/step - loss: 0.1701 - val_loss: 0.1719\n",
      "Epoch 17/150\n",
      "16032/16032 [==============================] - 2s 110us/step - loss: 0.1673 - val_loss: 0.1630\n",
      "Epoch 18/150\n",
      "16032/16032 [==============================] - 2s 110us/step - loss: 0.1661 - val_loss: 0.1656\n",
      "Epoch 19/150\n",
      "16032/16032 [==============================] - 2s 113us/step - loss: 0.1638 - val_loss: 0.1584\n",
      "Epoch 20/150\n",
      "16032/16032 [==============================] - 2s 113us/step - loss: 0.1593 - val_loss: 0.1621\n",
      "Epoch 21/150\n",
      "16032/16032 [==============================] - 2s 112us/step - loss: 0.1587 - val_loss: 0.1606\n",
      "Epoch 22/150\n",
      "16032/16032 [==============================] - 2s 109us/step - loss: 0.1570 - val_loss: 0.1537\n",
      "Epoch 23/150\n",
      "16032/16032 [==============================] - 2s 108us/step - loss: 0.1572 - val_loss: 0.1564\n",
      "Epoch 24/150\n",
      "16032/16032 [==============================] - 2s 110us/step - loss: 0.1513 - val_loss: 0.1526\n",
      "Epoch 25/150\n",
      "16032/16032 [==============================] - 2s 107us/step - loss: 0.1521 - val_loss: 0.1485\n",
      "Epoch 26/150\n",
      "16032/16032 [==============================] - 2s 109us/step - loss: 0.1510 - val_loss: 0.1540\n",
      "Epoch 27/150\n",
      "16032/16032 [==============================] - 2s 108us/step - loss: 0.1498 - val_loss: 0.1522\n",
      "Epoch 28/150\n",
      "16032/16032 [==============================] - 2s 102us/step - loss: 0.1463 - val_loss: 0.1477\n",
      "Epoch 29/150\n",
      "16032/16032 [==============================] - 2s 110us/step - loss: 0.1437 - val_loss: 0.1425\n",
      "Epoch 30/150\n",
      "16032/16032 [==============================] - 2s 108us/step - loss: 0.1426 - val_loss: 0.1428\n",
      "Epoch 31/150\n",
      "16032/16032 [==============================] - 2s 108us/step - loss: 0.1410 - val_loss: 0.1415\n",
      "Epoch 32/150\n",
      "16032/16032 [==============================] - 2s 111us/step - loss: 0.1388 - val_loss: 0.1401\n",
      "Epoch 33/150\n",
      "16032/16032 [==============================] - 2s 108us/step - loss: 0.1387 - val_loss: 0.1404\n",
      "Epoch 34/150\n",
      "16032/16032 [==============================] - 2s 111us/step - loss: 0.1378 - val_loss: 0.1400\n",
      "Epoch 35/150\n",
      "16032/16032 [==============================] - 2s 110us/step - loss: 0.1362 - val_loss: 0.1411\n",
      "Epoch 36/150\n",
      "16032/16032 [==============================] - 2s 108us/step - loss: 0.1344 - val_loss: 0.1381\n",
      "Epoch 37/150\n",
      "16032/16032 [==============================] - 2s 110us/step - loss: 0.1355 - val_loss: 0.1343\n",
      "Epoch 38/150\n",
      "16032/16032 [==============================] - 2s 107us/step - loss: 0.1321 - val_loss: 0.1385\n",
      "Epoch 39/150\n",
      "16032/16032 [==============================] - 2s 109us/step - loss: 0.1303 - val_loss: 0.1337\n",
      "Epoch 40/150\n",
      "16032/16032 [==============================] - 2s 105us/step - loss: 0.1304 - val_loss: 0.1288\n",
      "Epoch 41/150\n",
      "16032/16032 [==============================] - 2s 107us/step - loss: 0.1288 - val_loss: 0.1288\n",
      "Epoch 42/150\n",
      "16032/16032 [==============================] - 2s 115us/step - loss: 0.1271 - val_loss: 0.1276\n",
      "Epoch 43/150\n",
      "16032/16032 [==============================] - 2s 107us/step - loss: 0.1277 - val_loss: 0.1273\n",
      "Epoch 44/150\n",
      "16032/16032 [==============================] - 2s 109us/step - loss: 0.1272 - val_loss: 0.1300\n",
      "Epoch 45/150\n",
      "16032/16032 [==============================] - 2s 99us/step - loss: 0.1264 - val_loss: 0.1286\n",
      "Epoch 46/150\n",
      "16032/16032 [==============================] - 2s 113us/step - loss: 0.1257 - val_loss: 0.1248\n",
      "Epoch 47/150\n",
      "16032/16032 [==============================] - 2s 106us/step - loss: 0.1246 - val_loss: 0.1268\n",
      "Epoch 48/150\n",
      "16032/16032 [==============================] - 2s 107us/step - loss: 0.1248 - val_loss: 0.1249\n",
      "Epoch 49/150\n",
      "16032/16032 [==============================] - 2s 107us/step - loss: 0.1250 - val_loss: 0.1236\n",
      "Epoch 50/150\n",
      "16032/16032 [==============================] - 2s 111us/step - loss: 0.1236 - val_loss: 0.1281\n",
      "Epoch 51/150\n",
      "16032/16032 [==============================] - 2s 98us/step - loss: 0.1248 - val_loss: 0.1220\n",
      "Epoch 52/150\n",
      "16032/16032 [==============================] - 2s 109us/step - loss: 0.1225 - val_loss: 0.1272\n",
      "Epoch 53/150\n",
      "16032/16032 [==============================] - 2s 104us/step - loss: 0.1226 - val_loss: 0.1265\n",
      "Epoch 54/150\n",
      "16032/16032 [==============================] - 2s 100us/step - loss: 0.1217 - val_loss: 0.1243\n",
      "Epoch 55/150\n",
      "16032/16032 [==============================] - 2s 100us/step - loss: 0.1212 - val_loss: 0.1230\n",
      "Evaluating model with testing data...\n",
      "3414/3414 [==============================] - 0s 16us/step\n",
      "Getting distribution of predictions and covariance matrix...\n",
      "      1 of 20\n",
      "      2 of 20\n",
      "      3 of 20\n",
      "      4 of 20\n",
      "      5 of 20\n",
      "      6 of 20\n",
      "      7 of 20\n",
      "      8 of 20\n",
      "      9 of 20\n",
      "      10 of 20\n",
      "      11 of 20\n",
      "      12 of 20\n",
      "      13 of 20\n",
      "      14 of 20\n",
      "      15 of 20\n",
      "      16 of 20\n",
      "      17 of 20\n",
      "      18 of 20\n",
      "      19 of 20\n",
      "      20 of 20\n",
      "Computing ensemble means...\n",
      "Computing mean squared error...\n",
      "Iteration 112\n",
      "Train on 16172 samples, validate on 3444 samples\n",
      "Epoch 1/150\n",
      "16172/16172 [==============================] - 2s 101us/step - loss: 0.4025 - val_loss: 0.2665\n",
      "Epoch 2/150\n",
      "16172/16172 [==============================] - 2s 102us/step - loss: 0.2412 - val_loss: 0.2201\n",
      "Epoch 3/150\n",
      "16172/16172 [==============================] - 2s 104us/step - loss: 0.2134 - val_loss: 0.2076\n",
      "Epoch 4/150\n",
      "16172/16172 [==============================] - 2s 107us/step - loss: 0.2009 - val_loss: 0.1954\n",
      "Epoch 5/150\n",
      "16172/16172 [==============================] - 2s 105us/step - loss: 0.1921 - val_loss: 0.1914\n",
      "Epoch 6/150\n",
      "16172/16172 [==============================] - 2s 107us/step - loss: 0.1868 - val_loss: 0.1794\n",
      "Epoch 7/150\n",
      "16172/16172 [==============================] - 2s 105us/step - loss: 0.1816 - val_loss: 0.1799\n",
      "Epoch 8/150\n",
      "16172/16172 [==============================] - 2s 101us/step - loss: 0.1774 - val_loss: 0.1753\n",
      "Epoch 9/150\n",
      "16172/16172 [==============================] - 2s 109us/step - loss: 0.1726 - val_loss: 0.1716\n",
      "Epoch 10/150\n",
      "16172/16172 [==============================] - 2s 102us/step - loss: 0.1721 - val_loss: 0.1730\n",
      "Epoch 11/150\n",
      "16172/16172 [==============================] - 2s 101us/step - loss: 0.1695 - val_loss: 0.1721\n",
      "Epoch 12/150\n",
      "16172/16172 [==============================] - 2s 97us/step - loss: 0.1682 - val_loss: 0.1692\n",
      "Epoch 13/150\n",
      "16172/16172 [==============================] - 2s 104us/step - loss: 0.1684 - val_loss: 0.1680\n",
      "Epoch 14/150\n",
      "16172/16172 [==============================] - 2s 104us/step - loss: 0.1679 - val_loss: 0.1669\n",
      "Epoch 15/150\n",
      "16172/16172 [==============================] - 2s 96us/step - loss: 0.1642 - val_loss: 0.1608\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 16/150\n",
      "16172/16172 [==============================] - 2s 111us/step - loss: 0.1592 - val_loss: 0.1591\n",
      "Epoch 17/150\n",
      "16172/16172 [==============================] - 2s 113us/step - loss: 0.1582 - val_loss: 0.1610\n",
      "Epoch 18/150\n",
      "16172/16172 [==============================] - 2s 112us/step - loss: 0.1561 - val_loss: 0.1571\n",
      "Epoch 19/150\n",
      "16172/16172 [==============================] - 2s 111us/step - loss: 0.1563 - val_loss: 0.1515\n",
      "Epoch 20/150\n",
      "16172/16172 [==============================] - 2s 111us/step - loss: 0.1517 - val_loss: 0.1489\n",
      "Epoch 21/150\n",
      "16172/16172 [==============================] - 2s 98us/step - loss: 0.1501 - val_loss: 0.1491\n",
      "Epoch 22/150\n",
      "16172/16172 [==============================] - 1s 58us/step - loss: 0.1488 - val_loss: 0.1485\n",
      "Epoch 23/150\n",
      "16172/16172 [==============================] - 1s 89us/step - loss: 0.1508 - val_loss: 0.1483\n",
      "Epoch 24/150\n",
      "16172/16172 [==============================] - 2s 112us/step - loss: 0.1473 - val_loss: 0.1501\n",
      "Epoch 25/150\n",
      "16172/16172 [==============================] - 2s 114us/step - loss: 0.1465 - val_loss: 0.1548\n",
      "Epoch 26/150\n",
      "16172/16172 [==============================] - 2s 110us/step - loss: 0.1469 - val_loss: 0.1477\n",
      "Epoch 27/150\n",
      "16172/16172 [==============================] - 2s 110us/step - loss: 0.1475 - val_loss: 0.1463\n",
      "Epoch 28/150\n",
      "16172/16172 [==============================] - 2s 110us/step - loss: 0.1473 - val_loss: 0.1463\n",
      "Epoch 29/150\n",
      "16172/16172 [==============================] - 2s 110us/step - loss: 0.1463 - val_loss: 0.1470\n",
      "Epoch 30/150\n",
      "16172/16172 [==============================] - 2s 113us/step - loss: 0.1452 - val_loss: 0.1396\n",
      "Epoch 31/150\n",
      "16172/16172 [==============================] - 2s 113us/step - loss: 0.1453 - val_loss: 0.1429\n",
      "Epoch 32/150\n",
      "16172/16172 [==============================] - 2s 112us/step - loss: 0.1435 - val_loss: 0.1435\n",
      "Epoch 33/150\n",
      "16172/16172 [==============================] - 2s 111us/step - loss: 0.1408 - val_loss: 0.1398\n",
      "Epoch 34/150\n",
      "16172/16172 [==============================] - 2s 112us/step - loss: 0.1424 - val_loss: 0.1385\n",
      "Epoch 35/150\n",
      "16172/16172 [==============================] - 2s 112us/step - loss: 0.1395 - val_loss: 0.1388\n",
      "Epoch 36/150\n",
      "16172/16172 [==============================] - 2s 110us/step - loss: 0.1385 - val_loss: 0.1391\n",
      "Epoch 37/150\n",
      "16172/16172 [==============================] - 2s 109us/step - loss: 0.1393 - val_loss: 0.1417\n",
      "Epoch 38/150\n",
      "16172/16172 [==============================] - 2s 104us/step - loss: 0.1381 - val_loss: 0.1392\n",
      "Evaluating model with testing data...\n",
      "3444/3444 [==============================] - 0s 17us/step\n",
      "Getting distribution of predictions and covariance matrix...\n",
      "      1 of 20\n",
      "      2 of 20\n",
      "      3 of 20\n",
      "      4 of 20\n",
      "      5 of 20\n",
      "      6 of 20\n",
      "      7 of 20\n",
      "      8 of 20\n",
      "      9 of 20\n",
      "      10 of 20\n",
      "      11 of 20\n",
      "      12 of 20\n",
      "      13 of 20\n",
      "      14 of 20\n",
      "      15 of 20\n",
      "      16 of 20\n",
      "      17 of 20\n",
      "      18 of 20\n",
      "      19 of 20\n",
      "      20 of 20\n",
      "Computing ensemble means...\n",
      "Computing mean squared error...\n",
      "Iteration 113\n",
      "Train on 16312 samples, validate on 3474 samples\n",
      "Epoch 1/150\n",
      "16312/16312 [==============================] - 2s 103us/step - loss: 0.3872 - val_loss: 0.2549\n",
      "Epoch 2/150\n",
      "16312/16312 [==============================] - 2s 111us/step - loss: 0.2264 - val_loss: 0.2037\n",
      "Epoch 3/150\n",
      "16312/16312 [==============================] - 2s 114us/step - loss: 0.1917 - val_loss: 0.1849\n",
      "Epoch 4/150\n",
      "16312/16312 [==============================] - 2s 104us/step - loss: 0.1774 - val_loss: 0.1810\n",
      "Epoch 5/150\n",
      "16312/16312 [==============================] - 2s 110us/step - loss: 0.1668 - val_loss: 0.1620\n",
      "Epoch 6/150\n",
      "16312/16312 [==============================] - 2s 105us/step - loss: 0.1587 - val_loss: 0.1549\n",
      "Epoch 7/150\n",
      "16312/16312 [==============================] - 2s 108us/step - loss: 0.1509 - val_loss: 0.1505\n",
      "Epoch 8/150\n",
      "16312/16312 [==============================] - 2s 104us/step - loss: 0.1503 - val_loss: 0.1492\n",
      "Epoch 9/150\n",
      "16312/16312 [==============================] - 2s 109us/step - loss: 0.1463 - val_loss: 0.1458\n",
      "Epoch 10/150\n",
      "16312/16312 [==============================] - 2s 108us/step - loss: 0.1403 - val_loss: 0.1390\n",
      "Epoch 11/150\n",
      "16312/16312 [==============================] - 2s 107us/step - loss: 0.1376 - val_loss: 0.1382\n",
      "Epoch 12/150\n",
      "16312/16312 [==============================] - 2s 108us/step - loss: 0.1350 - val_loss: 0.1325\n",
      "Epoch 13/150\n",
      "16312/16312 [==============================] - 2s 104us/step - loss: 0.1324 - val_loss: 0.1330\n",
      "Epoch 14/150\n",
      "16312/16312 [==============================] - 2s 110us/step - loss: 0.1303 - val_loss: 0.1292\n",
      "Epoch 15/150\n",
      "16312/16312 [==============================] - 2s 112us/step - loss: 0.1265 - val_loss: 0.1263\n",
      "Epoch 16/150\n",
      "16312/16312 [==============================] - 2s 107us/step - loss: 0.1280 - val_loss: 0.1280\n",
      "Epoch 17/150\n",
      "16312/16312 [==============================] - 2s 112us/step - loss: 0.1268 - val_loss: 0.1248\n",
      "Epoch 18/150\n",
      "16312/16312 [==============================] - 2s 108us/step - loss: 0.1230 - val_loss: 0.1226\n",
      "Epoch 19/150\n",
      "16312/16312 [==============================] - 2s 103us/step - loss: 0.1226 - val_loss: 0.1233\n",
      "Epoch 20/150\n",
      "16312/16312 [==============================] - 2s 107us/step - loss: 0.1235 - val_loss: 0.1250\n",
      "Epoch 21/150\n",
      "16312/16312 [==============================] - 2s 106us/step - loss: 0.1233 - val_loss: 0.1222\n",
      "Epoch 22/150\n",
      "16312/16312 [==============================] - 2s 105us/step - loss: 0.1199 - val_loss: 0.1238\n",
      "Epoch 23/150\n",
      "16312/16312 [==============================] - 2s 108us/step - loss: 0.1196 - val_loss: 0.1175\n",
      "Epoch 24/150\n",
      "16312/16312 [==============================] - 2s 106us/step - loss: 0.1187 - val_loss: 0.1223\n",
      "Epoch 25/150\n",
      "16312/16312 [==============================] - 2s 103us/step - loss: 0.1177 - val_loss: 0.1186\n",
      "Epoch 26/150\n",
      "16312/16312 [==============================] - 2s 104us/step - loss: 0.1164 - val_loss: 0.1154\n",
      "Epoch 27/150\n",
      "16312/16312 [==============================] - 2s 104us/step - loss: 0.1148 - val_loss: 0.1141\n",
      "Epoch 28/150\n",
      "16312/16312 [==============================] - 2s 101us/step - loss: 0.1135 - val_loss: 0.1156\n",
      "Epoch 29/150\n",
      "16312/16312 [==============================] - 2s 106us/step - loss: 0.1112 - val_loss: 0.1111\n",
      "Epoch 30/150\n",
      "16312/16312 [==============================] - 2s 108us/step - loss: 0.1090 - val_loss: 0.1093\n",
      "Epoch 31/150\n",
      "16312/16312 [==============================] - 2s 105us/step - loss: 0.1073 - val_loss: 0.1092\n",
      "Epoch 32/150\n",
      "16312/16312 [==============================] - 2s 104us/step - loss: 0.1074 - val_loss: 0.1063\n",
      "Epoch 33/150\n",
      "16312/16312 [==============================] - 2s 100us/step - loss: 0.1069 - val_loss: 0.1094\n",
      "Epoch 34/150\n",
      "16312/16312 [==============================] - 2s 103us/step - loss: 0.1053 - val_loss: 0.1055\n",
      "Epoch 35/150\n",
      "16312/16312 [==============================] - 2s 104us/step - loss: 0.1045 - val_loss: 0.1050\n",
      "Epoch 36/150\n",
      "16312/16312 [==============================] - 2s 103us/step - loss: 0.1047 - val_loss: 0.1075\n",
      "Epoch 37/150\n",
      "16312/16312 [==============================] - 2s 106us/step - loss: 0.1035 - val_loss: 0.1027\n",
      "Epoch 38/150\n",
      "16312/16312 [==============================] - 2s 107us/step - loss: 0.1025 - val_loss: 0.1035\n",
      "Epoch 39/150\n",
      "16312/16312 [==============================] - 2s 104us/step - loss: 0.1021 - val_loss: 0.1007\n",
      "Epoch 40/150\n",
      "16312/16312 [==============================] - 2s 98us/step - loss: 0.1008 - val_loss: 0.0995\n",
      "Epoch 41/150\n",
      "16312/16312 [==============================] - 2s 105us/step - loss: 0.1000 - val_loss: 0.1010\n",
      "Epoch 42/150\n",
      "16312/16312 [==============================] - 2s 105us/step - loss: 0.0988 - val_loss: 0.0972\n",
      "Epoch 43/150\n",
      "16312/16312 [==============================] - 2s 101us/step - loss: 0.0988 - val_loss: 0.1008\n",
      "Epoch 44/150\n",
      "16312/16312 [==============================] - 2s 96us/step - loss: 0.0985 - val_loss: 0.0990\n",
      "Epoch 45/150\n",
      "16312/16312 [==============================] - 2s 100us/step - loss: 0.0973 - val_loss: 0.0987\n",
      "Epoch 46/150\n",
      "16312/16312 [==============================] - 2s 95us/step - loss: 0.0982 - val_loss: 0.0994\n",
      "Evaluating model with testing data...\n",
      "3474/3474 [==============================] - 0s 16us/step\n",
      "Getting distribution of predictions and covariance matrix...\n",
      "      1 of 20\n",
      "      2 of 20\n",
      "      3 of 20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      4 of 20\n",
      "      5 of 20\n",
      "      6 of 20\n",
      "      7 of 20\n",
      "      8 of 20\n",
      "      9 of 20\n",
      "      10 of 20\n",
      "      11 of 20\n",
      "      12 of 20\n",
      "      13 of 20\n",
      "      14 of 20\n",
      "      15 of 20\n",
      "      16 of 20\n",
      "      17 of 20\n",
      "      18 of 20\n",
      "      19 of 20\n",
      "      20 of 20\n",
      "Computing ensemble means...\n",
      "Computing mean squared error...\n",
      "Iteration 114\n",
      "Train on 16452 samples, validate on 3504 samples\n",
      "Epoch 1/150\n",
      "16452/16452 [==============================] - 2s 111us/step - loss: 0.4162 - val_loss: 0.2922\n",
      "Epoch 2/150\n",
      "16452/16452 [==============================] - 2s 111us/step - loss: 0.2436 - val_loss: 0.2147\n",
      "Epoch 3/150\n",
      "16452/16452 [==============================] - 2s 111us/step - loss: 0.1943 - val_loss: 0.1818\n",
      "Epoch 4/150\n",
      "16452/16452 [==============================] - 2s 95us/step - loss: 0.1764 - val_loss: 0.1723\n",
      "Epoch 5/150\n",
      "16452/16452 [==============================] - 1s 59us/step - loss: 0.1643 - val_loss: 0.1613\n",
      "Epoch 6/150\n",
      "16452/16452 [==============================] - 2s 93us/step - loss: 0.1540 - val_loss: 0.1501\n",
      "Epoch 7/150\n",
      "16452/16452 [==============================] - 2s 106us/step - loss: 0.1484 - val_loss: 0.1446\n",
      "Epoch 8/150\n",
      "16452/16452 [==============================] - 2s 112us/step - loss: 0.1428 - val_loss: 0.1406\n",
      "Epoch 9/150\n",
      "16452/16452 [==============================] - 2s 115us/step - loss: 0.1374 - val_loss: 0.1367\n",
      "Epoch 10/150\n",
      "16452/16452 [==============================] - 2s 111us/step - loss: 0.1349 - val_loss: 0.1343\n",
      "Epoch 11/150\n",
      "16452/16452 [==============================] - 2s 110us/step - loss: 0.1317 - val_loss: 0.1281\n",
      "Epoch 12/150\n",
      "16452/16452 [==============================] - 2s 115us/step - loss: 0.1305 - val_loss: 0.1306\n",
      "Epoch 13/150\n",
      "16452/16452 [==============================] - 2s 111us/step - loss: 0.1273 - val_loss: 0.1302\n",
      "Epoch 14/150\n",
      "16452/16452 [==============================] - 2s 109us/step - loss: 0.1269 - val_loss: 0.1270\n",
      "Epoch 15/150\n",
      "16452/16452 [==============================] - 2s 112us/step - loss: 0.1254 - val_loss: 0.1270\n",
      "Epoch 16/150\n",
      "16452/16452 [==============================] - 2s 107us/step - loss: 0.1267 - val_loss: 0.1246\n",
      "Epoch 17/150\n",
      "16452/16452 [==============================] - 2s 113us/step - loss: 0.1224 - val_loss: 0.1249\n",
      "Epoch 18/150\n",
      "16452/16452 [==============================] - 2s 114us/step - loss: 0.1220 - val_loss: 0.1217\n",
      "Epoch 19/150\n",
      "16452/16452 [==============================] - 2s 111us/step - loss: 0.1220 - val_loss: 0.1193\n",
      "Epoch 20/150\n",
      "16452/16452 [==============================] - 2s 112us/step - loss: 0.1206 - val_loss: 0.1225\n",
      "Epoch 21/150\n",
      "16452/16452 [==============================] - 2s 110us/step - loss: 0.1198 - val_loss: 0.1228\n",
      "Epoch 22/150\n",
      "16452/16452 [==============================] - 2s 114us/step - loss: 0.1164 - val_loss: 0.1181\n",
      "Epoch 23/150\n",
      "16452/16452 [==============================] - 2s 113us/step - loss: 0.1160 - val_loss: 0.1194\n",
      "Epoch 24/150\n",
      "16452/16452 [==============================] - 2s 105us/step - loss: 0.1165 - val_loss: 0.1153\n",
      "Epoch 25/150\n",
      "16452/16452 [==============================] - 2s 109us/step - loss: 0.1158 - val_loss: 0.1161\n",
      "Epoch 26/150\n",
      "16452/16452 [==============================] - 2s 112us/step - loss: 0.1154 - val_loss: 0.1162\n",
      "Epoch 27/150\n",
      "16452/16452 [==============================] - 2s 110us/step - loss: 0.1149 - val_loss: 0.1174\n",
      "Epoch 28/150\n",
      "16452/16452 [==============================] - 2s 112us/step - loss: 0.1126 - val_loss: 0.1110\n",
      "Epoch 29/150\n",
      "16452/16452 [==============================] - 2s 109us/step - loss: 0.1132 - val_loss: 0.1173\n",
      "Epoch 30/150\n",
      "16452/16452 [==============================] - 2s 110us/step - loss: 0.1111 - val_loss: 0.1136\n",
      "Epoch 31/150\n",
      "16452/16452 [==============================] - 2s 99us/step - loss: 0.1115 - val_loss: 0.1135\n",
      "Epoch 32/150\n",
      "16452/16452 [==============================] - 2s 112us/step - loss: 0.1104 - val_loss: 0.1128\n",
      "Evaluating model with testing data...\n",
      "3504/3504 [==============================] - 0s 16us/step\n",
      "Getting distribution of predictions and covariance matrix...\n",
      "      1 of 20\n",
      "      2 of 20\n",
      "      3 of 20\n",
      "      4 of 20\n",
      "      5 of 20\n",
      "      6 of 20\n",
      "      7 of 20\n",
      "      8 of 20\n",
      "      9 of 20\n",
      "      10 of 20\n",
      "      11 of 20\n",
      "      12 of 20\n",
      "      13 of 20\n",
      "      14 of 20\n",
      "      15 of 20\n",
      "      16 of 20\n",
      "      17 of 20\n",
      "      18 of 20\n",
      "      19 of 20\n",
      "      20 of 20\n",
      "Computing ensemble means...\n",
      "Computing mean squared error...\n",
      "Iteration 115\n",
      "Train on 16592 samples, validate on 3534 samples\n",
      "Epoch 1/150\n",
      "16592/16592 [==============================] - 2s 102us/step - loss: 0.3931 - val_loss: 0.2735\n",
      "Epoch 2/150\n",
      "16592/16592 [==============================] - 2s 110us/step - loss: 0.2436 - val_loss: 0.2213\n",
      "Epoch 3/150\n",
      "16592/16592 [==============================] - 2s 107us/step - loss: 0.2086 - val_loss: 0.2004\n",
      "Epoch 4/150\n",
      "16592/16592 [==============================] - 2s 109us/step - loss: 0.1819 - val_loss: 0.1729\n",
      "Epoch 5/150\n",
      "16592/16592 [==============================] - 2s 107us/step - loss: 0.1687 - val_loss: 0.1578\n",
      "Epoch 6/150\n",
      "16592/16592 [==============================] - 2s 108us/step - loss: 0.1531 - val_loss: 0.1461\n",
      "Epoch 7/150\n",
      "16592/16592 [==============================] - 2s 108us/step - loss: 0.1457 - val_loss: 0.1430\n",
      "Epoch 8/150\n",
      "16592/16592 [==============================] - 2s 108us/step - loss: 0.1416 - val_loss: 0.1390\n",
      "Epoch 9/150\n",
      "16592/16592 [==============================] - 2s 104us/step - loss: 0.1391 - val_loss: 0.1351\n",
      "Epoch 10/150\n",
      "16592/16592 [==============================] - 2s 108us/step - loss: 0.1347 - val_loss: 0.1300\n",
      "Epoch 11/150\n",
      "16592/16592 [==============================] - 2s 101us/step - loss: 0.1317 - val_loss: 0.1291\n",
      "Epoch 12/150\n",
      "16592/16592 [==============================] - 2s 107us/step - loss: 0.1300 - val_loss: 0.1267\n",
      "Epoch 13/150\n",
      "16592/16592 [==============================] - 2s 106us/step - loss: 0.1277 - val_loss: 0.1267\n",
      "Epoch 14/150\n",
      "16592/16592 [==============================] - 2s 110us/step - loss: 0.1250 - val_loss: 0.1238\n",
      "Epoch 15/150\n",
      "16592/16592 [==============================] - 2s 106us/step - loss: 0.1242 - val_loss: 0.1244\n",
      "Epoch 16/150\n",
      "16592/16592 [==============================] - 2s 103us/step - loss: 0.1231 - val_loss: 0.1198\n",
      "Epoch 17/150\n",
      "16592/16592 [==============================] - 2s 108us/step - loss: 0.1220 - val_loss: 0.1222\n",
      "Epoch 18/150\n",
      "16592/16592 [==============================] - 2s 102us/step - loss: 0.1203 - val_loss: 0.1213\n",
      "Epoch 19/150\n",
      "16592/16592 [==============================] - 2s 107us/step - loss: 0.1203 - val_loss: 0.1196\n",
      "Epoch 20/150\n",
      "16592/16592 [==============================] - 2s 105us/step - loss: 0.1187 - val_loss: 0.1201\n",
      "Epoch 21/150\n",
      "16592/16592 [==============================] - 2s 100us/step - loss: 0.1154 - val_loss: 0.1155\n",
      "Epoch 22/150\n",
      "16592/16592 [==============================] - 2s 104us/step - loss: 0.1178 - val_loss: 0.1153\n",
      "Epoch 23/150\n",
      "16592/16592 [==============================] - 2s 103us/step - loss: 0.1152 - val_loss: 0.1113\n",
      "Epoch 24/150\n",
      "16592/16592 [==============================] - 2s 104us/step - loss: 0.1133 - val_loss: 0.1141\n",
      "Epoch 25/150\n",
      "16592/16592 [==============================] - 2s 107us/step - loss: 0.1133 - val_loss: 0.1138\n",
      "Epoch 26/150\n",
      "16592/16592 [==============================] - 2s 103us/step - loss: 0.1121 - val_loss: 0.1129\n",
      "Epoch 27/150\n",
      "16592/16592 [==============================] - 2s 103us/step - loss: 0.1114 - val_loss: 0.1095\n",
      "Epoch 28/150\n",
      "16592/16592 [==============================] - 2s 105us/step - loss: 0.1115 - val_loss: 0.1082\n",
      "Epoch 29/150\n",
      "16592/16592 [==============================] - 2s 101us/step - loss: 0.1105 - val_loss: 0.1120\n",
      "Epoch 30/150\n",
      "16592/16592 [==============================] - 2s 103us/step - loss: 0.1087 - val_loss: 0.1145\n",
      "Epoch 31/150\n",
      "16592/16592 [==============================] - 2s 107us/step - loss: 0.1097 - val_loss: 0.1095\n",
      "Epoch 32/150\n",
      "16592/16592 [==============================] - 2s 103us/step - loss: 0.1078 - val_loss: 0.1075\n",
      "Epoch 33/150\n",
      "16592/16592 [==============================] - 2s 104us/step - loss: 0.1072 - val_loss: 0.1045\n",
      "Epoch 34/150\n",
      "16592/16592 [==============================] - 2s 98us/step - loss: 0.1059 - val_loss: 0.1067\n",
      "Epoch 35/150\n",
      "16592/16592 [==============================] - 2s 100us/step - loss: 0.1040 - val_loss: 0.1041\n",
      "Epoch 36/150\n",
      "16592/16592 [==============================] - 2s 107us/step - loss: 0.1034 - val_loss: 0.1066\n",
      "Epoch 37/150\n",
      "16592/16592 [==============================] - 2s 106us/step - loss: 0.1036 - val_loss: 0.1037\n",
      "Epoch 38/150\n",
      "16592/16592 [==============================] - 2s 112us/step - loss: 0.1006 - val_loss: 0.1042\n",
      "Epoch 39/150\n",
      "16592/16592 [==============================] - 2s 95us/step - loss: 0.1018 - val_loss: 0.1027\n",
      "Epoch 40/150\n",
      "16592/16592 [==============================] - 1s 59us/step - loss: 0.0993 - val_loss: 0.1011\n",
      "Epoch 41/150\n",
      "16592/16592 [==============================] - 2s 92us/step - loss: 0.1007 - val_loss: 0.0957\n",
      "Epoch 42/150\n",
      "16592/16592 [==============================] - 2s 108us/step - loss: 0.0992 - val_loss: 0.1000\n",
      "Epoch 43/150\n",
      "16592/16592 [==============================] - 2s 108us/step - loss: 0.0975 - val_loss: 0.0963\n",
      "Epoch 44/150\n",
      "16592/16592 [==============================] - 2s 109us/step - loss: 0.0964 - val_loss: 0.0928\n",
      "Epoch 45/150\n",
      "16592/16592 [==============================] - 2s 113us/step - loss: 0.0961 - val_loss: 0.0975\n",
      "Epoch 46/150\n",
      "16592/16592 [==============================] - 2s 112us/step - loss: 0.0956 - val_loss: 0.0947\n",
      "Epoch 47/150\n",
      "16592/16592 [==============================] - 2s 111us/step - loss: 0.0938 - val_loss: 0.0924\n",
      "Epoch 48/150\n",
      "16592/16592 [==============================] - 2s 112us/step - loss: 0.0928 - val_loss: 0.0917\n",
      "Epoch 49/150\n",
      "16592/16592 [==============================] - 2s 112us/step - loss: 0.0935 - val_loss: 0.0932\n",
      "Epoch 50/150\n",
      "16592/16592 [==============================] - 2s 111us/step - loss: 0.0923 - val_loss: 0.0941\n",
      "Epoch 51/150\n",
      "16592/16592 [==============================] - 2s 111us/step - loss: 0.0929 - val_loss: 0.0940\n",
      "Epoch 52/150\n",
      "16592/16592 [==============================] - 2s 107us/step - loss: 0.0911 - val_loss: 0.0932\n",
      "Evaluating model with testing data...\n",
      "3534/3534 [==============================] - 0s 16us/step\n",
      "Getting distribution of predictions and covariance matrix...\n",
      "      1 of 20\n",
      "      2 of 20\n",
      "      3 of 20\n",
      "      4 of 20\n",
      "      5 of 20\n",
      "      6 of 20\n",
      "      7 of 20\n",
      "      8 of 20\n",
      "      9 of 20\n",
      "      10 of 20\n",
      "      11 of 20\n",
      "      12 of 20\n",
      "      13 of 20\n",
      "      14 of 20\n",
      "      15 of 20\n",
      "      16 of 20\n",
      "      17 of 20\n",
      "      18 of 20\n",
      "      19 of 20\n",
      "      20 of 20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|          | 0/20 [00:00<?, ?it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing ensemble means...\n",
      "Computing mean squared error...\n",
      "Getting distribution of predictions...\n",
      "      1 of 20\n",
      "1600/1600 [==============================] - 0s 28us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  5%|▌         | 1/20 [00:29<09:18, 29.42s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      2 of 20\n",
      "1600/1600 [==============================] - 0s 29us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 10%|█         | 2/20 [00:59<08:51, 29.52s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      3 of 20\n",
      "1600/1600 [==============================] - 0s 31us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 15%|█▌        | 3/20 [01:28<08:22, 29.56s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      4 of 20\n",
      "1600/1600 [==============================] - 0s 30us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 20%|██        | 4/20 [01:58<07:51, 29.48s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      5 of 20\n",
      "1600/1600 [==============================] - 0s 29us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 25%|██▌       | 5/20 [02:27<07:23, 29.55s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      6 of 20\n",
      "1600/1600 [==============================] - 0s 28us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 30%|███       | 6/20 [02:57<06:53, 29.51s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      7 of 20\n",
      "1600/1600 [==============================] - 0s 29us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 35%|███▌      | 7/20 [03:27<06:25, 29.63s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      8 of 20\n",
      "1600/1600 [==============================] - 0s 30us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 40%|████      | 8/20 [03:56<05:54, 29.56s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      9 of 20\n",
      "1600/1600 [==============================] - 0s 29us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 45%|████▌     | 9/20 [04:26<05:25, 29.55s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      10 of 20\n",
      "1600/1600 [==============================] - 0s 29us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 50%|█████     | 10/20 [04:55<04:54, 29.45s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      11 of 20\n",
      "1600/1600 [==============================] - 0s 29us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 55%|█████▌    | 11/20 [05:24<04:25, 29.49s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      12 of 20\n",
      "1600/1600 [==============================] - 0s 28us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 60%|██████    | 12/20 [05:54<03:55, 29.49s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      13 of 20\n",
      "1600/1600 [==============================] - 0s 29us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 65%|██████▌   | 13/20 [06:23<03:26, 29.50s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      14 of 20\n",
      "1600/1600 [==============================] - 0s 29us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 70%|███████   | 14/20 [06:53<02:57, 29.59s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      15 of 20\n",
      "1600/1600 [==============================] - 0s 29us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 75%|███████▌  | 15/20 [07:23<02:27, 29.54s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      16 of 20\n",
      "1600/1600 [==============================] - 0s 29us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 80%|████████  | 16/20 [07:52<01:58, 29.58s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      17 of 20\n",
      "1600/1600 [==============================] - 0s 29us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 85%|████████▌ | 17/20 [08:22<01:28, 29.54s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      18 of 20\n",
      "1600/1600 [==============================] - 0s 29us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 90%|█████████ | 18/20 [08:52<00:59, 29.61s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      19 of 20\n",
      "1600/1600 [==============================] - 0s 30us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 95%|█████████▌| 19/20 [09:21<00:29, 29.62s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      20 of 20\n",
      "1600/1600 [==============================] - 0s 29us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 20/20 [09:51<00:00, 29.57s/it]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing ensemble predictions...\n",
      "Iteration 116\n",
      "Train on 16732 samples, validate on 3564 samples\n",
      "Epoch 1/150\n",
      "16732/16732 [==============================] - 2s 112us/step - loss: 0.3851 - val_loss: 0.2807\n",
      "Epoch 2/150\n",
      "16732/16732 [==============================] - 2s 109us/step - loss: 0.2535 - val_loss: 0.2295\n",
      "Epoch 3/150\n",
      "16732/16732 [==============================] - 2s 111us/step - loss: 0.2145 - val_loss: 0.2035\n",
      "Epoch 4/150\n",
      "16732/16732 [==============================] - 2s 107us/step - loss: 0.1936 - val_loss: 0.1769\n",
      "Epoch 5/150\n",
      "16732/16732 [==============================] - 2s 112us/step - loss: 0.1717 - val_loss: 0.1635\n",
      "Epoch 6/150\n",
      "16732/16732 [==============================] - 2s 113us/step - loss: 0.1651 - val_loss: 0.1605\n",
      "Epoch 7/150\n",
      "16732/16732 [==============================] - 2s 109us/step - loss: 0.1588 - val_loss: 0.1591\n",
      "Epoch 8/150\n",
      "16732/16732 [==============================] - 2s 111us/step - loss: 0.1550 - val_loss: 0.1513\n",
      "Epoch 9/150\n",
      "16732/16732 [==============================] - 2s 110us/step - loss: 0.1523 - val_loss: 0.1550\n",
      "Epoch 10/150\n",
      "16732/16732 [==============================] - 2s 110us/step - loss: 0.1506 - val_loss: 0.1469\n",
      "Epoch 11/150\n",
      "16732/16732 [==============================] - 2s 102us/step - loss: 0.1487 - val_loss: 0.1479\n",
      "Epoch 12/150\n",
      "16732/16732 [==============================] - 2s 113us/step - loss: 0.1461 - val_loss: 0.1452\n",
      "Epoch 13/150\n",
      "16732/16732 [==============================] - 2s 106us/step - loss: 0.1451 - val_loss: 0.1522\n",
      "Epoch 14/150\n",
      "16732/16732 [==============================] - 2s 109us/step - loss: 0.1452 - val_loss: 0.1445\n",
      "Epoch 15/150\n",
      "16732/16732 [==============================] - 2s 111us/step - loss: 0.1432 - val_loss: 0.1461\n",
      "Epoch 16/150\n",
      "16732/16732 [==============================] - 2s 108us/step - loss: 0.1433 - val_loss: 0.1434\n",
      "Epoch 17/150\n",
      "16732/16732 [==============================] - 2s 111us/step - loss: 0.1452 - val_loss: 0.1449\n",
      "Epoch 18/150\n",
      "16732/16732 [==============================] - 2s 103us/step - loss: 0.1427 - val_loss: 0.1421\n",
      "Epoch 19/150\n",
      "16732/16732 [==============================] - 2s 112us/step - loss: 0.1435 - val_loss: 0.1420\n",
      "Epoch 20/150\n",
      "16732/16732 [==============================] - 2s 105us/step - loss: 0.1415 - val_loss: 0.1440\n",
      "Epoch 21/150\n",
      "16732/16732 [==============================] - 2s 109us/step - loss: 0.1417 - val_loss: 0.1434\n",
      "Epoch 22/150\n",
      "16732/16732 [==============================] - 2s 111us/step - loss: 0.1419 - val_loss: 0.1425\n",
      "Epoch 23/150\n",
      "16732/16732 [==============================] - 2s 110us/step - loss: 0.1397 - val_loss: 0.1399\n",
      "Epoch 24/150\n",
      "16732/16732 [==============================] - 2s 107us/step - loss: 0.1397 - val_loss: 0.1403\n",
      "Epoch 25/150\n",
      "16732/16732 [==============================] - 2s 110us/step - loss: 0.1393 - val_loss: 0.1415\n",
      "Epoch 26/150\n",
      "16732/16732 [==============================] - 2s 104us/step - loss: 0.1398 - val_loss: 0.1398\n",
      "Epoch 27/150\n",
      "16732/16732 [==============================] - 2s 106us/step - loss: 0.1399 - val_loss: 0.1418\n",
      "Epoch 28/150\n",
      "16732/16732 [==============================] - 2s 107us/step - loss: 0.1405 - val_loss: 0.1395\n",
      "Epoch 29/150\n",
      "16732/16732 [==============================] - 2s 108us/step - loss: 0.1382 - val_loss: 0.1381\n",
      "Epoch 30/150\n",
      "16732/16732 [==============================] - 2s 104us/step - loss: 0.1378 - val_loss: 0.1399\n",
      "Epoch 31/150\n",
      "16732/16732 [==============================] - 2s 108us/step - loss: 0.1380 - val_loss: 0.1398\n",
      "Epoch 32/150\n",
      "16732/16732 [==============================] - 2s 106us/step - loss: 0.1376 - val_loss: 0.1412\n",
      "Epoch 33/150\n",
      "16732/16732 [==============================] - 2s 107us/step - loss: 0.1381 - val_loss: 0.1380\n",
      "Epoch 34/150\n",
      "16732/16732 [==============================] - 2s 108us/step - loss: 0.1366 - val_loss: 0.1342\n",
      "Epoch 35/150\n",
      "16732/16732 [==============================] - 2s 110us/step - loss: 0.1354 - val_loss: 0.1370\n",
      "Epoch 36/150\n",
      "16732/16732 [==============================] - 2s 108us/step - loss: 0.1353 - val_loss: 0.1353\n",
      "Epoch 37/150\n",
      "16732/16732 [==============================] - 2s 109us/step - loss: 0.1364 - val_loss: 0.1382\n",
      "Epoch 38/150\n",
      "16732/16732 [==============================] - 2s 110us/step - loss: 0.1359 - val_loss: 0.1350\n",
      "Evaluating model with testing data...\n",
      "3564/3564 [==============================] - 0s 16us/step\n",
      "Getting distribution of predictions and covariance matrix...\n",
      "      1 of 20\n",
      "      2 of 20\n",
      "      3 of 20\n",
      "      4 of 20\n",
      "      5 of 20\n",
      "      6 of 20\n",
      "      7 of 20\n",
      "      8 of 20\n",
      "      9 of 20\n",
      "      10 of 20\n",
      "      11 of 20\n",
      "      12 of 20\n",
      "      13 of 20\n",
      "      14 of 20\n",
      "      15 of 20\n",
      "      16 of 20\n",
      "      17 of 20\n",
      "      18 of 20\n",
      "      19 of 20\n",
      "      20 of 20\n",
      "Computing ensemble means...\n",
      "Computing mean squared error...\n",
      "Iteration 117\n",
      "Train on 16872 samples, validate on 3594 samples\n",
      "Epoch 1/150\n",
      "16872/16872 [==============================] - 2s 108us/step - loss: 0.3661 - val_loss: 0.2512\n",
      "Epoch 2/150\n",
      "16872/16872 [==============================] - 2s 106us/step - loss: 0.2260 - val_loss: 0.2027\n",
      "Epoch 3/150\n",
      "16872/16872 [==============================] - 2s 103us/step - loss: 0.1959 - val_loss: 0.1859\n",
      "Epoch 4/150\n",
      "16872/16872 [==============================] - 2s 106us/step - loss: 0.1777 - val_loss: 0.1713\n",
      "Epoch 5/150\n",
      "16872/16872 [==============================] - 2s 109us/step - loss: 0.1662 - val_loss: 0.1604\n",
      "Epoch 6/150\n",
      "16872/16872 [==============================] - 2s 105us/step - loss: 0.1590 - val_loss: 0.1529\n",
      "Epoch 7/150\n",
      "16872/16872 [==============================] - 2s 110us/step - loss: 0.1533 - val_loss: 0.1517\n",
      "Epoch 8/150\n",
      "16872/16872 [==============================] - 2s 100us/step - loss: 0.1473 - val_loss: 0.1412\n",
      "Epoch 9/150\n",
      "16872/16872 [==============================] - 2s 101us/step - loss: 0.1430 - val_loss: 0.1432\n",
      "Epoch 10/150\n",
      "16872/16872 [==============================] - 2s 113us/step - loss: 0.1411 - val_loss: 0.1422\n",
      "Epoch 11/150\n",
      "16872/16872 [==============================] - 2s 106us/step - loss: 0.1373 - val_loss: 0.1340\n",
      "Epoch 12/150\n",
      "16872/16872 [==============================] - 2s 101us/step - loss: 0.1359 - val_loss: 0.1319\n",
      "Epoch 13/150\n",
      "16872/16872 [==============================] - 2s 100us/step - loss: 0.1304 - val_loss: 0.1293\n",
      "Epoch 14/150\n",
      "16872/16872 [==============================] - 2s 107us/step - loss: 0.1309 - val_loss: 0.1287\n",
      "Epoch 15/150\n",
      "16872/16872 [==============================] - 2s 104us/step - loss: 0.1287 - val_loss: 0.1272\n",
      "Epoch 16/150\n",
      "16872/16872 [==============================] - 2s 108us/step - loss: 0.1268 - val_loss: 0.1251\n",
      "Epoch 17/150\n",
      "16872/16872 [==============================] - 2s 105us/step - loss: 0.1253 - val_loss: 0.1239\n",
      "Epoch 18/150\n",
      "16872/16872 [==============================] - 2s 98us/step - loss: 0.1230 - val_loss: 0.1224\n",
      "Epoch 19/150\n",
      "16872/16872 [==============================] - 1s 59us/step - loss: 0.1217 - val_loss: 0.1189\n",
      "Epoch 20/150\n",
      "16872/16872 [==============================] - 1s 79us/step - loss: 0.1203 - val_loss: 0.1222\n",
      "Epoch 21/150\n",
      "16872/16872 [==============================] - 2s 105us/step - loss: 0.1198 - val_loss: 0.1194\n",
      "Epoch 22/150\n",
      "16872/16872 [==============================] - 2s 105us/step - loss: 0.1169 - val_loss: 0.1175\n",
      "Epoch 23/150\n",
      "16872/16872 [==============================] - 2s 100us/step - loss: 0.1149 - val_loss: 0.1163\n",
      "Epoch 24/150\n",
      "16872/16872 [==============================] - 2s 107us/step - loss: 0.1146 - val_loss: 0.1167\n",
      "Epoch 25/150\n",
      "16872/16872 [==============================] - 2s 100us/step - loss: 0.1134 - val_loss: 0.1169\n",
      "Epoch 26/150\n",
      "16872/16872 [==============================] - 2s 103us/step - loss: 0.1135 - val_loss: 0.1190\n",
      "Epoch 27/150\n",
      "16872/16872 [==============================] - 2s 108us/step - loss: 0.1115 - val_loss: 0.1162\n",
      "Epoch 28/150\n",
      "16872/16872 [==============================] - 2s 101us/step - loss: 0.1116 - val_loss: 0.1133\n",
      "Epoch 29/150\n",
      "16872/16872 [==============================] - 2s 102us/step - loss: 0.1119 - val_loss: 0.1099\n",
      "Epoch 30/150\n",
      "16872/16872 [==============================] - 2s 104us/step - loss: 0.1102 - val_loss: 0.1109\n",
      "Epoch 31/150\n",
      "16872/16872 [==============================] - 2s 99us/step - loss: 0.1107 - val_loss: 0.1086\n",
      "Epoch 32/150\n",
      "16872/16872 [==============================] - 2s 97us/step - loss: 0.1078 - val_loss: 0.1120\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 33/150\n",
      "16872/16872 [==============================] - 2s 110us/step - loss: 0.1076 - val_loss: 0.1126\n",
      "Epoch 34/150\n",
      "16872/16872 [==============================] - 2s 113us/step - loss: 0.1071 - val_loss: 0.1107\n",
      "Epoch 35/150\n",
      "16872/16872 [==============================] - 2s 110us/step - loss: 0.1088 - val_loss: 0.1072\n",
      "Epoch 36/150\n",
      "16872/16872 [==============================] - 2s 113us/step - loss: 0.1071 - val_loss: 0.1085\n",
      "Epoch 37/150\n",
      "16872/16872 [==============================] - 2s 112us/step - loss: 0.1068 - val_loss: 0.1092\n",
      "Epoch 38/150\n",
      "16872/16872 [==============================] - 2s 113us/step - loss: 0.1061 - val_loss: 0.1054\n",
      "Epoch 39/150\n",
      "16872/16872 [==============================] - 2s 109us/step - loss: 0.1057 - val_loss: 0.1076\n",
      "Epoch 40/150\n",
      "16872/16872 [==============================] - 2s 114us/step - loss: 0.1047 - val_loss: 0.1071\n",
      "Epoch 41/150\n",
      "16872/16872 [==============================] - 2s 114us/step - loss: 0.1055 - val_loss: 0.1093\n",
      "Epoch 42/150\n",
      "16872/16872 [==============================] - 2s 112us/step - loss: 0.1043 - val_loss: 0.1062\n",
      "Evaluating model with testing data...\n",
      "3594/3594 [==============================] - 0s 16us/step\n",
      "Getting distribution of predictions and covariance matrix...\n",
      "      1 of 20\n",
      "      2 of 20\n",
      "      3 of 20\n",
      "      4 of 20\n",
      "      5 of 20\n",
      "      6 of 20\n",
      "      7 of 20\n",
      "      8 of 20\n",
      "      9 of 20\n",
      "      10 of 20\n",
      "      11 of 20\n",
      "      12 of 20\n",
      "      13 of 20\n",
      "      14 of 20\n",
      "      15 of 20\n",
      "      16 of 20\n",
      "      17 of 20\n",
      "      18 of 20\n",
      "      19 of 20\n",
      "      20 of 20\n",
      "Computing ensemble means...\n",
      "Computing mean squared error...\n",
      "Iteration 118\n",
      "Train on 17012 samples, validate on 3624 samples\n",
      "Epoch 1/150\n",
      "17012/17012 [==============================] - 2s 107us/step - loss: 0.4200 - val_loss: 0.3058\n",
      "Epoch 2/150\n",
      "17012/17012 [==============================] - 2s 112us/step - loss: 0.2720 - val_loss: 0.2340\n",
      "Epoch 3/150\n",
      "17012/17012 [==============================] - 2s 107us/step - loss: 0.2222 - val_loss: 0.2157\n",
      "Epoch 4/150\n",
      "17012/17012 [==============================] - 2s 112us/step - loss: 0.2020 - val_loss: 0.1974\n",
      "Epoch 5/150\n",
      "17012/17012 [==============================] - 2s 108us/step - loss: 0.1880 - val_loss: 0.1837\n",
      "Epoch 6/150\n",
      "17012/17012 [==============================] - 2s 110us/step - loss: 0.1748 - val_loss: 0.1766\n",
      "Epoch 7/150\n",
      "17012/17012 [==============================] - 2s 103us/step - loss: 0.1675 - val_loss: 0.1637\n",
      "Epoch 8/150\n",
      "17012/17012 [==============================] - 2s 106us/step - loss: 0.1619 - val_loss: 0.1589\n",
      "Epoch 9/150\n",
      "17012/17012 [==============================] - 2s 106us/step - loss: 0.1580 - val_loss: 0.1531\n",
      "Epoch 10/150\n",
      "17012/17012 [==============================] - 2s 107us/step - loss: 0.1500 - val_loss: 0.1485\n",
      "Epoch 11/150\n",
      "17012/17012 [==============================] - 2s 111us/step - loss: 0.1474 - val_loss: 0.1497\n",
      "Epoch 12/150\n",
      "17012/17012 [==============================] - 2s 111us/step - loss: 0.1442 - val_loss: 0.1441\n",
      "Epoch 13/150\n",
      "17012/17012 [==============================] - 2s 113us/step - loss: 0.1437 - val_loss: 0.1464\n",
      "Epoch 14/150\n",
      "17012/17012 [==============================] - 2s 108us/step - loss: 0.1409 - val_loss: 0.1414\n",
      "Epoch 15/150\n",
      "17012/17012 [==============================] - 2s 108us/step - loss: 0.1387 - val_loss: 0.1385\n",
      "Epoch 16/150\n",
      "17012/17012 [==============================] - 2s 112us/step - loss: 0.1352 - val_loss: 0.1355\n",
      "Epoch 17/150\n",
      "17012/17012 [==============================] - 2s 109us/step - loss: 0.1332 - val_loss: 0.1348\n",
      "Epoch 18/150\n",
      "17012/17012 [==============================] - 2s 109us/step - loss: 0.1318 - val_loss: 0.1304\n",
      "Epoch 19/150\n",
      "17012/17012 [==============================] - 2s 108us/step - loss: 0.1285 - val_loss: 0.1340\n",
      "Epoch 20/150\n",
      "17012/17012 [==============================] - 2s 101us/step - loss: 0.1277 - val_loss: 0.1318\n",
      "Epoch 21/150\n",
      "17012/17012 [==============================] - 2s 107us/step - loss: 0.1269 - val_loss: 0.1277\n",
      "Epoch 22/150\n",
      "17012/17012 [==============================] - 2s 109us/step - loss: 0.1255 - val_loss: 0.1305\n",
      "Epoch 23/150\n",
      "17012/17012 [==============================] - 2s 111us/step - loss: 0.1227 - val_loss: 0.1289\n",
      "Epoch 24/150\n",
      "17012/17012 [==============================] - 2s 103us/step - loss: 0.1222 - val_loss: 0.1238\n",
      "Epoch 25/150\n",
      "17012/17012 [==============================] - 2s 108us/step - loss: 0.1212 - val_loss: 0.1233\n",
      "Epoch 26/150\n",
      "17012/17012 [==============================] - 2s 102us/step - loss: 0.1191 - val_loss: 0.1205\n",
      "Epoch 27/150\n",
      "17012/17012 [==============================] - 2s 108us/step - loss: 0.1177 - val_loss: 0.1203\n",
      "Epoch 28/150\n",
      "17012/17012 [==============================] - 2s 105us/step - loss: 0.1176 - val_loss: 0.1199\n",
      "Epoch 29/150\n",
      "17012/17012 [==============================] - 2s 103us/step - loss: 0.1173 - val_loss: 0.1163\n",
      "Epoch 30/150\n",
      "17012/17012 [==============================] - 2s 104us/step - loss: 0.1174 - val_loss: 0.1185\n",
      "Epoch 31/150\n",
      "17012/17012 [==============================] - 2s 103us/step - loss: 0.1159 - val_loss: 0.1178\n",
      "Epoch 32/150\n",
      "17012/17012 [==============================] - 2s 105us/step - loss: 0.1153 - val_loss: 0.1180\n",
      "Epoch 33/150\n",
      "17012/17012 [==============================] - 2s 108us/step - loss: 0.1145 - val_loss: 0.1178\n",
      "Evaluating model with testing data...\n",
      "3624/3624 [==============================] - 0s 15us/step\n",
      "Getting distribution of predictions and covariance matrix...\n",
      "      1 of 20\n",
      "      2 of 20\n",
      "      3 of 20\n",
      "      4 of 20\n",
      "      5 of 20\n",
      "      6 of 20\n",
      "      7 of 20\n",
      "      8 of 20\n",
      "      9 of 20\n",
      "      10 of 20\n",
      "      11 of 20\n",
      "      12 of 20\n",
      "      13 of 20\n",
      "      14 of 20\n",
      "      15 of 20\n",
      "      16 of 20\n",
      "      17 of 20\n",
      "      18 of 20\n",
      "      19 of 20\n",
      "      20 of 20\n",
      "Computing ensemble means...\n",
      "Computing mean squared error...\n",
      "Iteration 119\n",
      "Train on 17152 samples, validate on 3654 samples\n",
      "Epoch 1/150\n",
      "17152/17152 [==============================] - 2s 105us/step - loss: 0.3727 - val_loss: 0.2716\n",
      "Epoch 2/150\n",
      "17152/17152 [==============================] - 2s 103us/step - loss: 0.2420 - val_loss: 0.2232\n",
      "Epoch 3/150\n",
      "17152/17152 [==============================] - 2s 106us/step - loss: 0.2110 - val_loss: 0.1984\n",
      "Epoch 4/150\n",
      "17152/17152 [==============================] - 2s 106us/step - loss: 0.1891 - val_loss: 0.1890\n",
      "Epoch 5/150\n",
      "17152/17152 [==============================] - 2s 109us/step - loss: 0.1767 - val_loss: 0.1736\n",
      "Epoch 6/150\n",
      "17152/17152 [==============================] - 2s 108us/step - loss: 0.1678 - val_loss: 0.1643\n",
      "Epoch 7/150\n",
      "17152/17152 [==============================] - 2s 103us/step - loss: 0.1626 - val_loss: 0.1635\n",
      "Epoch 8/150\n",
      "17152/17152 [==============================] - 1s 62us/step - loss: 0.1588 - val_loss: 0.1553\n",
      "Epoch 9/150\n",
      "17152/17152 [==============================] - 1s 71us/step - loss: 0.1556 - val_loss: 0.1566\n",
      "Epoch 10/150\n",
      "17152/17152 [==============================] - 2s 103us/step - loss: 0.1536 - val_loss: 0.1546\n",
      "Epoch 11/150\n",
      "17152/17152 [==============================] - 2s 104us/step - loss: 0.1528 - val_loss: 0.1518\n",
      "Epoch 12/150\n",
      "17152/17152 [==============================] - 2s 103us/step - loss: 0.1508 - val_loss: 0.1513\n",
      "Epoch 13/150\n",
      "17152/17152 [==============================] - 2s 104us/step - loss: 0.1496 - val_loss: 0.1485\n",
      "Epoch 14/150\n",
      "17152/17152 [==============================] - 2s 106us/step - loss: 0.1482 - val_loss: 0.1513\n",
      "Epoch 15/150\n",
      "17152/17152 [==============================] - 2s 100us/step - loss: 0.1474 - val_loss: 0.1490\n",
      "Epoch 16/150\n",
      "17152/17152 [==============================] - 2s 103us/step - loss: 0.1471 - val_loss: 0.1476\n",
      "Epoch 17/150\n",
      "17152/17152 [==============================] - 2s 107us/step - loss: 0.1465 - val_loss: 0.1485\n",
      "Epoch 18/150\n",
      "17152/17152 [==============================] - 2s 102us/step - loss: 0.1450 - val_loss: 0.1421\n",
      "Epoch 19/150\n",
      "17152/17152 [==============================] - 2s 103us/step - loss: 0.1447 - val_loss: 0.1472\n",
      "Epoch 20/150\n",
      "17152/17152 [==============================] - 2s 104us/step - loss: 0.1437 - val_loss: 0.1453\n",
      "Epoch 21/150\n",
      "17152/17152 [==============================] - 2s 98us/step - loss: 0.1436 - val_loss: 0.1419\n",
      "Epoch 22/150\n",
      "17152/17152 [==============================] - 2s 101us/step - loss: 0.1445 - val_loss: 0.1442\n",
      "Epoch 23/150\n",
      "17152/17152 [==============================] - 2s 110us/step - loss: 0.1433 - val_loss: 0.1391\n",
      "Epoch 24/150\n",
      "17152/17152 [==============================] - 2s 113us/step - loss: 0.1407 - val_loss: 0.1398\n",
      "Epoch 25/150\n",
      "17152/17152 [==============================] - 2s 111us/step - loss: 0.1387 - val_loss: 0.1379\n",
      "Epoch 26/150\n",
      "17152/17152 [==============================] - 2s 113us/step - loss: 0.1398 - val_loss: 0.1419\n",
      "Epoch 27/150\n",
      "17152/17152 [==============================] - 2s 110us/step - loss: 0.1382 - val_loss: 0.1394\n",
      "Epoch 28/150\n",
      "17152/17152 [==============================] - 2s 106us/step - loss: 0.1379 - val_loss: 0.1393\n",
      "Epoch 29/150\n",
      "17152/17152 [==============================] - 2s 114us/step - loss: 0.1370 - val_loss: 0.1395\n",
      "Evaluating model with testing data...\n",
      "3654/3654 [==============================] - 0s 16us/step\n",
      "Getting distribution of predictions and covariance matrix...\n",
      "      1 of 20\n",
      "      2 of 20\n",
      "      3 of 20\n",
      "      4 of 20\n",
      "      5 of 20\n",
      "      6 of 20\n",
      "      7 of 20\n",
      "      8 of 20\n",
      "      9 of 20\n",
      "      10 of 20\n",
      "      11 of 20\n",
      "      12 of 20\n",
      "      13 of 20\n",
      "      14 of 20\n",
      "      15 of 20\n",
      "      16 of 20\n",
      "      17 of 20\n",
      "      18 of 20\n",
      "      19 of 20\n",
      "      20 of 20\n",
      "Computing ensemble means...\n",
      "Computing mean squared error...\n",
      "Iteration 120\n",
      "Train on 17292 samples, validate on 3684 samples\n",
      "Epoch 1/150\n",
      "17292/17292 [==============================] - 2s 111us/step - loss: 0.4513 - val_loss: 0.3068\n",
      "Epoch 2/150\n",
      "17292/17292 [==============================] - 2s 110us/step - loss: 0.2708 - val_loss: 0.2439\n",
      "Epoch 3/150\n",
      "17292/17292 [==============================] - 2s 110us/step - loss: 0.2286 - val_loss: 0.2222\n",
      "Epoch 4/150\n",
      "17292/17292 [==============================] - 2s 111us/step - loss: 0.2107 - val_loss: 0.2039\n",
      "Epoch 5/150\n",
      "17292/17292 [==============================] - 2s 108us/step - loss: 0.1960 - val_loss: 0.1859\n",
      "Epoch 6/150\n",
      "17292/17292 [==============================] - 2s 114us/step - loss: 0.1833 - val_loss: 0.1827\n",
      "Epoch 7/150\n",
      "17292/17292 [==============================] - 2s 110us/step - loss: 0.1761 - val_loss: 0.1775\n",
      "Epoch 8/150\n",
      "17292/17292 [==============================] - 2s 112us/step - loss: 0.1714 - val_loss: 0.1672\n",
      "Epoch 9/150\n",
      "17292/17292 [==============================] - 2s 106us/step - loss: 0.1645 - val_loss: 0.1661\n",
      "Epoch 10/150\n",
      "17292/17292 [==============================] - 2s 109us/step - loss: 0.1619 - val_loss: 0.1622\n",
      "Epoch 11/150\n",
      "17292/17292 [==============================] - 2s 113us/step - loss: 0.1586 - val_loss: 0.1616\n",
      "Epoch 12/150\n",
      "17292/17292 [==============================] - 2s 112us/step - loss: 0.1576 - val_loss: 0.1590\n",
      "Epoch 13/150\n",
      "17292/17292 [==============================] - 2s 105us/step - loss: 0.1566 - val_loss: 0.1594\n",
      "Epoch 14/150\n",
      "17292/17292 [==============================] - 2s 110us/step - loss: 0.1559 - val_loss: 0.1540\n",
      "Epoch 15/150\n",
      "17292/17292 [==============================] - 2s 108us/step - loss: 0.1534 - val_loss: 0.1531\n",
      "Epoch 16/150\n",
      "17292/17292 [==============================] - 2s 106us/step - loss: 0.1551 - val_loss: 0.1521\n",
      "Epoch 17/150\n",
      "17292/17292 [==============================] - 2s 107us/step - loss: 0.1534 - val_loss: 0.1543\n",
      "Epoch 18/150\n",
      "17292/17292 [==============================] - 2s 111us/step - loss: 0.1531 - val_loss: 0.1567\n",
      "Epoch 19/150\n",
      "17292/17292 [==============================] - 2s 96us/step - loss: 0.1529 - val_loss: 0.1532\n",
      "Epoch 20/150\n",
      "17292/17292 [==============================] - 2s 109us/step - loss: 0.1491 - val_loss: 0.1551\n",
      "Evaluating model with testing data...\n",
      "3684/3684 [==============================] - 0s 15us/step\n",
      "Getting distribution of predictions and covariance matrix...\n",
      "      1 of 20\n",
      "      2 of 20\n",
      "      3 of 20\n",
      "      4 of 20\n",
      "      5 of 20\n",
      "      6 of 20\n",
      "      7 of 20\n",
      "      8 of 20\n",
      "      9 of 20\n",
      "      10 of 20\n",
      "      11 of 20\n",
      "      12 of 20\n",
      "      13 of 20\n",
      "      14 of 20\n",
      "      15 of 20\n",
      "      16 of 20\n",
      "      17 of 20\n",
      "      18 of 20\n",
      "      19 of 20\n",
      "      20 of 20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|          | 0/20 [00:00<?, ?it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing ensemble means...\n",
      "Computing mean squared error...\n",
      "Getting distribution of predictions...\n",
      "      1 of 20\n",
      "1600/1600 [==============================] - 0s 28us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  5%|▌         | 1/20 [00:29<09:26, 29.79s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      2 of 20\n",
      "1600/1600 [==============================] - 0s 28us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 10%|█         | 2/20 [00:59<08:53, 29.67s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      3 of 20\n",
      "1600/1600 [==============================] - 0s 28us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 15%|█▌        | 3/20 [01:28<08:23, 29.62s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      4 of 20\n",
      "1600/1600 [==============================] - 0s 30us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 20%|██        | 4/20 [01:58<07:54, 29.64s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      5 of 20\n",
      "1600/1600 [==============================] - 0s 29us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 25%|██▌       | 5/20 [02:28<07:24, 29.65s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      6 of 20\n",
      "1600/1600 [==============================] - 0s 29us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 30%|███       | 6/20 [02:57<06:53, 29.56s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      7 of 20\n",
      "1600/1600 [==============================] - 0s 29us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 35%|███▌      | 7/20 [03:26<06:24, 29.55s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      8 of 20\n",
      "1600/1600 [==============================] - 0s 30us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 40%|████      | 8/20 [03:56<05:54, 29.58s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      9 of 20\n",
      "1600/1600 [==============================] - 0s 28us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 45%|████▌     | 9/20 [04:26<05:25, 29.59s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      10 of 20\n",
      "1600/1600 [==============================] - 0s 29us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 50%|█████     | 10/20 [04:55<04:54, 29.48s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      11 of 20\n",
      "1600/1600 [==============================] - 0s 29us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 55%|█████▌    | 11/20 [05:24<04:25, 29.49s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      12 of 20\n",
      "1600/1600 [==============================] - 0s 28us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 60%|██████    | 12/20 [05:54<03:56, 29.58s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      13 of 20\n",
      "1600/1600 [==============================] - 0s 30us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 65%|██████▌   | 13/20 [06:24<03:27, 29.62s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      14 of 20\n",
      "1600/1600 [==============================] - 0s 30us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 70%|███████   | 14/20 [06:53<02:57, 29.57s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      15 of 20\n",
      "1600/1600 [==============================] - 0s 29us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 75%|███████▌  | 15/20 [07:23<02:27, 29.58s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      16 of 20\n",
      "1600/1600 [==============================] - 0s 29us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 80%|████████  | 16/20 [07:53<01:58, 29.64s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      17 of 20\n",
      "1600/1600 [==============================] - 0s 28us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 85%|████████▌ | 17/20 [08:22<01:28, 29.64s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      18 of 20\n",
      "1600/1600 [==============================] - 0s 28us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 90%|█████████ | 18/20 [08:52<00:59, 29.61s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      19 of 20\n",
      "1600/1600 [==============================] - 0s 28us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 95%|█████████▌| 19/20 [09:21<00:29, 29.57s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      20 of 20\n",
      "1600/1600 [==============================] - 0s 29us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 20/20 [09:51<00:00, 29.58s/it]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing ensemble predictions...\n",
      "Iteration 121\n",
      "Train on 17432 samples, validate on 3714 samples\n",
      "Epoch 1/150\n",
      "17432/17432 [==============================] - 2s 114us/step - loss: 0.4695 - val_loss: 0.3652\n",
      "Epoch 2/150\n",
      "17432/17432 [==============================] - 2s 102us/step - loss: 0.3408 - val_loss: 0.3185\n",
      "Epoch 3/150\n",
      "17432/17432 [==============================] - 2s 108us/step - loss: 0.3035 - val_loss: 0.2869\n",
      "Epoch 4/150\n",
      "17432/17432 [==============================] - 2s 111us/step - loss: 0.2721 - val_loss: 0.2600\n",
      "Epoch 5/150\n",
      "17432/17432 [==============================] - 2s 110us/step - loss: 0.2480 - val_loss: 0.2277\n",
      "Epoch 6/150\n",
      "17432/17432 [==============================] - 2s 109us/step - loss: 0.2117 - val_loss: 0.1990\n",
      "Epoch 7/150\n",
      "17432/17432 [==============================] - 2s 106us/step - loss: 0.1942 - val_loss: 0.1855\n",
      "Epoch 8/150\n",
      "17432/17432 [==============================] - 2s 111us/step - loss: 0.1865 - val_loss: 0.1802\n",
      "Epoch 9/150\n",
      "17432/17432 [==============================] - 2s 107us/step - loss: 0.1826 - val_loss: 0.1814\n",
      "Epoch 10/150\n",
      "17432/17432 [==============================] - 2s 113us/step - loss: 0.1812 - val_loss: 0.1772\n",
      "Epoch 11/150\n",
      "17432/17432 [==============================] - 2s 111us/step - loss: 0.1790 - val_loss: 0.1810\n",
      "Epoch 12/150\n",
      "17432/17432 [==============================] - 2s 112us/step - loss: 0.1772 - val_loss: 0.1721\n",
      "Epoch 13/150\n",
      "17432/17432 [==============================] - 2s 113us/step - loss: 0.1759 - val_loss: 0.1748\n",
      "Epoch 14/150\n",
      "17432/17432 [==============================] - 2s 110us/step - loss: 0.1749 - val_loss: 0.1709\n",
      "Epoch 15/150\n",
      "17432/17432 [==============================] - 2s 111us/step - loss: 0.1727 - val_loss: 0.1720\n",
      "Epoch 16/150\n",
      "17432/17432 [==============================] - 2s 111us/step - loss: 0.1733 - val_loss: 0.1692\n",
      "Epoch 17/150\n",
      "17432/17432 [==============================] - 2s 108us/step - loss: 0.1750 - val_loss: 0.1732\n",
      "Epoch 18/150\n",
      "17432/17432 [==============================] - 2s 112us/step - loss: 0.1737 - val_loss: 0.1690\n",
      "Epoch 19/150\n",
      "17432/17432 [==============================] - 2s 109us/step - loss: 0.1719 - val_loss: 0.1713\n",
      "Epoch 20/150\n",
      "17432/17432 [==============================] - 2s 101us/step - loss: 0.1709 - val_loss: 0.1704\n",
      "Epoch 21/150\n",
      "17432/17432 [==============================] - 2s 107us/step - loss: 0.1661 - val_loss: 0.1657\n",
      "Epoch 22/150\n",
      "17432/17432 [==============================] - 2s 105us/step - loss: 0.1663 - val_loss: 0.1698\n",
      "Epoch 23/150\n",
      "17432/17432 [==============================] - 2s 109us/step - loss: 0.1644 - val_loss: 0.1624\n",
      "Epoch 24/150\n",
      "17432/17432 [==============================] - 2s 109us/step - loss: 0.1642 - val_loss: 0.1629\n",
      "Epoch 25/150\n",
      "17432/17432 [==============================] - 2s 105us/step - loss: 0.1634 - val_loss: 0.1616\n",
      "Epoch 26/150\n",
      "17432/17432 [==============================] - 1s 59us/step - loss: 0.1632 - val_loss: 0.1624\n",
      "Epoch 27/150\n",
      "17432/17432 [==============================] - 1s 85us/step - loss: 0.1625 - val_loss: 0.1621\n",
      "Epoch 28/150\n",
      "17432/17432 [==============================] - 2s 104us/step - loss: 0.1616 - val_loss: 0.1632\n",
      "Epoch 29/150\n",
      "17432/17432 [==============================] - 2s 104us/step - loss: 0.1607 - val_loss: 0.1586\n",
      "Epoch 30/150\n",
      "17432/17432 [==============================] - 2s 112us/step - loss: 0.1613 - val_loss: 0.1609\n",
      "Epoch 31/150\n",
      "17432/17432 [==============================] - 2s 108us/step - loss: 0.1603 - val_loss: 0.1586\n",
      "Epoch 32/150\n",
      "17432/17432 [==============================] - 2s 110us/step - loss: 0.1590 - val_loss: 0.1559\n",
      "Epoch 33/150\n",
      "17432/17432 [==============================] - 2s 108us/step - loss: 0.1590 - val_loss: 0.1643\n",
      "Epoch 34/150\n",
      "17432/17432 [==============================] - 2s 110us/step - loss: 0.1590 - val_loss: 0.1625\n",
      "Epoch 35/150\n",
      "17432/17432 [==============================] - 2s 108us/step - loss: 0.1583 - val_loss: 0.1585\n",
      "Epoch 36/150\n",
      "17432/17432 [==============================] - 2s 107us/step - loss: 0.1598 - val_loss: 0.1596\n",
      "Evaluating model with testing data...\n",
      "3714/3714 [==============================] - 0s 18us/step\n",
      "Getting distribution of predictions and covariance matrix...\n",
      "      1 of 20\n",
      "      2 of 20\n",
      "      3 of 20\n",
      "      4 of 20\n",
      "      5 of 20\n",
      "      6 of 20\n",
      "      7 of 20\n",
      "      8 of 20\n",
      "      9 of 20\n",
      "      10 of 20\n",
      "      11 of 20\n",
      "      12 of 20\n",
      "      13 of 20\n",
      "      14 of 20\n",
      "      15 of 20\n",
      "      16 of 20\n",
      "      17 of 20\n",
      "      18 of 20\n",
      "      19 of 20\n",
      "      20 of 20\n",
      "Computing ensemble means...\n",
      "Computing mean squared error...\n",
      "Iteration 122\n",
      "Train on 17572 samples, validate on 3744 samples\n",
      "Epoch 1/150\n",
      "17572/17572 [==============================] - 2s 104us/step - loss: 0.3927 - val_loss: 0.2472\n",
      "Epoch 2/150\n",
      "17572/17572 [==============================] - 2s 106us/step - loss: 0.2093 - val_loss: 0.1865\n",
      "Epoch 3/150\n",
      "17572/17572 [==============================] - 2s 112us/step - loss: 0.1756 - val_loss: 0.1681\n",
      "Epoch 4/150\n",
      "17572/17572 [==============================] - 2s 109us/step - loss: 0.1597 - val_loss: 0.1560\n",
      "Epoch 5/150\n",
      "17572/17572 [==============================] - 2s 108us/step - loss: 0.1513 - val_loss: 0.1495\n",
      "Epoch 6/150\n",
      "17572/17572 [==============================] - 2s 108us/step - loss: 0.1464 - val_loss: 0.1420\n",
      "Epoch 7/150\n",
      "17572/17572 [==============================] - 2s 105us/step - loss: 0.1410 - val_loss: 0.1386\n",
      "Epoch 8/150\n",
      "17572/17572 [==============================] - 2s 105us/step - loss: 0.1373 - val_loss: 0.1318\n",
      "Epoch 9/150\n",
      "17572/17572 [==============================] - 2s 108us/step - loss: 0.1332 - val_loss: 0.1329\n",
      "Epoch 10/150\n",
      "17572/17572 [==============================] - 2s 109us/step - loss: 0.1308 - val_loss: 0.1293\n",
      "Epoch 11/150\n",
      "17572/17572 [==============================] - 2s 106us/step - loss: 0.1262 - val_loss: 0.1275\n",
      "Epoch 12/150\n",
      "17572/17572 [==============================] - 2s 108us/step - loss: 0.1253 - val_loss: 0.1231\n",
      "Epoch 13/150\n",
      "17572/17572 [==============================] - 2s 105us/step - loss: 0.1226 - val_loss: 0.1244\n",
      "Epoch 14/150\n",
      "17572/17572 [==============================] - 2s 110us/step - loss: 0.1218 - val_loss: 0.1227\n",
      "Epoch 15/150\n",
      "17572/17572 [==============================] - 2s 106us/step - loss: 0.1190 - val_loss: 0.1208\n",
      "Epoch 16/150\n",
      "17572/17572 [==============================] - 2s 107us/step - loss: 0.1187 - val_loss: 0.1196\n",
      "Epoch 17/150\n",
      "17572/17572 [==============================] - 2s 105us/step - loss: 0.1176 - val_loss: 0.1201\n",
      "Epoch 18/150\n",
      "17572/17572 [==============================] - 2s 101us/step - loss: 0.1169 - val_loss: 0.1163\n",
      "Epoch 19/150\n",
      "17572/17572 [==============================] - 2s 109us/step - loss: 0.1163 - val_loss: 0.1163\n",
      "Epoch 20/150\n",
      "17572/17572 [==============================] - 2s 107us/step - loss: 0.1141 - val_loss: 0.1162\n",
      "Epoch 21/150\n",
      "17572/17572 [==============================] - 2s 106us/step - loss: 0.1139 - val_loss: 0.1136\n",
      "Epoch 22/150\n",
      "17572/17572 [==============================] - 2s 102us/step - loss: 0.1124 - val_loss: 0.1165\n",
      "Epoch 23/150\n",
      "17572/17572 [==============================] - 2s 100us/step - loss: 0.1119 - val_loss: 0.1128\n",
      "Epoch 24/150\n",
      "17572/17572 [==============================] - 2s 97us/step - loss: 0.1118 - val_loss: 0.1104\n",
      "Epoch 25/150\n",
      "17572/17572 [==============================] - 2s 103us/step - loss: 0.1099 - val_loss: 0.1131\n",
      "Epoch 26/150\n",
      "17572/17572 [==============================] - 2s 105us/step - loss: 0.1092 - val_loss: 0.1087\n",
      "Epoch 27/150\n",
      "17572/17572 [==============================] - 2s 103us/step - loss: 0.1095 - val_loss: 0.1097\n",
      "Epoch 28/150\n",
      "17572/17572 [==============================] - 2s 100us/step - loss: 0.1090 - val_loss: 0.1093\n",
      "Epoch 29/150\n",
      "17572/17572 [==============================] - 2s 103us/step - loss: 0.1080 - val_loss: 0.1094\n",
      "Epoch 30/150\n",
      "17572/17572 [==============================] - 2s 102us/step - loss: 0.1074 - val_loss: 0.1097\n",
      "Evaluating model with testing data...\n",
      "3744/3744 [==============================] - 0s 16us/step\n",
      "Getting distribution of predictions and covariance matrix...\n",
      "      1 of 20\n",
      "      2 of 20\n",
      "      3 of 20\n",
      "      4 of 20\n",
      "      5 of 20\n",
      "      6 of 20\n",
      "      7 of 20\n",
      "      8 of 20\n",
      "      9 of 20\n",
      "      10 of 20\n",
      "      11 of 20\n",
      "      12 of 20\n",
      "      13 of 20\n",
      "      14 of 20\n",
      "      15 of 20\n",
      "      16 of 20\n",
      "      17 of 20\n",
      "      18 of 20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      19 of 20\n",
      "      20 of 20\n",
      "Computing ensemble means...\n",
      "Computing mean squared error...\n",
      "Iteration 123\n",
      "Train on 17712 samples, validate on 3774 samples\n",
      "Epoch 1/150\n",
      "17712/17712 [==============================] - 2s 112us/step - loss: 0.4510 - val_loss: 0.3035\n",
      "Epoch 2/150\n",
      "17712/17712 [==============================] - 2s 112us/step - loss: 0.2781 - val_loss: 0.2599\n",
      "Epoch 3/150\n",
      "17712/17712 [==============================] - 2s 110us/step - loss: 0.2504 - val_loss: 0.2394\n",
      "Epoch 4/150\n",
      "17712/17712 [==============================] - 2s 111us/step - loss: 0.2327 - val_loss: 0.2287\n",
      "Epoch 5/150\n",
      "17712/17712 [==============================] - 2s 112us/step - loss: 0.2223 - val_loss: 0.2142\n",
      "Epoch 6/150\n",
      "17712/17712 [==============================] - 2s 110us/step - loss: 0.2085 - val_loss: 0.2049\n",
      "Epoch 7/150\n",
      "17712/17712 [==============================] - 2s 112us/step - loss: 0.1998 - val_loss: 0.1993\n",
      "Epoch 8/150\n",
      "17712/17712 [==============================] - 2s 111us/step - loss: 0.1943 - val_loss: 0.1917\n",
      "Epoch 9/150\n",
      "17712/17712 [==============================] - 2s 109us/step - loss: 0.1919 - val_loss: 0.1897\n",
      "Epoch 10/150\n",
      "17712/17712 [==============================] - 2s 111us/step - loss: 0.1898 - val_loss: 0.1881\n",
      "Epoch 11/150\n",
      "17712/17712 [==============================] - 2s 109us/step - loss: 0.1879 - val_loss: 0.1861\n",
      "Epoch 12/150\n",
      "17712/17712 [==============================] - 2s 108us/step - loss: 0.1881 - val_loss: 0.1904\n",
      "Epoch 13/150\n",
      "17712/17712 [==============================] - 2s 110us/step - loss: 0.1827 - val_loss: 0.1848\n",
      "Epoch 14/150\n",
      "17712/17712 [==============================] - 2s 111us/step - loss: 0.1782 - val_loss: 0.1803\n",
      "Epoch 15/150\n",
      "17712/17712 [==============================] - 2s 108us/step - loss: 0.1781 - val_loss: 0.1760\n",
      "Epoch 16/150\n",
      "17712/17712 [==============================] - 2s 110us/step - loss: 0.1768 - val_loss: 0.1737\n",
      "Epoch 17/150\n",
      "17712/17712 [==============================] - 2s 109us/step - loss: 0.1749 - val_loss: 0.1758\n",
      "Epoch 18/150\n",
      "17712/17712 [==============================] - 2s 109us/step - loss: 0.1697 - val_loss: 0.1712\n",
      "Epoch 19/150\n",
      "17712/17712 [==============================] - 2s 112us/step - loss: 0.1688 - val_loss: 0.1717\n",
      "Epoch 20/150\n",
      "17712/17712 [==============================] - 2s 111us/step - loss: 0.1664 - val_loss: 0.1680\n",
      "Epoch 21/150\n",
      "17712/17712 [==============================] - 1s 84us/step - loss: 0.1668 - val_loss: 0.1667\n",
      "Epoch 22/150\n",
      "17712/17712 [==============================] - 1s 59us/step - loss: 0.1660 - val_loss: 0.1699\n",
      "Epoch 23/150\n",
      "17712/17712 [==============================] - 2s 106us/step - loss: 0.1662 - val_loss: 0.1668\n",
      "Epoch 24/150\n",
      "17712/17712 [==============================] - 2s 101us/step - loss: 0.1647 - val_loss: 0.1655\n",
      "Epoch 25/150\n",
      "17712/17712 [==============================] - 2s 110us/step - loss: 0.1637 - val_loss: 0.1619\n",
      "Epoch 26/150\n",
      "17712/17712 [==============================] - 2s 113us/step - loss: 0.1632 - val_loss: 0.1675\n",
      "Epoch 27/150\n",
      "17712/17712 [==============================] - 2s 107us/step - loss: 0.1613 - val_loss: 0.1646\n",
      "Epoch 28/150\n",
      "17712/17712 [==============================] - 2s 105us/step - loss: 0.1613 - val_loss: 0.1636\n",
      "Epoch 29/150\n",
      "17712/17712 [==============================] - 2s 108us/step - loss: 0.1632 - val_loss: 0.1610\n",
      "Epoch 30/150\n",
      "17712/17712 [==============================] - 2s 109us/step - loss: 0.1602 - val_loss: 0.1630\n",
      "Epoch 31/150\n",
      "17712/17712 [==============================] - 2s 107us/step - loss: 0.1615 - val_loss: 0.1591\n",
      "Epoch 32/150\n",
      "17712/17712 [==============================] - 2s 109us/step - loss: 0.1593 - val_loss: 0.1607\n",
      "Epoch 33/150\n",
      "17712/17712 [==============================] - 2s 108us/step - loss: 0.1579 - val_loss: 0.1624\n",
      "Epoch 34/150\n",
      "17712/17712 [==============================] - 2s 109us/step - loss: 0.1599 - val_loss: 0.1596\n",
      "Epoch 35/150\n",
      "17712/17712 [==============================] - 2s 103us/step - loss: 0.1586 - val_loss: 0.1577\n",
      "Epoch 36/150\n",
      "17712/17712 [==============================] - 2s 112us/step - loss: 0.1576 - val_loss: 0.1631\n",
      "Epoch 37/150\n",
      "17712/17712 [==============================] - 2s 106us/step - loss: 0.1578 - val_loss: 0.1604\n",
      "Epoch 38/150\n",
      "17712/17712 [==============================] - 2s 109us/step - loss: 0.1555 - val_loss: 0.1577\n",
      "Epoch 39/150\n",
      "17712/17712 [==============================] - 2s 110us/step - loss: 0.1554 - val_loss: 0.1564\n",
      "Epoch 40/150\n",
      "17712/17712 [==============================] - 2s 103us/step - loss: 0.1558 - val_loss: 0.1580\n",
      "Epoch 41/150\n",
      "17712/17712 [==============================] - 2s 104us/step - loss: 0.1550 - val_loss: 0.1561\n",
      "Epoch 42/150\n",
      "17712/17712 [==============================] - 2s 111us/step - loss: 0.1549 - val_loss: 0.1583\n",
      "Epoch 43/150\n",
      "17712/17712 [==============================] - 2s 111us/step - loss: 0.1543 - val_loss: 0.1555\n",
      "Epoch 44/150\n",
      "17712/17712 [==============================] - 2s 106us/step - loss: 0.1544 - val_loss: 0.1576\n",
      "Epoch 45/150\n",
      "17712/17712 [==============================] - 2s 109us/step - loss: 0.1544 - val_loss: 0.1583\n",
      "Epoch 46/150\n",
      "17712/17712 [==============================] - 2s 107us/step - loss: 0.1528 - val_loss: 0.1556\n",
      "Epoch 47/150\n",
      "17712/17712 [==============================] - 2s 110us/step - loss: 0.1535 - val_loss: 0.1541\n",
      "Epoch 48/150\n",
      "17712/17712 [==============================] - 2s 109us/step - loss: 0.1522 - val_loss: 0.1552\n",
      "Epoch 49/150\n",
      "17712/17712 [==============================] - 2s 109us/step - loss: 0.1515 - val_loss: 0.1498\n",
      "Epoch 50/150\n",
      "17712/17712 [==============================] - 2s 108us/step - loss: 0.1483 - val_loss: 0.1477\n",
      "Epoch 51/150\n",
      "17712/17712 [==============================] - 2s 103us/step - loss: 0.1472 - val_loss: 0.1484\n",
      "Epoch 52/150\n",
      "17712/17712 [==============================] - 2s 107us/step - loss: 0.1444 - val_loss: 0.1465\n",
      "Epoch 53/150\n",
      "17712/17712 [==============================] - 2s 107us/step - loss: 0.1445 - val_loss: 0.1465\n",
      "Epoch 54/150\n",
      "17712/17712 [==============================] - 2s 106us/step - loss: 0.1439 - val_loss: 0.1484\n",
      "Epoch 55/150\n",
      "17712/17712 [==============================] - 2s 106us/step - loss: 0.1423 - val_loss: 0.1471\n",
      "Epoch 56/150\n",
      "17712/17712 [==============================] - 2s 105us/step - loss: 0.1421 - val_loss: 0.1432\n",
      "Epoch 57/150\n",
      "17712/17712 [==============================] - 2s 109us/step - loss: 0.1422 - val_loss: 0.1454\n",
      "Epoch 58/150\n",
      "17712/17712 [==============================] - 2s 106us/step - loss: 0.1422 - val_loss: 0.1450\n",
      "Epoch 59/150\n",
      "17712/17712 [==============================] - 2s 105us/step - loss: 0.1422 - val_loss: 0.1443\n",
      "Epoch 60/150\n",
      "17712/17712 [==============================] - 2s 107us/step - loss: 0.1429 - val_loss: 0.1386\n",
      "Epoch 61/150\n",
      "17712/17712 [==============================] - 2s 105us/step - loss: 0.1407 - val_loss: 0.1445\n",
      "Epoch 62/150\n",
      "17712/17712 [==============================] - 2s 107us/step - loss: 0.1418 - val_loss: 0.1449\n",
      "Epoch 63/150\n",
      "17712/17712 [==============================] - 2s 104us/step - loss: 0.1410 - val_loss: 0.1442\n",
      "Epoch 64/150\n",
      "17712/17712 [==============================] - 2s 102us/step - loss: 0.1420 - val_loss: 0.1462\n",
      "Evaluating model with testing data...\n",
      "3774/3774 [==============================] - 0s 16us/step\n",
      "Getting distribution of predictions and covariance matrix...\n",
      "      1 of 20\n",
      "      2 of 20\n",
      "      3 of 20\n",
      "      4 of 20\n",
      "      5 of 20\n",
      "      6 of 20\n",
      "      7 of 20\n",
      "      8 of 20\n",
      "      9 of 20\n",
      "      10 of 20\n",
      "      11 of 20\n",
      "      12 of 20\n",
      "      13 of 20\n",
      "      14 of 20\n",
      "      15 of 20\n",
      "      16 of 20\n",
      "      17 of 20\n",
      "      18 of 20\n",
      "      19 of 20\n",
      "      20 of 20\n",
      "Computing ensemble means...\n",
      "Computing mean squared error...\n",
      "Iteration 124\n",
      "Train on 17852 samples, validate on 3804 samples\n",
      "Epoch 1/150\n",
      "17852/17852 [==============================] - 2s 103us/step - loss: 0.4558 - val_loss: 0.2731\n",
      "Epoch 2/150\n",
      "17852/17852 [==============================] - 2s 100us/step - loss: 0.2410 - val_loss: 0.2187\n",
      "Epoch 3/150\n",
      "17852/17852 [==============================] - 2s 98us/step - loss: 0.2092 - val_loss: 0.2009\n",
      "Epoch 4/150\n",
      "17852/17852 [==============================] - 2s 96us/step - loss: 0.1958 - val_loss: 0.1877\n",
      "Epoch 5/150\n",
      "17852/17852 [==============================] - 2s 97us/step - loss: 0.1819 - val_loss: 0.1743\n",
      "Epoch 6/150\n",
      "17852/17852 [==============================] - 2s 110us/step - loss: 0.1729 - val_loss: 0.1733\n",
      "Epoch 7/150\n",
      "17852/17852 [==============================] - 2s 111us/step - loss: 0.1675 - val_loss: 0.1653\n",
      "Epoch 8/150\n",
      "17852/17852 [==============================] - 2s 112us/step - loss: 0.1615 - val_loss: 0.1617\n",
      "Epoch 9/150\n",
      "17852/17852 [==============================] - 2s 110us/step - loss: 0.1580 - val_loss: 0.1594\n",
      "Epoch 10/150\n",
      "17852/17852 [==============================] - 2s 108us/step - loss: 0.1549 - val_loss: 0.1495\n",
      "Epoch 11/150\n",
      "17852/17852 [==============================] - 2s 112us/step - loss: 0.1503 - val_loss: 0.1498\n",
      "Epoch 12/150\n",
      "17852/17852 [==============================] - 2s 111us/step - loss: 0.1461 - val_loss: 0.1455\n",
      "Epoch 13/150\n",
      "17852/17852 [==============================] - 2s 112us/step - loss: 0.1438 - val_loss: 0.1446\n",
      "Epoch 14/150\n",
      "17852/17852 [==============================] - 2s 111us/step - loss: 0.1427 - val_loss: 0.1412\n",
      "Epoch 15/150\n",
      "17852/17852 [==============================] - 2s 106us/step - loss: 0.1415 - val_loss: 0.1429\n",
      "Epoch 16/150\n",
      "17852/17852 [==============================] - 2s 106us/step - loss: 0.1388 - val_loss: 0.1441\n",
      "Epoch 17/150\n",
      "17852/17852 [==============================] - 2s 114us/step - loss: 0.1405 - val_loss: 0.1402\n",
      "Epoch 18/150\n",
      "17852/17852 [==============================] - 2s 109us/step - loss: 0.1383 - val_loss: 0.1398\n",
      "Epoch 19/150\n",
      "17852/17852 [==============================] - 2s 104us/step - loss: 0.1383 - val_loss: 0.1407\n",
      "Epoch 20/150\n",
      "17852/17852 [==============================] - 1s 59us/step - loss: 0.1373 - val_loss: 0.1385\n",
      "Epoch 21/150\n",
      "17852/17852 [==============================] - 2s 89us/step - loss: 0.1350 - val_loss: 0.1380\n",
      "Epoch 22/150\n",
      "17852/17852 [==============================] - 2s 104us/step - loss: 0.1357 - val_loss: 0.1356\n",
      "Epoch 23/150\n",
      "17852/17852 [==============================] - 2s 112us/step - loss: 0.1341 - val_loss: 0.1377\n",
      "Epoch 24/150\n",
      "17852/17852 [==============================] - 2s 111us/step - loss: 0.1343 - val_loss: 0.1313\n",
      "Epoch 25/150\n",
      "17852/17852 [==============================] - 2s 112us/step - loss: 0.1334 - val_loss: 0.1387\n",
      "Epoch 26/150\n",
      "17852/17852 [==============================] - 2s 109us/step - loss: 0.1326 - val_loss: 0.1340\n",
      "Epoch 27/150\n",
      "17852/17852 [==============================] - 2s 108us/step - loss: 0.1319 - val_loss: 0.1364\n",
      "Epoch 28/150\n",
      "17852/17852 [==============================] - 2s 106us/step - loss: 0.1311 - val_loss: 0.1322\n",
      "Evaluating model with testing data...\n",
      "3804/3804 [==============================] - 0s 16us/step\n",
      "Getting distribution of predictions and covariance matrix...\n",
      "      1 of 20\n",
      "      2 of 20\n",
      "      3 of 20\n",
      "      4 of 20\n",
      "      5 of 20\n",
      "      6 of 20\n",
      "      7 of 20\n",
      "      8 of 20\n",
      "      9 of 20\n",
      "      10 of 20\n",
      "      11 of 20\n",
      "      12 of 20\n",
      "      13 of 20\n",
      "      14 of 20\n",
      "      15 of 20\n",
      "      16 of 20\n",
      "      17 of 20\n",
      "      18 of 20\n",
      "      19 of 20\n",
      "      20 of 20\n",
      "Computing ensemble means...\n",
      "Computing mean squared error...\n",
      "Iteration 125\n",
      "Train on 17992 samples, validate on 3834 samples\n",
      "Epoch 1/150\n",
      "17992/17992 [==============================] - 2s 100us/step - loss: 0.4453 - val_loss: 0.3292\n",
      "Epoch 2/150\n",
      "17992/17992 [==============================] - 2s 109us/step - loss: 0.2897 - val_loss: 0.2602\n",
      "Epoch 3/150\n",
      "17992/17992 [==============================] - 2s 110us/step - loss: 0.2323 - val_loss: 0.2181\n",
      "Epoch 4/150\n",
      "17992/17992 [==============================] - 2s 110us/step - loss: 0.2075 - val_loss: 0.1982\n",
      "Epoch 5/150\n",
      "17992/17992 [==============================] - 2s 111us/step - loss: 0.1962 - val_loss: 0.1930\n",
      "Epoch 6/150\n",
      "17992/17992 [==============================] - 2s 106us/step - loss: 0.1867 - val_loss: 0.1882\n",
      "Epoch 7/150\n",
      "17992/17992 [==============================] - 2s 109us/step - loss: 0.1792 - val_loss: 0.1821\n",
      "Epoch 8/150\n",
      "17992/17992 [==============================] - 2s 107us/step - loss: 0.1758 - val_loss: 0.1758\n",
      "Epoch 9/150\n",
      "17992/17992 [==============================] - 2s 103us/step - loss: 0.1700 - val_loss: 0.1694\n",
      "Epoch 10/150\n",
      "17992/17992 [==============================] - 2s 106us/step - loss: 0.1661 - val_loss: 0.1648\n",
      "Epoch 11/150\n",
      "17992/17992 [==============================] - 2s 110us/step - loss: 0.1644 - val_loss: 0.1648\n",
      "Epoch 12/150\n",
      "17992/17992 [==============================] - 2s 110us/step - loss: 0.1634 - val_loss: 0.1607\n",
      "Epoch 13/150\n",
      "17992/17992 [==============================] - 2s 107us/step - loss: 0.1602 - val_loss: 0.1611\n",
      "Epoch 14/150\n",
      "17992/17992 [==============================] - 2s 103us/step - loss: 0.1608 - val_loss: 0.1589\n",
      "Epoch 15/150\n",
      "17992/17992 [==============================] - 2s 107us/step - loss: 0.1608 - val_loss: 0.1565\n",
      "Epoch 16/150\n",
      "17992/17992 [==============================] - 2s 104us/step - loss: 0.1593 - val_loss: 0.1608\n",
      "Epoch 17/150\n",
      "17992/17992 [==============================] - 2s 107us/step - loss: 0.1581 - val_loss: 0.1599\n",
      "Epoch 18/150\n",
      "17992/17992 [==============================] - 2s 102us/step - loss: 0.1578 - val_loss: 0.1561\n",
      "Epoch 19/150\n",
      "17992/17992 [==============================] - 2s 108us/step - loss: 0.1556 - val_loss: 0.1635\n",
      "Epoch 20/150\n",
      "17992/17992 [==============================] - 2s 99us/step - loss: 0.1562 - val_loss: 0.1532\n",
      "Epoch 21/150\n",
      "17992/17992 [==============================] - 2s 105us/step - loss: 0.1533 - val_loss: 0.1529\n",
      "Epoch 22/150\n",
      "17992/17992 [==============================] - 2s 110us/step - loss: 0.1506 - val_loss: 0.1497\n",
      "Epoch 23/150\n",
      "17992/17992 [==============================] - 2s 103us/step - loss: 0.1500 - val_loss: 0.1508\n",
      "Epoch 24/150\n",
      "17992/17992 [==============================] - 2s 105us/step - loss: 0.1490 - val_loss: 0.1469\n",
      "Epoch 25/150\n",
      "17992/17992 [==============================] - 2s 104us/step - loss: 0.1486 - val_loss: 0.1525\n",
      "Epoch 26/150\n",
      "17992/17992 [==============================] - 2s 105us/step - loss: 0.1484 - val_loss: 0.1500\n",
      "Epoch 27/150\n",
      "17992/17992 [==============================] - 2s 103us/step - loss: 0.1461 - val_loss: 0.1481\n",
      "Epoch 28/150\n",
      "17992/17992 [==============================] - 2s 111us/step - loss: 0.1447 - val_loss: 0.1468\n",
      "Epoch 29/150\n",
      "17992/17992 [==============================] - 2s 105us/step - loss: 0.1433 - val_loss: 0.1463\n",
      "Epoch 30/150\n",
      "17992/17992 [==============================] - 2s 104us/step - loss: 0.1439 - val_loss: 0.1440\n",
      "Epoch 31/150\n",
      "17992/17992 [==============================] - 2s 99us/step - loss: 0.1424 - val_loss: 0.1452\n",
      "Epoch 32/150\n",
      "17992/17992 [==============================] - 2s 102us/step - loss: 0.1417 - val_loss: 0.1404\n",
      "Epoch 33/150\n",
      "17992/17992 [==============================] - 2s 104us/step - loss: 0.1407 - val_loss: 0.1432\n",
      "Epoch 34/150\n",
      "17992/17992 [==============================] - 2s 109us/step - loss: 0.1397 - val_loss: 0.1405\n",
      "Epoch 35/150\n",
      "17992/17992 [==============================] - 2s 104us/step - loss: 0.1389 - val_loss: 0.1382\n",
      "Epoch 36/150\n",
      "17992/17992 [==============================] - 2s 102us/step - loss: 0.1366 - val_loss: 0.1417\n",
      "Epoch 37/150\n",
      "17992/17992 [==============================] - 2s 104us/step - loss: 0.1353 - val_loss: 0.1375\n",
      "Epoch 38/150\n",
      "17992/17992 [==============================] - 2s 99us/step - loss: 0.1350 - val_loss: 0.1360\n",
      "Epoch 39/150\n",
      "17992/17992 [==============================] - 2s 105us/step - loss: 0.1333 - val_loss: 0.1358\n",
      "Epoch 40/150\n",
      "17992/17992 [==============================] - 2s 103us/step - loss: 0.1317 - val_loss: 0.1308\n",
      "Epoch 41/150\n",
      "17992/17992 [==============================] - 2s 101us/step - loss: 0.1293 - val_loss: 0.1298\n",
      "Epoch 42/150\n",
      "17992/17992 [==============================] - 2s 100us/step - loss: 0.1299 - val_loss: 0.1294\n",
      "Epoch 43/150\n",
      "17992/17992 [==============================] - 2s 97us/step - loss: 0.1277 - val_loss: 0.1308\n",
      "Epoch 44/150\n",
      "17992/17992 [==============================] - 2s 97us/step - loss: 0.1273 - val_loss: 0.1260\n",
      "Epoch 45/150\n",
      "17992/17992 [==============================] - 2s 99us/step - loss: 0.1260 - val_loss: 0.1247\n",
      "Epoch 46/150\n",
      "17992/17992 [==============================] - 2s 105us/step - loss: 0.1256 - val_loss: 0.1264\n",
      "Epoch 47/150\n",
      "17992/17992 [==============================] - 2s 98us/step - loss: 0.1231 - val_loss: 0.1243\n",
      "Epoch 48/150\n",
      "17992/17992 [==============================] - 2s 100us/step - loss: 0.1248 - val_loss: 0.1249\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 49/150\n",
      "17992/17992 [==============================] - 2s 107us/step - loss: 0.1236 - val_loss: 0.1240\n",
      "Epoch 50/150\n",
      "17992/17992 [==============================] - 2s 111us/step - loss: 0.1230 - val_loss: 0.1241\n",
      "Epoch 51/150\n",
      "17992/17992 [==============================] - 2s 107us/step - loss: 0.1225 - val_loss: 0.1245\n",
      "Epoch 52/150\n",
      "17992/17992 [==============================] - 2s 112us/step - loss: 0.1206 - val_loss: 0.1252\n",
      "Epoch 53/150\n",
      "17992/17992 [==============================] - 2s 112us/step - loss: 0.1211 - val_loss: 0.1233\n",
      "Epoch 54/150\n",
      "17992/17992 [==============================] - 2s 87us/step - loss: 0.1198 - val_loss: 0.1193\n",
      "Epoch 55/150\n",
      "17992/17992 [==============================] - 1s 59us/step - loss: 0.1206 - val_loss: 0.1240\n",
      "Epoch 56/150\n",
      "17992/17992 [==============================] - 2s 112us/step - loss: 0.1196 - val_loss: 0.1219\n",
      "Epoch 57/150\n",
      "17992/17992 [==============================] - 2s 108us/step - loss: 0.1197 - val_loss: 0.1210\n",
      "Epoch 58/150\n",
      "17992/17992 [==============================] - 2s 112us/step - loss: 0.1180 - val_loss: 0.1204\n",
      "Evaluating model with testing data...\n",
      "3834/3834 [==============================] - 0s 16us/step\n",
      "Getting distribution of predictions and covariance matrix...\n",
      "      1 of 20\n",
      "      2 of 20\n",
      "      3 of 20\n",
      "      4 of 20\n",
      "      5 of 20\n",
      "      6 of 20\n",
      "      7 of 20\n",
      "      8 of 20\n",
      "      9 of 20\n",
      "      10 of 20\n",
      "      11 of 20\n",
      "      12 of 20\n",
      "      13 of 20\n",
      "      14 of 20\n",
      "      15 of 20\n",
      "      16 of 20\n",
      "      17 of 20\n",
      "      18 of 20\n",
      "      19 of 20\n",
      "      20 of 20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|          | 0/20 [00:00<?, ?it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing ensemble means...\n",
      "Computing mean squared error...\n",
      "Getting distribution of predictions...\n",
      "      1 of 20\n",
      "1600/1600 [==============================] - 0s 27us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  5%|▌         | 1/20 [00:29<09:25, 29.74s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      2 of 20\n",
      "1600/1600 [==============================] - 0s 30us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 10%|█         | 2/20 [00:59<08:55, 29.76s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      3 of 20\n",
      "1600/1600 [==============================] - 0s 29us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 15%|█▌        | 3/20 [01:29<08:24, 29.68s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      4 of 20\n",
      "1600/1600 [==============================] - 0s 29us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 20%|██        | 4/20 [01:58<07:53, 29.59s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      5 of 20\n",
      "1600/1600 [==============================] - 0s 29us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 25%|██▌       | 5/20 [02:28<07:23, 29.60s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      6 of 20\n",
      "1600/1600 [==============================] - 0s 29us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 30%|███       | 6/20 [02:57<06:53, 29.54s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      7 of 20\n",
      "1600/1600 [==============================] - 0s 30us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 35%|███▌      | 7/20 [03:27<06:24, 29.58s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      8 of 20\n",
      "1600/1600 [==============================] - 0s 29us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 40%|████      | 8/20 [03:56<05:55, 29.59s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      9 of 20\n",
      "1600/1600 [==============================] - 0s 28us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 45%|████▌     | 9/20 [04:26<05:24, 29.54s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      10 of 20\n",
      "1600/1600 [==============================] - 0s 30us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 50%|█████     | 10/20 [04:55<04:55, 29.54s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      11 of 20\n",
      "1600/1600 [==============================] - 0s 29us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 55%|█████▌    | 11/20 [05:25<04:25, 29.51s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      12 of 20\n",
      "1600/1600 [==============================] - 0s 30us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 60%|██████    | 12/20 [05:54<03:55, 29.48s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      13 of 20\n",
      "1600/1600 [==============================] - 0s 29us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 65%|██████▌   | 13/20 [06:24<03:26, 29.48s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      14 of 20\n",
      "1600/1600 [==============================] - 0s 29us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 70%|███████   | 14/20 [06:53<02:57, 29.52s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      15 of 20\n",
      "1600/1600 [==============================] - 0s 29us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 75%|███████▌  | 15/20 [07:23<02:28, 29.63s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      16 of 20\n",
      "1600/1600 [==============================] - 0s 29us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 80%|████████  | 16/20 [07:53<01:58, 29.62s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      17 of 20\n",
      "1600/1600 [==============================] - 0s 29us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 85%|████████▌ | 17/20 [08:23<01:29, 29.77s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      18 of 20\n",
      "1600/1600 [==============================] - 0s 29us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 90%|█████████ | 18/20 [08:52<00:59, 29.74s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      19 of 20\n",
      "1600/1600 [==============================] - 0s 29us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 95%|█████████▌| 19/20 [09:22<00:29, 29.68s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      20 of 20\n",
      "1600/1600 [==============================] - 0s 30us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 20/20 [09:52<00:00, 29.60s/it]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing ensemble predictions...\n",
      "Iteration 126\n",
      "Train on 18132 samples, validate on 3864 samples\n",
      "Epoch 1/150\n",
      "18132/18132 [==============================] - 2s 107us/step - loss: 0.4196 - val_loss: 0.2706\n",
      "Epoch 2/150\n",
      "18132/18132 [==============================] - 2s 113us/step - loss: 0.2462 - val_loss: 0.2255\n",
      "Epoch 3/150\n",
      "18132/18132 [==============================] - 2s 112us/step - loss: 0.2210 - val_loss: 0.2128\n",
      "Epoch 4/150\n",
      "18132/18132 [==============================] - 2s 110us/step - loss: 0.2089 - val_loss: 0.2033\n",
      "Epoch 5/150\n",
      "18132/18132 [==============================] - 2s 110us/step - loss: 0.1980 - val_loss: 0.1902\n",
      "Epoch 6/150\n",
      "18132/18132 [==============================] - 2s 113us/step - loss: 0.1866 - val_loss: 0.1814\n",
      "Epoch 7/150\n",
      "18132/18132 [==============================] - 2s 113us/step - loss: 0.1792 - val_loss: 0.1784\n",
      "Epoch 8/150\n",
      "18132/18132 [==============================] - 2s 115us/step - loss: 0.1758 - val_loss: 0.1747\n",
      "Epoch 9/150\n",
      "18132/18132 [==============================] - 2s 110us/step - loss: 0.1718 - val_loss: 0.1697\n",
      "Epoch 10/150\n",
      "18132/18132 [==============================] - 2s 109us/step - loss: 0.1686 - val_loss: 0.1684\n",
      "Epoch 11/150\n",
      "18132/18132 [==============================] - 2s 112us/step - loss: 0.1681 - val_loss: 0.1654\n",
      "Epoch 12/150\n",
      "18132/18132 [==============================] - 2s 110us/step - loss: 0.1673 - val_loss: 0.1663\n",
      "Epoch 13/150\n",
      "18132/18132 [==============================] - 2s 114us/step - loss: 0.1670 - val_loss: 0.1663\n",
      "Epoch 14/150\n",
      "18132/18132 [==============================] - 2s 110us/step - loss: 0.1652 - val_loss: 0.1673\n",
      "Epoch 15/150\n",
      "18132/18132 [==============================] - 2s 112us/step - loss: 0.1654 - val_loss: 0.1663\n",
      "Evaluating model with testing data...\n",
      "3864/3864 [==============================] - 0s 16us/step\n",
      "Getting distribution of predictions and covariance matrix...\n",
      "      1 of 20\n",
      "      2 of 20\n",
      "      3 of 20\n",
      "      4 of 20\n",
      "      5 of 20\n",
      "      6 of 20\n",
      "      7 of 20\n",
      "      8 of 20\n",
      "      9 of 20\n",
      "      10 of 20\n",
      "      11 of 20\n",
      "      12 of 20\n",
      "      13 of 20\n",
      "      14 of 20\n",
      "      15 of 20\n",
      "      16 of 20\n",
      "      17 of 20\n",
      "      18 of 20\n",
      "      19 of 20\n",
      "      20 of 20\n",
      "Computing ensemble means...\n",
      "Computing mean squared error...\n",
      "Iteration 127\n",
      "Train on 18272 samples, validate on 3894 samples\n",
      "Epoch 1/150\n",
      "18272/18272 [==============================] - 2s 109us/step - loss: 0.3683 - val_loss: 0.2540\n",
      "Epoch 2/150\n",
      "18272/18272 [==============================] - 2s 109us/step - loss: 0.2250 - val_loss: 0.2052\n",
      "Epoch 3/150\n",
      "18272/18272 [==============================] - 2s 100us/step - loss: 0.1927 - val_loss: 0.1840\n",
      "Epoch 4/150\n",
      "18272/18272 [==============================] - 2s 103us/step - loss: 0.1777 - val_loss: 0.1703\n",
      "Epoch 5/150\n",
      "18272/18272 [==============================] - 2s 101us/step - loss: 0.1696 - val_loss: 0.1665\n",
      "Epoch 6/150\n",
      "18272/18272 [==============================] - 2s 107us/step - loss: 0.1634 - val_loss: 0.1614\n",
      "Epoch 7/150\n",
      "18272/18272 [==============================] - 2s 106us/step - loss: 0.1567 - val_loss: 0.1552\n",
      "Epoch 8/150\n",
      "18272/18272 [==============================] - 2s 110us/step - loss: 0.1536 - val_loss: 0.1495\n",
      "Epoch 9/150\n",
      "18272/18272 [==============================] - 2s 108us/step - loss: 0.1507 - val_loss: 0.1537\n",
      "Epoch 10/150\n",
      "18272/18272 [==============================] - 2s 108us/step - loss: 0.1481 - val_loss: 0.1526\n",
      "Epoch 11/150\n",
      "18272/18272 [==============================] - 2s 111us/step - loss: 0.1467 - val_loss: 0.1448\n",
      "Epoch 12/150\n",
      "18272/18272 [==============================] - 2s 107us/step - loss: 0.1454 - val_loss: 0.1457\n",
      "Epoch 13/150\n",
      "18272/18272 [==============================] - 2s 109us/step - loss: 0.1442 - val_loss: 0.1439\n",
      "Epoch 14/150\n",
      "18272/18272 [==============================] - 2s 104us/step - loss: 0.1437 - val_loss: 0.1435\n",
      "Epoch 15/150\n",
      "18272/18272 [==============================] - 2s 110us/step - loss: 0.1419 - val_loss: 0.1408\n",
      "Epoch 16/150\n",
      "18272/18272 [==============================] - 2s 100us/step - loss: 0.1412 - val_loss: 0.1427\n",
      "Epoch 17/150\n",
      "18272/18272 [==============================] - 2s 111us/step - loss: 0.1414 - val_loss: 0.1425\n",
      "Epoch 18/150\n",
      "18272/18272 [==============================] - 2s 106us/step - loss: 0.1379 - val_loss: 0.1377\n",
      "Epoch 19/150\n",
      "18272/18272 [==============================] - 2s 107us/step - loss: 0.1360 - val_loss: 0.1335\n",
      "Epoch 20/150\n",
      "18272/18272 [==============================] - 2s 109us/step - loss: 0.1341 - val_loss: 0.1351\n",
      "Epoch 21/150\n",
      "18272/18272 [==============================] - 2s 104us/step - loss: 0.1340 - val_loss: 0.1347\n",
      "Epoch 22/150\n",
      "18272/18272 [==============================] - 2s 104us/step - loss: 0.1340 - val_loss: 0.1336\n",
      "Epoch 23/150\n",
      "18272/18272 [==============================] - 2s 110us/step - loss: 0.1314 - val_loss: 0.1306\n",
      "Epoch 24/150\n",
      "18272/18272 [==============================] - 2s 103us/step - loss: 0.1297 - val_loss: 0.1335\n",
      "Epoch 25/150\n",
      "18272/18272 [==============================] - 2s 107us/step - loss: 0.1321 - val_loss: 0.1307\n",
      "Epoch 26/150\n",
      "18272/18272 [==============================] - 2s 106us/step - loss: 0.1317 - val_loss: 0.1294\n",
      "Epoch 27/150\n",
      "18272/18272 [==============================] - 2s 105us/step - loss: 0.1306 - val_loss: 0.1299\n",
      "Epoch 28/150\n",
      "18272/18272 [==============================] - 2s 110us/step - loss: 0.1291 - val_loss: 0.1284\n",
      "Epoch 29/150\n",
      "18272/18272 [==============================] - 2s 109us/step - loss: 0.1294 - val_loss: 0.1289\n",
      "Epoch 30/150\n",
      "18272/18272 [==============================] - 2s 105us/step - loss: 0.1296 - val_loss: 0.1318\n",
      "Epoch 31/150\n",
      "18272/18272 [==============================] - 2s 106us/step - loss: 0.1285 - val_loss: 0.1290\n",
      "Epoch 32/150\n",
      "18272/18272 [==============================] - 2s 103us/step - loss: 0.1278 - val_loss: 0.1266\n",
      "Epoch 33/150\n",
      "18272/18272 [==============================] - 2s 108us/step - loss: 0.1277 - val_loss: 0.1286\n",
      "Epoch 34/150\n",
      "18272/18272 [==============================] - 2s 108us/step - loss: 0.1280 - val_loss: 0.1263\n",
      "Epoch 35/150\n",
      "18272/18272 [==============================] - 2s 109us/step - loss: 0.1272 - val_loss: 0.1273\n",
      "Epoch 36/150\n",
      "18272/18272 [==============================] - 2s 102us/step - loss: 0.1257 - val_loss: 0.1298\n",
      "Epoch 37/150\n",
      "18272/18272 [==============================] - 2s 106us/step - loss: 0.1275 - val_loss: 0.1266\n",
      "Epoch 38/150\n",
      "18272/18272 [==============================] - 2s 106us/step - loss: 0.1261 - val_loss: 0.1282\n",
      "Evaluating model with testing data...\n",
      "3894/3894 [==============================] - 0s 18us/step\n",
      "Getting distribution of predictions and covariance matrix...\n",
      "      1 of 20\n",
      "      2 of 20\n",
      "      3 of 20\n",
      "      4 of 20\n",
      "      5 of 20\n",
      "      6 of 20\n",
      "      7 of 20\n",
      "      8 of 20\n",
      "      9 of 20\n",
      "      10 of 20\n",
      "      11 of 20\n",
      "      12 of 20\n",
      "      13 of 20\n",
      "      14 of 20\n",
      "      15 of 20\n",
      "      16 of 20\n",
      "      17 of 20\n",
      "      18 of 20\n",
      "      19 of 20\n",
      "      20 of 20\n",
      "Computing ensemble means...\n",
      "Computing mean squared error...\n",
      "Iteration 128\n",
      "Train on 18412 samples, validate on 3924 samples\n",
      "Epoch 1/150\n",
      "18412/18412 [==============================] - 2s 104us/step - loss: 0.4130 - val_loss: 0.2768\n",
      "Epoch 2/150\n",
      "18412/18412 [==============================] - 2s 100us/step - loss: 0.2466 - val_loss: 0.2334\n",
      "Epoch 3/150\n",
      "18412/18412 [==============================] - 2s 103us/step - loss: 0.2201 - val_loss: 0.2101\n",
      "Epoch 4/150\n",
      "18412/18412 [==============================] - 2s 103us/step - loss: 0.2049 - val_loss: 0.1989\n",
      "Epoch 5/150\n",
      "18412/18412 [==============================] - 2s 85us/step - loss: 0.1949 - val_loss: 0.1920\n",
      "Epoch 6/150\n",
      "18412/18412 [==============================] - 1s 58us/step - loss: 0.1883 - val_loss: 0.1820\n",
      "Epoch 7/150\n",
      "18412/18412 [==============================] - 2s 92us/step - loss: 0.1806 - val_loss: 0.1769\n",
      "Epoch 8/150\n",
      "18412/18412 [==============================] - 2s 97us/step - loss: 0.1705 - val_loss: 0.1680\n",
      "Epoch 9/150\n",
      "18412/18412 [==============================] - 2s 100us/step - loss: 0.1637 - val_loss: 0.1647\n",
      "Epoch 10/150\n",
      "18412/18412 [==============================] - 2s 97us/step - loss: 0.1617 - val_loss: 0.1611\n",
      "Epoch 11/150\n",
      "18412/18412 [==============================] - 2s 95us/step - loss: 0.1608 - val_loss: 0.1611\n",
      "Epoch 12/150\n",
      "18412/18412 [==============================] - 2s 110us/step - loss: 0.1587 - val_loss: 0.1623\n",
      "Epoch 13/150\n",
      "18412/18412 [==============================] - 2s 113us/step - loss: 0.1554 - val_loss: 0.1569\n",
      "Epoch 14/150\n",
      "18412/18412 [==============================] - 2s 112us/step - loss: 0.1496 - val_loss: 0.1528\n",
      "Epoch 15/150\n",
      "18412/18412 [==============================] - 2s 112us/step - loss: 0.1492 - val_loss: 0.1497\n",
      "Epoch 16/150\n",
      "18412/18412 [==============================] - 2s 111us/step - loss: 0.1467 - val_loss: 0.1473\n",
      "Epoch 17/150\n",
      "18412/18412 [==============================] - 2s 111us/step - loss: 0.1456 - val_loss: 0.1515\n",
      "Epoch 18/150\n",
      "18412/18412 [==============================] - 2s 110us/step - loss: 0.1468 - val_loss: 0.1456\n",
      "Epoch 19/150\n",
      "18412/18412 [==============================] - 2s 111us/step - loss: 0.1445 - val_loss: 0.1454\n",
      "Epoch 20/150\n",
      "18412/18412 [==============================] - 2s 107us/step - loss: 0.1435 - val_loss: 0.1434\n",
      "Epoch 21/150\n",
      "18412/18412 [==============================] - 2s 111us/step - loss: 0.1423 - val_loss: 0.1422\n",
      "Epoch 22/150\n",
      "18412/18412 [==============================] - 2s 105us/step - loss: 0.1427 - val_loss: 0.1415\n",
      "Epoch 23/150\n",
      "18412/18412 [==============================] - 2s 106us/step - loss: 0.1416 - val_loss: 0.1396\n",
      "Epoch 24/150\n",
      "18412/18412 [==============================] - 2s 109us/step - loss: 0.1420 - val_loss: 0.1398\n",
      "Epoch 25/150\n",
      "18412/18412 [==============================] - 2s 110us/step - loss: 0.1406 - val_loss: 0.1402\n",
      "Epoch 26/150\n",
      "18412/18412 [==============================] - 2s 105us/step - loss: 0.1399 - val_loss: 0.1421\n",
      "Epoch 27/150\n",
      "18412/18412 [==============================] - 2s 105us/step - loss: 0.1397 - val_loss: 0.1437\n",
      "Evaluating model with testing data...\n",
      "3924/3924 [==============================] - 0s 16us/step\n",
      "Getting distribution of predictions and covariance matrix...\n",
      "      1 of 20\n",
      "      2 of 20\n",
      "      3 of 20\n",
      "      4 of 20\n",
      "      5 of 20\n",
      "      6 of 20\n",
      "      7 of 20\n",
      "      8 of 20\n",
      "      9 of 20\n",
      "      10 of 20\n",
      "      11 of 20\n",
      "      12 of 20\n",
      "      13 of 20\n",
      "      14 of 20\n",
      "      15 of 20\n",
      "      16 of 20\n",
      "      17 of 20\n",
      "      18 of 20\n",
      "      19 of 20\n",
      "      20 of 20\n",
      "Computing ensemble means...\n",
      "Computing mean squared error...\n",
      "Iteration 129\n",
      "Train on 18552 samples, validate on 3954 samples\n",
      "Epoch 1/150\n",
      "18552/18552 [==============================] - 2s 103us/step - loss: 0.4820 - val_loss: 0.3444\n",
      "Epoch 2/150\n",
      "18552/18552 [==============================] - 2s 107us/step - loss: 0.2855 - val_loss: 0.2439\n",
      "Epoch 3/150\n",
      "18552/18552 [==============================] - 2s 112us/step - loss: 0.2265 - val_loss: 0.2112\n",
      "Epoch 4/150\n",
      "18552/18552 [==============================] - 2s 104us/step - loss: 0.2058 - val_loss: 0.2001\n",
      "Epoch 5/150\n",
      "18552/18552 [==============================] - 2s 111us/step - loss: 0.1916 - val_loss: 0.1863\n",
      "Epoch 6/150\n",
      "18552/18552 [==============================] - 2s 111us/step - loss: 0.1838 - val_loss: 0.1803\n",
      "Epoch 7/150\n",
      "18552/18552 [==============================] - 2s 108us/step - loss: 0.1771 - val_loss: 0.1779\n",
      "Epoch 8/150\n",
      "18552/18552 [==============================] - 2s 111us/step - loss: 0.1729 - val_loss: 0.1763\n",
      "Epoch 9/150\n",
      "18552/18552 [==============================] - 2s 105us/step - loss: 0.1723 - val_loss: 0.1729\n",
      "Epoch 10/150\n",
      "18552/18552 [==============================] - 2s 111us/step - loss: 0.1683 - val_loss: 0.1681\n",
      "Epoch 11/150\n",
      "18552/18552 [==============================] - 2s 106us/step - loss: 0.1666 - val_loss: 0.1647\n",
      "Epoch 12/150\n",
      "18552/18552 [==============================] - 2s 106us/step - loss: 0.1656 - val_loss: 0.1637\n",
      "Epoch 13/150\n",
      "18552/18552 [==============================] - 2s 109us/step - loss: 0.1633 - val_loss: 0.1631\n",
      "Epoch 14/150\n",
      "18552/18552 [==============================] - 2s 108us/step - loss: 0.1612 - val_loss: 0.1650\n",
      "Epoch 15/150\n",
      "18552/18552 [==============================] - 2s 102us/step - loss: 0.1616 - val_loss: 0.1593\n",
      "Epoch 16/150\n",
      "18552/18552 [==============================] - 2s 96us/step - loss: 0.1569 - val_loss: 0.1576\n",
      "Epoch 17/150\n",
      "18552/18552 [==============================] - 2s 112us/step - loss: 0.1579 - val_loss: 0.1553\n",
      "Epoch 18/150\n",
      "18552/18552 [==============================] - 2s 109us/step - loss: 0.1576 - val_loss: 0.1581\n",
      "Epoch 19/150\n",
      "18552/18552 [==============================] - 2s 110us/step - loss: 0.1511 - val_loss: 0.1513\n",
      "Epoch 20/150\n",
      "18552/18552 [==============================] - 2s 102us/step - loss: 0.1486 - val_loss: 0.1475\n",
      "Epoch 21/150\n",
      "18552/18552 [==============================] - 2s 108us/step - loss: 0.1492 - val_loss: 0.1475\n",
      "Epoch 22/150\n",
      "18552/18552 [==============================] - 2s 105us/step - loss: 0.1478 - val_loss: 0.1498\n",
      "Epoch 23/150\n",
      "18552/18552 [==============================] - 2s 110us/step - loss: 0.1464 - val_loss: 0.1503\n",
      "Epoch 24/150\n",
      "18552/18552 [==============================] - 2s 104us/step - loss: 0.1458 - val_loss: 0.1461\n",
      "Epoch 25/150\n",
      "18552/18552 [==============================] - 2s 103us/step - loss: 0.1426 - val_loss: 0.1431\n",
      "Epoch 26/150\n",
      "18552/18552 [==============================] - 2s 108us/step - loss: 0.1404 - val_loss: 0.1439\n",
      "Epoch 27/150\n",
      "18552/18552 [==============================] - 2s 107us/step - loss: 0.1411 - val_loss: 0.1411\n",
      "Epoch 28/150\n",
      "18552/18552 [==============================] - 2s 106us/step - loss: 0.1411 - val_loss: 0.1392\n",
      "Epoch 29/150\n",
      "18552/18552 [==============================] - 2s 103us/step - loss: 0.1382 - val_loss: 0.1367\n",
      "Epoch 30/150\n",
      "18552/18552 [==============================] - 2s 107us/step - loss: 0.1385 - val_loss: 0.1398\n",
      "Epoch 31/150\n",
      "18552/18552 [==============================] - 2s 107us/step - loss: 0.1370 - val_loss: 0.1384\n",
      "Epoch 32/150\n",
      "18552/18552 [==============================] - 2s 108us/step - loss: 0.1383 - val_loss: 0.1410\n",
      "Epoch 33/150\n",
      "18552/18552 [==============================] - 2s 97us/step - loss: 0.1386 - val_loss: 0.1414\n",
      "Evaluating model with testing data...\n",
      "3954/3954 [==============================] - 0s 16us/step\n",
      "Getting distribution of predictions and covariance matrix...\n",
      "      1 of 20\n",
      "      2 of 20\n",
      "      3 of 20\n",
      "      4 of 20\n",
      "      5 of 20\n",
      "      6 of 20\n",
      "      7 of 20\n",
      "      8 of 20\n",
      "      9 of 20\n",
      "      10 of 20\n",
      "      11 of 20\n",
      "      12 of 20\n",
      "      13 of 20\n",
      "      14 of 20\n",
      "      15 of 20\n",
      "      16 of 20\n",
      "      17 of 20\n",
      "      18 of 20\n",
      "      19 of 20\n",
      "      20 of 20\n",
      "Computing ensemble means...\n",
      "Computing mean squared error...\n",
      "Iteration 130\n",
      "Train on 18692 samples, validate on 3984 samples\n",
      "Epoch 1/150\n",
      "18692/18692 [==============================] - 2s 103us/step - loss: 0.5026 - val_loss: 0.3967\n",
      "Epoch 2/150\n",
      "18692/18692 [==============================] - 2s 99us/step - loss: 0.3620 - val_loss: 0.3381\n",
      "Epoch 3/150\n",
      "18692/18692 [==============================] - 2s 108us/step - loss: 0.3212 - val_loss: 0.3080\n",
      "Epoch 4/150\n",
      "18692/18692 [==============================] - 2s 93us/step - loss: 0.2950 - val_loss: 0.2902\n",
      "Epoch 5/150\n",
      "18692/18692 [==============================] - 1s 59us/step - loss: 0.2842 - val_loss: 0.2846\n",
      "Epoch 6/150\n",
      "18692/18692 [==============================] - 2s 92us/step - loss: 0.2776 - val_loss: 0.2774\n",
      "Epoch 7/150\n",
      "18692/18692 [==============================] - 2s 99us/step - loss: 0.2748 - val_loss: 0.2697\n",
      "Epoch 8/150\n",
      "18692/18692 [==============================] - 2s 102us/step - loss: 0.2723 - val_loss: 0.2694\n",
      "Epoch 9/150\n",
      "18692/18692 [==============================] - 2s 101us/step - loss: 0.2719 - val_loss: 0.2707\n",
      "Epoch 10/150\n",
      "18692/18692 [==============================] - 2s 102us/step - loss: 0.2718 - val_loss: 0.2679\n",
      "Epoch 11/150\n",
      "18692/18692 [==============================] - 2s 102us/step - loss: 0.2691 - val_loss: 0.2692\n",
      "Epoch 12/150\n",
      "18692/18692 [==============================] - 2s 98us/step - loss: 0.2704 - val_loss: 0.2707\n",
      "Epoch 13/150\n",
      "18692/18692 [==============================] - 2s 99us/step - loss: 0.2686 - val_loss: 0.2727\n",
      "Epoch 14/150\n",
      "18692/18692 [==============================] - 2s 102us/step - loss: 0.2709 - val_loss: 0.2690\n",
      "Evaluating model with testing data...\n",
      "3984/3984 [==============================] - 0s 16us/step\n",
      "Getting distribution of predictions and covariance matrix...\n",
      "      1 of 20\n",
      "      2 of 20\n",
      "      3 of 20\n",
      "      4 of 20\n",
      "      5 of 20\n",
      "      6 of 20\n",
      "      7 of 20\n",
      "      8 of 20\n",
      "      9 of 20\n",
      "      10 of 20\n",
      "      11 of 20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      12 of 20\n",
      "      13 of 20\n",
      "      14 of 20\n",
      "      15 of 20\n",
      "      16 of 20\n",
      "      17 of 20\n",
      "      18 of 20\n",
      "      19 of 20\n",
      "      20 of 20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|          | 0/20 [00:00<?, ?it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing ensemble means...\n",
      "Computing mean squared error...\n",
      "Getting distribution of predictions...\n",
      "      1 of 20\n",
      "1600/1600 [==============================] - 0s 27us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  5%|▌         | 1/20 [00:29<09:22, 29.59s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      2 of 20\n",
      "1600/1600 [==============================] - 0s 29us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 10%|█         | 2/20 [00:59<08:52, 29.58s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      3 of 20\n",
      "1600/1600 [==============================] - 0s 30us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 15%|█▌        | 3/20 [01:28<08:21, 29.47s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      4 of 20\n",
      "1600/1600 [==============================] - 0s 29us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 20%|██        | 4/20 [01:57<07:50, 29.41s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      5 of 20\n",
      "1600/1600 [==============================] - 0s 29us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 25%|██▌       | 5/20 [02:27<07:22, 29.53s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      6 of 20\n",
      "1600/1600 [==============================] - 0s 29us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 30%|███       | 6/20 [02:57<06:54, 29.58s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      7 of 20\n",
      "1600/1600 [==============================] - 0s 29us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 35%|███▌      | 7/20 [03:26<06:25, 29.65s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      8 of 20\n",
      "1600/1600 [==============================] - 0s 29us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 40%|████      | 8/20 [03:56<05:54, 29.54s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      9 of 20\n",
      "1600/1600 [==============================] - 0s 29us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 45%|████▌     | 9/20 [04:26<05:26, 29.64s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      10 of 20\n",
      "1600/1600 [==============================] - 0s 29us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 50%|█████     | 10/20 [04:55<04:57, 29.71s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      11 of 20\n",
      "1600/1600 [==============================] - 0s 29us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 55%|█████▌    | 11/20 [05:25<04:28, 29.78s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      12 of 20\n",
      "1600/1600 [==============================] - 0s 29us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 60%|██████    | 12/20 [05:55<03:57, 29.67s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      13 of 20\n",
      "1600/1600 [==============================] - 0s 28us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 65%|██████▌   | 13/20 [06:24<03:27, 29.65s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      14 of 20\n",
      "1600/1600 [==============================] - 0s 29us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 70%|███████   | 14/20 [06:54<02:58, 29.74s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      15 of 20\n",
      "1600/1600 [==============================] - 0s 30us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 75%|███████▌  | 15/20 [07:24<02:28, 29.75s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      16 of 20\n",
      "1600/1600 [==============================] - 0s 29us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 80%|████████  | 16/20 [07:53<01:58, 29.61s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      17 of 20\n",
      "1600/1600 [==============================] - 0s 30us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 85%|████████▌ | 17/20 [08:23<01:28, 29.63s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      18 of 20\n",
      "1600/1600 [==============================] - 0s 29us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 90%|█████████ | 18/20 [08:53<00:59, 29.70s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      19 of 20\n",
      "1600/1600 [==============================] - 0s 29us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 95%|█████████▌| 19/20 [09:23<00:29, 29.65s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      20 of 20\n",
      "1600/1600 [==============================] - 0s 30us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 20/20 [09:52<00:00, 29.62s/it]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing ensemble predictions...\n",
      "Iteration 131\n",
      "Train on 18832 samples, validate on 4014 samples\n",
      "Epoch 1/150\n",
      "18832/18832 [==============================] - 2s 112us/step - loss: 0.4512 - val_loss: 0.3349\n",
      "Epoch 2/150\n",
      "18832/18832 [==============================] - 2s 108us/step - loss: 0.2945 - val_loss: 0.2720\n",
      "Epoch 3/150\n",
      "18832/18832 [==============================] - 2s 108us/step - loss: 0.2451 - val_loss: 0.2174\n",
      "Epoch 4/150\n",
      "18832/18832 [==============================] - 2s 111us/step - loss: 0.2083 - val_loss: 0.2011\n",
      "Epoch 5/150\n",
      "18832/18832 [==============================] - 2s 111us/step - loss: 0.1963 - val_loss: 0.1921\n",
      "Epoch 6/150\n",
      "18832/18832 [==============================] - 2s 111us/step - loss: 0.1814 - val_loss: 0.1804\n",
      "Epoch 7/150\n",
      "18832/18832 [==============================] - 2s 108us/step - loss: 0.1752 - val_loss: 0.1736\n",
      "Epoch 8/150\n",
      "18832/18832 [==============================] - 2s 108us/step - loss: 0.1694 - val_loss: 0.1687\n",
      "Epoch 9/150\n",
      "18832/18832 [==============================] - 2s 110us/step - loss: 0.1669 - val_loss: 0.1697\n",
      "Epoch 10/150\n",
      "18832/18832 [==============================] - 2s 112us/step - loss: 0.1673 - val_loss: 0.1664\n",
      "Epoch 11/150\n",
      "18832/18832 [==============================] - 2s 109us/step - loss: 0.1639 - val_loss: 0.1644\n",
      "Epoch 12/150\n",
      "18832/18832 [==============================] - 2s 107us/step - loss: 0.1604 - val_loss: 0.1622\n",
      "Epoch 13/150\n",
      "18832/18832 [==============================] - 2s 113us/step - loss: 0.1575 - val_loss: 0.1609\n",
      "Epoch 14/150\n",
      "18832/18832 [==============================] - 2s 110us/step - loss: 0.1551 - val_loss: 0.1529\n",
      "Epoch 15/150\n",
      "18832/18832 [==============================] - 2s 108us/step - loss: 0.1520 - val_loss: 0.1557\n",
      "Epoch 16/150\n",
      "18832/18832 [==============================] - 2s 115us/step - loss: 0.1494 - val_loss: 0.1496\n",
      "Epoch 17/150\n",
      "18832/18832 [==============================] - 2s 111us/step - loss: 0.1501 - val_loss: 0.1519\n",
      "Epoch 18/150\n",
      "18832/18832 [==============================] - 2s 116us/step - loss: 0.1488 - val_loss: 0.1506\n",
      "Epoch 19/150\n",
      "18832/18832 [==============================] - 2s 113us/step - loss: 0.1477 - val_loss: 0.1507\n",
      "Epoch 20/150\n",
      "18832/18832 [==============================] - 2s 110us/step - loss: 0.1452 - val_loss: 0.1465\n",
      "Epoch 21/150\n",
      "18832/18832 [==============================] - 2s 108us/step - loss: 0.1447 - val_loss: 0.1396\n",
      "Epoch 22/150\n",
      "18832/18832 [==============================] - 2s 113us/step - loss: 0.1402 - val_loss: 0.1404\n",
      "Epoch 23/150\n",
      "18832/18832 [==============================] - 2s 114us/step - loss: 0.1388 - val_loss: 0.1391\n",
      "Epoch 24/150\n",
      "18832/18832 [==============================] - 2s 112us/step - loss: 0.1355 - val_loss: 0.1358\n",
      "Epoch 25/150\n",
      "18832/18832 [==============================] - 2s 98us/step - loss: 0.1345 - val_loss: 0.1335\n",
      "Epoch 26/150\n",
      "18832/18832 [==============================] - 2s 108us/step - loss: 0.1313 - val_loss: 0.1315\n",
      "Epoch 27/150\n",
      "18832/18832 [==============================] - 2s 108us/step - loss: 0.1283 - val_loss: 0.1274\n",
      "Epoch 28/150\n",
      "18832/18832 [==============================] - 2s 113us/step - loss: 0.1278 - val_loss: 0.1298\n",
      "Epoch 29/150\n",
      "18832/18832 [==============================] - 2s 112us/step - loss: 0.1269 - val_loss: 0.1259\n",
      "Epoch 30/150\n",
      "18832/18832 [==============================] - 2s 108us/step - loss: 0.1267 - val_loss: 0.1285\n",
      "Epoch 31/150\n",
      "18832/18832 [==============================] - 2s 101us/step - loss: 0.1254 - val_loss: 0.1275\n",
      "Epoch 32/150\n",
      "18832/18832 [==============================] - 2s 107us/step - loss: 0.1252 - val_loss: 0.1255\n",
      "Epoch 33/150\n",
      "18832/18832 [==============================] - 2s 110us/step - loss: 0.1242 - val_loss: 0.1263\n",
      "Epoch 34/150\n",
      "18832/18832 [==============================] - 2s 107us/step - loss: 0.1216 - val_loss: 0.1250\n",
      "Epoch 35/150\n",
      "18832/18832 [==============================] - 2s 106us/step - loss: 0.1227 - val_loss: 0.1260\n",
      "Epoch 36/150\n",
      "18832/18832 [==============================] - 2s 107us/step - loss: 0.1226 - val_loss: 0.1231\n",
      "Epoch 37/150\n",
      "18832/18832 [==============================] - 2s 108us/step - loss: 0.1207 - val_loss: 0.1273\n",
      "Epoch 38/150\n",
      "18832/18832 [==============================] - 2s 106us/step - loss: 0.1215 - val_loss: 0.1209\n",
      "Epoch 39/150\n",
      "18832/18832 [==============================] - 2s 109us/step - loss: 0.1215 - val_loss: 0.1209\n",
      "Epoch 40/150\n",
      "18832/18832 [==============================] - 2s 107us/step - loss: 0.1201 - val_loss: 0.1257\n",
      "Epoch 41/150\n",
      "18832/18832 [==============================] - 2s 109us/step - loss: 0.1221 - val_loss: 0.1216\n",
      "Epoch 42/150\n",
      "18832/18832 [==============================] - 2s 105us/step - loss: 0.1194 - val_loss: 0.1220\n",
      "Epoch 43/150\n",
      "18832/18832 [==============================] - 2s 105us/step - loss: 0.1207 - val_loss: 0.1218\n",
      "Evaluating model with testing data...\n",
      "4014/4014 [==============================] - 0s 16us/step\n",
      "Getting distribution of predictions and covariance matrix...\n",
      "      1 of 20\n",
      "      2 of 20\n",
      "      3 of 20\n",
      "      4 of 20\n",
      "      5 of 20\n",
      "      6 of 20\n",
      "      7 of 20\n",
      "      8 of 20\n",
      "      9 of 20\n",
      "      10 of 20\n",
      "      11 of 20\n",
      "      12 of 20\n",
      "      13 of 20\n",
      "      14 of 20\n",
      "      15 of 20\n",
      "      16 of 20\n",
      "      17 of 20\n",
      "      18 of 20\n",
      "      19 of 20\n",
      "      20 of 20\n",
      "Computing ensemble means...\n",
      "Computing mean squared error...\n",
      "Iteration 132\n",
      "Train on 18972 samples, validate on 4044 samples\n",
      "Epoch 1/150\n",
      "18972/18972 [==============================] - 2s 102us/step - loss: 0.4418 - val_loss: 0.3180\n",
      "Epoch 2/150\n",
      "18972/18972 [==============================] - 2s 101us/step - loss: 0.2707 - val_loss: 0.2512\n",
      "Epoch 3/150\n",
      "18972/18972 [==============================] - 2s 105us/step - loss: 0.2384 - val_loss: 0.2372\n",
      "Epoch 4/150\n",
      "18972/18972 [==============================] - 2s 113us/step - loss: 0.2223 - val_loss: 0.2182\n",
      "Epoch 5/150\n",
      "18972/18972 [==============================] - 2s 104us/step - loss: 0.2133 - val_loss: 0.2151\n",
      "Epoch 6/150\n",
      "18972/18972 [==============================] - 2s 104us/step - loss: 0.2042 - val_loss: 0.2083\n",
      "Epoch 7/150\n",
      "18972/18972 [==============================] - 2s 99us/step - loss: 0.1975 - val_loss: 0.1962\n",
      "Epoch 8/150\n",
      "18972/18972 [==============================] - 2s 106us/step - loss: 0.1928 - val_loss: 0.1930\n",
      "Epoch 9/150\n",
      "18972/18972 [==============================] - 1s 63us/step - loss: 0.1900 - val_loss: 0.1906\n",
      "Epoch 10/150\n",
      "18972/18972 [==============================] - 1s 76us/step - loss: 0.1885 - val_loss: 0.1918\n",
      "Epoch 11/150\n",
      "18972/18972 [==============================] - 2s 100us/step - loss: 0.1870 - val_loss: 0.1887\n",
      "Epoch 12/150\n",
      "18972/18972 [==============================] - 2s 102us/step - loss: 0.1864 - val_loss: 0.1879\n",
      "Epoch 13/150\n",
      "18972/18972 [==============================] - 2s 100us/step - loss: 0.1845 - val_loss: 0.1879\n",
      "Epoch 14/150\n",
      "18972/18972 [==============================] - 2s 101us/step - loss: 0.1845 - val_loss: 0.1879\n",
      "Epoch 15/150\n",
      "18972/18972 [==============================] - 2s 102us/step - loss: 0.1850 - val_loss: 0.1846\n",
      "Epoch 16/150\n",
      "18972/18972 [==============================] - 2s 101us/step - loss: 0.1843 - val_loss: 0.1858\n",
      "Epoch 17/150\n",
      "18972/18972 [==============================] - 2s 103us/step - loss: 0.1836 - val_loss: 0.1865\n",
      "Epoch 18/150\n",
      "18972/18972 [==============================] - 2s 106us/step - loss: 0.1824 - val_loss: 0.1835\n",
      "Epoch 19/150\n",
      "18972/18972 [==============================] - 2s 99us/step - loss: 0.1793 - val_loss: 0.1822\n",
      "Epoch 20/150\n",
      "18972/18972 [==============================] - 2s 102us/step - loss: 0.1765 - val_loss: 0.1796\n",
      "Epoch 21/150\n",
      "18972/18972 [==============================] - 2s 103us/step - loss: 0.1751 - val_loss: 0.1781\n",
      "Epoch 22/150\n",
      "18972/18972 [==============================] - 2s 100us/step - loss: 0.1736 - val_loss: 0.1726\n",
      "Epoch 23/150\n",
      "18972/18972 [==============================] - 2s 101us/step - loss: 0.1735 - val_loss: 0.1757\n",
      "Epoch 24/150\n",
      "18972/18972 [==============================] - 2s 103us/step - loss: 0.1737 - val_loss: 0.1738\n",
      "Epoch 25/150\n",
      "18972/18972 [==============================] - 2s 97us/step - loss: 0.1724 - val_loss: 0.1784\n",
      "Epoch 26/150\n",
      "18972/18972 [==============================] - 2s 98us/step - loss: 0.1712 - val_loss: 0.1765\n",
      "Evaluating model with testing data...\n",
      "4044/4044 [==============================] - 0s 16us/step\n",
      "Getting distribution of predictions and covariance matrix...\n",
      "      1 of 20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      2 of 20\n",
      "      3 of 20\n",
      "      4 of 20\n",
      "      5 of 20\n",
      "      6 of 20\n",
      "      7 of 20\n",
      "      8 of 20\n",
      "      9 of 20\n",
      "      10 of 20\n",
      "      11 of 20\n",
      "      12 of 20\n",
      "      13 of 20\n",
      "      14 of 20\n",
      "      15 of 20\n",
      "      16 of 20\n",
      "      17 of 20\n",
      "      18 of 20\n",
      "      19 of 20\n",
      "      20 of 20\n",
      "Computing ensemble means...\n",
      "Computing mean squared error...\n",
      "Iteration 133\n",
      "Train on 19112 samples, validate on 4074 samples\n",
      "Epoch 1/150\n",
      "19112/19112 [==============================] - 2s 109us/step - loss: 0.4373 - val_loss: 0.3454\n",
      "Epoch 2/150\n",
      "19112/19112 [==============================] - 2s 115us/step - loss: 0.3200 - val_loss: 0.3056\n",
      "Epoch 3/150\n",
      "19112/19112 [==============================] - 2s 109us/step - loss: 0.2871 - val_loss: 0.2752\n",
      "Epoch 4/150\n",
      "19112/19112 [==============================] - 2s 112us/step - loss: 0.2678 - val_loss: 0.2647\n",
      "Epoch 5/150\n",
      "19112/19112 [==============================] - 2s 110us/step - loss: 0.2570 - val_loss: 0.2536\n",
      "Epoch 6/150\n",
      "19112/19112 [==============================] - 2s 112us/step - loss: 0.2500 - val_loss: 0.2476\n",
      "Epoch 7/150\n",
      "19112/19112 [==============================] - 2s 110us/step - loss: 0.2376 - val_loss: 0.2339\n",
      "Epoch 8/150\n",
      "19112/19112 [==============================] - 2s 110us/step - loss: 0.2318 - val_loss: 0.2303\n",
      "Epoch 9/150\n",
      "19112/19112 [==============================] - 2s 111us/step - loss: 0.2286 - val_loss: 0.2262\n",
      "Epoch 10/150\n",
      "19112/19112 [==============================] - 2s 108us/step - loss: 0.2245 - val_loss: 0.2281\n",
      "Epoch 11/150\n",
      "19112/19112 [==============================] - 2s 112us/step - loss: 0.2227 - val_loss: 0.2197\n",
      "Epoch 12/150\n",
      "19112/19112 [==============================] - 2s 111us/step - loss: 0.2198 - val_loss: 0.2176\n",
      "Epoch 13/150\n",
      "19112/19112 [==============================] - 2s 110us/step - loss: 0.2180 - val_loss: 0.2218\n",
      "Epoch 14/150\n",
      "19112/19112 [==============================] - 2s 113us/step - loss: 0.2175 - val_loss: 0.2151\n",
      "Epoch 15/150\n",
      "19112/19112 [==============================] - 2s 113us/step - loss: 0.2161 - val_loss: 0.2200\n",
      "Epoch 16/150\n",
      "19112/19112 [==============================] - 2s 111us/step - loss: 0.2164 - val_loss: 0.2195\n",
      "Epoch 17/150\n",
      "19112/19112 [==============================] - 2s 114us/step - loss: 0.2138 - val_loss: 0.2141\n",
      "Epoch 18/150\n",
      "19112/19112 [==============================] - 2s 109us/step - loss: 0.2145 - val_loss: 0.2136\n",
      "Epoch 19/150\n",
      "19112/19112 [==============================] - 2s 112us/step - loss: 0.2138 - val_loss: 0.2138\n",
      "Epoch 20/150\n",
      "19112/19112 [==============================] - 2s 110us/step - loss: 0.2084 - val_loss: 0.2062\n",
      "Epoch 21/150\n",
      "19112/19112 [==============================] - 2s 109us/step - loss: 0.1958 - val_loss: 0.1911\n",
      "Epoch 22/150\n",
      "19112/19112 [==============================] - 2s 110us/step - loss: 0.1885 - val_loss: 0.1857\n",
      "Epoch 23/150\n",
      "19112/19112 [==============================] - 2s 112us/step - loss: 0.1857 - val_loss: 0.1858\n",
      "Epoch 24/150\n",
      "19112/19112 [==============================] - 2s 101us/step - loss: 0.1828 - val_loss: 0.1834\n",
      "Epoch 25/150\n",
      "19112/19112 [==============================] - 2s 106us/step - loss: 0.1830 - val_loss: 0.1832\n",
      "Epoch 26/150\n",
      "19112/19112 [==============================] - 2s 108us/step - loss: 0.1813 - val_loss: 0.1829\n",
      "Epoch 27/150\n",
      "19112/19112 [==============================] - 2s 105us/step - loss: 0.1818 - val_loss: 0.1812\n",
      "Epoch 28/150\n",
      "19112/19112 [==============================] - 2s 107us/step - loss: 0.1800 - val_loss: 0.1712\n",
      "Epoch 29/150\n",
      "19112/19112 [==============================] - 2s 110us/step - loss: 0.1730 - val_loss: 0.1698\n",
      "Epoch 30/150\n",
      "19112/19112 [==============================] - 2s 110us/step - loss: 0.1685 - val_loss: 0.1704\n",
      "Epoch 31/150\n",
      "19112/19112 [==============================] - 2s 108us/step - loss: 0.1679 - val_loss: 0.1687\n",
      "Epoch 32/150\n",
      "19112/19112 [==============================] - 2s 107us/step - loss: 0.1686 - val_loss: 0.1666\n",
      "Epoch 33/150\n",
      "19112/19112 [==============================] - 2s 110us/step - loss: 0.1665 - val_loss: 0.1657\n",
      "Epoch 34/150\n",
      "19112/19112 [==============================] - 2s 110us/step - loss: 0.1604 - val_loss: 0.1655\n",
      "Epoch 35/150\n",
      "19112/19112 [==============================] - 2s 108us/step - loss: 0.1617 - val_loss: 0.1568\n",
      "Epoch 36/150\n",
      "19112/19112 [==============================] - 2s 108us/step - loss: 0.1569 - val_loss: 0.1574\n",
      "Epoch 37/150\n",
      "19112/19112 [==============================] - 2s 108us/step - loss: 0.1544 - val_loss: 0.1552\n",
      "Epoch 38/150\n",
      "19112/19112 [==============================] - 2s 107us/step - loss: 0.1566 - val_loss: 0.1508\n",
      "Epoch 39/150\n",
      "19112/19112 [==============================] - 2s 109us/step - loss: 0.1531 - val_loss: 0.1517\n",
      "Epoch 40/150\n",
      "19112/19112 [==============================] - 2s 110us/step - loss: 0.1516 - val_loss: 0.1534\n",
      "Epoch 41/150\n",
      "19112/19112 [==============================] - 1s 67us/step - loss: 0.1510 - val_loss: 0.1510\n",
      "Epoch 42/150\n",
      "19112/19112 [==============================] - 1s 73us/step - loss: 0.1506 - val_loss: 0.1492\n",
      "Epoch 43/150\n",
      "19112/19112 [==============================] - 2s 102us/step - loss: 0.1497 - val_loss: 0.1490\n",
      "Epoch 44/150\n",
      "19112/19112 [==============================] - 2s 111us/step - loss: 0.1484 - val_loss: 0.1512\n",
      "Epoch 45/150\n",
      "19112/19112 [==============================] - 2s 107us/step - loss: 0.1477 - val_loss: 0.1440\n",
      "Epoch 46/150\n",
      "19112/19112 [==============================] - 2s 105us/step - loss: 0.1475 - val_loss: 0.1505\n",
      "Epoch 47/150\n",
      "19112/19112 [==============================] - 2s 98us/step - loss: 0.1465 - val_loss: 0.1487\n",
      "Epoch 48/150\n",
      "19112/19112 [==============================] - 2s 109us/step - loss: 0.1482 - val_loss: 0.1517\n",
      "Epoch 49/150\n",
      "19112/19112 [==============================] - 2s 105us/step - loss: 0.1465 - val_loss: 0.1482\n",
      "Evaluating model with testing data...\n",
      "4074/4074 [==============================] - 0s 16us/step\n",
      "Getting distribution of predictions and covariance matrix...\n",
      "      1 of 20\n",
      "      2 of 20\n",
      "      3 of 20\n",
      "      4 of 20\n",
      "      5 of 20\n",
      "      6 of 20\n",
      "      7 of 20\n",
      "      8 of 20\n",
      "      9 of 20\n",
      "      10 of 20\n",
      "      11 of 20\n",
      "      12 of 20\n",
      "      13 of 20\n",
      "      14 of 20\n",
      "      15 of 20\n",
      "      16 of 20\n",
      "      17 of 20\n",
      "      18 of 20\n",
      "      19 of 20\n",
      "      20 of 20\n",
      "Computing ensemble means...\n",
      "Computing mean squared error...\n",
      "Iteration 134\n",
      "Train on 19252 samples, validate on 4104 samples\n",
      "Epoch 1/150\n",
      "19252/19252 [==============================] - 2s 100us/step - loss: 0.3530 - val_loss: 0.2355\n",
      "Epoch 2/150\n",
      "19252/19252 [==============================] - 2s 103us/step - loss: 0.2088 - val_loss: 0.1963\n",
      "Epoch 3/150\n",
      "19252/19252 [==============================] - 2s 101us/step - loss: 0.1901 - val_loss: 0.1833\n",
      "Epoch 4/150\n",
      "19252/19252 [==============================] - 2s 103us/step - loss: 0.1780 - val_loss: 0.1737\n",
      "Epoch 5/150\n",
      "19252/19252 [==============================] - 2s 103us/step - loss: 0.1688 - val_loss: 0.1628\n",
      "Epoch 6/150\n",
      "19252/19252 [==============================] - 2s 101us/step - loss: 0.1586 - val_loss: 0.1551\n",
      "Epoch 7/150\n",
      "19252/19252 [==============================] - 2s 104us/step - loss: 0.1510 - val_loss: 0.1494\n",
      "Epoch 8/150\n",
      "19252/19252 [==============================] - 2s 107us/step - loss: 0.1481 - val_loss: 0.1504\n",
      "Epoch 9/150\n",
      "19252/19252 [==============================] - 2s 104us/step - loss: 0.1450 - val_loss: 0.1443\n",
      "Epoch 10/150\n",
      "19252/19252 [==============================] - 2s 103us/step - loss: 0.1431 - val_loss: 0.1406\n",
      "Epoch 11/150\n",
      "19252/19252 [==============================] - 2s 103us/step - loss: 0.1388 - val_loss: 0.1388\n",
      "Epoch 12/150\n",
      "19252/19252 [==============================] - 2s 102us/step - loss: 0.1353 - val_loss: 0.1342\n",
      "Epoch 13/150\n",
      "19252/19252 [==============================] - 2s 103us/step - loss: 0.1336 - val_loss: 0.1345\n",
      "Epoch 14/150\n",
      "19252/19252 [==============================] - 2s 100us/step - loss: 0.1324 - val_loss: 0.1359\n",
      "Epoch 15/150\n",
      "19252/19252 [==============================] - 2s 101us/step - loss: 0.1326 - val_loss: 0.1318\n",
      "Epoch 16/150\n",
      "19252/19252 [==============================] - 2s 96us/step - loss: 0.1292 - val_loss: 0.1321\n",
      "Epoch 17/150\n",
      "19252/19252 [==============================] - 2s 99us/step - loss: 0.1276 - val_loss: 0.1298\n",
      "Epoch 18/150\n",
      "19252/19252 [==============================] - 2s 96us/step - loss: 0.1275 - val_loss: 0.1283\n",
      "Epoch 19/150\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19252/19252 [==============================] - 2s 111us/step - loss: 0.1246 - val_loss: 0.1262\n",
      "Epoch 20/150\n",
      "19252/19252 [==============================] - 2s 113us/step - loss: 0.1263 - val_loss: 0.1264\n",
      "Epoch 21/150\n",
      "19252/19252 [==============================] - 2s 109us/step - loss: 0.1229 - val_loss: 0.1241\n",
      "Epoch 22/150\n",
      "19252/19252 [==============================] - 2s 112us/step - loss: 0.1223 - val_loss: 0.1235\n",
      "Epoch 23/150\n",
      "19252/19252 [==============================] - 2s 112us/step - loss: 0.1218 - val_loss: 0.1244\n",
      "Epoch 24/150\n",
      "19252/19252 [==============================] - 2s 114us/step - loss: 0.1214 - val_loss: 0.1230\n",
      "Epoch 25/150\n",
      "19252/19252 [==============================] - 2s 112us/step - loss: 0.1195 - val_loss: 0.1193\n",
      "Epoch 26/150\n",
      "19252/19252 [==============================] - 2s 112us/step - loss: 0.1194 - val_loss: 0.1204\n",
      "Epoch 27/150\n",
      "19252/19252 [==============================] - 2s 105us/step - loss: 0.1178 - val_loss: 0.1196\n",
      "Epoch 28/150\n",
      "19252/19252 [==============================] - 2s 113us/step - loss: 0.1170 - val_loss: 0.1223\n",
      "Epoch 29/150\n",
      "19252/19252 [==============================] - 2s 112us/step - loss: 0.1182 - val_loss: 0.1174\n",
      "Epoch 30/150\n",
      "19252/19252 [==============================] - 2s 110us/step - loss: 0.1171 - val_loss: 0.1176\n",
      "Epoch 31/150\n",
      "19252/19252 [==============================] - 2s 110us/step - loss: 0.1176 - val_loss: 0.1149\n",
      "Epoch 32/150\n",
      "19252/19252 [==============================] - 2s 110us/step - loss: 0.1160 - val_loss: 0.1158\n",
      "Epoch 33/150\n",
      "19252/19252 [==============================] - 2s 109us/step - loss: 0.1146 - val_loss: 0.1161\n",
      "Epoch 34/150\n",
      "19252/19252 [==============================] - 2s 112us/step - loss: 0.1146 - val_loss: 0.1146\n",
      "Epoch 35/150\n",
      "19252/19252 [==============================] - 2s 112us/step - loss: 0.1138 - val_loss: 0.1117\n",
      "Epoch 36/150\n",
      "19252/19252 [==============================] - 2s 113us/step - loss: 0.1140 - val_loss: 0.1130\n",
      "Epoch 37/150\n",
      "19252/19252 [==============================] - 2s 113us/step - loss: 0.1126 - val_loss: 0.1146\n",
      "Epoch 38/150\n",
      "19252/19252 [==============================] - 2s 113us/step - loss: 0.1108 - val_loss: 0.1137\n",
      "Epoch 39/150\n",
      "19252/19252 [==============================] - 2s 108us/step - loss: 0.1100 - val_loss: 0.1133\n",
      "Evaluating model with testing data...\n",
      "4104/4104 [==============================] - 0s 16us/step\n",
      "Getting distribution of predictions and covariance matrix...\n",
      "      1 of 20\n",
      "      2 of 20\n",
      "      3 of 20\n",
      "      4 of 20\n",
      "      5 of 20\n",
      "      6 of 20\n",
      "      7 of 20\n",
      "      8 of 20\n",
      "      9 of 20\n",
      "      10 of 20\n",
      "      11 of 20\n",
      "      12 of 20\n",
      "      13 of 20\n",
      "      14 of 20\n",
      "      15 of 20\n",
      "      16 of 20\n",
      "      17 of 20\n",
      "      18 of 20\n",
      "      19 of 20\n",
      "      20 of 20\n",
      "Computing ensemble means...\n",
      "Computing mean squared error...\n",
      "Iteration 135\n",
      "Train on 19392 samples, validate on 4134 samples\n",
      "Epoch 1/150\n",
      "19392/19392 [==============================] - 2s 111us/step - loss: 0.4377 - val_loss: 0.3138\n",
      "Epoch 2/150\n",
      "19392/19392 [==============================] - 2s 112us/step - loss: 0.2784 - val_loss: 0.2631\n",
      "Epoch 3/150\n",
      "19392/19392 [==============================] - 2s 108us/step - loss: 0.2461 - val_loss: 0.2315\n",
      "Epoch 4/150\n",
      "19392/19392 [==============================] - 2s 110us/step - loss: 0.2211 - val_loss: 0.2105\n",
      "Epoch 5/150\n",
      "19392/19392 [==============================] - 2s 110us/step - loss: 0.1988 - val_loss: 0.1968\n",
      "Epoch 6/150\n",
      "19392/19392 [==============================] - 2s 106us/step - loss: 0.1899 - val_loss: 0.1898\n",
      "Epoch 7/150\n",
      "19392/19392 [==============================] - 2s 111us/step - loss: 0.1854 - val_loss: 0.1832\n",
      "Epoch 8/150\n",
      "19392/19392 [==============================] - 2s 106us/step - loss: 0.1833 - val_loss: 0.1798\n",
      "Epoch 9/150\n",
      "19392/19392 [==============================] - 2s 89us/step - loss: 0.1816 - val_loss: 0.1837\n",
      "Epoch 10/150\n",
      "19392/19392 [==============================] - 1s 58us/step - loss: 0.1792 - val_loss: 0.1786\n",
      "Epoch 11/150\n",
      "19392/19392 [==============================] - 2s 97us/step - loss: 0.1736 - val_loss: 0.1705\n",
      "Epoch 12/150\n",
      "19392/19392 [==============================] - 2s 102us/step - loss: 0.1736 - val_loss: 0.1719\n",
      "Epoch 13/150\n",
      "19392/19392 [==============================] - 2s 105us/step - loss: 0.1695 - val_loss: 0.1723\n",
      "Epoch 14/150\n",
      "19392/19392 [==============================] - 2s 104us/step - loss: 0.1693 - val_loss: 0.1684\n",
      "Epoch 15/150\n",
      "19392/19392 [==============================] - 2s 106us/step - loss: 0.1678 - val_loss: 0.1698\n",
      "Epoch 16/150\n",
      "19392/19392 [==============================] - 2s 108us/step - loss: 0.1675 - val_loss: 0.1696\n",
      "Epoch 17/150\n",
      "19392/19392 [==============================] - 2s 106us/step - loss: 0.1673 - val_loss: 0.1678\n",
      "Epoch 18/150\n",
      "19392/19392 [==============================] - 2s 107us/step - loss: 0.1664 - val_loss: 0.1671\n",
      "Epoch 19/150\n",
      "19392/19392 [==============================] - 2s 111us/step - loss: 0.1672 - val_loss: 0.1675\n",
      "Epoch 20/150\n",
      "19392/19392 [==============================] - 2s 100us/step - loss: 0.1630 - val_loss: 0.1717\n",
      "Epoch 21/150\n",
      "19392/19392 [==============================] - 2s 107us/step - loss: 0.1646 - val_loss: 0.1630\n",
      "Epoch 22/150\n",
      "19392/19392 [==============================] - 2s 110us/step - loss: 0.1641 - val_loss: 0.1651\n",
      "Epoch 23/150\n",
      "19392/19392 [==============================] - 2s 106us/step - loss: 0.1633 - val_loss: 0.1614\n",
      "Epoch 24/150\n",
      "19392/19392 [==============================] - 2s 104us/step - loss: 0.1619 - val_loss: 0.1638\n",
      "Epoch 25/150\n",
      "19392/19392 [==============================] - 2s 104us/step - loss: 0.1611 - val_loss: 0.1619\n",
      "Epoch 26/150\n",
      "19392/19392 [==============================] - 2s 107us/step - loss: 0.1631 - val_loss: 0.1629\n",
      "Epoch 27/150\n",
      "19392/19392 [==============================] - 2s 108us/step - loss: 0.1621 - val_loss: 0.1653\n",
      "Evaluating model with testing data...\n",
      "4134/4134 [==============================] - 0s 15us/step\n",
      "Getting distribution of predictions and covariance matrix...\n",
      "      1 of 20\n",
      "      2 of 20\n",
      "      3 of 20\n",
      "      4 of 20\n",
      "      5 of 20\n",
      "      6 of 20\n",
      "      7 of 20\n",
      "      8 of 20\n",
      "      9 of 20\n",
      "      10 of 20\n",
      "      11 of 20\n",
      "      12 of 20\n",
      "      13 of 20\n",
      "      14 of 20\n",
      "      15 of 20\n",
      "      16 of 20\n",
      "      17 of 20\n",
      "      18 of 20\n",
      "      19 of 20\n",
      "      20 of 20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|          | 0/20 [00:00<?, ?it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing ensemble means...\n",
      "Computing mean squared error...\n",
      "Getting distribution of predictions...\n",
      "      1 of 20\n",
      "1600/1600 [==============================] - 0s 28us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  5%|▌         | 1/20 [00:29<09:21, 29.56s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      2 of 20\n",
      "1600/1600 [==============================] - 0s 30us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 10%|█         | 2/20 [00:59<08:53, 29.63s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      3 of 20\n",
      "1600/1600 [==============================] - 0s 29us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 15%|█▌        | 3/20 [01:28<08:21, 29.47s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      4 of 20\n",
      "1600/1600 [==============================] - 0s 30us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 20%|██        | 4/20 [01:58<07:52, 29.54s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      5 of 20\n",
      "1600/1600 [==============================] - 0s 29us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 25%|██▌       | 5/20 [02:27<07:22, 29.52s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      6 of 20\n",
      "1600/1600 [==============================] - 0s 30us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 30%|███       | 6/20 [02:57<06:54, 29.58s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      7 of 20\n",
      "1600/1600 [==============================] - 0s 29us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 35%|███▌      | 7/20 [03:27<06:25, 29.64s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      8 of 20\n",
      "1600/1600 [==============================] - 0s 29us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 40%|████      | 8/20 [03:56<05:55, 29.65s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      9 of 20\n",
      "1600/1600 [==============================] - 0s 30us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 45%|████▌     | 9/20 [04:26<05:25, 29.57s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      10 of 20\n",
      "1600/1600 [==============================] - 0s 29us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 50%|█████     | 10/20 [04:55<04:55, 29.56s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      11 of 20\n",
      "1600/1600 [==============================] - 0s 29us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 55%|█████▌    | 11/20 [05:25<04:25, 29.50s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      12 of 20\n",
      "1600/1600 [==============================] - 0s 29us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 60%|██████    | 12/20 [05:54<03:56, 29.59s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      13 of 20\n",
      "1600/1600 [==============================] - 0s 28us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 65%|██████▌   | 13/20 [06:24<03:26, 29.52s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      14 of 20\n",
      "1600/1600 [==============================] - 0s 29us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 70%|███████   | 14/20 [06:54<02:57, 29.60s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      15 of 20\n",
      "1600/1600 [==============================] - 0s 29us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 75%|███████▌  | 15/20 [07:23<02:27, 29.53s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      16 of 20\n",
      "1600/1600 [==============================] - 0s 29us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 80%|████████  | 16/20 [07:53<01:58, 29.59s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      17 of 20\n",
      "1600/1600 [==============================] - 0s 29us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 85%|████████▌ | 17/20 [08:23<01:29, 29.70s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      18 of 20\n",
      "1600/1600 [==============================] - 0s 30us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 90%|█████████ | 18/20 [08:52<00:59, 29.75s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      19 of 20\n",
      "1600/1600 [==============================] - 0s 29us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 95%|█████████▌| 19/20 [09:22<00:29, 29.74s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      20 of 20\n",
      "1600/1600 [==============================] - 0s 28us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 20/20 [09:52<00:00, 29.62s/it]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing ensemble predictions...\n",
      "Iteration 136\n",
      "Train on 19532 samples, validate on 4164 samples\n",
      "Epoch 1/150\n",
      "19532/19532 [==============================] - 2s 114us/step - loss: 0.4251 - val_loss: 0.3064\n",
      "Epoch 2/150\n",
      "19532/19532 [==============================] - 2s 113us/step - loss: 0.2630 - val_loss: 0.2387\n",
      "Epoch 3/150\n",
      "19532/19532 [==============================] - 2s 104us/step - loss: 0.2141 - val_loss: 0.2018\n",
      "Epoch 4/150\n",
      "19532/19532 [==============================] - 2s 109us/step - loss: 0.1917 - val_loss: 0.1932\n",
      "Epoch 5/150\n",
      "19532/19532 [==============================] - 2s 111us/step - loss: 0.1784 - val_loss: 0.1716\n",
      "Epoch 6/150\n",
      "19532/19532 [==============================] - 2s 111us/step - loss: 0.1677 - val_loss: 0.1641\n",
      "Epoch 7/150\n",
      "19532/19532 [==============================] - 2s 111us/step - loss: 0.1624 - val_loss: 0.1589\n",
      "Epoch 8/150\n",
      "19532/19532 [==============================] - 2s 110us/step - loss: 0.1559 - val_loss: 0.1557\n",
      "Epoch 9/150\n",
      "19532/19532 [==============================] - 2s 112us/step - loss: 0.1532 - val_loss: 0.1536\n",
      "Epoch 10/150\n",
      "19532/19532 [==============================] - 2s 109us/step - loss: 0.1503 - val_loss: 0.1504\n",
      "Epoch 11/150\n",
      "19532/19532 [==============================] - 2s 110us/step - loss: 0.1470 - val_loss: 0.1442\n",
      "Epoch 12/150\n",
      "19532/19532 [==============================] - 2s 109us/step - loss: 0.1459 - val_loss: 0.1450\n",
      "Epoch 13/150\n",
      "19532/19532 [==============================] - 2s 105us/step - loss: 0.1430 - val_loss: 0.1465\n",
      "Epoch 14/150\n",
      "19532/19532 [==============================] - 2s 112us/step - loss: 0.1436 - val_loss: 0.1454\n",
      "Epoch 15/150\n",
      "19532/19532 [==============================] - 2s 111us/step - loss: 0.1424 - val_loss: 0.1439\n",
      "Epoch 16/150\n",
      "19532/19532 [==============================] - 2s 109us/step - loss: 0.1419 - val_loss: 0.1443\n",
      "Epoch 17/150\n",
      "19532/19532 [==============================] - 2s 108us/step - loss: 0.1410 - val_loss: 0.1426\n",
      "Epoch 18/150\n",
      "19532/19532 [==============================] - 2s 106us/step - loss: 0.1405 - val_loss: 0.1408\n",
      "Epoch 19/150\n",
      "19532/19532 [==============================] - 2s 111us/step - loss: 0.1405 - val_loss: 0.1412\n",
      "Epoch 20/150\n",
      "19532/19532 [==============================] - 2s 114us/step - loss: 0.1393 - val_loss: 0.1422\n",
      "Epoch 21/150\n",
      "19532/19532 [==============================] - 2s 109us/step - loss: 0.1362 - val_loss: 0.1311\n",
      "Epoch 22/150\n",
      "19532/19532 [==============================] - 2s 113us/step - loss: 0.1327 - val_loss: 0.1336\n",
      "Epoch 23/150\n",
      "19532/19532 [==============================] - 2s 111us/step - loss: 0.1333 - val_loss: 0.1327\n",
      "Epoch 24/150\n",
      "19532/19532 [==============================] - 2s 106us/step - loss: 0.1321 - val_loss: 0.1328\n",
      "Epoch 25/150\n",
      "19532/19532 [==============================] - 2s 111us/step - loss: 0.1303 - val_loss: 0.1302\n",
      "Epoch 26/150\n",
      "19532/19532 [==============================] - 2s 106us/step - loss: 0.1313 - val_loss: 0.1324\n",
      "Epoch 27/150\n",
      "19532/19532 [==============================] - 2s 107us/step - loss: 0.1298 - val_loss: 0.1289\n",
      "Epoch 28/150\n",
      "19532/19532 [==============================] - 2s 110us/step - loss: 0.1291 - val_loss: 0.1326\n",
      "Epoch 29/150\n",
      "19532/19532 [==============================] - 2s 112us/step - loss: 0.1302 - val_loss: 0.1317\n",
      "Epoch 30/150\n",
      "19532/19532 [==============================] - 2s 112us/step - loss: 0.1289 - val_loss: 0.1321\n",
      "Epoch 31/150\n",
      "19532/19532 [==============================] - 2s 109us/step - loss: 0.1299 - val_loss: 0.1269\n",
      "Epoch 32/150\n",
      "19532/19532 [==============================] - 2s 109us/step - loss: 0.1278 - val_loss: 0.1251\n",
      "Epoch 33/150\n",
      "19532/19532 [==============================] - 2s 107us/step - loss: 0.1259 - val_loss: 0.1270\n",
      "Epoch 34/150\n",
      "19532/19532 [==============================] - 2s 109us/step - loss: 0.1249 - val_loss: 0.1241\n",
      "Epoch 35/150\n",
      "19532/19532 [==============================] - 2s 110us/step - loss: 0.1238 - val_loss: 0.1269\n",
      "Epoch 36/150\n",
      "19532/19532 [==============================] - 2s 102us/step - loss: 0.1242 - val_loss: 0.1238\n",
      "Epoch 37/150\n",
      "19532/19532 [==============================] - 2s 106us/step - loss: 0.1226 - val_loss: 0.1275\n",
      "Epoch 38/150\n",
      "19532/19532 [==============================] - 2s 106us/step - loss: 0.1211 - val_loss: 0.1210\n",
      "Epoch 39/150\n",
      "19532/19532 [==============================] - 2s 108us/step - loss: 0.1228 - val_loss: 0.1223\n",
      "Epoch 40/150\n",
      "19532/19532 [==============================] - 2s 109us/step - loss: 0.1202 - val_loss: 0.1200\n",
      "Epoch 41/150\n",
      "19532/19532 [==============================] - 2s 110us/step - loss: 0.1206 - val_loss: 0.1208\n",
      "Epoch 42/150\n",
      "19532/19532 [==============================] - 2s 82us/step - loss: 0.1209 - val_loss: 0.1209\n",
      "Epoch 43/150\n",
      "19532/19532 [==============================] - 1s 59us/step - loss: 0.1198 - val_loss: 0.1208\n",
      "Epoch 44/150\n",
      "19532/19532 [==============================] - 2s 105us/step - loss: 0.1197 - val_loss: 0.1207\n",
      "Evaluating model with testing data...\n",
      "4164/4164 [==============================] - 0s 15us/step\n",
      "Getting distribution of predictions and covariance matrix...\n",
      "      1 of 20\n",
      "      2 of 20\n",
      "      3 of 20\n",
      "      4 of 20\n",
      "      5 of 20\n",
      "      6 of 20\n",
      "      7 of 20\n",
      "      8 of 20\n",
      "      9 of 20\n",
      "      10 of 20\n",
      "      11 of 20\n",
      "      12 of 20\n",
      "      13 of 20\n",
      "      14 of 20\n",
      "      15 of 20\n",
      "      16 of 20\n",
      "      17 of 20\n",
      "      18 of 20\n",
      "      19 of 20\n",
      "      20 of 20\n",
      "Computing ensemble means...\n",
      "Computing mean squared error...\n",
      "Iteration 137\n",
      "Train on 19672 samples, validate on 4194 samples\n",
      "Epoch 1/150\n",
      "19672/19672 [==============================] - 2s 100us/step - loss: 0.3821 - val_loss: 0.2606\n",
      "Epoch 2/150\n",
      "19672/19672 [==============================] - 2s 103us/step - loss: 0.2267 - val_loss: 0.2046\n",
      "Epoch 3/150\n",
      "19672/19672 [==============================] - 2s 105us/step - loss: 0.1967 - val_loss: 0.1852\n",
      "Epoch 4/150\n",
      "19672/19672 [==============================] - 2s 108us/step - loss: 0.1802 - val_loss: 0.1775\n",
      "Epoch 5/150\n",
      "19672/19672 [==============================] - 2s 101us/step - loss: 0.1731 - val_loss: 0.1722\n",
      "Epoch 6/150\n",
      "19672/19672 [==============================] - 2s 100us/step - loss: 0.1636 - val_loss: 0.1568\n",
      "Epoch 7/150\n",
      "19672/19672 [==============================] - 2s 105us/step - loss: 0.1577 - val_loss: 0.1593\n",
      "Epoch 8/150\n",
      "19672/19672 [==============================] - 2s 102us/step - loss: 0.1534 - val_loss: 0.1515\n",
      "Epoch 9/150\n",
      "19672/19672 [==============================] - 2s 100us/step - loss: 0.1477 - val_loss: 0.1499\n",
      "Epoch 10/150\n",
      "19672/19672 [==============================] - 2s 101us/step - loss: 0.1454 - val_loss: 0.1456\n",
      "Epoch 11/150\n",
      "19672/19672 [==============================] - 2s 101us/step - loss: 0.1427 - val_loss: 0.1437\n",
      "Epoch 12/150\n",
      "19672/19672 [==============================] - 2s 102us/step - loss: 0.1410 - val_loss: 0.1377\n",
      "Epoch 13/150\n",
      "19672/19672 [==============================] - 2s 107us/step - loss: 0.1382 - val_loss: 0.1396\n",
      "Epoch 14/150\n",
      "19672/19672 [==============================] - 2s 104us/step - loss: 0.1379 - val_loss: 0.1361\n",
      "Epoch 15/150\n",
      "19672/19672 [==============================] - 2s 100us/step - loss: 0.1356 - val_loss: 0.1397\n",
      "Epoch 16/150\n",
      "19672/19672 [==============================] - 2s 101us/step - loss: 0.1354 - val_loss: 0.1372\n",
      "Epoch 17/150\n",
      "19672/19672 [==============================] - 2s 103us/step - loss: 0.1347 - val_loss: 0.1322\n",
      "Epoch 18/150\n",
      "19672/19672 [==============================] - 2s 99us/step - loss: 0.1323 - val_loss: 0.1345\n",
      "Epoch 19/150\n",
      "19672/19672 [==============================] - 2s 98us/step - loss: 0.1324 - val_loss: 0.1324\n",
      "Epoch 20/150\n",
      "19672/19672 [==============================] - 2s 97us/step - loss: 0.1315 - val_loss: 0.1351\n",
      "Epoch 21/150\n",
      "19672/19672 [==============================] - 2s 101us/step - loss: 0.1295 - val_loss: 0.1327\n",
      "Evaluating model with testing data...\n",
      "4194/4194 [==============================] - 0s 16us/step\n",
      "Getting distribution of predictions and covariance matrix...\n",
      "      1 of 20\n",
      "      2 of 20\n",
      "      3 of 20\n",
      "      4 of 20\n",
      "      5 of 20\n",
      "      6 of 20\n",
      "      7 of 20\n",
      "      8 of 20\n",
      "      9 of 20\n",
      "      10 of 20\n",
      "      11 of 20\n",
      "      12 of 20\n",
      "      13 of 20\n",
      "      14 of 20\n",
      "      15 of 20\n",
      "      16 of 20\n",
      "      17 of 20\n",
      "      18 of 20\n",
      "      19 of 20\n",
      "      20 of 20\n",
      "Computing ensemble means...\n",
      "Computing mean squared error...\n",
      "Iteration 138\n",
      "Train on 19812 samples, validate on 4224 samples\n",
      "Epoch 1/150\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19812/19812 [==============================] - 2s 106us/step - loss: 0.4638 - val_loss: 0.3355\n",
      "Epoch 2/150\n",
      "19812/19812 [==============================] - 2s 111us/step - loss: 0.3035 - val_loss: 0.2855\n",
      "Epoch 3/150\n",
      "19812/19812 [==============================] - 2s 109us/step - loss: 0.2738 - val_loss: 0.2662\n",
      "Epoch 4/150\n",
      "19812/19812 [==============================] - 2s 107us/step - loss: 0.2534 - val_loss: 0.2413\n",
      "Epoch 5/150\n",
      "19812/19812 [==============================] - 2s 111us/step - loss: 0.2338 - val_loss: 0.2315\n",
      "Epoch 6/150\n",
      "19812/19812 [==============================] - 2s 105us/step - loss: 0.2257 - val_loss: 0.2240\n",
      "Epoch 7/150\n",
      "19812/19812 [==============================] - 2s 110us/step - loss: 0.2210 - val_loss: 0.2193\n",
      "Epoch 8/150\n",
      "19812/19812 [==============================] - 2s 111us/step - loss: 0.2208 - val_loss: 0.2149\n",
      "Epoch 9/150\n",
      "19812/19812 [==============================] - 2s 111us/step - loss: 0.2170 - val_loss: 0.2137\n",
      "Epoch 10/150\n",
      "19812/19812 [==============================] - 2s 114us/step - loss: 0.2150 - val_loss: 0.2113\n",
      "Epoch 11/150\n",
      "19812/19812 [==============================] - 2s 113us/step - loss: 0.2150 - val_loss: 0.2124\n",
      "Epoch 12/150\n",
      "19812/19812 [==============================] - 2s 101us/step - loss: 0.2124 - val_loss: 0.2152\n",
      "Epoch 13/150\n",
      "19812/19812 [==============================] - 2s 110us/step - loss: 0.2123 - val_loss: 0.2094\n",
      "Epoch 14/150\n",
      "19812/19812 [==============================] - 2s 114us/step - loss: 0.2125 - val_loss: 0.2092\n",
      "Epoch 15/150\n",
      "19812/19812 [==============================] - 2s 104us/step - loss: 0.2103 - val_loss: 0.2056\n",
      "Epoch 16/150\n",
      "19812/19812 [==============================] - 2s 106us/step - loss: 0.2107 - val_loss: 0.2112\n",
      "Epoch 17/150\n",
      "19812/19812 [==============================] - 2s 111us/step - loss: 0.2103 - val_loss: 0.2075\n",
      "Epoch 18/150\n",
      "19812/19812 [==============================] - 2s 111us/step - loss: 0.2083 - val_loss: 0.2095\n",
      "Epoch 19/150\n",
      "19812/19812 [==============================] - 2s 112us/step - loss: 0.2092 - val_loss: 0.2067\n",
      "Evaluating model with testing data...\n",
      "4224/4224 [==============================] - 0s 15us/step\n",
      "Getting distribution of predictions and covariance matrix...\n",
      "      1 of 20\n",
      "      2 of 20\n",
      "      3 of 20\n",
      "      4 of 20\n",
      "      5 of 20\n",
      "      6 of 20\n",
      "      7 of 20\n",
      "      8 of 20\n",
      "      9 of 20\n",
      "      10 of 20\n",
      "      11 of 20\n",
      "      12 of 20\n",
      "      13 of 20\n",
      "      14 of 20\n",
      "      15 of 20\n",
      "      16 of 20\n",
      "      17 of 20\n",
      "      18 of 20\n",
      "      19 of 20\n",
      "      20 of 20\n",
      "Computing ensemble means...\n",
      "Computing mean squared error...\n",
      "Iteration 139\n",
      "Train on 19952 samples, validate on 4254 samples\n",
      "Epoch 1/150\n",
      "19952/19952 [==============================] - 2s 105us/step - loss: 0.4904 - val_loss: 0.3983\n",
      "Epoch 2/150\n",
      "19952/19952 [==============================] - 2s 110us/step - loss: 0.3646 - val_loss: 0.3430\n",
      "Epoch 3/150\n",
      "19952/19952 [==============================] - 2s 112us/step - loss: 0.3192 - val_loss: 0.3100\n",
      "Epoch 4/150\n",
      "19952/19952 [==============================] - 2s 108us/step - loss: 0.2939 - val_loss: 0.2920\n",
      "Epoch 5/150\n",
      "19952/19952 [==============================] - 2s 110us/step - loss: 0.2824 - val_loss: 0.2829\n",
      "Epoch 6/150\n",
      "19952/19952 [==============================] - 2s 106us/step - loss: 0.2752 - val_loss: 0.2792\n",
      "Epoch 7/150\n",
      "19952/19952 [==============================] - 2s 103us/step - loss: 0.2727 - val_loss: 0.2777\n",
      "Epoch 8/150\n",
      "19952/19952 [==============================] - 2s 110us/step - loss: 0.2712 - val_loss: 0.2763\n",
      "Epoch 9/150\n",
      "19952/19952 [==============================] - 2s 109us/step - loss: 0.2701 - val_loss: 0.2705\n",
      "Epoch 10/150\n",
      "19952/19952 [==============================] - 2s 109us/step - loss: 0.2633 - val_loss: 0.2504\n",
      "Epoch 11/150\n",
      "19952/19952 [==============================] - 2s 105us/step - loss: 0.2471 - val_loss: 0.2464\n",
      "Epoch 12/150\n",
      "19952/19952 [==============================] - 2s 93us/step - loss: 0.2427 - val_loss: 0.2428\n",
      "Epoch 13/150\n",
      "19952/19952 [==============================] - 1s 59us/step - loss: 0.2422 - val_loss: 0.2409\n",
      "Epoch 14/150\n",
      "19952/19952 [==============================] - 2s 100us/step - loss: 0.2401 - val_loss: 0.2429\n",
      "Epoch 15/150\n",
      "19952/19952 [==============================] - 2s 103us/step - loss: 0.2384 - val_loss: 0.2342\n",
      "Epoch 16/150\n",
      "19952/19952 [==============================] - 2s 111us/step - loss: 0.2315 - val_loss: 0.2315\n",
      "Epoch 17/150\n",
      "19952/19952 [==============================] - 2s 106us/step - loss: 0.2283 - val_loss: 0.2259\n",
      "Epoch 18/150\n",
      "19952/19952 [==============================] - 2s 105us/step - loss: 0.2199 - val_loss: 0.2082\n",
      "Epoch 19/150\n",
      "19952/19952 [==============================] - 2s 108us/step - loss: 0.2084 - val_loss: 0.2062\n",
      "Epoch 20/150\n",
      "19952/19952 [==============================] - 2s 104us/step - loss: 0.1972 - val_loss: 0.1945\n",
      "Epoch 21/150\n",
      "19952/19952 [==============================] - 2s 105us/step - loss: 0.1918 - val_loss: 0.1859\n",
      "Epoch 22/150\n",
      "19952/19952 [==============================] - 2s 104us/step - loss: 0.1881 - val_loss: 0.1873\n",
      "Epoch 23/150\n",
      "19952/19952 [==============================] - 2s 107us/step - loss: 0.1863 - val_loss: 0.1875\n",
      "Epoch 24/150\n",
      "19952/19952 [==============================] - 2s 102us/step - loss: 0.1882 - val_loss: 0.1868\n",
      "Epoch 25/150\n",
      "19952/19952 [==============================] - 2s 103us/step - loss: 0.1844 - val_loss: 0.1893\n",
      "Evaluating model with testing data...\n",
      "4254/4254 [==============================] - 0s 15us/step\n",
      "Getting distribution of predictions and covariance matrix...\n",
      "      1 of 20\n",
      "      2 of 20\n",
      "      3 of 20\n",
      "      4 of 20\n",
      "      5 of 20\n",
      "      6 of 20\n",
      "      7 of 20\n",
      "      8 of 20\n",
      "      9 of 20\n",
      "      10 of 20\n",
      "      11 of 20\n",
      "      12 of 20\n",
      "      13 of 20\n",
      "      14 of 20\n",
      "      15 of 20\n",
      "      16 of 20\n",
      "      17 of 20\n",
      "      18 of 20\n",
      "      19 of 20\n",
      "      20 of 20\n",
      "Computing ensemble means...\n",
      "Computing mean squared error...\n",
      "Iteration 140\n",
      "Train on 20092 samples, validate on 4284 samples\n",
      "Epoch 1/150\n",
      "20092/20092 [==============================] - 2s 101us/step - loss: 0.3936 - val_loss: 0.2707\n",
      "Epoch 2/150\n",
      "20092/20092 [==============================] - 2s 106us/step - loss: 0.2351 - val_loss: 0.2112\n",
      "Epoch 3/150\n",
      "20092/20092 [==============================] - 2s 99us/step - loss: 0.2015 - val_loss: 0.1888\n",
      "Epoch 4/150\n",
      "20092/20092 [==============================] - 2s 105us/step - loss: 0.1836 - val_loss: 0.1746\n",
      "Epoch 5/150\n",
      "20092/20092 [==============================] - 2s 103us/step - loss: 0.1737 - val_loss: 0.1750\n",
      "Epoch 6/150\n",
      "20092/20092 [==============================] - 2s 99us/step - loss: 0.1679 - val_loss: 0.1688\n",
      "Epoch 7/150\n",
      "20092/20092 [==============================] - 2s 102us/step - loss: 0.1653 - val_loss: 0.1612\n",
      "Epoch 8/150\n",
      "20092/20092 [==============================] - 2s 100us/step - loss: 0.1617 - val_loss: 0.1582\n",
      "Epoch 9/150\n",
      "20092/20092 [==============================] - 2s 104us/step - loss: 0.1580 - val_loss: 0.1599\n",
      "Epoch 10/150\n",
      "20092/20092 [==============================] - 2s 104us/step - loss: 0.1573 - val_loss: 0.1525\n",
      "Epoch 11/150\n",
      "20092/20092 [==============================] - 2s 102us/step - loss: 0.1518 - val_loss: 0.1495\n",
      "Epoch 12/150\n",
      "20092/20092 [==============================] - 2s 97us/step - loss: 0.1478 - val_loss: 0.1475\n",
      "Epoch 13/150\n",
      "20092/20092 [==============================] - 2s 101us/step - loss: 0.1440 - val_loss: 0.1427\n",
      "Epoch 14/150\n",
      "20092/20092 [==============================] - 2s 102us/step - loss: 0.1424 - val_loss: 0.1375\n",
      "Epoch 15/150\n",
      "20092/20092 [==============================] - 2s 107us/step - loss: 0.1387 - val_loss: 0.1395\n",
      "Epoch 16/150\n",
      "20092/20092 [==============================] - 2s 99us/step - loss: 0.1361 - val_loss: 0.1363\n",
      "Epoch 17/150\n",
      "20092/20092 [==============================] - 2s 104us/step - loss: 0.1333 - val_loss: 0.1326\n",
      "Epoch 18/150\n",
      "20092/20092 [==============================] - 2s 101us/step - loss: 0.1319 - val_loss: 0.1307\n",
      "Epoch 19/150\n",
      "20092/20092 [==============================] - 2s 95us/step - loss: 0.1309 - val_loss: 0.1293\n",
      "Epoch 20/150\n",
      "20092/20092 [==============================] - 2s 101us/step - loss: 0.1296 - val_loss: 0.1304\n",
      "Epoch 21/150\n",
      "20092/20092 [==============================] - 2s 100us/step - loss: 0.1297 - val_loss: 0.1289\n",
      "Epoch 22/150\n",
      "20092/20092 [==============================] - 2s 107us/step - loss: 0.1266 - val_loss: 0.1280\n",
      "Epoch 23/150\n",
      "20092/20092 [==============================] - 2s 113us/step - loss: 0.1250 - val_loss: 0.1251\n",
      "Epoch 24/150\n",
      "20092/20092 [==============================] - 2s 110us/step - loss: 0.1236 - val_loss: 0.1259\n",
      "Epoch 25/150\n",
      "20092/20092 [==============================] - 2s 114us/step - loss: 0.1232 - val_loss: 0.1247\n",
      "Epoch 26/150\n",
      "20092/20092 [==============================] - 2s 111us/step - loss: 0.1227 - val_loss: 0.1248\n",
      "Epoch 27/150\n",
      "20092/20092 [==============================] - 2s 111us/step - loss: 0.1210 - val_loss: 0.1212\n",
      "Epoch 28/150\n",
      "20092/20092 [==============================] - 2s 108us/step - loss: 0.1187 - val_loss: 0.1213\n",
      "Epoch 29/150\n",
      "20092/20092 [==============================] - 2s 111us/step - loss: 0.1170 - val_loss: 0.1176\n",
      "Epoch 30/150\n",
      "20092/20092 [==============================] - 2s 111us/step - loss: 0.1190 - val_loss: 0.1160\n",
      "Epoch 31/150\n",
      "20092/20092 [==============================] - 2s 112us/step - loss: 0.1171 - val_loss: 0.1161\n",
      "Epoch 32/150\n",
      "20092/20092 [==============================] - 2s 114us/step - loss: 0.1161 - val_loss: 0.1169\n",
      "Epoch 33/150\n",
      "20092/20092 [==============================] - 2s 106us/step - loss: 0.1159 - val_loss: 0.1167\n",
      "Epoch 34/150\n",
      "20092/20092 [==============================] - 2s 110us/step - loss: 0.1163 - val_loss: 0.1156\n",
      "Epoch 35/150\n",
      "20092/20092 [==============================] - 2s 109us/step - loss: 0.1159 - val_loss: 0.1145\n",
      "Epoch 36/150\n",
      "20092/20092 [==============================] - 2s 111us/step - loss: 0.1145 - val_loss: 0.1177\n",
      "Epoch 37/150\n",
      "20092/20092 [==============================] - 2s 113us/step - loss: 0.1152 - val_loss: 0.1140\n",
      "Epoch 38/150\n",
      "20092/20092 [==============================] - 2s 111us/step - loss: 0.1153 - val_loss: 0.1137\n",
      "Epoch 39/150\n",
      "20092/20092 [==============================] - 2s 110us/step - loss: 0.1135 - val_loss: 0.1153\n",
      "Epoch 40/150\n",
      "20092/20092 [==============================] - 2s 106us/step - loss: 0.1131 - val_loss: 0.1131\n",
      "Epoch 41/150\n",
      "20092/20092 [==============================] - 2s 111us/step - loss: 0.1126 - val_loss: 0.1129\n",
      "Epoch 42/150\n",
      "20092/20092 [==============================] - 2s 112us/step - loss: 0.1122 - val_loss: 0.1122\n",
      "Epoch 43/150\n",
      "20092/20092 [==============================] - 2s 83us/step - loss: 0.1129 - val_loss: 0.1126\n",
      "Epoch 44/150\n",
      "20092/20092 [==============================] - 1s 61us/step - loss: 0.1118 - val_loss: 0.1130\n",
      "Epoch 45/150\n",
      "20092/20092 [==============================] - 2s 108us/step - loss: 0.1124 - val_loss: 0.1156\n",
      "Epoch 46/150\n",
      "20092/20092 [==============================] - 2s 109us/step - loss: 0.1115 - val_loss: 0.1103\n",
      "Epoch 47/150\n",
      "20092/20092 [==============================] - 2s 107us/step - loss: 0.1118 - val_loss: 0.1131\n",
      "Epoch 48/150\n",
      "20092/20092 [==============================] - 2s 112us/step - loss: 0.1106 - val_loss: 0.1110\n",
      "Epoch 49/150\n",
      "20092/20092 [==============================] - 2s 104us/step - loss: 0.1108 - val_loss: 0.1088\n",
      "Epoch 50/150\n",
      "20092/20092 [==============================] - 2s 108us/step - loss: 0.1109 - val_loss: 0.1114\n",
      "Epoch 51/150\n",
      "20092/20092 [==============================] - 2s 114us/step - loss: 0.1110 - val_loss: 0.1093\n",
      "Epoch 52/150\n",
      "20092/20092 [==============================] - 2s 103us/step - loss: 0.1107 - val_loss: 0.1104\n",
      "Epoch 53/150\n",
      "20092/20092 [==============================] - 2s 108us/step - loss: 0.1093 - val_loss: 0.1107\n",
      "Evaluating model with testing data...\n",
      "4284/4284 [==============================] - 0s 16us/step\n",
      "Getting distribution of predictions and covariance matrix...\n",
      "      1 of 20\n",
      "      2 of 20\n",
      "      3 of 20\n",
      "      4 of 20\n",
      "      5 of 20\n",
      "      6 of 20\n",
      "      7 of 20\n",
      "      8 of 20\n",
      "      9 of 20\n",
      "      10 of 20\n",
      "      11 of 20\n",
      "      12 of 20\n",
      "      13 of 20\n",
      "      14 of 20\n",
      "      15 of 20\n",
      "      16 of 20\n",
      "      17 of 20\n",
      "      18 of 20\n",
      "      19 of 20\n",
      "      20 of 20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|          | 0/20 [00:00<?, ?it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing ensemble means...\n",
      "Computing mean squared error...\n",
      "Getting distribution of predictions...\n",
      "      1 of 20\n",
      "1600/1600 [==============================] - 0s 28us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  5%|▌         | 1/20 [00:29<09:18, 29.40s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      2 of 20\n",
      "1600/1600 [==============================] - 0s 29us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 10%|█         | 2/20 [00:58<08:48, 29.39s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      3 of 20\n",
      "1600/1600 [==============================] - 0s 30us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 15%|█▌        | 3/20 [01:28<08:20, 29.47s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      4 of 20\n",
      "1600/1600 [==============================] - 0s 30us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 20%|██        | 4/20 [01:57<07:49, 29.37s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      5 of 20\n",
      "1600/1600 [==============================] - 0s 29us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 25%|██▌       | 5/20 [02:27<07:21, 29.47s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      6 of 20\n",
      "1600/1600 [==============================] - 0s 29us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 30%|███       | 6/20 [02:57<06:54, 29.59s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      7 of 20\n",
      "1600/1600 [==============================] - 0s 29us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 35%|███▌      | 7/20 [03:26<06:25, 29.64s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      8 of 20\n",
      "1600/1600 [==============================] - 0s 29us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 40%|████      | 8/20 [03:56<05:54, 29.54s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      9 of 20\n",
      "1600/1600 [==============================] - 0s 29us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 45%|████▌     | 9/20 [04:26<05:25, 29.62s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      10 of 20\n",
      "1600/1600 [==============================] - 0s 29us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 50%|█████     | 10/20 [04:55<04:56, 29.66s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      11 of 20\n",
      "1600/1600 [==============================] - 0s 29us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 55%|█████▌    | 11/20 [05:25<04:26, 29.62s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      12 of 20\n",
      "1600/1600 [==============================] - 0s 29us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 60%|██████    | 12/20 [05:54<03:56, 29.53s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      13 of 20\n",
      "1600/1600 [==============================] - 0s 29us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 65%|██████▌   | 13/20 [06:24<03:26, 29.56s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      14 of 20\n",
      "1600/1600 [==============================] - 0s 30us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 70%|███████   | 14/20 [06:53<02:57, 29.58s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      15 of 20\n",
      "1600/1600 [==============================] - 0s 28us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 75%|███████▌  | 15/20 [07:23<02:27, 29.52s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      16 of 20\n",
      "1600/1600 [==============================] - 0s 29us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 80%|████████  | 16/20 [07:52<01:57, 29.48s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      17 of 20\n",
      "1600/1600 [==============================] - 0s 29us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 85%|████████▌ | 17/20 [08:22<01:28, 29.55s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      18 of 20\n",
      "1600/1600 [==============================] - 0s 28us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 90%|█████████ | 18/20 [08:51<00:59, 29.57s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      19 of 20\n",
      "1600/1600 [==============================] - 0s 29us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 95%|█████████▌| 19/20 [09:21<00:29, 29.65s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      20 of 20\n",
      "1600/1600 [==============================] - 0s 29us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 20/20 [09:51<00:00, 29.57s/it]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing ensemble predictions...\n",
      "Iteration 141\n",
      "Train on 20232 samples, validate on 4314 samples\n",
      "Epoch 1/150\n",
      "20232/20232 [==============================] - 2s 107us/step - loss: 0.4207 - val_loss: 0.2737\n",
      "Epoch 2/150\n",
      "20232/20232 [==============================] - 2s 109us/step - loss: 0.2503 - val_loss: 0.2310\n",
      "Epoch 3/150\n",
      "20232/20232 [==============================] - 2s 107us/step - loss: 0.2264 - val_loss: 0.2198\n",
      "Epoch 4/150\n",
      "20232/20232 [==============================] - 2s 110us/step - loss: 0.2100 - val_loss: 0.1995\n",
      "Epoch 5/150\n",
      "20232/20232 [==============================] - 2s 115us/step - loss: 0.2000 - val_loss: 0.1929\n",
      "Epoch 6/150\n",
      "20232/20232 [==============================] - 2s 106us/step - loss: 0.1907 - val_loss: 0.1840\n",
      "Epoch 7/150\n",
      "20232/20232 [==============================] - 2s 110us/step - loss: 0.1848 - val_loss: 0.1802\n",
      "Epoch 8/150\n",
      "20232/20232 [==============================] - 2s 111us/step - loss: 0.1822 - val_loss: 0.1798\n",
      "Epoch 9/150\n",
      "20232/20232 [==============================] - 2s 110us/step - loss: 0.1790 - val_loss: 0.1793\n",
      "Epoch 10/150\n",
      "20232/20232 [==============================] - 2s 114us/step - loss: 0.1779 - val_loss: 0.1811\n",
      "Epoch 11/150\n",
      "20232/20232 [==============================] - 2s 111us/step - loss: 0.1763 - val_loss: 0.1775\n",
      "Epoch 12/150\n",
      "20232/20232 [==============================] - 2s 112us/step - loss: 0.1755 - val_loss: 0.1760\n",
      "Epoch 13/150\n",
      "20232/20232 [==============================] - 2s 112us/step - loss: 0.1758 - val_loss: 0.1768\n",
      "Epoch 14/150\n",
      "20232/20232 [==============================] - 2s 112us/step - loss: 0.1748 - val_loss: 0.1711\n",
      "Epoch 15/150\n",
      "20232/20232 [==============================] - 2s 112us/step - loss: 0.1742 - val_loss: 0.1786\n",
      "Epoch 16/150\n",
      "20232/20232 [==============================] - 2s 107us/step - loss: 0.1717 - val_loss: 0.1743\n",
      "Epoch 17/150\n",
      "20232/20232 [==============================] - 2s 112us/step - loss: 0.1747 - val_loss: 0.1717\n",
      "Epoch 18/150\n",
      "20232/20232 [==============================] - 2s 110us/step - loss: 0.1723 - val_loss: 0.1694\n",
      "Epoch 19/150\n",
      "20232/20232 [==============================] - 2s 107us/step - loss: 0.1711 - val_loss: 0.1723\n",
      "Epoch 20/150\n",
      "20232/20232 [==============================] - 2s 106us/step - loss: 0.1709 - val_loss: 0.1686\n",
      "Epoch 21/150\n",
      "20232/20232 [==============================] - 2s 106us/step - loss: 0.1705 - val_loss: 0.1734\n",
      "Epoch 22/150\n",
      "20232/20232 [==============================] - 2s 105us/step - loss: 0.1688 - val_loss: 0.1705\n",
      "Epoch 23/150\n",
      "20232/20232 [==============================] - 2s 110us/step - loss: 0.1701 - val_loss: 0.1681\n",
      "Epoch 24/150\n",
      "20232/20232 [==============================] - 2s 112us/step - loss: 0.1691 - val_loss: 0.1676\n",
      "Epoch 25/150\n",
      "20232/20232 [==============================] - 2s 111us/step - loss: 0.1667 - val_loss: 0.1711\n",
      "Epoch 26/150\n",
      "20232/20232 [==============================] - 2s 107us/step - loss: 0.1682 - val_loss: 0.1669\n",
      "Epoch 27/150\n",
      "20232/20232 [==============================] - 2s 103us/step - loss: 0.1687 - val_loss: 0.1649\n",
      "Epoch 28/150\n",
      "20232/20232 [==============================] - 2s 110us/step - loss: 0.1670 - val_loss: 0.1705\n",
      "Epoch 29/150\n",
      "20232/20232 [==============================] - 2s 109us/step - loss: 0.1669 - val_loss: 0.1641\n",
      "Epoch 30/150\n",
      "20232/20232 [==============================] - 2s 98us/step - loss: 0.1652 - val_loss: 0.1705\n",
      "Epoch 31/150\n",
      "20232/20232 [==============================] - 2s 105us/step - loss: 0.1653 - val_loss: 0.1681\n",
      "Epoch 32/150\n",
      "20232/20232 [==============================] - 2s 108us/step - loss: 0.1635 - val_loss: 0.1647\n",
      "Epoch 33/150\n",
      "20232/20232 [==============================] - 2s 108us/step - loss: 0.1643 - val_loss: 0.1655\n",
      "Evaluating model with testing data...\n",
      "4314/4314 [==============================] - 0s 16us/step\n",
      "Getting distribution of predictions and covariance matrix...\n",
      "      1 of 20\n",
      "      2 of 20\n",
      "      3 of 20\n",
      "      4 of 20\n",
      "      5 of 20\n",
      "      6 of 20\n",
      "      7 of 20\n",
      "      8 of 20\n",
      "      9 of 20\n",
      "      10 of 20\n",
      "      11 of 20\n",
      "      12 of 20\n",
      "      13 of 20\n",
      "      14 of 20\n",
      "      15 of 20\n",
      "      16 of 20\n",
      "      17 of 20\n",
      "      18 of 20\n",
      "      19 of 20\n",
      "      20 of 20\n",
      "Computing ensemble means...\n",
      "Computing mean squared error...\n",
      "Iteration 142\n",
      "Train on 20372 samples, validate on 4344 samples\n",
      "Epoch 1/150\n",
      "20372/20372 [==============================] - 2s 105us/step - loss: 0.4349 - val_loss: 0.3102\n",
      "Epoch 2/150\n",
      "20372/20372 [==============================] - 2s 105us/step - loss: 0.2715 - val_loss: 0.2441\n",
      "Epoch 3/150\n",
      "20372/20372 [==============================] - 2s 109us/step - loss: 0.2303 - val_loss: 0.2212\n",
      "Epoch 4/150\n",
      "20372/20372 [==============================] - 2s 105us/step - loss: 0.2075 - val_loss: 0.1987\n",
      "Epoch 5/150\n",
      "20372/20372 [==============================] - 2s 104us/step - loss: 0.1945 - val_loss: 0.1858\n",
      "Epoch 6/150\n",
      "20372/20372 [==============================] - 2s 101us/step - loss: 0.1848 - val_loss: 0.1815\n",
      "Epoch 7/150\n",
      "20372/20372 [==============================] - 2s 104us/step - loss: 0.1747 - val_loss: 0.1684\n",
      "Epoch 8/150\n",
      "20372/20372 [==============================] - 2s 101us/step - loss: 0.1683 - val_loss: 0.1700\n",
      "Epoch 9/150\n",
      "20372/20372 [==============================] - 2s 107us/step - loss: 0.1652 - val_loss: 0.1675\n",
      "Epoch 10/150\n",
      "20372/20372 [==============================] - 2s 107us/step - loss: 0.1639 - val_loss: 0.1634\n",
      "Epoch 11/150\n",
      "20372/20372 [==============================] - 2s 108us/step - loss: 0.1634 - val_loss: 0.1643\n",
      "Epoch 12/150\n",
      "20372/20372 [==============================] - 2s 104us/step - loss: 0.1629 - val_loss: 0.1629\n",
      "Epoch 13/150\n",
      "20372/20372 [==============================] - 2s 105us/step - loss: 0.1619 - val_loss: 0.1601\n",
      "Epoch 14/150\n",
      "20372/20372 [==============================] - 2s 91us/step - loss: 0.1581 - val_loss: 0.1618\n",
      "Epoch 15/150\n",
      "20372/20372 [==============================] - 1s 58us/step - loss: 0.1589 - val_loss: 0.1592\n",
      "Epoch 16/150\n",
      "20372/20372 [==============================] - 2s 90us/step - loss: 0.1571 - val_loss: 0.1547\n",
      "Epoch 17/150\n",
      "20372/20372 [==============================] - 2s 99us/step - loss: 0.1572 - val_loss: 0.1563\n",
      "Epoch 18/150\n",
      "20372/20372 [==============================] - 2s 103us/step - loss: 0.1563 - val_loss: 0.1610\n",
      "Epoch 19/150\n",
      "20372/20372 [==============================] - 2s 101us/step - loss: 0.1559 - val_loss: 0.1575\n",
      "Epoch 20/150\n",
      "20372/20372 [==============================] - 2s 101us/step - loss: 0.1564 - val_loss: 0.1564\n",
      "Evaluating model with testing data...\n",
      "4344/4344 [==============================] - 0s 16us/step\n",
      "Getting distribution of predictions and covariance matrix...\n",
      "      1 of 20\n",
      "      2 of 20\n",
      "      3 of 20\n",
      "      4 of 20\n",
      "      5 of 20\n",
      "      6 of 20\n",
      "      7 of 20\n",
      "      8 of 20\n",
      "      9 of 20\n",
      "      10 of 20\n",
      "      11 of 20\n",
      "      12 of 20\n",
      "      13 of 20\n",
      "      14 of 20\n",
      "      15 of 20\n",
      "      16 of 20\n",
      "      17 of 20\n",
      "      18 of 20\n",
      "      19 of 20\n",
      "      20 of 20\n",
      "Computing ensemble means...\n",
      "Computing mean squared error...\n",
      "Iteration 143\n",
      "Train on 20512 samples, validate on 4374 samples\n",
      "Epoch 1/150\n",
      "20512/20512 [==============================] - 2s 100us/step - loss: 0.4236 - val_loss: 0.3048\n",
      "Epoch 2/150\n",
      "20512/20512 [==============================] - 2s 98us/step - loss: 0.2769 - val_loss: 0.2571\n",
      "Epoch 3/150\n",
      "20512/20512 [==============================] - 2s 96us/step - loss: 0.2422 - val_loss: 0.2383\n",
      "Epoch 4/150\n",
      "20512/20512 [==============================] - 2s 102us/step - loss: 0.2240 - val_loss: 0.2239\n",
      "Epoch 5/150\n",
      "20512/20512 [==============================] - 2s 100us/step - loss: 0.2167 - val_loss: 0.2173\n",
      "Epoch 6/150\n",
      "20512/20512 [==============================] - 2s 102us/step - loss: 0.2090 - val_loss: 0.2091\n",
      "Epoch 7/150\n",
      "20512/20512 [==============================] - 2s 97us/step - loss: 0.2053 - val_loss: 0.2073\n",
      "Epoch 8/150\n",
      "20512/20512 [==============================] - 2s 101us/step - loss: 0.2008 - val_loss: 0.1983\n",
      "Epoch 9/150\n",
      "20512/20512 [==============================] - 2s 101us/step - loss: 0.1962 - val_loss: 0.1890\n",
      "Epoch 10/150\n",
      "20512/20512 [==============================] - 2s 98us/step - loss: 0.1879 - val_loss: 0.1882\n",
      "Epoch 11/150\n",
      "20512/20512 [==============================] - 2s 96us/step - loss: 0.1869 - val_loss: 0.1875\n",
      "Epoch 12/150\n",
      "20512/20512 [==============================] - 2s 110us/step - loss: 0.1854 - val_loss: 0.1858\n",
      "Epoch 13/150\n",
      "20512/20512 [==============================] - 2s 110us/step - loss: 0.1823 - val_loss: 0.1831\n",
      "Epoch 14/150\n",
      "20512/20512 [==============================] - 2s 114us/step - loss: 0.1818 - val_loss: 0.1845\n",
      "Epoch 15/150\n",
      "20512/20512 [==============================] - 2s 114us/step - loss: 0.1819 - val_loss: 0.1861\n",
      "Epoch 16/150\n",
      "20512/20512 [==============================] - 2s 110us/step - loss: 0.1820 - val_loss: 0.1836\n",
      "Epoch 17/150\n",
      "20512/20512 [==============================] - 2s 107us/step - loss: 0.1800 - val_loss: 0.1854\n",
      "Evaluating model with testing data...\n",
      "4374/4374 [==============================] - 0s 16us/step\n",
      "Getting distribution of predictions and covariance matrix...\n",
      "      1 of 20\n",
      "      2 of 20\n",
      "      3 of 20\n",
      "      4 of 20\n",
      "      5 of 20\n",
      "      6 of 20\n",
      "      7 of 20\n",
      "      8 of 20\n",
      "      9 of 20\n",
      "      10 of 20\n",
      "      11 of 20\n",
      "      12 of 20\n",
      "      13 of 20\n",
      "      14 of 20\n",
      "      15 of 20\n",
      "      16 of 20\n",
      "      17 of 20\n",
      "      18 of 20\n",
      "      19 of 20\n",
      "      20 of 20\n",
      "Computing ensemble means...\n",
      "Computing mean squared error...\n",
      "Iteration 144\n",
      "Train on 20652 samples, validate on 4404 samples\n",
      "Epoch 1/150\n",
      "20652/20652 [==============================] - 2s 110us/step - loss: 0.3824 - val_loss: 0.2430\n",
      "Epoch 2/150\n",
      "20652/20652 [==============================] - 2s 110us/step - loss: 0.2149 - val_loss: 0.1995\n",
      "Epoch 3/150\n",
      "20652/20652 [==============================] - 2s 114us/step - loss: 0.1875 - val_loss: 0.1818\n",
      "Epoch 4/150\n",
      "20652/20652 [==============================] - 2s 111us/step - loss: 0.1759 - val_loss: 0.1703\n",
      "Epoch 5/150\n",
      "20652/20652 [==============================] - 2s 107us/step - loss: 0.1658 - val_loss: 0.1634\n",
      "Epoch 6/150\n",
      "20652/20652 [==============================] - 2s 111us/step - loss: 0.1593 - val_loss: 0.1586\n",
      "Epoch 7/150\n",
      "20652/20652 [==============================] - 2s 109us/step - loss: 0.1566 - val_loss: 0.1511\n",
      "Epoch 8/150\n",
      "20652/20652 [==============================] - 2s 110us/step - loss: 0.1501 - val_loss: 0.1505\n",
      "Epoch 9/150\n",
      "20652/20652 [==============================] - 2s 112us/step - loss: 0.1486 - val_loss: 0.1535\n",
      "Epoch 10/150\n",
      "20652/20652 [==============================] - 2s 114us/step - loss: 0.1457 - val_loss: 0.1534\n",
      "Epoch 11/150\n",
      "20652/20652 [==============================] - 2s 108us/step - loss: 0.1460 - val_loss: 0.1466\n",
      "Epoch 12/150\n",
      "20652/20652 [==============================] - 2s 113us/step - loss: 0.1453 - val_loss: 0.1492\n",
      "Epoch 13/150\n",
      "20652/20652 [==============================] - 2s 107us/step - loss: 0.1432 - val_loss: 0.1431\n",
      "Epoch 14/150\n",
      "20652/20652 [==============================] - 2s 105us/step - loss: 0.1426 - val_loss: 0.1426\n",
      "Epoch 15/150\n",
      "20652/20652 [==============================] - 2s 110us/step - loss: 0.1415 - val_loss: 0.1464\n",
      "Epoch 16/150\n",
      "20652/20652 [==============================] - 2s 112us/step - loss: 0.1402 - val_loss: 0.1371\n",
      "Epoch 17/150\n",
      "20652/20652 [==============================] - 2s 106us/step - loss: 0.1395 - val_loss: 0.1408\n",
      "Epoch 18/150\n",
      "20652/20652 [==============================] - 2s 103us/step - loss: 0.1392 - val_loss: 0.1420\n",
      "Epoch 19/150\n",
      "20652/20652 [==============================] - 2s 108us/step - loss: 0.1385 - val_loss: 0.1381\n",
      "Epoch 20/150\n",
      "20652/20652 [==============================] - 2s 107us/step - loss: 0.1384 - val_loss: 0.1413\n",
      "Evaluating model with testing data...\n",
      "4404/4404 [==============================] - 0s 15us/step\n",
      "Getting distribution of predictions and covariance matrix...\n",
      "      1 of 20\n",
      "      2 of 20\n",
      "      3 of 20\n",
      "      4 of 20\n",
      "      5 of 20\n",
      "      6 of 20\n",
      "      7 of 20\n",
      "      8 of 20\n",
      "      9 of 20\n",
      "      10 of 20\n",
      "      11 of 20\n",
      "      12 of 20\n",
      "      13 of 20\n",
      "      14 of 20\n",
      "      15 of 20\n",
      "      16 of 20\n",
      "      17 of 20\n",
      "      18 of 20\n",
      "      19 of 20\n",
      "      20 of 20\n",
      "Computing ensemble means...\n",
      "Computing mean squared error...\n",
      "Iteration 145\n",
      "Train on 20792 samples, validate on 4434 samples\n",
      "Epoch 1/150\n",
      "20792/20792 [==============================] - 2s 110us/step - loss: 0.3821 - val_loss: 0.2592\n",
      "Epoch 2/150\n",
      "20792/20792 [==============================] - 2s 101us/step - loss: 0.2280 - val_loss: 0.2120\n",
      "Epoch 3/150\n",
      "20792/20792 [==============================] - 2s 108us/step - loss: 0.1966 - val_loss: 0.1870\n",
      "Epoch 4/150\n",
      "20792/20792 [==============================] - 2s 103us/step - loss: 0.1801 - val_loss: 0.1680\n",
      "Epoch 5/150\n",
      "20792/20792 [==============================] - 2s 104us/step - loss: 0.1679 - val_loss: 0.1677\n",
      "Epoch 6/150\n",
      "20792/20792 [==============================] - 2s 109us/step - loss: 0.1580 - val_loss: 0.1610\n",
      "Epoch 7/150\n",
      "20792/20792 [==============================] - 2s 103us/step - loss: 0.1528 - val_loss: 0.1506\n",
      "Epoch 8/150\n",
      "20792/20792 [==============================] - 2s 100us/step - loss: 0.1476 - val_loss: 0.1496\n",
      "Epoch 9/150\n",
      "20792/20792 [==============================] - 2s 94us/step - loss: 0.1451 - val_loss: 0.1508\n",
      "Epoch 10/150\n",
      "20792/20792 [==============================] - 1s 59us/step - loss: 0.1432 - val_loss: 0.1452\n",
      "Epoch 11/150\n",
      "20792/20792 [==============================] - 2s 93us/step - loss: 0.1410 - val_loss: 0.1416\n",
      "Epoch 12/150\n",
      "20792/20792 [==============================] - 2s 101us/step - loss: 0.1403 - val_loss: 0.1374\n",
      "Epoch 13/150\n",
      "20792/20792 [==============================] - 2s 106us/step - loss: 0.1365 - val_loss: 0.1362\n",
      "Epoch 14/150\n",
      "20792/20792 [==============================] - 2s 107us/step - loss: 0.1377 - val_loss: 0.1408\n",
      "Epoch 15/150\n",
      "20792/20792 [==============================] - 2s 102us/step - loss: 0.1365 - val_loss: 0.1385\n",
      "Epoch 16/150\n",
      "20792/20792 [==============================] - 2s 107us/step - loss: 0.1348 - val_loss: 0.1363\n",
      "Epoch 17/150\n",
      "20792/20792 [==============================] - 2s 98us/step - loss: 0.1348 - val_loss: 0.1331\n",
      "Epoch 18/150\n",
      "20792/20792 [==============================] - 2s 103us/step - loss: 0.1320 - val_loss: 0.1361\n",
      "Epoch 19/150\n",
      "20792/20792 [==============================] - 2s 101us/step - loss: 0.1317 - val_loss: 0.1304\n",
      "Epoch 20/150\n",
      "20792/20792 [==============================] - 2s 103us/step - loss: 0.1298 - val_loss: 0.1330\n",
      "Epoch 21/150\n",
      "20792/20792 [==============================] - 2s 101us/step - loss: 0.1292 - val_loss: 0.1339\n",
      "Epoch 22/150\n",
      "20792/20792 [==============================] - 2s 103us/step - loss: 0.1279 - val_loss: 0.1310\n",
      "Epoch 23/150\n",
      "20792/20792 [==============================] - 2s 102us/step - loss: 0.1268 - val_loss: 0.1294\n",
      "Epoch 24/150\n",
      "20792/20792 [==============================] - 2s 102us/step - loss: 0.1256 - val_loss: 0.1314\n",
      "Epoch 25/150\n",
      "20792/20792 [==============================] - 2s 104us/step - loss: 0.1252 - val_loss: 0.1240\n",
      "Epoch 26/150\n",
      "20792/20792 [==============================] - 2s 101us/step - loss: 0.1245 - val_loss: 0.1256\n",
      "Epoch 27/150\n",
      "20792/20792 [==============================] - 2s 96us/step - loss: 0.1233 - val_loss: 0.1241\n",
      "Epoch 28/150\n",
      "20792/20792 [==============================] - 2s 102us/step - loss: 0.1212 - val_loss: 0.1264\n",
      "Epoch 29/150\n",
      "20792/20792 [==============================] - 2s 104us/step - loss: 0.1203 - val_loss: 0.1221\n",
      "Epoch 30/150\n",
      "20792/20792 [==============================] - 2s 100us/step - loss: 0.1194 - val_loss: 0.1236\n",
      "Epoch 31/150\n",
      "20792/20792 [==============================] - 2s 100us/step - loss: 0.1181 - val_loss: 0.1230\n",
      "Epoch 32/150\n",
      "20792/20792 [==============================] - 2s 105us/step - loss: 0.1196 - val_loss: 0.1232\n",
      "Epoch 33/150\n",
      "20792/20792 [==============================] - 2s 100us/step - loss: 0.1175 - val_loss: 0.1194\n",
      "Epoch 34/150\n",
      "20792/20792 [==============================] - 2s 95us/step - loss: 0.1156 - val_loss: 0.1177\n",
      "Epoch 35/150\n",
      "20792/20792 [==============================] - 2s 99us/step - loss: 0.1166 - val_loss: 0.1213\n",
      "Epoch 36/150\n",
      "20792/20792 [==============================] - 2s 99us/step - loss: 0.1155 - val_loss: 0.1186\n",
      "Epoch 37/150\n",
      "20792/20792 [==============================] - 2s 102us/step - loss: 0.1151 - val_loss: 0.1193\n",
      "Epoch 38/150\n",
      "20792/20792 [==============================] - 2s 95us/step - loss: 0.1148 - val_loss: 0.1180\n",
      "Evaluating model with testing data...\n",
      "4434/4434 [==============================] - 0s 15us/step\n",
      "Getting distribution of predictions and covariance matrix...\n",
      "      1 of 20\n",
      "      2 of 20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      3 of 20\n",
      "      4 of 20\n",
      "      5 of 20\n",
      "      6 of 20\n",
      "      7 of 20\n",
      "      8 of 20\n",
      "      9 of 20\n",
      "      10 of 20\n",
      "      11 of 20\n",
      "      12 of 20\n",
      "      13 of 20\n",
      "      14 of 20\n",
      "      15 of 20\n",
      "      16 of 20\n",
      "      17 of 20\n",
      "      18 of 20\n",
      "      19 of 20\n",
      "      20 of 20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|          | 0/20 [00:00<?, ?it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing ensemble means...\n",
      "Computing mean squared error...\n",
      "Getting distribution of predictions...\n",
      "      1 of 20\n",
      "1600/1600 [==============================] - 0s 27us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  5%|▌         | 1/20 [00:29<09:14, 29.18s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      2 of 20\n",
      "1600/1600 [==============================] - 0s 30us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 10%|█         | 2/20 [00:58<08:45, 29.22s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      3 of 20\n",
      "1600/1600 [==============================] - 0s 28us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 15%|█▌        | 3/20 [01:27<08:17, 29.28s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      4 of 20\n",
      "1600/1600 [==============================] - 0s 29us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 20%|██        | 4/20 [01:57<07:50, 29.44s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      5 of 20\n",
      "1600/1600 [==============================] - 0s 29us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 25%|██▌       | 5/20 [02:27<07:22, 29.47s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      6 of 20\n",
      "1600/1600 [==============================] - 0s 33us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 30%|███       | 6/20 [02:56<06:53, 29.54s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      7 of 20\n",
      "1600/1600 [==============================] - 0s 30us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 35%|███▌      | 7/20 [03:26<06:22, 29.46s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      8 of 20\n",
      "1600/1600 [==============================] - 0s 29us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 40%|████      | 8/20 [03:55<05:53, 29.45s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      9 of 20\n",
      "1600/1600 [==============================] - 0s 30us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 45%|████▌     | 9/20 [04:25<05:24, 29.51s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      10 of 20\n",
      "1600/1600 [==============================] - 0s 28us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 50%|█████     | 10/20 [04:54<04:55, 29.52s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      11 of 20\n",
      "1600/1600 [==============================] - 0s 29us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 55%|█████▌    | 11/20 [05:24<04:24, 29.44s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      12 of 20\n",
      "1600/1600 [==============================] - 0s 29us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 60%|██████    | 12/20 [05:53<03:56, 29.57s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      13 of 20\n",
      "1600/1600 [==============================] - 0s 29us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 65%|██████▌   | 13/20 [06:23<03:26, 29.51s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      14 of 20\n",
      "1600/1600 [==============================] - 0s 29us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 70%|███████   | 14/20 [06:52<02:56, 29.47s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      15 of 20\n",
      "1600/1600 [==============================] - 0s 29us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 75%|███████▌  | 15/20 [07:21<02:26, 29.39s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      16 of 20\n",
      "1600/1600 [==============================] - 0s 28us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 80%|████████  | 16/20 [07:51<01:57, 29.47s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      17 of 20\n",
      "1600/1600 [==============================] - 0s 29us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 85%|████████▌ | 17/20 [08:21<01:28, 29.54s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      18 of 20\n",
      "1600/1600 [==============================] - 0s 29us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 90%|█████████ | 18/20 [08:50<00:59, 29.59s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      19 of 20\n",
      "1600/1600 [==============================] - 0s 29us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 95%|█████████▌| 19/20 [09:20<00:29, 29.49s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      20 of 20\n",
      "1600/1600 [==============================] - 0s 29us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 20/20 [09:50<00:00, 29.51s/it]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing ensemble predictions...\n",
      "Iteration 146\n",
      "Train on 20932 samples, validate on 4464 samples\n",
      "Epoch 1/150\n",
      "20932/20932 [==============================] - 2s 109us/step - loss: 0.4310 - val_loss: 0.3133\n",
      "Epoch 2/150\n",
      "20932/20932 [==============================] - 2s 111us/step - loss: 0.2832 - val_loss: 0.2629\n",
      "Epoch 3/150\n",
      "20932/20932 [==============================] - 2s 106us/step - loss: 0.2400 - val_loss: 0.2282\n",
      "Epoch 4/150\n",
      "20932/20932 [==============================] - 2s 112us/step - loss: 0.2183 - val_loss: 0.2109\n",
      "Epoch 5/150\n",
      "20932/20932 [==============================] - 2s 111us/step - loss: 0.2025 - val_loss: 0.2013\n",
      "Epoch 6/150\n",
      "20932/20932 [==============================] - 2s 108us/step - loss: 0.1959 - val_loss: 0.1966\n",
      "Epoch 7/150\n",
      "20932/20932 [==============================] - 2s 110us/step - loss: 0.1915 - val_loss: 0.1892\n",
      "Epoch 8/150\n",
      "20932/20932 [==============================] - 2s 109us/step - loss: 0.1899 - val_loss: 0.1855\n",
      "Epoch 9/150\n",
      "20932/20932 [==============================] - 2s 109us/step - loss: 0.1854 - val_loss: 0.1861\n",
      "Epoch 10/150\n",
      "20932/20932 [==============================] - 2s 110us/step - loss: 0.1773 - val_loss: 0.1758\n",
      "Epoch 11/150\n",
      "20932/20932 [==============================] - 2s 110us/step - loss: 0.1691 - val_loss: 0.1684\n",
      "Epoch 12/150\n",
      "20932/20932 [==============================] - 2s 112us/step - loss: 0.1648 - val_loss: 0.1631\n",
      "Epoch 13/150\n",
      "20932/20932 [==============================] - 2s 109us/step - loss: 0.1606 - val_loss: 0.1621\n",
      "Epoch 14/150\n",
      "20932/20932 [==============================] - 2s 109us/step - loss: 0.1573 - val_loss: 0.1600\n",
      "Epoch 15/150\n",
      "20932/20932 [==============================] - 2s 108us/step - loss: 0.1535 - val_loss: 0.1513\n",
      "Epoch 16/150\n",
      "20932/20932 [==============================] - 2s 110us/step - loss: 0.1492 - val_loss: 0.1528\n",
      "Epoch 17/150\n",
      "20932/20932 [==============================] - 2s 107us/step - loss: 0.1478 - val_loss: 0.1485\n",
      "Epoch 18/150\n",
      "20932/20932 [==============================] - 2s 109us/step - loss: 0.1461 - val_loss: 0.1470\n",
      "Epoch 19/150\n",
      "20932/20932 [==============================] - 2s 105us/step - loss: 0.1450 - val_loss: 0.1504\n",
      "Epoch 20/150\n",
      "20932/20932 [==============================] - 2s 111us/step - loss: 0.1444 - val_loss: 0.1456\n",
      "Epoch 21/150\n",
      "20932/20932 [==============================] - 2s 105us/step - loss: 0.1454 - val_loss: 0.1465\n",
      "Epoch 22/150\n",
      "20932/20932 [==============================] - 2s 109us/step - loss: 0.1444 - val_loss: 0.1439\n",
      "Epoch 23/150\n",
      "20932/20932 [==============================] - 2s 110us/step - loss: 0.1431 - val_loss: 0.1462\n",
      "Epoch 24/150\n",
      "20932/20932 [==============================] - 2s 109us/step - loss: 0.1412 - val_loss: 0.1439\n",
      "Epoch 25/150\n",
      "20932/20932 [==============================] - 2s 109us/step - loss: 0.1407 - val_loss: 0.1427\n",
      "Epoch 26/150\n",
      "20932/20932 [==============================] - 2s 106us/step - loss: 0.1416 - val_loss: 0.1393\n",
      "Epoch 27/150\n",
      "20932/20932 [==============================] - 2s 108us/step - loss: 0.1409 - val_loss: 0.1442\n",
      "Epoch 28/150\n",
      "20932/20932 [==============================] - 2s 107us/step - loss: 0.1391 - val_loss: 0.1411\n",
      "Epoch 29/150\n",
      "20932/20932 [==============================] - 2s 103us/step - loss: 0.1388 - val_loss: 0.1413\n",
      "Epoch 30/150\n",
      "20932/20932 [==============================] - 2s 76us/step - loss: 0.1378 - val_loss: 0.1428\n",
      "Evaluating model with testing data...\n",
      "4464/4464 [==============================] - 0s 16us/step\n",
      "Getting distribution of predictions and covariance matrix...\n",
      "      1 of 20\n",
      "      2 of 20\n",
      "      3 of 20\n",
      "      4 of 20\n",
      "      5 of 20\n",
      "      6 of 20\n",
      "      7 of 20\n",
      "      8 of 20\n",
      "      9 of 20\n",
      "      10 of 20\n",
      "      11 of 20\n",
      "      12 of 20\n",
      "      13 of 20\n",
      "      14 of 20\n",
      "      15 of 20\n",
      "      16 of 20\n",
      "      17 of 20\n",
      "      18 of 20\n",
      "      19 of 20\n",
      "      20 of 20\n",
      "Computing ensemble means...\n",
      "Computing mean squared error...\n",
      "Iteration 147\n",
      "Train on 21072 samples, validate on 4494 samples\n",
      "Epoch 1/150\n",
      "21072/21072 [==============================] - 2s 101us/step - loss: 0.4021 - val_loss: 0.2892\n",
      "Epoch 2/150\n",
      "21072/21072 [==============================] - 2s 106us/step - loss: 0.2577 - val_loss: 0.2388\n",
      "Epoch 3/150\n",
      "21072/21072 [==============================] - 2s 109us/step - loss: 0.2233 - val_loss: 0.2106\n",
      "Epoch 4/150\n",
      "21072/21072 [==============================] - 2s 104us/step - loss: 0.1978 - val_loss: 0.1918\n",
      "Epoch 5/150\n",
      "21072/21072 [==============================] - 2s 107us/step - loss: 0.1849 - val_loss: 0.1816\n",
      "Epoch 6/150\n",
      "21072/21072 [==============================] - 2s 102us/step - loss: 0.1772 - val_loss: 0.1770\n",
      "Epoch 7/150\n",
      "21072/21072 [==============================] - 2s 102us/step - loss: 0.1725 - val_loss: 0.1727\n",
      "Epoch 8/150\n",
      "21072/21072 [==============================] - 2s 105us/step - loss: 0.1682 - val_loss: 0.1615\n",
      "Epoch 9/150\n",
      "21072/21072 [==============================] - 2s 105us/step - loss: 0.1587 - val_loss: 0.1552\n",
      "Epoch 10/150\n",
      "21072/21072 [==============================] - 2s 106us/step - loss: 0.1541 - val_loss: 0.1545\n",
      "Epoch 11/150\n",
      "21072/21072 [==============================] - 2s 105us/step - loss: 0.1511 - val_loss: 0.1515\n",
      "Epoch 12/150\n",
      "21072/21072 [==============================] - 2s 105us/step - loss: 0.1489 - val_loss: 0.1490\n",
      "Epoch 13/150\n",
      "21072/21072 [==============================] - 2s 98us/step - loss: 0.1482 - val_loss: 0.1465\n",
      "Epoch 14/150\n",
      "21072/21072 [==============================] - 2s 105us/step - loss: 0.1459 - val_loss: 0.1430\n",
      "Epoch 15/150\n",
      "21072/21072 [==============================] - 2s 100us/step - loss: 0.1423 - val_loss: 0.1457\n",
      "Epoch 16/150\n",
      "21072/21072 [==============================] - 2s 104us/step - loss: 0.1409 - val_loss: 0.1460\n",
      "Epoch 17/150\n",
      "21072/21072 [==============================] - 2s 99us/step - loss: 0.1395 - val_loss: 0.1427\n",
      "Epoch 18/150\n",
      "21072/21072 [==============================] - 2s 102us/step - loss: 0.1399 - val_loss: 0.1415\n",
      "Epoch 19/150\n",
      "21072/21072 [==============================] - 2s 103us/step - loss: 0.1396 - val_loss: 0.1399\n",
      "Epoch 20/150\n",
      "21072/21072 [==============================] - 2s 104us/step - loss: 0.1397 - val_loss: 0.1422\n",
      "Epoch 21/150\n",
      "21072/21072 [==============================] - 2s 102us/step - loss: 0.1379 - val_loss: 0.1400\n",
      "Epoch 22/150\n",
      "21072/21072 [==============================] - 2s 103us/step - loss: 0.1359 - val_loss: 0.1356\n",
      "Epoch 23/150\n",
      "21072/21072 [==============================] - 2s 103us/step - loss: 0.1354 - val_loss: 0.1368\n",
      "Epoch 24/150\n",
      "21072/21072 [==============================] - 2s 100us/step - loss: 0.1344 - val_loss: 0.1378\n",
      "Epoch 25/150\n",
      "21072/21072 [==============================] - 2s 102us/step - loss: 0.1336 - val_loss: 0.1367\n",
      "Epoch 26/150\n",
      "21072/21072 [==============================] - 2s 98us/step - loss: 0.1345 - val_loss: 0.1347\n",
      "Epoch 27/150\n",
      "21072/21072 [==============================] - 2s 98us/step - loss: 0.1332 - val_loss: 0.1349\n",
      "Epoch 28/150\n",
      "21072/21072 [==============================] - 2s 100us/step - loss: 0.1325 - val_loss: 0.1343\n",
      "Epoch 29/150\n",
      "21072/21072 [==============================] - 2s 99us/step - loss: 0.1339 - val_loss: 0.1369\n",
      "Epoch 30/150\n",
      "21072/21072 [==============================] - 2s 101us/step - loss: 0.1317 - val_loss: 0.1350\n",
      "Epoch 31/150\n",
      "21072/21072 [==============================] - 2s 103us/step - loss: 0.1310 - val_loss: 0.1324\n",
      "Epoch 32/150\n",
      "21072/21072 [==============================] - 2s 101us/step - loss: 0.1312 - val_loss: 0.1330\n",
      "Epoch 33/150\n",
      "21072/21072 [==============================] - 2s 97us/step - loss: 0.1302 - val_loss: 0.1306\n",
      "Epoch 34/150\n",
      "21072/21072 [==============================] - 2s 92us/step - loss: 0.1309 - val_loss: 0.1309\n",
      "Epoch 35/150\n",
      "21072/21072 [==============================] - 2s 98us/step - loss: 0.1302 - val_loss: 0.1321\n",
      "Epoch 36/150\n",
      "21072/21072 [==============================] - 2s 98us/step - loss: 0.1312 - val_loss: 0.1288\n",
      "Epoch 37/150\n",
      "21072/21072 [==============================] - 2s 99us/step - loss: 0.1295 - val_loss: 0.1290\n",
      "Epoch 38/150\n",
      "21072/21072 [==============================] - 2s 94us/step - loss: 0.1283 - val_loss: 0.1316\n",
      "Epoch 39/150\n",
      "21072/21072 [==============================] - 2s 96us/step - loss: 0.1293 - val_loss: 0.1288\n",
      "Epoch 40/150\n",
      "21072/21072 [==============================] - 2s 100us/step - loss: 0.1297 - val_loss: 0.1292\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 41/150\n",
      "21072/21072 [==============================] - 2s 112us/step - loss: 0.1288 - val_loss: 0.1297\n",
      "Epoch 42/150\n",
      "21072/21072 [==============================] - 2s 110us/step - loss: 0.1272 - val_loss: 0.1275\n",
      "Epoch 43/150\n",
      "21072/21072 [==============================] - 2s 111us/step - loss: 0.1273 - val_loss: 0.1286\n",
      "Epoch 44/150\n",
      "21072/21072 [==============================] - 2s 110us/step - loss: 0.1272 - val_loss: 0.1305\n",
      "Epoch 45/150\n",
      "21072/21072 [==============================] - 2s 112us/step - loss: 0.1265 - val_loss: 0.1264\n",
      "Epoch 46/150\n",
      "21072/21072 [==============================] - 2s 109us/step - loss: 0.1268 - val_loss: 0.1300\n",
      "Epoch 47/150\n",
      "21072/21072 [==============================] - 2s 111us/step - loss: 0.1267 - val_loss: 0.1315\n",
      "Epoch 48/150\n",
      "21072/21072 [==============================] - 2s 109us/step - loss: 0.1264 - val_loss: 0.1285\n",
      "Epoch 49/150\n",
      "21072/21072 [==============================] - 2s 108us/step - loss: 0.1269 - val_loss: 0.1293\n",
      "Evaluating model with testing data...\n",
      "4494/4494 [==============================] - 0s 15us/step\n",
      "Getting distribution of predictions and covariance matrix...\n",
      "      1 of 20\n",
      "      2 of 20\n",
      "      3 of 20\n",
      "      4 of 20\n",
      "      5 of 20\n",
      "      6 of 20\n",
      "      7 of 20\n",
      "      8 of 20\n",
      "      9 of 20\n",
      "      10 of 20\n",
      "      11 of 20\n",
      "      12 of 20\n",
      "      13 of 20\n",
      "      14 of 20\n",
      "      15 of 20\n",
      "      16 of 20\n",
      "      17 of 20\n",
      "      18 of 20\n",
      "      19 of 20\n",
      "      20 of 20\n",
      "Computing ensemble means...\n",
      "Computing mean squared error...\n",
      "Iteration 148\n",
      "Train on 21212 samples, validate on 4524 samples\n",
      "Epoch 1/150\n",
      "21212/21212 [==============================] - 2s 108us/step - loss: 0.4077 - val_loss: 0.2993\n",
      "Epoch 2/150\n",
      "21212/21212 [==============================] - 2s 106us/step - loss: 0.2685 - val_loss: 0.2521\n",
      "Epoch 3/150\n",
      "21212/21212 [==============================] - 2s 112us/step - loss: 0.2325 - val_loss: 0.2154\n",
      "Epoch 4/150\n",
      "21212/21212 [==============================] - 1s 69us/step - loss: 0.2015 - val_loss: 0.1933\n",
      "Epoch 5/150\n",
      "21212/21212 [==============================] - 2s 82us/step - loss: 0.1803 - val_loss: 0.1701\n",
      "Epoch 6/150\n",
      "21212/21212 [==============================] - 2s 104us/step - loss: 0.1690 - val_loss: 0.1657\n",
      "Epoch 7/150\n",
      "21212/21212 [==============================] - 2s 106us/step - loss: 0.1632 - val_loss: 0.1655\n",
      "Epoch 8/150\n",
      "21212/21212 [==============================] - 2s 110us/step - loss: 0.1601 - val_loss: 0.1590\n",
      "Epoch 9/150\n",
      "21212/21212 [==============================] - 2s 109us/step - loss: 0.1554 - val_loss: 0.1535\n",
      "Epoch 10/150\n",
      "21212/21212 [==============================] - 2s 111us/step - loss: 0.1515 - val_loss: 0.1511\n",
      "Epoch 11/150\n",
      "21212/21212 [==============================] - 2s 100us/step - loss: 0.1496 - val_loss: 0.1504\n",
      "Epoch 12/150\n",
      "21212/21212 [==============================] - 2s 110us/step - loss: 0.1488 - val_loss: 0.1493\n",
      "Epoch 13/150\n",
      "21212/21212 [==============================] - 2s 112us/step - loss: 0.1467 - val_loss: 0.1498\n",
      "Epoch 14/150\n",
      "21212/21212 [==============================] - 2s 113us/step - loss: 0.1452 - val_loss: 0.1439\n",
      "Epoch 15/150\n",
      "21212/21212 [==============================] - 2s 105us/step - loss: 0.1409 - val_loss: 0.1414\n",
      "Epoch 16/150\n",
      "21212/21212 [==============================] - 2s 110us/step - loss: 0.1396 - val_loss: 0.1398\n",
      "Epoch 17/150\n",
      "21212/21212 [==============================] - 2s 106us/step - loss: 0.1387 - val_loss: 0.1389\n",
      "Epoch 18/150\n",
      "21212/21212 [==============================] - 2s 104us/step - loss: 0.1394 - val_loss: 0.1411\n",
      "Epoch 19/150\n",
      "21212/21212 [==============================] - 2s 106us/step - loss: 0.1376 - val_loss: 0.1383\n",
      "Epoch 20/150\n",
      "21212/21212 [==============================] - 2s 107us/step - loss: 0.1364 - val_loss: 0.1381\n",
      "Epoch 21/150\n",
      "21212/21212 [==============================] - 2s 107us/step - loss: 0.1357 - val_loss: 0.1378\n",
      "Epoch 22/150\n",
      "21212/21212 [==============================] - 2s 106us/step - loss: 0.1352 - val_loss: 0.1375\n",
      "Epoch 23/150\n",
      "21212/21212 [==============================] - 2s 104us/step - loss: 0.1341 - val_loss: 0.1338\n",
      "Epoch 24/150\n",
      "21212/21212 [==============================] - 2s 107us/step - loss: 0.1333 - val_loss: 0.1345\n",
      "Epoch 25/150\n",
      "21212/21212 [==============================] - 2s 102us/step - loss: 0.1309 - val_loss: 0.1317\n",
      "Epoch 26/150\n",
      "21212/21212 [==============================] - 2s 104us/step - loss: 0.1297 - val_loss: 0.1332\n",
      "Epoch 27/150\n",
      "21212/21212 [==============================] - 2s 105us/step - loss: 0.1278 - val_loss: 0.1266\n",
      "Epoch 28/150\n",
      "21212/21212 [==============================] - 2s 108us/step - loss: 0.1262 - val_loss: 0.1275\n",
      "Epoch 29/150\n",
      "21212/21212 [==============================] - 2s 108us/step - loss: 0.1215 - val_loss: 0.1218\n",
      "Epoch 30/150\n",
      "21212/21212 [==============================] - 2s 103us/step - loss: 0.1207 - val_loss: 0.1185\n",
      "Epoch 31/150\n",
      "21212/21212 [==============================] - 2s 105us/step - loss: 0.1197 - val_loss: 0.1203\n",
      "Epoch 32/150\n",
      "21212/21212 [==============================] - 2s 100us/step - loss: 0.1175 - val_loss: 0.1182\n",
      "Epoch 33/150\n",
      "21212/21212 [==============================] - 2s 106us/step - loss: 0.1171 - val_loss: 0.1165\n",
      "Epoch 34/150\n",
      "21212/21212 [==============================] - 2s 95us/step - loss: 0.1159 - val_loss: 0.1165\n",
      "Epoch 35/150\n",
      "21212/21212 [==============================] - 2s 105us/step - loss: 0.1138 - val_loss: 0.1156\n",
      "Epoch 36/150\n",
      "21212/21212 [==============================] - 2s 106us/step - loss: 0.1122 - val_loss: 0.1132\n",
      "Epoch 37/150\n",
      "21212/21212 [==============================] - 2s 104us/step - loss: 0.1122 - val_loss: 0.1130\n",
      "Epoch 38/150\n",
      "21212/21212 [==============================] - 2s 107us/step - loss: 0.1115 - val_loss: 0.1128\n",
      "Epoch 39/150\n",
      "21212/21212 [==============================] - 2s 99us/step - loss: 0.1112 - val_loss: 0.1109\n",
      "Epoch 40/150\n",
      "21212/21212 [==============================] - 2s 100us/step - loss: 0.1117 - val_loss: 0.1123\n",
      "Epoch 41/150\n",
      "21212/21212 [==============================] - 2s 102us/step - loss: 0.1088 - val_loss: 0.1129\n",
      "Epoch 42/150\n",
      "21212/21212 [==============================] - 2s 106us/step - loss: 0.1102 - val_loss: 0.1092\n",
      "Epoch 43/150\n",
      "21212/21212 [==============================] - 2s 102us/step - loss: 0.1094 - val_loss: 0.1126\n",
      "Epoch 44/150\n",
      "21212/21212 [==============================] - 2s 102us/step - loss: 0.1081 - val_loss: 0.1107\n",
      "Epoch 45/150\n",
      "21212/21212 [==============================] - 2s 99us/step - loss: 0.1077 - val_loss: 0.1100\n",
      "Epoch 46/150\n",
      "21212/21212 [==============================] - 2s 104us/step - loss: 0.1088 - val_loss: 0.1134\n",
      "Evaluating model with testing data...\n",
      "4524/4524 [==============================] - 0s 15us/step\n",
      "Getting distribution of predictions and covariance matrix...\n",
      "      1 of 20\n",
      "      2 of 20\n",
      "      3 of 20\n",
      "      4 of 20\n",
      "      5 of 20\n",
      "      6 of 20\n",
      "      7 of 20\n",
      "      8 of 20\n",
      "      9 of 20\n",
      "      10 of 20\n",
      "      11 of 20\n",
      "      12 of 20\n",
      "      13 of 20\n",
      "      14 of 20\n",
      "      15 of 20\n",
      "      16 of 20\n",
      "      17 of 20\n",
      "      18 of 20\n",
      "      19 of 20\n",
      "      20 of 20\n",
      "Computing ensemble means...\n",
      "Computing mean squared error...\n",
      "Iteration 149\n",
      "Train on 21352 samples, validate on 4554 samples\n",
      "Epoch 1/150\n",
      "21352/21352 [==============================] - 2s 103us/step - loss: 0.4075 - val_loss: 0.3108\n",
      "Epoch 2/150\n",
      "21352/21352 [==============================] - 2s 100us/step - loss: 0.2896 - val_loss: 0.2747\n",
      "Epoch 3/150\n",
      "21352/21352 [==============================] - 2s 101us/step - loss: 0.2522 - val_loss: 0.2364\n",
      "Epoch 4/150\n",
      "21352/21352 [==============================] - 2s 95us/step - loss: 0.2252 - val_loss: 0.2147\n",
      "Epoch 5/150\n",
      "21352/21352 [==============================] - 2s 97us/step - loss: 0.2066 - val_loss: 0.1980\n",
      "Epoch 6/150\n",
      "21352/21352 [==============================] - 2s 98us/step - loss: 0.1871 - val_loss: 0.1797\n",
      "Epoch 7/150\n",
      "21352/21352 [==============================] - 2s 101us/step - loss: 0.1768 - val_loss: 0.1782\n",
      "Epoch 8/150\n",
      "21352/21352 [==============================] - 2s 97us/step - loss: 0.1756 - val_loss: 0.1783\n",
      "Epoch 9/150\n",
      "21352/21352 [==============================] - 2s 97us/step - loss: 0.1727 - val_loss: 0.1697\n",
      "Epoch 10/150\n",
      "21352/21352 [==============================] - 2s 99us/step - loss: 0.1703 - val_loss: 0.1742\n",
      "Epoch 11/150\n",
      "21352/21352 [==============================] - 2s 96us/step - loss: 0.1700 - val_loss: 0.1710\n",
      "Epoch 12/150\n",
      "21352/21352 [==============================] - 1s 60us/step - loss: 0.1683 - val_loss: 0.1665\n",
      "Epoch 13/150\n",
      "21352/21352 [==============================] - 2s 106us/step - loss: 0.1677 - val_loss: 0.1721\n",
      "Epoch 14/150\n",
      "21352/21352 [==============================] - 2s 109us/step - loss: 0.1662 - val_loss: 0.1714\n",
      "Epoch 15/150\n",
      "21352/21352 [==============================] - 2s 111us/step - loss: 0.1670 - val_loss: 0.1685\n",
      "Epoch 16/150\n",
      "21352/21352 [==============================] - 2s 111us/step - loss: 0.1651 - val_loss: 0.1697\n",
      "Evaluating model with testing data...\n",
      "4554/4554 [==============================] - 0s 16us/step\n",
      "Getting distribution of predictions and covariance matrix...\n",
      "      1 of 20\n",
      "      2 of 20\n",
      "      3 of 20\n",
      "      4 of 20\n",
      "      5 of 20\n",
      "      6 of 20\n",
      "      7 of 20\n",
      "      8 of 20\n",
      "      9 of 20\n",
      "      10 of 20\n",
      "      11 of 20\n",
      "      12 of 20\n",
      "      13 of 20\n",
      "      14 of 20\n",
      "      15 of 20\n",
      "      16 of 20\n",
      "      17 of 20\n",
      "      18 of 20\n",
      "      19 of 20\n",
      "      20 of 20\n",
      "Computing ensemble means...\n",
      "Computing mean squared error...\n",
      "Iteration 150\n",
      "Train on 21492 samples, validate on 4584 samples\n",
      "Epoch 1/150\n",
      "21492/21492 [==============================] - 2s 108us/step - loss: 0.4110 - val_loss: 0.2603\n",
      "Epoch 2/150\n",
      "21492/21492 [==============================] - 2s 107us/step - loss: 0.2364 - val_loss: 0.2232\n",
      "Epoch 3/150\n",
      "21492/21492 [==============================] - 2s 110us/step - loss: 0.2137 - val_loss: 0.2072\n",
      "Epoch 4/150\n",
      "21492/21492 [==============================] - 2s 111us/step - loss: 0.1964 - val_loss: 0.1950\n",
      "Epoch 5/150\n",
      "21492/21492 [==============================] - 2s 110us/step - loss: 0.1856 - val_loss: 0.1806\n",
      "Epoch 6/150\n",
      "21492/21492 [==============================] - 2s 111us/step - loss: 0.1767 - val_loss: 0.1742\n",
      "Epoch 7/150\n",
      "21492/21492 [==============================] - 2s 111us/step - loss: 0.1695 - val_loss: 0.1711\n",
      "Epoch 8/150\n",
      "21492/21492 [==============================] - 2s 112us/step - loss: 0.1654 - val_loss: 0.1653\n",
      "Epoch 9/150\n",
      "21492/21492 [==============================] - 2s 110us/step - loss: 0.1649 - val_loss: 0.1673\n",
      "Epoch 10/150\n",
      "21492/21492 [==============================] - 2s 112us/step - loss: 0.1615 - val_loss: 0.1605\n",
      "Epoch 11/150\n",
      "21492/21492 [==============================] - 2s 109us/step - loss: 0.1595 - val_loss: 0.1569\n",
      "Epoch 12/150\n",
      "21492/21492 [==============================] - 2s 105us/step - loss: 0.1559 - val_loss: 0.1585\n",
      "Epoch 13/150\n",
      "21492/21492 [==============================] - 2s 108us/step - loss: 0.1543 - val_loss: 0.1551\n",
      "Epoch 14/150\n",
      "21492/21492 [==============================] - 2s 110us/step - loss: 0.1520 - val_loss: 0.1478\n",
      "Epoch 15/150\n",
      "21492/21492 [==============================] - 2s 107us/step - loss: 0.1516 - val_loss: 0.1529\n",
      "Epoch 16/150\n",
      "21492/21492 [==============================] - 2s 111us/step - loss: 0.1517 - val_loss: 0.1522\n",
      "Epoch 17/150\n",
      "21492/21492 [==============================] - 2s 111us/step - loss: 0.1502 - val_loss: 0.1506\n",
      "Epoch 18/150\n",
      "21492/21492 [==============================] - 2s 111us/step - loss: 0.1491 - val_loss: 0.1484\n",
      "Evaluating model with testing data...\n",
      "4584/4584 [==============================] - 0s 15us/step\n",
      "Getting distribution of predictions and covariance matrix...\n",
      "      1 of 20\n",
      "      2 of 20\n",
      "      3 of 20\n",
      "      4 of 20\n",
      "      5 of 20\n",
      "      6 of 20\n",
      "      7 of 20\n",
      "      8 of 20\n",
      "      9 of 20\n",
      "      10 of 20\n",
      "      11 of 20\n",
      "      12 of 20\n",
      "      13 of 20\n",
      "      14 of 20\n",
      "      15 of 20\n",
      "      16 of 20\n",
      "      17 of 20\n",
      "      18 of 20\n",
      "      19 of 20\n",
      "      20 of 20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|          | 0/20 [00:00<?, ?it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing ensemble means...\n",
      "Computing mean squared error...\n",
      "Getting distribution of predictions...\n",
      "      1 of 20\n",
      "1600/1600 [==============================] - 0s 27us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  5%|▌         | 1/20 [00:29<09:17, 29.34s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      2 of 20\n",
      "1600/1600 [==============================] - 0s 29us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 10%|█         | 2/20 [00:58<08:49, 29.39s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      3 of 20\n",
      "1600/1600 [==============================] - 0s 29us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 15%|█▌        | 3/20 [01:28<08:19, 29.36s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      4 of 20\n",
      "1600/1600 [==============================] - 0s 29us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 20%|██        | 4/20 [01:57<07:52, 29.50s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      5 of 20\n",
      "1600/1600 [==============================] - 0s 32us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 25%|██▌       | 5/20 [02:27<07:23, 29.57s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      6 of 20\n",
      "1600/1600 [==============================] - 0s 29us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 30%|███       | 6/20 [02:57<06:54, 29.59s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      7 of 20\n",
      "1600/1600 [==============================] - 0s 30us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 35%|███▌      | 7/20 [03:26<06:23, 29.49s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      8 of 20\n",
      "1600/1600 [==============================] - 0s 28us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 40%|████      | 8/20 [03:56<05:54, 29.58s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      9 of 20\n",
      "1600/1600 [==============================] - 0s 30us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 45%|████▌     | 9/20 [04:25<05:25, 29.57s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      10 of 20\n",
      "1600/1600 [==============================] - 0s 29us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 50%|█████     | 10/20 [04:55<04:57, 29.71s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      11 of 20\n",
      "1600/1600 [==============================] - 0s 30us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 55%|█████▌    | 11/20 [05:25<04:26, 29.63s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      12 of 20\n",
      "1600/1600 [==============================] - 0s 29us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 60%|██████    | 12/20 [05:55<03:57, 29.65s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      13 of 20\n",
      "1600/1600 [==============================] - 0s 29us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 65%|██████▌   | 13/20 [06:24<03:27, 29.66s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      14 of 20\n",
      "1600/1600 [==============================] - 0s 29us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 70%|███████   | 14/20 [06:54<02:57, 29.54s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      15 of 20\n",
      "1600/1600 [==============================] - 0s 29us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 75%|███████▌  | 15/20 [07:23<02:27, 29.51s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      16 of 20\n",
      "1600/1600 [==============================] - 0s 29us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 80%|████████  | 16/20 [07:53<01:58, 29.62s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      17 of 20\n",
      "1600/1600 [==============================] - 0s 29us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 85%|████████▌ | 17/20 [08:23<01:28, 29.66s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      18 of 20\n",
      "1600/1600 [==============================] - 0s 30us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 90%|█████████ | 18/20 [08:52<00:59, 29.68s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      19 of 20\n",
      "1600/1600 [==============================] - 0s 30us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 95%|█████████▌| 19/20 [09:22<00:29, 29.53s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      20 of 20\n",
      "1600/1600 [==============================] - 0s 29us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 20/20 [09:51<00:00, 29.58s/it]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing ensemble predictions...\n",
      "Iteration 151\n",
      "Train on 21632 samples, validate on 4614 samples\n",
      "Epoch 1/150\n",
      "21632/21632 [==============================] - 2s 105us/step - loss: 0.3644 - val_loss: 0.2419\n",
      "Epoch 2/150\n",
      "21632/21632 [==============================] - 2s 110us/step - loss: 0.2135 - val_loss: 0.1982\n",
      "Epoch 3/150\n",
      "21632/21632 [==============================] - 2s 106us/step - loss: 0.1863 - val_loss: 0.1816\n",
      "Epoch 4/150\n",
      "21632/21632 [==============================] - 2s 111us/step - loss: 0.1713 - val_loss: 0.1651\n",
      "Epoch 5/150\n",
      "21632/21632 [==============================] - 2s 112us/step - loss: 0.1611 - val_loss: 0.1565\n",
      "Epoch 6/150\n",
      "21632/21632 [==============================] - 2s 113us/step - loss: 0.1550 - val_loss: 0.1510\n",
      "Epoch 7/150\n",
      "21632/21632 [==============================] - 2s 106us/step - loss: 0.1493 - val_loss: 0.1489\n",
      "Epoch 8/150\n",
      "21632/21632 [==============================] - 2s 107us/step - loss: 0.1446 - val_loss: 0.1442\n",
      "Epoch 9/150\n",
      "21632/21632 [==============================] - 2s 112us/step - loss: 0.1446 - val_loss: 0.1454\n",
      "Epoch 10/150\n",
      "21632/21632 [==============================] - 2s 107us/step - loss: 0.1422 - val_loss: 0.1459\n",
      "Epoch 11/150\n",
      "21632/21632 [==============================] - 2s 108us/step - loss: 0.1393 - val_loss: 0.1430\n",
      "Epoch 12/150\n",
      "21632/21632 [==============================] - 2s 108us/step - loss: 0.1405 - val_loss: 0.1419\n",
      "Epoch 13/150\n",
      "21632/21632 [==============================] - 2s 108us/step - loss: 0.1367 - val_loss: 0.1342\n",
      "Epoch 14/150\n",
      "21632/21632 [==============================] - 2s 110us/step - loss: 0.1373 - val_loss: 0.1384\n",
      "Epoch 15/150\n",
      "21632/21632 [==============================] - 2s 111us/step - loss: 0.1348 - val_loss: 0.1357\n",
      "Epoch 16/150\n",
      "21632/21632 [==============================] - 2s 112us/step - loss: 0.1348 - val_loss: 0.1382\n",
      "Epoch 17/150\n",
      "21632/21632 [==============================] - 2s 110us/step - loss: 0.1341 - val_loss: 0.1354\n",
      "Evaluating model with testing data...\n",
      "4614/4614 [==============================] - 0s 16us/step\n",
      "Getting distribution of predictions and covariance matrix...\n",
      "      1 of 20\n",
      "      2 of 20\n",
      "      3 of 20\n",
      "      4 of 20\n",
      "      5 of 20\n",
      "      6 of 20\n",
      "      7 of 20\n",
      "      8 of 20\n",
      "      9 of 20\n",
      "      10 of 20\n",
      "      11 of 20\n",
      "      12 of 20\n",
      "      13 of 20\n",
      "      14 of 20\n",
      "      15 of 20\n",
      "      16 of 20\n",
      "      17 of 20\n",
      "      18 of 20\n",
      "      19 of 20\n",
      "      20 of 20\n",
      "Computing ensemble means...\n",
      "Computing mean squared error...\n",
      "Iteration 152\n",
      "Train on 21772 samples, validate on 4644 samples\n",
      "Epoch 1/150\n",
      "21772/21772 [==============================] - 2s 103us/step - loss: 0.3563 - val_loss: 0.2399\n",
      "Epoch 2/150\n",
      "21772/21772 [==============================] - 2s 104us/step - loss: 0.2116 - val_loss: 0.1980\n",
      "Epoch 3/150\n",
      "21772/21772 [==============================] - 2s 107us/step - loss: 0.1850 - val_loss: 0.1817\n",
      "Epoch 4/150\n",
      "21772/21772 [==============================] - 2s 105us/step - loss: 0.1705 - val_loss: 0.1654\n",
      "Epoch 5/150\n",
      "21772/21772 [==============================] - 2s 105us/step - loss: 0.1595 - val_loss: 0.1579\n",
      "Epoch 6/150\n",
      "21772/21772 [==============================] - 2s 108us/step - loss: 0.1532 - val_loss: 0.1507\n",
      "Epoch 7/150\n",
      "21772/21772 [==============================] - 2s 103us/step - loss: 0.1499 - val_loss: 0.1474\n",
      "Epoch 8/150\n",
      "21772/21772 [==============================] - 2s 109us/step - loss: 0.1449 - val_loss: 0.1446\n",
      "Epoch 9/150\n",
      "21772/21772 [==============================] - 2s 106us/step - loss: 0.1420 - val_loss: 0.1404\n",
      "Epoch 10/150\n",
      "21772/21772 [==============================] - 2s 96us/step - loss: 0.1399 - val_loss: 0.1401\n",
      "Epoch 11/150\n",
      "21772/21772 [==============================] - 2s 105us/step - loss: 0.1368 - val_loss: 0.1379\n",
      "Epoch 12/150\n",
      "21772/21772 [==============================] - 2s 83us/step - loss: 0.1341 - val_loss: 0.1376\n",
      "Epoch 13/150\n",
      "21772/21772 [==============================] - 1s 67us/step - loss: 0.1333 - val_loss: 0.1311\n",
      "Epoch 14/150\n",
      "21772/21772 [==============================] - 2s 101us/step - loss: 0.1308 - val_loss: 0.1336\n",
      "Epoch 15/150\n",
      "21772/21772 [==============================] - 2s 104us/step - loss: 0.1302 - val_loss: 0.1341\n",
      "Epoch 16/150\n",
      "21772/21772 [==============================] - 2s 103us/step - loss: 0.1289 - val_loss: 0.1268\n",
      "Epoch 17/150\n",
      "21772/21772 [==============================] - 2s 104us/step - loss: 0.1252 - val_loss: 0.1292\n",
      "Epoch 18/150\n",
      "21772/21772 [==============================] - 2s 106us/step - loss: 0.1254 - val_loss: 0.1272\n",
      "Epoch 19/150\n",
      "21772/21772 [==============================] - 2s 106us/step - loss: 0.1243 - val_loss: 0.1216\n",
      "Epoch 20/150\n",
      "21772/21772 [==============================] - 2s 110us/step - loss: 0.1219 - val_loss: 0.1240\n",
      "Epoch 21/150\n",
      "21772/21772 [==============================] - 2s 106us/step - loss: 0.1208 - val_loss: 0.1246\n",
      "Epoch 22/150\n",
      "21772/21772 [==============================] - 2s 105us/step - loss: 0.1191 - val_loss: 0.1224\n",
      "Epoch 23/150\n",
      "21772/21772 [==============================] - 2s 100us/step - loss: 0.1194 - val_loss: 0.1231\n",
      "Evaluating model with testing data...\n",
      "4644/4644 [==============================] - 0s 16us/step\n",
      "Getting distribution of predictions and covariance matrix...\n",
      "      1 of 20\n",
      "      2 of 20\n",
      "      3 of 20\n",
      "      4 of 20\n",
      "      5 of 20\n",
      "      6 of 20\n",
      "      7 of 20\n",
      "      8 of 20\n",
      "      9 of 20\n",
      "      10 of 20\n",
      "      11 of 20\n",
      "      12 of 20\n",
      "      13 of 20\n",
      "      14 of 20\n",
      "      15 of 20\n",
      "      16 of 20\n",
      "      17 of 20\n",
      "      18 of 20\n",
      "      19 of 20\n",
      "      20 of 20\n",
      "Computing ensemble means...\n",
      "Computing mean squared error...\n",
      "Iteration 153\n",
      "Train on 21912 samples, validate on 4674 samples\n",
      "Epoch 1/150\n",
      "21912/21912 [==============================] - 2s 104us/step - loss: 0.4162 - val_loss: 0.2967\n",
      "Epoch 2/150\n",
      "21912/21912 [==============================] - 2s 101us/step - loss: 0.2606 - val_loss: 0.2400\n",
      "Epoch 3/150\n",
      "21912/21912 [==============================] - 2s 100us/step - loss: 0.2258 - val_loss: 0.2177\n",
      "Epoch 4/150\n",
      "21912/21912 [==============================] - 2s 102us/step - loss: 0.2074 - val_loss: 0.2020\n",
      "Epoch 5/150\n",
      "21912/21912 [==============================] - 2s 100us/step - loss: 0.1904 - val_loss: 0.1922\n",
      "Epoch 6/150\n",
      "21912/21912 [==============================] - 2s 98us/step - loss: 0.1848 - val_loss: 0.1875\n",
      "Epoch 7/150\n",
      "21912/21912 [==============================] - 2s 97us/step - loss: 0.1822 - val_loss: 0.1894\n",
      "Epoch 8/150\n",
      "21912/21912 [==============================] - 2s 102us/step - loss: 0.1797 - val_loss: 0.1799\n",
      "Epoch 9/150\n",
      "21912/21912 [==============================] - 2s 104us/step - loss: 0.1766 - val_loss: 0.1797\n",
      "Epoch 10/150\n",
      "21912/21912 [==============================] - 2s 94us/step - loss: 0.1747 - val_loss: 0.1756\n",
      "Epoch 11/150\n",
      "21912/21912 [==============================] - 2s 97us/step - loss: 0.1688 - val_loss: 0.1701\n",
      "Epoch 12/150\n",
      "21912/21912 [==============================] - 2s 98us/step - loss: 0.1632 - val_loss: 0.1637\n",
      "Epoch 13/150\n",
      "21912/21912 [==============================] - 2s 99us/step - loss: 0.1631 - val_loss: 0.1634\n",
      "Epoch 14/150\n",
      "21912/21912 [==============================] - 2s 97us/step - loss: 0.1616 - val_loss: 0.1624\n",
      "Epoch 15/150\n",
      "21912/21912 [==============================] - 2s 102us/step - loss: 0.1607 - val_loss: 0.1620\n",
      "Epoch 16/150\n",
      "21912/21912 [==============================] - 2s 100us/step - loss: 0.1594 - val_loss: 0.1577\n",
      "Epoch 17/150\n",
      "21912/21912 [==============================] - 2s 96us/step - loss: 0.1529 - val_loss: 0.1570\n",
      "Epoch 18/150\n",
      "21912/21912 [==============================] - 2s 100us/step - loss: 0.1495 - val_loss: 0.1534\n",
      "Epoch 19/150\n",
      "21912/21912 [==============================] - 2s 98us/step - loss: 0.1471 - val_loss: 0.1498\n",
      "Epoch 20/150\n",
      "21912/21912 [==============================] - 2s 100us/step - loss: 0.1457 - val_loss: 0.1507\n",
      "Epoch 21/150\n",
      "21912/21912 [==============================] - 2s 96us/step - loss: 0.1445 - val_loss: 0.1492\n",
      "Epoch 22/150\n",
      "21912/21912 [==============================] - 2s 100us/step - loss: 0.1441 - val_loss: 0.1439\n",
      "Epoch 23/150\n",
      "21912/21912 [==============================] - 2s 96us/step - loss: 0.1440 - val_loss: 0.1459\n",
      "Epoch 24/150\n",
      "21912/21912 [==============================] - 2s 98us/step - loss: 0.1430 - val_loss: 0.1465\n",
      "Epoch 25/150\n",
      "21912/21912 [==============================] - 2s 97us/step - loss: 0.1427 - val_loss: 0.1459\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 26/150\n",
      "21912/21912 [==============================] - 2s 108us/step - loss: 0.1419 - val_loss: 0.1427\n",
      "Epoch 27/150\n",
      "21912/21912 [==============================] - 2s 106us/step - loss: 0.1404 - val_loss: 0.1416\n",
      "Epoch 28/150\n",
      "21912/21912 [==============================] - 2s 109us/step - loss: 0.1403 - val_loss: 0.1446\n",
      "Epoch 29/150\n",
      "21912/21912 [==============================] - 2s 110us/step - loss: 0.1393 - val_loss: 0.1407\n",
      "Epoch 30/150\n",
      "21912/21912 [==============================] - 2s 108us/step - loss: 0.1401 - val_loss: 0.1405\n",
      "Epoch 31/150\n",
      "21912/21912 [==============================] - 2s 109us/step - loss: 0.1381 - val_loss: 0.1418\n",
      "Epoch 32/150\n",
      "21912/21912 [==============================] - 2s 113us/step - loss: 0.1379 - val_loss: 0.1371\n",
      "Epoch 33/150\n",
      "21912/21912 [==============================] - 2s 113us/step - loss: 0.1359 - val_loss: 0.1381\n",
      "Epoch 34/150\n",
      "21912/21912 [==============================] - 2s 113us/step - loss: 0.1336 - val_loss: 0.1303\n",
      "Epoch 35/150\n",
      "21912/21912 [==============================] - 2s 110us/step - loss: 0.1352 - val_loss: 0.1361\n",
      "Epoch 36/150\n",
      "21912/21912 [==============================] - 2s 113us/step - loss: 0.1347 - val_loss: 0.1347\n",
      "Epoch 37/150\n",
      "21912/21912 [==============================] - 2s 113us/step - loss: 0.1327 - val_loss: 0.1351\n",
      "Epoch 38/150\n",
      "21912/21912 [==============================] - 2s 113us/step - loss: 0.1329 - val_loss: 0.1322\n",
      "Evaluating model with testing data...\n",
      "4674/4674 [==============================] - 0s 16us/step\n",
      "Getting distribution of predictions and covariance matrix...\n",
      "      1 of 20\n",
      "      2 of 20\n",
      "      3 of 20\n",
      "      4 of 20\n",
      "      5 of 20\n",
      "      6 of 20\n",
      "      7 of 20\n",
      "      8 of 20\n",
      "      9 of 20\n",
      "      10 of 20\n",
      "      11 of 20\n",
      "      12 of 20\n",
      "      13 of 20\n",
      "      14 of 20\n",
      "      15 of 20\n",
      "      16 of 20\n",
      "      17 of 20\n",
      "      18 of 20\n",
      "      19 of 20\n",
      "      20 of 20\n",
      "Computing ensemble means...\n",
      "Computing mean squared error...\n",
      "Iteration 154\n",
      "Train on 22052 samples, validate on 4704 samples\n",
      "Epoch 1/150\n",
      "22052/22052 [==============================] - 2s 105us/step - loss: 0.4260 - val_loss: 0.3133\n",
      "Epoch 2/150\n",
      "22052/22052 [==============================] - 2s 90us/step - loss: 0.2740 - val_loss: 0.2509\n",
      "Epoch 3/150\n",
      "22052/22052 [==============================] - 1s 62us/step - loss: 0.2323 - val_loss: 0.2182\n",
      "Epoch 4/150\n",
      "22052/22052 [==============================] - 2s 101us/step - loss: 0.2074 - val_loss: 0.1900\n",
      "Epoch 5/150\n",
      "22052/22052 [==============================] - 2s 106us/step - loss: 0.1818 - val_loss: 0.1759\n",
      "Epoch 6/150\n",
      "22052/22052 [==============================] - 2s 107us/step - loss: 0.1726 - val_loss: 0.1691\n",
      "Epoch 7/150\n",
      "22052/22052 [==============================] - 2s 102us/step - loss: 0.1668 - val_loss: 0.1660\n",
      "Epoch 8/150\n",
      "22052/22052 [==============================] - 2s 106us/step - loss: 0.1634 - val_loss: 0.1612\n",
      "Epoch 9/150\n",
      "22052/22052 [==============================] - 2s 108us/step - loss: 0.1612 - val_loss: 0.1661\n",
      "Epoch 10/150\n",
      "22052/22052 [==============================] - 2s 107us/step - loss: 0.1608 - val_loss: 0.1580\n",
      "Epoch 11/150\n",
      "22052/22052 [==============================] - 2s 108us/step - loss: 0.1586 - val_loss: 0.1575\n",
      "Epoch 12/150\n",
      "22052/22052 [==============================] - 2s 108us/step - loss: 0.1577 - val_loss: 0.1600\n",
      "Epoch 13/150\n",
      "22052/22052 [==============================] - 2s 108us/step - loss: 0.1563 - val_loss: 0.1590\n",
      "Epoch 14/150\n",
      "22052/22052 [==============================] - 2s 104us/step - loss: 0.1557 - val_loss: 0.1537\n",
      "Epoch 15/150\n",
      "22052/22052 [==============================] - 2s 108us/step - loss: 0.1573 - val_loss: 0.1552\n",
      "Epoch 16/150\n",
      "22052/22052 [==============================] - 2s 103us/step - loss: 0.1552 - val_loss: 0.1554\n",
      "Epoch 17/150\n",
      "22052/22052 [==============================] - 2s 103us/step - loss: 0.1542 - val_loss: 0.1553\n",
      "Epoch 18/150\n",
      "22052/22052 [==============================] - 2s 107us/step - loss: 0.1531 - val_loss: 0.1576\n",
      "Evaluating model with testing data...\n",
      "4704/4704 [==============================] - 0s 16us/step\n",
      "Getting distribution of predictions and covariance matrix...\n",
      "      1 of 20\n",
      "      2 of 20\n",
      "      3 of 20\n",
      "      4 of 20\n",
      "      5 of 20\n",
      "      6 of 20\n",
      "      7 of 20\n",
      "      8 of 20\n",
      "      9 of 20\n",
      "      10 of 20\n",
      "      11 of 20\n",
      "      12 of 20\n",
      "      13 of 20\n",
      "      14 of 20\n",
      "      15 of 20\n",
      "      16 of 20\n",
      "      17 of 20\n",
      "      18 of 20\n",
      "      19 of 20\n",
      "      20 of 20\n",
      "Computing ensemble means...\n",
      "Computing mean squared error...\n",
      "Iteration 155\n",
      "Train on 22192 samples, validate on 4734 samples\n",
      "Epoch 1/150\n",
      "22192/22192 [==============================] - 2s 101us/step - loss: 0.3777 - val_loss: 0.2654\n",
      "Epoch 2/150\n",
      "22192/22192 [==============================] - 2s 104us/step - loss: 0.2455 - val_loss: 0.2297\n",
      "Epoch 3/150\n",
      "22192/22192 [==============================] - 2s 105us/step - loss: 0.2177 - val_loss: 0.2106\n",
      "Epoch 4/150\n",
      "22192/22192 [==============================] - 2s 107us/step - loss: 0.2004 - val_loss: 0.1912\n",
      "Epoch 5/150\n",
      "22192/22192 [==============================] - 2s 101us/step - loss: 0.1881 - val_loss: 0.1827\n",
      "Epoch 6/150\n",
      "22192/22192 [==============================] - 2s 105us/step - loss: 0.1788 - val_loss: 0.1773\n",
      "Epoch 7/150\n",
      "22192/22192 [==============================] - 2s 107us/step - loss: 0.1752 - val_loss: 0.1720\n",
      "Epoch 8/150\n",
      "22192/22192 [==============================] - 2s 106us/step - loss: 0.1727 - val_loss: 0.1717\n",
      "Epoch 9/150\n",
      "22192/22192 [==============================] - 2s 102us/step - loss: 0.1690 - val_loss: 0.1717\n",
      "Epoch 10/150\n",
      "22192/22192 [==============================] - 2s 102us/step - loss: 0.1655 - val_loss: 0.1668\n",
      "Epoch 11/150\n",
      "22192/22192 [==============================] - 2s 104us/step - loss: 0.1640 - val_loss: 0.1626\n",
      "Epoch 12/150\n",
      "22192/22192 [==============================] - 2s 102us/step - loss: 0.1635 - val_loss: 0.1651\n",
      "Epoch 13/150\n",
      "22192/22192 [==============================] - 2s 102us/step - loss: 0.1614 - val_loss: 0.1624\n",
      "Epoch 14/150\n",
      "22192/22192 [==============================] - 2s 101us/step - loss: 0.1591 - val_loss: 0.1616\n",
      "Epoch 15/150\n",
      "22192/22192 [==============================] - 2s 103us/step - loss: 0.1599 - val_loss: 0.1584\n",
      "Epoch 16/150\n",
      "22192/22192 [==============================] - 2s 101us/step - loss: 0.1587 - val_loss: 0.1601\n",
      "Epoch 17/150\n",
      "22192/22192 [==============================] - 2s 102us/step - loss: 0.1587 - val_loss: 0.1583\n",
      "Epoch 18/150\n",
      "22192/22192 [==============================] - 2s 99us/step - loss: 0.1567 - val_loss: 0.1605\n",
      "Epoch 19/150\n",
      "22192/22192 [==============================] - 2s 103us/step - loss: 0.1553 - val_loss: 0.1566\n",
      "Epoch 20/150\n",
      "22192/22192 [==============================] - 2s 100us/step - loss: 0.1548 - val_loss: 0.1532\n",
      "Epoch 21/150\n",
      "22192/22192 [==============================] - 2s 101us/step - loss: 0.1530 - val_loss: 0.1580\n",
      "Epoch 22/150\n",
      "22192/22192 [==============================] - 2s 95us/step - loss: 0.1530 - val_loss: 0.1554\n",
      "Epoch 23/150\n",
      "22192/22192 [==============================] - 2s 97us/step - loss: 0.1522 - val_loss: 0.1550\n",
      "Epoch 24/150\n",
      "22192/22192 [==============================] - 2s 98us/step - loss: 0.1519 - val_loss: 0.1547\n",
      "Evaluating model with testing data...\n",
      "4734/4734 [==============================] - 0s 15us/step\n",
      "Getting distribution of predictions and covariance matrix...\n",
      "      1 of 20\n",
      "      2 of 20\n",
      "      3 of 20\n",
      "      4 of 20\n",
      "      5 of 20\n",
      "      6 of 20\n",
      "      7 of 20\n",
      "      8 of 20\n",
      "      9 of 20\n",
      "      10 of 20\n",
      "      11 of 20\n",
      "      12 of 20\n",
      "      13 of 20\n",
      "      14 of 20\n",
      "      15 of 20\n",
      "      16 of 20\n",
      "      17 of 20\n",
      "      18 of 20\n",
      "      19 of 20\n",
      "      20 of 20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|          | 0/20 [00:00<?, ?it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing ensemble means...\n",
      "Computing mean squared error...\n",
      "Getting distribution of predictions...\n",
      "      1 of 20\n",
      "1600/1600 [==============================] - 0s 28us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  5%|▌         | 1/20 [00:29<09:15, 29.23s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      2 of 20\n",
      "1600/1600 [==============================] - 0s 29us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 10%|█         | 2/20 [00:58<08:46, 29.24s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      3 of 20\n",
      "1600/1600 [==============================] - 0s 31us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 15%|█▌        | 3/20 [01:27<08:18, 29.30s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      4 of 20\n",
      "1600/1600 [==============================] - 0s 29us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 20%|██        | 4/20 [01:57<07:51, 29.48s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      5 of 20\n",
      "1600/1600 [==============================] - 0s 29us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 25%|██▌       | 5/20 [02:27<07:23, 29.55s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      6 of 20\n",
      "1600/1600 [==============================] - 0s 29us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 30%|███       | 6/20 [02:57<06:55, 29.68s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      7 of 20\n",
      "1600/1600 [==============================] - 0s 29us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 35%|███▌      | 7/20 [03:27<06:25, 29.67s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      8 of 20\n",
      "1600/1600 [==============================] - 0s 29us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 40%|████      | 8/20 [03:56<05:55, 29.61s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      9 of 20\n",
      "1600/1600 [==============================] - 0s 31us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 45%|████▌     | 9/20 [04:25<05:24, 29.48s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      10 of 20\n",
      "1600/1600 [==============================] - 0s 29us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 50%|█████     | 10/20 [04:55<04:54, 29.48s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      11 of 20\n",
      "1600/1600 [==============================] - 0s 29us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 55%|█████▌    | 11/20 [05:24<04:25, 29.53s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      12 of 20\n",
      "1600/1600 [==============================] - 0s 28us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 60%|██████    | 12/20 [05:54<03:57, 29.63s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      13 of 20\n",
      "1600/1600 [==============================] - 0s 29us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 65%|██████▌   | 13/20 [06:24<03:27, 29.62s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      14 of 20\n",
      "1600/1600 [==============================] - 0s 29us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 70%|███████   | 14/20 [06:53<02:57, 29.57s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      15 of 20\n",
      "1600/1600 [==============================] - 0s 29us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 75%|███████▌  | 15/20 [07:23<02:28, 29.64s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      16 of 20\n",
      "1600/1600 [==============================] - 0s 29us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 80%|████████  | 16/20 [07:53<01:58, 29.66s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      17 of 20\n",
      "1600/1600 [==============================] - 0s 29us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 85%|████████▌ | 17/20 [08:23<01:29, 29.69s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      18 of 20\n",
      "1600/1600 [==============================] - 0s 29us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 90%|█████████ | 18/20 [08:52<00:59, 29.50s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      19 of 20\n",
      "1600/1600 [==============================] - 0s 29us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 95%|█████████▌| 19/20 [09:21<00:29, 29.58s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      20 of 20\n",
      "1600/1600 [==============================] - 0s 30us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 20/20 [09:51<00:00, 29.56s/it]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing ensemble predictions...\n",
      "Iteration 156\n",
      "Train on 22332 samples, validate on 4764 samples\n",
      "Epoch 1/150\n",
      "22332/22332 [==============================] - 3s 112us/step - loss: 0.3881 - val_loss: 0.2641\n",
      "Epoch 2/150\n",
      "22332/22332 [==============================] - 2s 106us/step - loss: 0.2265 - val_loss: 0.2031\n",
      "Epoch 3/150\n",
      "22332/22332 [==============================] - 2s 110us/step - loss: 0.1940 - val_loss: 0.1860\n",
      "Epoch 4/150\n",
      "22332/22332 [==============================] - 2s 107us/step - loss: 0.1747 - val_loss: 0.1688\n",
      "Epoch 5/150\n",
      "22332/22332 [==============================] - 2s 112us/step - loss: 0.1662 - val_loss: 0.1622\n",
      "Epoch 6/150\n",
      "22332/22332 [==============================] - 2s 111us/step - loss: 0.1581 - val_loss: 0.1560\n",
      "Epoch 7/150\n",
      "22332/22332 [==============================] - 2s 108us/step - loss: 0.1507 - val_loss: 0.1502\n",
      "Epoch 8/150\n",
      "22332/22332 [==============================] - 2s 112us/step - loss: 0.1485 - val_loss: 0.1510\n",
      "Epoch 9/150\n",
      "22332/22332 [==============================] - 2s 111us/step - loss: 0.1470 - val_loss: 0.1507\n",
      "Epoch 10/150\n",
      "22332/22332 [==============================] - 2s 110us/step - loss: 0.1444 - val_loss: 0.1457\n",
      "Epoch 11/150\n",
      "22332/22332 [==============================] - 2s 107us/step - loss: 0.1429 - val_loss: 0.1446\n",
      "Epoch 12/150\n",
      "22332/22332 [==============================] - 2s 109us/step - loss: 0.1417 - val_loss: 0.1428\n",
      "Epoch 13/150\n",
      "22332/22332 [==============================] - 2s 109us/step - loss: 0.1416 - val_loss: 0.1435\n",
      "Epoch 14/150\n",
      "22332/22332 [==============================] - 1s 58us/step - loss: 0.1394 - val_loss: 0.1424\n",
      "Epoch 15/150\n",
      "22332/22332 [==============================] - 2s 98us/step - loss: 0.1396 - val_loss: 0.1435\n",
      "Epoch 16/150\n",
      "22332/22332 [==============================] - 2s 105us/step - loss: 0.1383 - val_loss: 0.1403\n",
      "Epoch 17/150\n",
      "22332/22332 [==============================] - 2s 107us/step - loss: 0.1355 - val_loss: 0.1353\n",
      "Epoch 18/150\n",
      "22332/22332 [==============================] - 2s 107us/step - loss: 0.1340 - val_loss: 0.1288\n",
      "Epoch 19/150\n",
      "22332/22332 [==============================] - 2s 111us/step - loss: 0.1304 - val_loss: 0.1326\n",
      "Epoch 20/150\n",
      "22332/22332 [==============================] - 2s 109us/step - loss: 0.1299 - val_loss: 0.1335\n",
      "Epoch 21/150\n",
      "22332/22332 [==============================] - 2s 106us/step - loss: 0.1297 - val_loss: 0.1321\n",
      "Epoch 22/150\n",
      "22332/22332 [==============================] - 2s 107us/step - loss: 0.1279 - val_loss: 0.1309\n",
      "Evaluating model with testing data...\n",
      "4764/4764 [==============================] - 0s 16us/step\n",
      "Getting distribution of predictions and covariance matrix...\n",
      "      1 of 20\n",
      "      2 of 20\n",
      "      3 of 20\n",
      "      4 of 20\n",
      "      5 of 20\n",
      "      6 of 20\n",
      "      7 of 20\n",
      "      8 of 20\n",
      "      9 of 20\n",
      "      10 of 20\n",
      "      11 of 20\n",
      "      12 of 20\n",
      "      13 of 20\n",
      "      14 of 20\n",
      "      15 of 20\n",
      "      16 of 20\n",
      "      17 of 20\n",
      "      18 of 20\n",
      "      19 of 20\n",
      "      20 of 20\n",
      "Computing ensemble means...\n",
      "Computing mean squared error...\n",
      "Iteration 157\n",
      "Train on 22472 samples, validate on 4794 samples\n",
      "Epoch 1/150\n",
      "22472/22472 [==============================] - 2s 108us/step - loss: 0.3985 - val_loss: 0.2541\n",
      "Epoch 2/150\n",
      "22472/22472 [==============================] - 2s 105us/step - loss: 0.2312 - val_loss: 0.2179\n",
      "Epoch 3/150\n",
      "22472/22472 [==============================] - 2s 107us/step - loss: 0.2086 - val_loss: 0.2038\n",
      "Epoch 4/150\n",
      "22472/22472 [==============================] - 2s 105us/step - loss: 0.1954 - val_loss: 0.1959\n",
      "Epoch 5/150\n",
      "22472/22472 [==============================] - 2s 108us/step - loss: 0.1856 - val_loss: 0.1865\n",
      "Epoch 6/150\n",
      "22472/22472 [==============================] - 2s 107us/step - loss: 0.1778 - val_loss: 0.1769\n",
      "Epoch 7/150\n",
      "22472/22472 [==============================] - 2s 105us/step - loss: 0.1700 - val_loss: 0.1699\n",
      "Epoch 8/150\n",
      "22472/22472 [==============================] - 2s 104us/step - loss: 0.1656 - val_loss: 0.1687\n",
      "Epoch 9/150\n",
      "22472/22472 [==============================] - 2s 105us/step - loss: 0.1628 - val_loss: 0.1648\n",
      "Epoch 10/150\n",
      "22472/22472 [==============================] - 2s 101us/step - loss: 0.1593 - val_loss: 0.1613\n",
      "Epoch 11/150\n",
      "22472/22472 [==============================] - 2s 106us/step - loss: 0.1583 - val_loss: 0.1601\n",
      "Epoch 12/150\n",
      "22472/22472 [==============================] - 2s 100us/step - loss: 0.1554 - val_loss: 0.1532\n",
      "Epoch 13/150\n",
      "22472/22472 [==============================] - 2s 101us/step - loss: 0.1512 - val_loss: 0.1530\n",
      "Epoch 14/150\n",
      "22472/22472 [==============================] - 2s 108us/step - loss: 0.1484 - val_loss: 0.1522\n",
      "Epoch 15/150\n",
      "22472/22472 [==============================] - 2s 104us/step - loss: 0.1447 - val_loss: 0.1464\n",
      "Epoch 16/150\n",
      "22472/22472 [==============================] - 2s 107us/step - loss: 0.1430 - val_loss: 0.1446\n",
      "Epoch 17/150\n",
      "22472/22472 [==============================] - 2s 105us/step - loss: 0.1386 - val_loss: 0.1416\n",
      "Epoch 18/150\n",
      "22472/22472 [==============================] - 2s 103us/step - loss: 0.1386 - val_loss: 0.1373\n",
      "Epoch 19/150\n",
      "22472/22472 [==============================] - 2s 103us/step - loss: 0.1361 - val_loss: 0.1410\n",
      "Epoch 20/150\n",
      "22472/22472 [==============================] - 2s 103us/step - loss: 0.1355 - val_loss: 0.1392\n",
      "Epoch 21/150\n",
      "22472/22472 [==============================] - 2s 105us/step - loss: 0.1359 - val_loss: 0.1377\n",
      "Epoch 22/150\n",
      "22472/22472 [==============================] - 2s 102us/step - loss: 0.1341 - val_loss: 0.1385\n",
      "Evaluating model with testing data...\n",
      "4794/4794 [==============================] - 0s 16us/step\n",
      "Getting distribution of predictions and covariance matrix...\n",
      "      1 of 20\n",
      "      2 of 20\n",
      "      3 of 20\n",
      "      4 of 20\n",
      "      5 of 20\n",
      "      6 of 20\n",
      "      7 of 20\n",
      "      8 of 20\n",
      "      9 of 20\n",
      "      10 of 20\n",
      "      11 of 20\n",
      "      12 of 20\n",
      "      13 of 20\n",
      "      14 of 20\n",
      "      15 of 20\n",
      "      16 of 20\n",
      "      17 of 20\n",
      "      18 of 20\n",
      "      19 of 20\n",
      "      20 of 20\n",
      "Computing ensemble means...\n",
      "Computing mean squared error...\n",
      "Iteration 158\n",
      "Train on 22612 samples, validate on 4824 samples\n",
      "Epoch 1/150\n",
      "22612/22612 [==============================] - 2s 99us/step - loss: 0.4147 - val_loss: 0.2951\n",
      "Epoch 2/150\n",
      "22612/22612 [==============================] - 2s 103us/step - loss: 0.2633 - val_loss: 0.2363\n",
      "Epoch 3/150\n",
      "22612/22612 [==============================] - 2s 101us/step - loss: 0.2189 - val_loss: 0.2070\n",
      "Epoch 4/150\n",
      "22612/22612 [==============================] - 2s 99us/step - loss: 0.1989 - val_loss: 0.1924\n",
      "Epoch 5/150\n",
      "22612/22612 [==============================] - 2s 96us/step - loss: 0.1809 - val_loss: 0.1762\n",
      "Epoch 6/150\n",
      "22612/22612 [==============================] - 2s 102us/step - loss: 0.1694 - val_loss: 0.1676\n",
      "Epoch 7/150\n",
      "22612/22612 [==============================] - 2s 100us/step - loss: 0.1646 - val_loss: 0.1634\n",
      "Epoch 8/150\n",
      "22612/22612 [==============================] - 2s 99us/step - loss: 0.1625 - val_loss: 0.1648\n",
      "Epoch 9/150\n",
      "22612/22612 [==============================] - 2s 94us/step - loss: 0.1609 - val_loss: 0.1673\n",
      "Epoch 10/150\n",
      "22612/22612 [==============================] - 2s 102us/step - loss: 0.1585 - val_loss: 0.1613\n",
      "Epoch 11/150\n",
      "22612/22612 [==============================] - 2s 100us/step - loss: 0.1576 - val_loss: 0.1614\n",
      "Epoch 12/150\n",
      "22612/22612 [==============================] - 2s 98us/step - loss: 0.1557 - val_loss: 0.1604\n",
      "Epoch 13/150\n",
      "22612/22612 [==============================] - 2s 101us/step - loss: 0.1548 - val_loss: 0.1580\n",
      "Epoch 14/150\n",
      "22612/22612 [==============================] - 2s 95us/step - loss: 0.1553 - val_loss: 0.1557\n",
      "Epoch 15/150\n",
      "22612/22612 [==============================] - 2s 93us/step - loss: 0.1555 - val_loss: 0.1582\n",
      "Epoch 16/150\n",
      "22612/22612 [==============================] - 2s 97us/step - loss: 0.1537 - val_loss: 0.1596\n",
      "Epoch 17/150\n",
      "22612/22612 [==============================] - 2s 98us/step - loss: 0.1518 - val_loss: 0.1536\n",
      "Epoch 18/150\n",
      "22612/22612 [==============================] - 2s 96us/step - loss: 0.1473 - val_loss: 0.1524\n",
      "Epoch 19/150\n",
      "22612/22612 [==============================] - 2s 92us/step - loss: 0.1469 - val_loss: 0.1492\n",
      "Epoch 20/150\n",
      "22612/22612 [==============================] - 1s 59us/step - loss: 0.1459 - val_loss: 0.1534\n",
      "Epoch 21/150\n",
      "22612/22612 [==============================] - 2s 90us/step - loss: 0.1459 - val_loss: 0.1478\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 22/150\n",
      "22612/22612 [==============================] - 2s 109us/step - loss: 0.1443 - val_loss: 0.1477\n",
      "Epoch 23/150\n",
      "22612/22612 [==============================] - 3s 111us/step - loss: 0.1451 - val_loss: 0.1462\n",
      "Epoch 24/150\n",
      "22612/22612 [==============================] - 2s 108us/step - loss: 0.1417 - val_loss: 0.1473\n",
      "Epoch 25/150\n",
      "22612/22612 [==============================] - 2s 109us/step - loss: 0.1416 - val_loss: 0.1432\n",
      "Epoch 26/150\n",
      "22612/22612 [==============================] - 2s 110us/step - loss: 0.1421 - val_loss: 0.1430\n",
      "Epoch 27/150\n",
      "22612/22612 [==============================] - 2s 109us/step - loss: 0.1414 - val_loss: 0.1442\n",
      "Epoch 28/150\n",
      "22612/22612 [==============================] - 2s 107us/step - loss: 0.1401 - val_loss: 0.1435\n",
      "Epoch 29/150\n",
      "22612/22612 [==============================] - 3s 112us/step - loss: 0.1395 - val_loss: 0.1387\n",
      "Epoch 30/150\n",
      "22612/22612 [==============================] - 3s 112us/step - loss: 0.1374 - val_loss: 0.1384\n",
      "Epoch 31/150\n",
      "22612/22612 [==============================] - 2s 108us/step - loss: 0.1363 - val_loss: 0.1348\n",
      "Epoch 32/150\n",
      "22612/22612 [==============================] - 2s 109us/step - loss: 0.1354 - val_loss: 0.1341\n",
      "Epoch 33/150\n",
      "22612/22612 [==============================] - 2s 110us/step - loss: 0.1345 - val_loss: 0.1381\n",
      "Epoch 34/150\n",
      "22612/22612 [==============================] - 2s 110us/step - loss: 0.1331 - val_loss: 0.1356\n",
      "Epoch 35/150\n",
      "22612/22612 [==============================] - 2s 109us/step - loss: 0.1327 - val_loss: 0.1346\n",
      "Epoch 36/150\n",
      "22612/22612 [==============================] - 2s 109us/step - loss: 0.1313 - val_loss: 0.1353\n",
      "Evaluating model with testing data...\n",
      "4824/4824 [==============================] - 0s 15us/step\n",
      "Getting distribution of predictions and covariance matrix...\n",
      "      1 of 20\n",
      "      2 of 20\n",
      "      3 of 20\n",
      "      4 of 20\n",
      "      5 of 20\n",
      "      6 of 20\n",
      "      7 of 20\n",
      "      8 of 20\n",
      "      9 of 20\n",
      "      10 of 20\n",
      "      11 of 20\n",
      "      12 of 20\n",
      "      13 of 20\n",
      "      14 of 20\n",
      "      15 of 20\n",
      "      16 of 20\n",
      "      17 of 20\n",
      "      18 of 20\n",
      "      19 of 20\n",
      "      20 of 20\n",
      "Computing ensemble means...\n",
      "Computing mean squared error...\n",
      "Iteration 159\n",
      "Train on 22752 samples, validate on 4854 samples\n",
      "Epoch 1/150\n",
      "22752/22752 [==============================] - 2s 107us/step - loss: 0.3188 - val_loss: 0.2185\n",
      "Epoch 2/150\n",
      "22752/22752 [==============================] - 2s 107us/step - loss: 0.1949 - val_loss: 0.1883\n",
      "Epoch 3/150\n",
      "22752/22752 [==============================] - 2s 106us/step - loss: 0.1723 - val_loss: 0.1704\n",
      "Epoch 4/150\n",
      "22752/22752 [==============================] - 2s 110us/step - loss: 0.1587 - val_loss: 0.1552\n",
      "Epoch 5/150\n",
      "22752/22752 [==============================] - 2s 107us/step - loss: 0.1477 - val_loss: 0.1483\n",
      "Epoch 6/150\n",
      "22752/22752 [==============================] - 2s 109us/step - loss: 0.1424 - val_loss: 0.1428\n",
      "Epoch 7/150\n",
      "22752/22752 [==============================] - 2s 110us/step - loss: 0.1368 - val_loss: 0.1372\n",
      "Epoch 8/150\n",
      "22752/22752 [==============================] - 2s 106us/step - loss: 0.1352 - val_loss: 0.1362\n",
      "Epoch 9/150\n",
      "22752/22752 [==============================] - 2s 104us/step - loss: 0.1320 - val_loss: 0.1367\n",
      "Epoch 10/150\n",
      "22752/22752 [==============================] - 2s 104us/step - loss: 0.1297 - val_loss: 0.1309\n",
      "Epoch 11/150\n",
      "22752/22752 [==============================] - 2s 106us/step - loss: 0.1281 - val_loss: 0.1347\n",
      "Epoch 12/150\n",
      "22752/22752 [==============================] - 2s 104us/step - loss: 0.1259 - val_loss: 0.1305\n",
      "Epoch 13/150\n",
      "22752/22752 [==============================] - 2s 105us/step - loss: 0.1248 - val_loss: 0.1261\n",
      "Epoch 14/150\n",
      "22752/22752 [==============================] - 2s 102us/step - loss: 0.1227 - val_loss: 0.1239\n",
      "Epoch 15/150\n",
      "22752/22752 [==============================] - 2s 104us/step - loss: 0.1205 - val_loss: 0.1216\n",
      "Epoch 16/150\n",
      "22752/22752 [==============================] - 2s 104us/step - loss: 0.1211 - val_loss: 0.1245\n",
      "Epoch 17/150\n",
      "22752/22752 [==============================] - 2s 98us/step - loss: 0.1184 - val_loss: 0.1225\n",
      "Epoch 18/150\n",
      "22752/22752 [==============================] - 2s 108us/step - loss: 0.1181 - val_loss: 0.1216\n",
      "Epoch 19/150\n",
      "22752/22752 [==============================] - 2s 104us/step - loss: 0.1161 - val_loss: 0.1203\n",
      "Epoch 20/150\n",
      "22752/22752 [==============================] - 2s 102us/step - loss: 0.1153 - val_loss: 0.1194\n",
      "Epoch 21/150\n",
      "22752/22752 [==============================] - 2s 102us/step - loss: 0.1146 - val_loss: 0.1210\n",
      "Epoch 22/150\n",
      "22752/22752 [==============================] - 2s 103us/step - loss: 0.1141 - val_loss: 0.1197\n",
      "Epoch 23/150\n",
      "22752/22752 [==============================] - 2s 103us/step - loss: 0.1135 - val_loss: 0.1153\n",
      "Epoch 24/150\n",
      "22752/22752 [==============================] - 2s 105us/step - loss: 0.1107 - val_loss: 0.1172\n",
      "Epoch 25/150\n",
      "22752/22752 [==============================] - 2s 105us/step - loss: 0.1111 - val_loss: 0.1132\n",
      "Epoch 26/150\n",
      "22752/22752 [==============================] - 2s 105us/step - loss: 0.1094 - val_loss: 0.1092\n",
      "Epoch 27/150\n",
      "22752/22752 [==============================] - 2s 104us/step - loss: 0.1088 - val_loss: 0.1134\n",
      "Epoch 28/150\n",
      "22752/22752 [==============================] - 2s 98us/step - loss: 0.1088 - val_loss: 0.1138\n",
      "Epoch 29/150\n",
      "22752/22752 [==============================] - 2s 102us/step - loss: 0.1070 - val_loss: 0.1107\n",
      "Epoch 30/150\n",
      "22752/22752 [==============================] - 2s 102us/step - loss: 0.1073 - val_loss: 0.1134\n",
      "Evaluating model with testing data...\n",
      "4854/4854 [==============================] - 0s 15us/step\n",
      "Getting distribution of predictions and covariance matrix...\n",
      "      1 of 20\n",
      "      2 of 20\n",
      "      3 of 20\n",
      "      4 of 20\n",
      "      5 of 20\n",
      "      6 of 20\n",
      "      7 of 20\n",
      "      8 of 20\n",
      "      9 of 20\n",
      "      10 of 20\n",
      "      11 of 20\n",
      "      12 of 20\n",
      "      13 of 20\n",
      "      14 of 20\n",
      "      15 of 20\n",
      "      16 of 20\n",
      "      17 of 20\n",
      "      18 of 20\n",
      "      19 of 20\n",
      "      20 of 20\n",
      "Computing ensemble means...\n",
      "Computing mean squared error...\n",
      "Iteration 160\n",
      "Train on 22892 samples, validate on 4884 samples\n",
      "Epoch 1/150\n",
      "22892/22892 [==============================] - 2s 99us/step - loss: 0.3097 - val_loss: 0.2153\n",
      "Epoch 2/150\n",
      "22892/22892 [==============================] - 1s 59us/step - loss: 0.1923 - val_loss: 0.1786\n",
      "Epoch 3/150\n",
      "22892/22892 [==============================] - 2s 95us/step - loss: 0.1650 - val_loss: 0.1569\n",
      "Epoch 4/150\n",
      "22892/22892 [==============================] - 2s 100us/step - loss: 0.1492 - val_loss: 0.1453\n",
      "Epoch 5/150\n",
      "22892/22892 [==============================] - 2s 101us/step - loss: 0.1411 - val_loss: 0.1393\n",
      "Epoch 6/150\n",
      "22892/22892 [==============================] - 2s 95us/step - loss: 0.1348 - val_loss: 0.1332\n",
      "Epoch 7/150\n",
      "22892/22892 [==============================] - 2s 102us/step - loss: 0.1308 - val_loss: 0.1324\n",
      "Epoch 8/150\n",
      "22892/22892 [==============================] - 2s 100us/step - loss: 0.1277 - val_loss: 0.1282\n",
      "Epoch 9/150\n",
      "22892/22892 [==============================] - 2s 96us/step - loss: 0.1258 - val_loss: 0.1267\n",
      "Epoch 10/150\n",
      "22892/22892 [==============================] - 2s 95us/step - loss: 0.1212 - val_loss: 0.1265\n",
      "Epoch 11/150\n",
      "22892/22892 [==============================] - 2s 97us/step - loss: 0.1211 - val_loss: 0.1230\n",
      "Epoch 12/150\n",
      "22892/22892 [==============================] - 2s 97us/step - loss: 0.1178 - val_loss: 0.1193\n",
      "Epoch 13/150\n",
      "22892/22892 [==============================] - 2s 97us/step - loss: 0.1160 - val_loss: 0.1157\n",
      "Epoch 14/150\n",
      "22892/22892 [==============================] - 2s 97us/step - loss: 0.1113 - val_loss: 0.1133\n",
      "Epoch 15/150\n",
      "22892/22892 [==============================] - 2s 93us/step - loss: 0.1103 - val_loss: 0.1138\n",
      "Epoch 16/150\n",
      "22892/22892 [==============================] - 2s 96us/step - loss: 0.1082 - val_loss: 0.1084\n",
      "Epoch 17/150\n",
      "22892/22892 [==============================] - 2s 90us/step - loss: 0.1059 - val_loss: 0.1090\n",
      "Epoch 18/150\n",
      "22892/22892 [==============================] - 2s 97us/step - loss: 0.1060 - val_loss: 0.1093\n",
      "Epoch 19/150\n",
      "22892/22892 [==============================] - 2s 93us/step - loss: 0.1044 - val_loss: 0.1055\n",
      "Epoch 20/150\n",
      "22892/22892 [==============================] - 2s 93us/step - loss: 0.1025 - val_loss: 0.1045\n",
      "Epoch 21/150\n",
      "22892/22892 [==============================] - 3s 111us/step - loss: 0.1031 - val_loss: 0.1037\n",
      "Epoch 22/150\n",
      "22892/22892 [==============================] - 3s 110us/step - loss: 0.1014 - val_loss: 0.1021\n",
      "Epoch 23/150\n",
      "22892/22892 [==============================] - 3s 109us/step - loss: 0.0997 - val_loss: 0.1056\n",
      "Epoch 24/150\n",
      "22892/22892 [==============================] - 2s 103us/step - loss: 0.0986 - val_loss: 0.1051\n",
      "Epoch 25/150\n",
      "22892/22892 [==============================] - 2s 103us/step - loss: 0.0982 - val_loss: 0.1038\n",
      "Epoch 26/150\n",
      "22892/22892 [==============================] - 3s 111us/step - loss: 0.0980 - val_loss: 0.1013\n",
      "Epoch 27/150\n",
      "22892/22892 [==============================] - 3s 113us/step - loss: 0.0967 - val_loss: 0.0975\n",
      "Epoch 28/150\n",
      "22892/22892 [==============================] - 3s 109us/step - loss: 0.0960 - val_loss: 0.0976\n",
      "Epoch 29/150\n",
      "22892/22892 [==============================] - 3s 111us/step - loss: 0.0955 - val_loss: 0.0981\n",
      "Epoch 30/150\n",
      "22892/22892 [==============================] - 3s 109us/step - loss: 0.0957 - val_loss: 0.0972\n",
      "Epoch 31/150\n",
      "22892/22892 [==============================] - 2s 108us/step - loss: 0.0934 - val_loss: 0.0961\n",
      "Epoch 32/150\n",
      "22892/22892 [==============================] - 3s 113us/step - loss: 0.0939 - val_loss: 0.0927\n",
      "Epoch 33/150\n",
      "22892/22892 [==============================] - 2s 108us/step - loss: 0.0932 - val_loss: 0.0943\n",
      "Epoch 34/150\n",
      "22892/22892 [==============================] - 3s 111us/step - loss: 0.0925 - val_loss: 0.0950\n",
      "Epoch 35/150\n",
      "22892/22892 [==============================] - 2s 106us/step - loss: 0.0926 - val_loss: 0.0978\n",
      "Epoch 36/150\n",
      "22892/22892 [==============================] - 2s 104us/step - loss: 0.0923 - val_loss: 0.0950\n",
      "Evaluating model with testing data...\n",
      "4884/4884 [==============================] - 0s 15us/step\n",
      "Getting distribution of predictions and covariance matrix...\n",
      "      1 of 20\n",
      "      2 of 20\n",
      "      3 of 20\n",
      "      4 of 20\n",
      "      5 of 20\n",
      "      6 of 20\n",
      "      7 of 20\n",
      "      8 of 20\n",
      "      9 of 20\n",
      "      10 of 20\n",
      "      11 of 20\n",
      "      12 of 20\n",
      "      13 of 20\n",
      "      14 of 20\n",
      "      15 of 20\n",
      "      16 of 20\n",
      "      17 of 20\n",
      "      18 of 20\n",
      "      19 of 20\n",
      "      20 of 20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|          | 0/20 [00:00<?, ?it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing ensemble means...\n",
      "Computing mean squared error...\n",
      "Getting distribution of predictions...\n",
      "      1 of 20\n",
      "1600/1600 [==============================] - 0s 27us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  5%|▌         | 1/20 [00:29<09:23, 29.68s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      2 of 20\n",
      "1600/1600 [==============================] - 0s 29us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 10%|█         | 2/20 [00:58<08:52, 29.56s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      3 of 20\n",
      "1600/1600 [==============================] - 0s 29us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 15%|█▌        | 3/20 [01:28<08:21, 29.49s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      4 of 20\n",
      "1600/1600 [==============================] - 0s 31us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 20%|██        | 4/20 [01:58<07:53, 29.58s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      5 of 20\n",
      "1600/1600 [==============================] - 0s 28us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 25%|██▌       | 5/20 [02:27<07:25, 29.67s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      6 of 20\n",
      "1600/1600 [==============================] - 0s 29us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 30%|███       | 6/20 [02:57<06:55, 29.71s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      7 of 20\n",
      "1600/1600 [==============================] - 0s 30us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 35%|███▌      | 7/20 [03:27<06:25, 29.68s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      8 of 20\n",
      "1600/1600 [==============================] - 0s 28us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 40%|████      | 8/20 [03:57<05:57, 29.80s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      9 of 20\n",
      "1600/1600 [==============================] - 0s 30us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 45%|████▌     | 9/20 [04:27<05:28, 29.84s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      10 of 20\n",
      "1600/1600 [==============================] - 0s 29us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 50%|█████     | 10/20 [04:56<04:57, 29.73s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      11 of 20\n",
      "1600/1600 [==============================] - 0s 30us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 55%|█████▌    | 11/20 [05:26<04:27, 29.71s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      12 of 20\n",
      "1600/1600 [==============================] - 0s 30us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 60%|██████    | 12/20 [05:56<03:57, 29.70s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      13 of 20\n",
      "1600/1600 [==============================] - 0s 29us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 65%|██████▌   | 13/20 [06:25<03:27, 29.70s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      14 of 20\n",
      "1600/1600 [==============================] - 0s 29us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 70%|███████   | 14/20 [06:54<02:57, 29.50s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      15 of 20\n",
      "1600/1600 [==============================] - 0s 29us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 75%|███████▌  | 15/20 [07:24<02:28, 29.64s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      16 of 20\n",
      "1600/1600 [==============================] - 0s 29us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 80%|████████  | 16/20 [07:54<01:58, 29.58s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      17 of 20\n",
      "1600/1600 [==============================] - 0s 30us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 85%|████████▌ | 17/20 [08:24<01:28, 29.62s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      18 of 20\n",
      "1600/1600 [==============================] - 0s 29us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 90%|█████████ | 18/20 [08:53<00:58, 29.48s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      19 of 20\n",
      "1600/1600 [==============================] - 0s 29us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 95%|█████████▌| 19/20 [09:22<00:29, 29.53s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      20 of 20\n",
      "1600/1600 [==============================] - 0s 29us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 20/20 [09:52<00:00, 29.62s/it]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing ensemble predictions...\n",
      "Iteration 161\n",
      "Train on 23032 samples, validate on 4914 samples\n",
      "Epoch 1/150\n",
      "23032/23032 [==============================] - 3s 109us/step - loss: 0.4014 - val_loss: 0.2846\n",
      "Epoch 2/150\n",
      "23032/23032 [==============================] - 2s 104us/step - loss: 0.2542 - val_loss: 0.2374\n",
      "Epoch 3/150\n",
      "23032/23032 [==============================] - 2s 108us/step - loss: 0.2249 - val_loss: 0.2243\n",
      "Epoch 4/150\n",
      "23032/23032 [==============================] - 3s 110us/step - loss: 0.2100 - val_loss: 0.2067\n",
      "Epoch 5/150\n",
      "23032/23032 [==============================] - 3s 112us/step - loss: 0.1993 - val_loss: 0.1940\n",
      "Epoch 6/150\n",
      "23032/23032 [==============================] - 2s 104us/step - loss: 0.1854 - val_loss: 0.1843\n",
      "Epoch 7/150\n",
      "23032/23032 [==============================] - 2s 107us/step - loss: 0.1759 - val_loss: 0.1740\n",
      "Epoch 8/150\n",
      "23032/23032 [==============================] - 3s 110us/step - loss: 0.1700 - val_loss: 0.1701\n",
      "Epoch 9/150\n",
      "23032/23032 [==============================] - 3s 111us/step - loss: 0.1621 - val_loss: 0.1582\n",
      "Epoch 10/150\n",
      "23032/23032 [==============================] - 2s 107us/step - loss: 0.1555 - val_loss: 0.1576\n",
      "Epoch 11/150\n",
      "23032/23032 [==============================] - 3s 111us/step - loss: 0.1524 - val_loss: 0.1546\n",
      "Epoch 12/150\n",
      "23032/23032 [==============================] - 3s 110us/step - loss: 0.1496 - val_loss: 0.1540\n",
      "Epoch 13/150\n",
      "23032/23032 [==============================] - 3s 109us/step - loss: 0.1493 - val_loss: 0.1501\n",
      "Epoch 14/150\n",
      "23032/23032 [==============================] - 2s 107us/step - loss: 0.1479 - val_loss: 0.1518\n",
      "Epoch 15/150\n",
      "23032/23032 [==============================] - 2s 105us/step - loss: 0.1458 - val_loss: 0.1492\n",
      "Epoch 16/150\n",
      "23032/23032 [==============================] - 2s 107us/step - loss: 0.1439 - val_loss: 0.1486\n",
      "Epoch 17/150\n",
      "23032/23032 [==============================] - 2s 107us/step - loss: 0.1444 - val_loss: 0.1463\n",
      "Epoch 18/150\n",
      "23032/23032 [==============================] - 2s 78us/step - loss: 0.1419 - val_loss: 0.1464\n",
      "Epoch 19/150\n",
      "23032/23032 [==============================] - 2s 72us/step - loss: 0.1413 - val_loss: 0.1475\n",
      "Epoch 20/150\n",
      "23032/23032 [==============================] - 2s 105us/step - loss: 0.1408 - val_loss: 0.1435\n",
      "Epoch 21/150\n",
      "23032/23032 [==============================] - 2s 107us/step - loss: 0.1405 - val_loss: 0.1432\n",
      "Epoch 22/150\n",
      "23032/23032 [==============================] - 3s 109us/step - loss: 0.1393 - val_loss: 0.1441\n",
      "Epoch 23/150\n",
      "23032/23032 [==============================] - 2s 105us/step - loss: 0.1385 - val_loss: 0.1438\n",
      "Epoch 24/150\n",
      "23032/23032 [==============================] - 2s 108us/step - loss: 0.1379 - val_loss: 0.1447\n",
      "Epoch 25/150\n",
      "23032/23032 [==============================] - 3s 109us/step - loss: 0.1374 - val_loss: 0.1422\n",
      "Epoch 26/150\n",
      "23032/23032 [==============================] - 2s 106us/step - loss: 0.1372 - val_loss: 0.1426\n",
      "Epoch 27/150\n",
      "23032/23032 [==============================] - 2s 100us/step - loss: 0.1375 - val_loss: 0.1406\n",
      "Epoch 28/150\n",
      "23032/23032 [==============================] - 2s 100us/step - loss: 0.1364 - val_loss: 0.1399\n",
      "Epoch 29/150\n",
      "23032/23032 [==============================] - 2s 103us/step - loss: 0.1360 - val_loss: 0.1386\n",
      "Epoch 30/150\n",
      "23032/23032 [==============================] - 2s 104us/step - loss: 0.1370 - val_loss: 0.1395\n",
      "Epoch 31/150\n",
      "23032/23032 [==============================] - 2s 106us/step - loss: 0.1358 - val_loss: 0.1403\n",
      "Epoch 32/150\n",
      "23032/23032 [==============================] - 2s 103us/step - loss: 0.1360 - val_loss: 0.1389\n",
      "Epoch 33/150\n",
      "23032/23032 [==============================] - 2s 106us/step - loss: 0.1352 - val_loss: 0.1378\n",
      "Epoch 34/150\n",
      "23032/23032 [==============================] - 2s 106us/step - loss: 0.1349 - val_loss: 0.1430\n",
      "Epoch 35/150\n",
      "23032/23032 [==============================] - 2s 106us/step - loss: 0.1350 - val_loss: 0.1384\n",
      "Epoch 36/150\n",
      "23032/23032 [==============================] - 2s 105us/step - loss: 0.1327 - val_loss: 0.1375\n",
      "Epoch 37/150\n",
      "23032/23032 [==============================] - 2s 107us/step - loss: 0.1335 - val_loss: 0.1387\n",
      "Epoch 38/150\n",
      "23032/23032 [==============================] - 2s 106us/step - loss: 0.1333 - val_loss: 0.1344\n",
      "Epoch 39/150\n",
      "23032/23032 [==============================] - 2s 100us/step - loss: 0.1334 - val_loss: 0.1340\n",
      "Epoch 40/150\n",
      "23032/23032 [==============================] - 2s 103us/step - loss: 0.1323 - val_loss: 0.1377\n",
      "Epoch 41/150\n",
      "23032/23032 [==============================] - 2s 103us/step - loss: 0.1311 - val_loss: 0.1365\n",
      "Epoch 42/150\n",
      "23032/23032 [==============================] - 2s 105us/step - loss: 0.1285 - val_loss: 0.1310\n",
      "Epoch 43/150\n",
      "23032/23032 [==============================] - 2s 99us/step - loss: 0.1301 - val_loss: 0.1286\n",
      "Epoch 44/150\n",
      "23032/23032 [==============================] - 2s 103us/step - loss: 0.1274 - val_loss: 0.1328\n",
      "Epoch 45/150\n",
      "23032/23032 [==============================] - 2s 105us/step - loss: 0.1257 - val_loss: 0.1315\n",
      "Epoch 46/150\n",
      "23032/23032 [==============================] - 2s 102us/step - loss: 0.1269 - val_loss: 0.1319\n",
      "Epoch 47/150\n",
      "23032/23032 [==============================] - 2s 100us/step - loss: 0.1270 - val_loss: 0.1285\n",
      "Epoch 48/150\n",
      "23032/23032 [==============================] - 2s 107us/step - loss: 0.1247 - val_loss: 0.1269\n",
      "Epoch 49/150\n",
      "23032/23032 [==============================] - 2s 103us/step - loss: 0.1236 - val_loss: 0.1286\n",
      "Epoch 50/150\n",
      "23032/23032 [==============================] - 2s 104us/step - loss: 0.1219 - val_loss: 0.1260\n",
      "Epoch 51/150\n",
      "23032/23032 [==============================] - 2s 103us/step - loss: 0.1208 - val_loss: 0.1250\n",
      "Epoch 52/150\n",
      "23032/23032 [==============================] - 2s 101us/step - loss: 0.1206 - val_loss: 0.1239\n",
      "Epoch 53/150\n",
      "23032/23032 [==============================] - 2s 102us/step - loss: 0.1200 - val_loss: 0.1253\n",
      "Epoch 54/150\n",
      "23032/23032 [==============================] - 2s 97us/step - loss: 0.1191 - val_loss: 0.1221\n",
      "Epoch 55/150\n",
      "23032/23032 [==============================] - 2s 98us/step - loss: 0.1176 - val_loss: 0.1235\n",
      "Epoch 56/150\n",
      "23032/23032 [==============================] - 2s 100us/step - loss: 0.1159 - val_loss: 0.1199\n",
      "Epoch 57/150\n",
      "23032/23032 [==============================] - 2s 99us/step - loss: 0.1162 - val_loss: 0.1199\n",
      "Epoch 58/150\n",
      "23032/23032 [==============================] - 2s 102us/step - loss: 0.1154 - val_loss: 0.1162\n",
      "Epoch 59/150\n",
      "23032/23032 [==============================] - 2s 100us/step - loss: 0.1155 - val_loss: 0.1171\n",
      "Epoch 60/150\n",
      "23032/23032 [==============================] - 2s 101us/step - loss: 0.1146 - val_loss: 0.1177\n",
      "Epoch 61/150\n",
      "23032/23032 [==============================] - 2s 103us/step - loss: 0.1158 - val_loss: 0.1195\n",
      "Epoch 62/150\n",
      "23032/23032 [==============================] - 2s 102us/step - loss: 0.1144 - val_loss: 0.1185\n",
      "Evaluating model with testing data...\n",
      "4914/4914 [==============================] - 0s 15us/step\n",
      "Getting distribution of predictions and covariance matrix...\n",
      "      1 of 20\n",
      "      2 of 20\n",
      "      3 of 20\n",
      "      4 of 20\n",
      "      5 of 20\n",
      "      6 of 20\n",
      "      7 of 20\n",
      "      8 of 20\n",
      "      9 of 20\n",
      "      10 of 20\n",
      "      11 of 20\n",
      "      12 of 20\n",
      "      13 of 20\n",
      "      14 of 20\n",
      "      15 of 20\n",
      "      16 of 20\n",
      "      17 of 20\n",
      "      18 of 20\n",
      "      19 of 20\n",
      "      20 of 20\n",
      "Computing ensemble means...\n",
      "Computing mean squared error...\n",
      "Iteration 162\n",
      "Train on 23172 samples, validate on 4944 samples\n",
      "Epoch 1/150\n",
      "23172/23172 [==============================] - 2s 95us/step - loss: 0.3710 - val_loss: 0.2513\n",
      "Epoch 2/150\n",
      "23172/23172 [==============================] - 2s 98us/step - loss: 0.2286 - val_loss: 0.2164\n",
      "Epoch 3/150\n",
      "23172/23172 [==============================] - 2s 95us/step - loss: 0.2057 - val_loss: 0.2042\n",
      "Epoch 4/150\n",
      "23172/23172 [==============================] - 2s 93us/step - loss: 0.1909 - val_loss: 0.1895\n",
      "Epoch 5/150\n",
      "23172/23172 [==============================] - 2s 95us/step - loss: 0.1801 - val_loss: 0.1768\n",
      "Epoch 6/150\n",
      "23172/23172 [==============================] - 2s 77us/step - loss: 0.1744 - val_loss: 0.1763\n",
      "Epoch 7/150\n",
      "23172/23172 [==============================] - 2s 68us/step - loss: 0.1700 - val_loss: 0.1805\n",
      "Epoch 8/150\n",
      "23172/23172 [==============================] - 2s 94us/step - loss: 0.1682 - val_loss: 0.1624\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9/150\n",
      "23172/23172 [==============================] - 2s 108us/step - loss: 0.1614 - val_loss: 0.1623\n",
      "Epoch 10/150\n",
      "23172/23172 [==============================] - 3s 113us/step - loss: 0.1579 - val_loss: 0.1556\n",
      "Epoch 11/150\n",
      "23172/23172 [==============================] - 3s 112us/step - loss: 0.1556 - val_loss: 0.1558\n",
      "Epoch 12/150\n",
      "23172/23172 [==============================] - 3s 108us/step - loss: 0.1540 - val_loss: 0.1553\n",
      "Epoch 13/150\n",
      "23172/23172 [==============================] - 3s 111us/step - loss: 0.1535 - val_loss: 0.1554\n",
      "Epoch 14/150\n",
      "23172/23172 [==============================] - 3s 111us/step - loss: 0.1525 - val_loss: 0.1511\n",
      "Epoch 15/150\n",
      "23172/23172 [==============================] - 3s 110us/step - loss: 0.1507 - val_loss: 0.1536\n",
      "Epoch 16/150\n",
      "23172/23172 [==============================] - 3s 109us/step - loss: 0.1501 - val_loss: 0.1520\n",
      "Epoch 17/150\n",
      "23172/23172 [==============================] - 3s 110us/step - loss: 0.1499 - val_loss: 0.1516\n",
      "Epoch 18/150\n",
      "23172/23172 [==============================] - 3s 110us/step - loss: 0.1472 - val_loss: 0.1474\n",
      "Epoch 19/150\n",
      "23172/23172 [==============================] - 2s 106us/step - loss: 0.1471 - val_loss: 0.1516\n",
      "Epoch 20/150\n",
      "23172/23172 [==============================] - 2s 108us/step - loss: 0.1463 - val_loss: 0.1507\n",
      "Epoch 21/150\n",
      "23172/23172 [==============================] - 3s 109us/step - loss: 0.1468 - val_loss: 0.1530\n",
      "Epoch 22/150\n",
      "23172/23172 [==============================] - 2s 108us/step - loss: 0.1443 - val_loss: 0.1486\n",
      "Evaluating model with testing data...\n",
      "4944/4944 [==============================] - 0s 16us/step\n",
      "Getting distribution of predictions and covariance matrix...\n",
      "      1 of 20\n",
      "      2 of 20\n",
      "      3 of 20\n",
      "      4 of 20\n",
      "      5 of 20\n",
      "      6 of 20\n",
      "      7 of 20\n",
      "      8 of 20\n",
      "      9 of 20\n",
      "      10 of 20\n",
      "      11 of 20\n",
      "      12 of 20\n",
      "      13 of 20\n",
      "      14 of 20\n",
      "      15 of 20\n",
      "      16 of 20\n",
      "      17 of 20\n",
      "      18 of 20\n",
      "      19 of 20\n",
      "      20 of 20\n",
      "Computing ensemble means...\n",
      "Computing mean squared error...\n",
      "Iteration 163\n",
      "Train on 23312 samples, validate on 4974 samples\n",
      "Epoch 1/150\n",
      "23312/23312 [==============================] - 2s 104us/step - loss: 0.4742 - val_loss: 0.3864\n",
      "Epoch 2/150\n",
      "23312/23312 [==============================] - 2s 104us/step - loss: 0.3483 - val_loss: 0.3204\n",
      "Epoch 3/150\n",
      "23312/23312 [==============================] - 3s 109us/step - loss: 0.2970 - val_loss: 0.2699\n",
      "Epoch 4/150\n",
      "23312/23312 [==============================] - 3s 107us/step - loss: 0.2615 - val_loss: 0.2559\n",
      "Epoch 5/150\n",
      "23312/23312 [==============================] - 2s 106us/step - loss: 0.2490 - val_loss: 0.2460\n",
      "Epoch 6/150\n",
      "23312/23312 [==============================] - 3s 109us/step - loss: 0.2457 - val_loss: 0.2495\n",
      "Epoch 7/150\n",
      "23312/23312 [==============================] - 2s 105us/step - loss: 0.2435 - val_loss: 0.2451\n",
      "Epoch 8/150\n",
      "23312/23312 [==============================] - 2s 103us/step - loss: 0.2441 - val_loss: 0.2417\n",
      "Epoch 9/150\n",
      "23312/23312 [==============================] - 2s 98us/step - loss: 0.2416 - val_loss: 0.2421\n",
      "Epoch 10/150\n",
      "23312/23312 [==============================] - 2s 106us/step - loss: 0.2425 - val_loss: 0.2403\n",
      "Epoch 11/150\n",
      "23312/23312 [==============================] - 2s 102us/step - loss: 0.2418 - val_loss: 0.2408\n",
      "Epoch 12/150\n",
      "23312/23312 [==============================] - 2s 106us/step - loss: 0.2403 - val_loss: 0.2387\n",
      "Epoch 13/150\n",
      "23312/23312 [==============================] - 2s 107us/step - loss: 0.2394 - val_loss: 0.2413\n",
      "Epoch 14/150\n",
      "23312/23312 [==============================] - 3s 108us/step - loss: 0.2341 - val_loss: 0.2297\n",
      "Epoch 15/150\n",
      "23312/23312 [==============================] - 2s 106us/step - loss: 0.2253 - val_loss: 0.2278\n",
      "Epoch 16/150\n",
      "23312/23312 [==============================] - 2s 103us/step - loss: 0.2234 - val_loss: 0.2262\n",
      "Epoch 17/150\n",
      "23312/23312 [==============================] - 2s 103us/step - loss: 0.2206 - val_loss: 0.2216\n",
      "Epoch 18/150\n",
      "23312/23312 [==============================] - 3s 108us/step - loss: 0.2197 - val_loss: 0.2243\n",
      "Epoch 19/150\n",
      "23312/23312 [==============================] - 2s 103us/step - loss: 0.2205 - val_loss: 0.2159\n",
      "Epoch 20/150\n",
      "23312/23312 [==============================] - 2s 104us/step - loss: 0.2184 - val_loss: 0.2211\n",
      "Epoch 21/150\n",
      "23312/23312 [==============================] - 2s 104us/step - loss: 0.2175 - val_loss: 0.2161\n",
      "Epoch 22/150\n",
      "23312/23312 [==============================] - 2s 107us/step - loss: 0.2171 - val_loss: 0.2158\n",
      "Epoch 23/150\n",
      "23312/23312 [==============================] - 2s 100us/step - loss: 0.2181 - val_loss: 0.2175\n",
      "Epoch 24/150\n",
      "23312/23312 [==============================] - 2s 101us/step - loss: 0.2135 - val_loss: 0.2075\n",
      "Epoch 25/150\n",
      "23312/23312 [==============================] - 2s 100us/step - loss: 0.2031 - val_loss: 0.2044\n",
      "Epoch 26/150\n",
      "23312/23312 [==============================] - 2s 107us/step - loss: 0.2015 - val_loss: 0.2013\n",
      "Epoch 27/150\n",
      "23312/23312 [==============================] - 2s 101us/step - loss: 0.2006 - val_loss: 0.2002\n",
      "Epoch 28/150\n",
      "23312/23312 [==============================] - 2s 103us/step - loss: 0.1985 - val_loss: 0.1980\n",
      "Epoch 29/150\n",
      "23312/23312 [==============================] - 2s 100us/step - loss: 0.1986 - val_loss: 0.1970\n",
      "Epoch 30/150\n",
      "23312/23312 [==============================] - 2s 100us/step - loss: 0.1956 - val_loss: 0.1973\n",
      "Epoch 31/150\n",
      "23312/23312 [==============================] - 2s 104us/step - loss: 0.1951 - val_loss: 0.1938\n",
      "Epoch 32/150\n",
      "23312/23312 [==============================] - 2s 90us/step - loss: 0.1949 - val_loss: 0.1945\n",
      "Epoch 33/150\n",
      "23312/23312 [==============================] - 1s 60us/step - loss: 0.1945 - val_loss: 0.1981\n",
      "Epoch 34/150\n",
      "23312/23312 [==============================] - 2s 99us/step - loss: 0.1928 - val_loss: 0.1939\n",
      "Epoch 35/150\n",
      "23312/23312 [==============================] - 2s 101us/step - loss: 0.1950 - val_loss: 0.1971\n",
      "Evaluating model with testing data...\n",
      "4974/4974 [==============================] - 0s 15us/step\n",
      "Getting distribution of predictions and covariance matrix...\n",
      "      1 of 20\n",
      "      2 of 20\n",
      "      3 of 20\n",
      "      4 of 20\n",
      "      5 of 20\n",
      "      6 of 20\n",
      "      7 of 20\n",
      "      8 of 20\n",
      "      9 of 20\n",
      "      10 of 20\n",
      "      11 of 20\n",
      "      12 of 20\n",
      "      13 of 20\n",
      "      14 of 20\n",
      "      15 of 20\n",
      "      16 of 20\n",
      "      17 of 20\n",
      "      18 of 20\n",
      "      19 of 20\n",
      "      20 of 20\n",
      "Computing ensemble means...\n",
      "Computing mean squared error...\n",
      "Iteration 164\n",
      "Train on 23452 samples, validate on 5004 samples\n",
      "Epoch 1/150\n",
      "23452/23452 [==============================] - 2s 100us/step - loss: 0.4681 - val_loss: 0.3679\n",
      "Epoch 2/150\n",
      "23452/23452 [==============================] - 2s 100us/step - loss: 0.3293 - val_loss: 0.2988\n",
      "Epoch 3/150\n",
      "23452/23452 [==============================] - 2s 99us/step - loss: 0.2727 - val_loss: 0.2435\n",
      "Epoch 4/150\n",
      "23452/23452 [==============================] - 2s 97us/step - loss: 0.2347 - val_loss: 0.2356\n",
      "Epoch 5/150\n",
      "23452/23452 [==============================] - 2s 96us/step - loss: 0.2230 - val_loss: 0.2223\n",
      "Epoch 6/150\n",
      "23452/23452 [==============================] - 2s 98us/step - loss: 0.2201 - val_loss: 0.2228\n",
      "Epoch 7/150\n",
      "23452/23452 [==============================] - 2s 98us/step - loss: 0.2174 - val_loss: 0.2191\n",
      "Epoch 8/150\n",
      "23452/23452 [==============================] - 2s 96us/step - loss: 0.2112 - val_loss: 0.2148\n",
      "Epoch 9/150\n",
      "23452/23452 [==============================] - 2s 98us/step - loss: 0.2061 - val_loss: 0.2068\n",
      "Epoch 10/150\n",
      "23452/23452 [==============================] - 2s 97us/step - loss: 0.2028 - val_loss: 0.2045\n",
      "Epoch 11/150\n",
      "23452/23452 [==============================] - 2s 100us/step - loss: 0.1935 - val_loss: 0.1921\n",
      "Epoch 12/150\n",
      "23452/23452 [==============================] - 2s 95us/step - loss: 0.1834 - val_loss: 0.1819\n",
      "Epoch 13/150\n",
      "23452/23452 [==============================] - 2s 95us/step - loss: 0.1767 - val_loss: 0.1774\n",
      "Epoch 14/150\n",
      "23452/23452 [==============================] - 2s 92us/step - loss: 0.1706 - val_loss: 0.1693\n",
      "Epoch 15/150\n",
      "23452/23452 [==============================] - 2s 96us/step - loss: 0.1698 - val_loss: 0.1745\n",
      "Epoch 16/150\n",
      "23452/23452 [==============================] - 2s 101us/step - loss: 0.1670 - val_loss: 0.1711\n",
      "Epoch 17/150\n",
      "23452/23452 [==============================] - 3s 110us/step - loss: 0.1629 - val_loss: 0.1608\n",
      "Epoch 18/150\n",
      "23452/23452 [==============================] - 3s 114us/step - loss: 0.1586 - val_loss: 0.1620\n",
      "Epoch 19/150\n",
      "23452/23452 [==============================] - 3s 108us/step - loss: 0.1552 - val_loss: 0.1552\n",
      "Epoch 20/150\n",
      "23452/23452 [==============================] - 3s 111us/step - loss: 0.1513 - val_loss: 0.1578\n",
      "Epoch 21/150\n",
      "23452/23452 [==============================] - 3s 112us/step - loss: 0.1513 - val_loss: 0.1532\n",
      "Epoch 22/150\n",
      "23452/23452 [==============================] - 3s 111us/step - loss: 0.1502 - val_loss: 0.1555\n",
      "Epoch 23/150\n",
      "23452/23452 [==============================] - 3s 112us/step - loss: 0.1491 - val_loss: 0.1497\n",
      "Epoch 24/150\n",
      "23452/23452 [==============================] - 3s 109us/step - loss: 0.1467 - val_loss: 0.1530\n",
      "Epoch 25/150\n",
      "23452/23452 [==============================] - 3s 108us/step - loss: 0.1472 - val_loss: 0.1489\n",
      "Epoch 26/150\n",
      "23452/23452 [==============================] - 2s 103us/step - loss: 0.1464 - val_loss: 0.1494\n",
      "Epoch 27/150\n",
      "23452/23452 [==============================] - 3s 109us/step - loss: 0.1454 - val_loss: 0.1460\n",
      "Epoch 28/150\n",
      "23452/23452 [==============================] - 2s 101us/step - loss: 0.1438 - val_loss: 0.1472\n",
      "Epoch 29/150\n",
      "23452/23452 [==============================] - 3s 112us/step - loss: 0.1452 - val_loss: 0.1480\n",
      "Epoch 30/150\n",
      "23452/23452 [==============================] - 3s 108us/step - loss: 0.1438 - val_loss: 0.1479\n",
      "Epoch 31/150\n",
      "23452/23452 [==============================] - 3s 110us/step - loss: 0.1439 - val_loss: 0.1432\n",
      "Epoch 32/150\n",
      "23452/23452 [==============================] - 2s 105us/step - loss: 0.1416 - val_loss: 0.1438\n",
      "Epoch 33/150\n",
      "23452/23452 [==============================] - 3s 109us/step - loss: 0.1425 - val_loss: 0.1454\n",
      "Epoch 34/150\n",
      "23452/23452 [==============================] - 3s 109us/step - loss: 0.1420 - val_loss: 0.1441\n",
      "Epoch 35/150\n",
      "23452/23452 [==============================] - 3s 110us/step - loss: 0.1413 - val_loss: 0.1449\n",
      "Evaluating model with testing data...\n",
      "5004/5004 [==============================] - 0s 15us/step\n",
      "Getting distribution of predictions and covariance matrix...\n",
      "      1 of 20\n",
      "      2 of 20\n",
      "      3 of 20\n",
      "      4 of 20\n",
      "      5 of 20\n",
      "      6 of 20\n",
      "      7 of 20\n",
      "      8 of 20\n",
      "      9 of 20\n",
      "      10 of 20\n",
      "      11 of 20\n",
      "      12 of 20\n",
      "      13 of 20\n",
      "      14 of 20\n",
      "      15 of 20\n",
      "      16 of 20\n",
      "      17 of 20\n",
      "      18 of 20\n",
      "      19 of 20\n",
      "      20 of 20\n",
      "Computing ensemble means...\n",
      "Computing mean squared error...\n",
      "Iteration 165\n",
      "Train on 23592 samples, validate on 5034 samples\n",
      "Epoch 1/150\n",
      "23592/23592 [==============================] - 3s 110us/step - loss: 0.3713 - val_loss: 0.2493\n",
      "Epoch 2/150\n",
      "23592/23592 [==============================] - 3s 107us/step - loss: 0.2246 - val_loss: 0.2132\n",
      "Epoch 3/150\n",
      "23592/23592 [==============================] - 3s 107us/step - loss: 0.2002 - val_loss: 0.1956\n",
      "Epoch 4/150\n",
      "23592/23592 [==============================] - 2s 105us/step - loss: 0.1865 - val_loss: 0.1772\n",
      "Epoch 5/150\n",
      "23592/23592 [==============================] - 2s 100us/step - loss: 0.1681 - val_loss: 0.1683\n",
      "Epoch 6/150\n",
      "23592/23592 [==============================] - 3s 113us/step - loss: 0.1591 - val_loss: 0.1570\n",
      "Epoch 7/150\n",
      "23592/23592 [==============================] - 2s 106us/step - loss: 0.1547 - val_loss: 0.1532\n",
      "Epoch 8/150\n",
      "23592/23592 [==============================] - 2s 102us/step - loss: 0.1510 - val_loss: 0.1537\n",
      "Epoch 9/150\n",
      "23592/23592 [==============================] - 3s 108us/step - loss: 0.1481 - val_loss: 0.1520\n",
      "Epoch 10/150\n",
      "23592/23592 [==============================] - 1s 60us/step - loss: 0.1465 - val_loss: 0.1483\n",
      "Epoch 11/150\n",
      "23592/23592 [==============================] - 2s 102us/step - loss: 0.1424 - val_loss: 0.1450\n",
      "Epoch 12/150\n",
      "23592/23592 [==============================] - 2s 103us/step - loss: 0.1405 - val_loss: 0.1419\n",
      "Epoch 13/150\n",
      "23592/23592 [==============================] - 2s 104us/step - loss: 0.1368 - val_loss: 0.1406\n",
      "Epoch 14/150\n",
      "23592/23592 [==============================] - 2s 104us/step - loss: 0.1367 - val_loss: 0.1365\n",
      "Epoch 15/150\n",
      "23592/23592 [==============================] - 3s 107us/step - loss: 0.1354 - val_loss: 0.1383\n",
      "Epoch 16/150\n",
      "23592/23592 [==============================] - 2s 105us/step - loss: 0.1344 - val_loss: 0.1343\n",
      "Epoch 17/150\n",
      "23592/23592 [==============================] - 2s 104us/step - loss: 0.1324 - val_loss: 0.1336\n",
      "Epoch 18/150\n",
      "23592/23592 [==============================] - 2s 105us/step - loss: 0.1298 - val_loss: 0.1281\n",
      "Epoch 19/150\n",
      "23592/23592 [==============================] - 2s 105us/step - loss: 0.1295 - val_loss: 0.1301\n",
      "Epoch 20/150\n",
      "23592/23592 [==============================] - 3s 108us/step - loss: 0.1274 - val_loss: 0.1282\n",
      "Epoch 21/150\n",
      "23592/23592 [==============================] - 3s 106us/step - loss: 0.1271 - val_loss: 0.1326\n",
      "Epoch 22/150\n",
      "23592/23592 [==============================] - 3s 108us/step - loss: 0.1265 - val_loss: 0.1282\n",
      "Evaluating model with testing data...\n",
      "5034/5034 [==============================] - 0s 16us/step\n",
      "Getting distribution of predictions and covariance matrix...\n",
      "      1 of 20\n",
      "      2 of 20\n",
      "      3 of 20\n",
      "      4 of 20\n",
      "      5 of 20\n",
      "      6 of 20\n",
      "      7 of 20\n",
      "      8 of 20\n",
      "      9 of 20\n",
      "      10 of 20\n",
      "      11 of 20\n",
      "      12 of 20\n",
      "      13 of 20\n",
      "      14 of 20\n",
      "      15 of 20\n",
      "      16 of 20\n",
      "      17 of 20\n",
      "      18 of 20\n",
      "      19 of 20\n",
      "      20 of 20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|          | 0/20 [00:00<?, ?it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing ensemble means...\n",
      "Computing mean squared error...\n",
      "Getting distribution of predictions...\n",
      "      1 of 20\n",
      "1600/1600 [==============================] - 0s 27us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  5%|▌         | 1/20 [00:29<09:25, 29.75s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      2 of 20\n",
      "1600/1600 [==============================] - 0s 29us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 10%|█         | 2/20 [00:59<08:54, 29.71s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      3 of 20\n",
      "1600/1600 [==============================] - 0s 29us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 15%|█▌        | 3/20 [01:28<08:22, 29.54s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      4 of 20\n",
      "1600/1600 [==============================] - 0s 30us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 20%|██        | 4/20 [01:58<07:52, 29.53s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      5 of 20\n",
      "1600/1600 [==============================] - 0s 38us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 25%|██▌       | 5/20 [02:27<07:23, 29.57s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      6 of 20\n",
      "1600/1600 [==============================] - 0s 29us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 30%|███       | 6/20 [02:57<06:55, 29.66s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      7 of 20\n",
      "1600/1600 [==============================] - 0s 29us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 35%|███▌      | 7/20 [03:27<06:25, 29.65s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      8 of 20\n",
      "1600/1600 [==============================] - 0s 28us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 40%|████      | 8/20 [03:56<05:55, 29.64s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      9 of 20\n",
      "1600/1600 [==============================] - 0s 30us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 45%|████▌     | 9/20 [04:26<05:26, 29.67s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      10 of 20\n",
      "1600/1600 [==============================] - 0s 29us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 50%|█████     | 10/20 [04:56<04:56, 29.67s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      11 of 20\n",
      "1600/1600 [==============================] - 0s 28us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 55%|█████▌    | 11/20 [05:25<04:26, 29.59s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      12 of 20\n",
      "1600/1600 [==============================] - 0s 29us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 60%|██████    | 12/20 [05:54<03:56, 29.52s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      13 of 20\n",
      "1600/1600 [==============================] - 0s 29us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 65%|██████▌   | 13/20 [06:24<03:27, 29.62s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      14 of 20\n",
      "1600/1600 [==============================] - 0s 30us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 70%|███████   | 14/20 [06:54<02:57, 29.57s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      15 of 20\n",
      "1600/1600 [==============================] - 0s 28us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 75%|███████▌  | 15/20 [07:24<02:28, 29.63s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      16 of 20\n",
      "1600/1600 [==============================] - 0s 29us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 80%|████████  | 16/20 [07:53<01:57, 29.47s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      17 of 20\n",
      "1600/1600 [==============================] - 0s 29us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 85%|████████▌ | 17/20 [08:22<01:28, 29.47s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      18 of 20\n",
      "1600/1600 [==============================] - 0s 29us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 90%|█████████ | 18/20 [08:52<00:59, 29.57s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      19 of 20\n",
      "1600/1600 [==============================] - 0s 30us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 95%|█████████▌| 19/20 [09:22<00:29, 29.61s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      20 of 20\n",
      "1600/1600 [==============================] - 0s 29us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 20/20 [09:51<00:00, 29.57s/it]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing ensemble predictions...\n",
      "Iteration 166\n",
      "Train on 23732 samples, validate on 5064 samples\n",
      "Epoch 1/150\n",
      "23732/23732 [==============================] - 3s 107us/step - loss: 0.3085 - val_loss: 0.2272\n",
      "Epoch 2/150\n",
      "23732/23732 [==============================] - 3s 106us/step - loss: 0.2052 - val_loss: 0.1874\n",
      "Epoch 3/150\n",
      "23732/23732 [==============================] - 2s 104us/step - loss: 0.1759 - val_loss: 0.1685\n",
      "Epoch 4/150\n",
      "23732/23732 [==============================] - 3s 109us/step - loss: 0.1609 - val_loss: 0.1600\n",
      "Epoch 5/150\n",
      "23732/23732 [==============================] - 3s 112us/step - loss: 0.1490 - val_loss: 0.1493\n",
      "Epoch 6/150\n",
      "23732/23732 [==============================] - 3s 107us/step - loss: 0.1418 - val_loss: 0.1422\n",
      "Epoch 7/150\n",
      "23732/23732 [==============================] - 3s 106us/step - loss: 0.1360 - val_loss: 0.1392\n",
      "Epoch 8/150\n",
      "23732/23732 [==============================] - 2s 105us/step - loss: 0.1337 - val_loss: 0.1345\n",
      "Epoch 9/150\n",
      "23732/23732 [==============================] - 3s 110us/step - loss: 0.1311 - val_loss: 0.1325\n",
      "Epoch 10/150\n",
      "23732/23732 [==============================] - 3s 108us/step - loss: 0.1292 - val_loss: 0.1321\n",
      "Epoch 11/150\n",
      "23732/23732 [==============================] - 3s 110us/step - loss: 0.1269 - val_loss: 0.1313\n",
      "Epoch 12/150\n",
      "23732/23732 [==============================] - 2s 103us/step - loss: 0.1255 - val_loss: 0.1281\n",
      "Epoch 13/150\n",
      "23732/23732 [==============================] - 3s 111us/step - loss: 0.1244 - val_loss: 0.1270\n",
      "Epoch 14/150\n",
      "23732/23732 [==============================] - 3s 109us/step - loss: 0.1223 - val_loss: 0.1262\n",
      "Epoch 15/150\n",
      "23732/23732 [==============================] - 3s 107us/step - loss: 0.1204 - val_loss: 0.1250\n",
      "Epoch 16/150\n",
      "23732/23732 [==============================] - 3s 107us/step - loss: 0.1186 - val_loss: 0.1239\n",
      "Epoch 17/150\n",
      "23732/23732 [==============================] - 3s 108us/step - loss: 0.1166 - val_loss: 0.1174\n",
      "Epoch 18/150\n",
      "23732/23732 [==============================] - 2s 104us/step - loss: 0.1156 - val_loss: 0.1196\n",
      "Epoch 19/150\n",
      "23732/23732 [==============================] - 3s 110us/step - loss: 0.1145 - val_loss: 0.1150\n",
      "Epoch 20/150\n",
      "23732/23732 [==============================] - 3s 109us/step - loss: 0.1128 - val_loss: 0.1165\n",
      "Epoch 21/150\n",
      "23732/23732 [==============================] - 3s 110us/step - loss: 0.1124 - val_loss: 0.1145\n",
      "Epoch 22/150\n",
      "23732/23732 [==============================] - 3s 110us/step - loss: 0.1097 - val_loss: 0.1139\n",
      "Epoch 23/150\n",
      "23732/23732 [==============================] - 3s 108us/step - loss: 0.1106 - val_loss: 0.1113\n",
      "Epoch 24/150\n",
      "23732/23732 [==============================] - 3s 106us/step - loss: 0.1105 - val_loss: 0.1112\n",
      "Epoch 25/150\n",
      "23732/23732 [==============================] - 3s 110us/step - loss: 0.1078 - val_loss: 0.1099\n",
      "Epoch 26/150\n",
      "23732/23732 [==============================] - 2s 103us/step - loss: 0.1071 - val_loss: 0.1081\n",
      "Epoch 27/150\n",
      "23732/23732 [==============================] - 2s 104us/step - loss: 0.1072 - val_loss: 0.1112\n",
      "Epoch 28/150\n",
      "23732/23732 [==============================] - 2s 102us/step - loss: 0.1056 - val_loss: 0.1061\n",
      "Epoch 29/150\n",
      "23732/23732 [==============================] - 3s 106us/step - loss: 0.1062 - val_loss: 0.1073\n",
      "Epoch 30/150\n",
      "23732/23732 [==============================] - 2s 96us/step - loss: 0.1055 - val_loss: 0.1083\n",
      "Epoch 31/150\n",
      "23732/23732 [==============================] - 2s 102us/step - loss: 0.1035 - val_loss: 0.1076\n",
      "Epoch 32/150\n",
      "23732/23732 [==============================] - 3s 107us/step - loss: 0.1049 - val_loss: 0.1069\n",
      "Evaluating model with testing data...\n",
      "5064/5064 [==============================] - 0s 16us/step\n",
      "Getting distribution of predictions and covariance matrix...\n",
      "      1 of 20\n",
      "      2 of 20\n",
      "      3 of 20\n",
      "      4 of 20\n",
      "      5 of 20\n",
      "      6 of 20\n",
      "      7 of 20\n",
      "      8 of 20\n",
      "      9 of 20\n",
      "      10 of 20\n",
      "      11 of 20\n",
      "      12 of 20\n",
      "      13 of 20\n",
      "      14 of 20\n",
      "      15 of 20\n",
      "      16 of 20\n",
      "      17 of 20\n",
      "      18 of 20\n",
      "      19 of 20\n",
      "      20 of 20\n",
      "Computing ensemble means...\n",
      "Computing mean squared error...\n",
      "Iteration 167\n",
      "Train on 23872 samples, validate on 5094 samples\n",
      "Epoch 1/150\n",
      "23872/23872 [==============================] - 2s 104us/step - loss: 0.3760 - val_loss: 0.2546\n",
      "Epoch 2/150\n",
      "23872/23872 [==============================] - 2s 102us/step - loss: 0.2288 - val_loss: 0.2208\n",
      "Epoch 3/150\n",
      "23872/23872 [==============================] - 3s 105us/step - loss: 0.2071 - val_loss: 0.1997\n",
      "Epoch 4/150\n",
      "23872/23872 [==============================] - 3s 106us/step - loss: 0.1865 - val_loss: 0.1799\n",
      "Epoch 5/150\n",
      "23872/23872 [==============================] - 1s 60us/step - loss: 0.1714 - val_loss: 0.1732\n",
      "Epoch 6/150\n",
      "23872/23872 [==============================] - 2s 87us/step - loss: 0.1661 - val_loss: 0.1671\n",
      "Epoch 7/150\n",
      "23872/23872 [==============================] - 2s 95us/step - loss: 0.1614 - val_loss: 0.1622\n",
      "Epoch 8/150\n",
      "23872/23872 [==============================] - 2s 102us/step - loss: 0.1581 - val_loss: 0.1656\n",
      "Epoch 9/150\n",
      "23872/23872 [==============================] - 2s 102us/step - loss: 0.1567 - val_loss: 0.1581\n",
      "Epoch 10/150\n",
      "23872/23872 [==============================] - 2s 103us/step - loss: 0.1535 - val_loss: 0.1529\n",
      "Epoch 11/150\n",
      "23872/23872 [==============================] - 2s 104us/step - loss: 0.1470 - val_loss: 0.1480\n",
      "Epoch 12/150\n",
      "23872/23872 [==============================] - 2s 100us/step - loss: 0.1430 - val_loss: 0.1495\n",
      "Epoch 13/150\n",
      "23872/23872 [==============================] - 2s 98us/step - loss: 0.1408 - val_loss: 0.1415\n",
      "Epoch 14/150\n",
      "23872/23872 [==============================] - 2s 98us/step - loss: 0.1393 - val_loss: 0.1447\n",
      "Epoch 15/150\n",
      "23872/23872 [==============================] - 2s 100us/step - loss: 0.1378 - val_loss: 0.1375\n",
      "Epoch 16/150\n",
      "23872/23872 [==============================] - 2s 101us/step - loss: 0.1346 - val_loss: 0.1374\n",
      "Epoch 17/150\n",
      "23872/23872 [==============================] - 2s 96us/step - loss: 0.1310 - val_loss: 0.1328\n",
      "Epoch 18/150\n",
      "23872/23872 [==============================] - 2s 98us/step - loss: 0.1289 - val_loss: 0.1286\n",
      "Epoch 19/150\n",
      "23872/23872 [==============================] - 2s 101us/step - loss: 0.1256 - val_loss: 0.1273\n",
      "Epoch 20/150\n",
      "23872/23872 [==============================] - 2s 98us/step - loss: 0.1223 - val_loss: 0.1234\n",
      "Epoch 21/150\n",
      "23872/23872 [==============================] - 2s 94us/step - loss: 0.1215 - val_loss: 0.1256\n",
      "Epoch 22/150\n",
      "23872/23872 [==============================] - 2s 103us/step - loss: 0.1195 - val_loss: 0.1239\n",
      "Epoch 23/150\n",
      "23872/23872 [==============================] - 2s 99us/step - loss: 0.1167 - val_loss: 0.1165\n",
      "Epoch 24/150\n",
      "23872/23872 [==============================] - 2s 96us/step - loss: 0.1162 - val_loss: 0.1191\n",
      "Epoch 25/150\n",
      "23872/23872 [==============================] - 2s 100us/step - loss: 0.1156 - val_loss: 0.1164\n",
      "Epoch 26/150\n",
      "23872/23872 [==============================] - 2s 99us/step - loss: 0.1145 - val_loss: 0.1188\n",
      "Epoch 27/150\n",
      "23872/23872 [==============================] - 2s 98us/step - loss: 0.1143 - val_loss: 0.1240\n",
      "Epoch 28/150\n",
      "23872/23872 [==============================] - 2s 99us/step - loss: 0.1130 - val_loss: 0.1149\n",
      "Epoch 29/150\n",
      "23872/23872 [==============================] - 2s 96us/step - loss: 0.1126 - val_loss: 0.1155\n",
      "Epoch 30/150\n",
      "23872/23872 [==============================] - 2s 102us/step - loss: 0.1120 - val_loss: 0.1130\n",
      "Epoch 31/150\n",
      "23872/23872 [==============================] - 2s 93us/step - loss: 0.1108 - val_loss: 0.1148\n",
      "Epoch 32/150\n",
      "23872/23872 [==============================] - 2s 97us/step - loss: 0.1115 - val_loss: 0.1150\n",
      "Epoch 33/150\n",
      "23872/23872 [==============================] - 2s 98us/step - loss: 0.1112 - val_loss: 0.1133\n",
      "Epoch 34/150\n",
      "23872/23872 [==============================] - 2s 98us/step - loss: 0.1113 - val_loss: 0.1129\n",
      "Epoch 35/150\n",
      "23872/23872 [==============================] - 2s 99us/step - loss: 0.1106 - val_loss: 0.1141\n",
      "Epoch 36/150\n",
      "23872/23872 [==============================] - 2s 96us/step - loss: 0.1079 - val_loss: 0.1082\n",
      "Epoch 37/150\n",
      "23872/23872 [==============================] - 2s 99us/step - loss: 0.1072 - val_loss: 0.1104\n",
      "Epoch 38/150\n",
      "23872/23872 [==============================] - 2s 98us/step - loss: 0.1063 - val_loss: 0.1092\n",
      "Epoch 39/150\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23872/23872 [==============================] - 3s 111us/step - loss: 0.1057 - val_loss: 0.1072\n",
      "Epoch 40/150\n",
      "23872/23872 [==============================] - 3s 108us/step - loss: 0.1043 - val_loss: 0.1062\n",
      "Epoch 41/150\n",
      "23872/23872 [==============================] - 3s 107us/step - loss: 0.1039 - val_loss: 0.1072\n",
      "Epoch 42/150\n",
      "23872/23872 [==============================] - 3s 107us/step - loss: 0.1025 - val_loss: 0.1081\n",
      "Epoch 43/150\n",
      "23872/23872 [==============================] - 3s 105us/step - loss: 0.1020 - val_loss: 0.1043\n",
      "Epoch 44/150\n",
      "23872/23872 [==============================] - 3s 111us/step - loss: 0.1017 - val_loss: 0.1045\n",
      "Epoch 45/150\n",
      "23872/23872 [==============================] - 3s 112us/step - loss: 0.1024 - val_loss: 0.1034\n",
      "Epoch 46/150\n",
      "23872/23872 [==============================] - 3s 108us/step - loss: 0.1007 - val_loss: 0.1062\n",
      "Epoch 47/150\n",
      "23872/23872 [==============================] - 3s 110us/step - loss: 0.1002 - val_loss: 0.1044\n",
      "Epoch 48/150\n",
      "23872/23872 [==============================] - 3s 112us/step - loss: 0.1008 - val_loss: 0.1030\n",
      "Epoch 49/150\n",
      "23872/23872 [==============================] - 3s 107us/step - loss: 0.1002 - val_loss: 0.1047\n",
      "Epoch 50/150\n",
      "23872/23872 [==============================] - 3s 108us/step - loss: 0.1000 - val_loss: 0.0999\n",
      "Epoch 51/150\n",
      "23872/23872 [==============================] - 3s 110us/step - loss: 0.1001 - val_loss: 0.1025\n",
      "Epoch 52/150\n",
      "23872/23872 [==============================] - 3s 111us/step - loss: 0.0998 - val_loss: 0.1030\n",
      "Epoch 53/150\n",
      "23872/23872 [==============================] - 3s 105us/step - loss: 0.0989 - val_loss: 0.1035\n",
      "Epoch 54/150\n",
      "23872/23872 [==============================] - 2s 99us/step - loss: 0.0988 - val_loss: 0.1022\n",
      "Evaluating model with testing data...\n",
      "5094/5094 [==============================] - 0s 15us/step\n",
      "Getting distribution of predictions and covariance matrix...\n",
      "      1 of 20\n",
      "      2 of 20\n",
      "      3 of 20\n",
      "      4 of 20\n",
      "      5 of 20\n",
      "      6 of 20\n",
      "      7 of 20\n",
      "      8 of 20\n",
      "      9 of 20\n",
      "      10 of 20\n",
      "      11 of 20\n",
      "      12 of 20\n",
      "      13 of 20\n",
      "      14 of 20\n",
      "      15 of 20\n",
      "      16 of 20\n",
      "      17 of 20\n",
      "      18 of 20\n",
      "      19 of 20\n",
      "      20 of 20\n",
      "Computing ensemble means...\n",
      "Computing mean squared error...\n",
      "Iteration 168\n",
      "Train on 24012 samples, validate on 5124 samples\n",
      "Epoch 1/150\n",
      "24012/24012 [==============================] - 3s 107us/step - loss: 0.4879 - val_loss: 0.3396\n",
      "Epoch 2/150\n",
      "24012/24012 [==============================] - 3s 107us/step - loss: 0.2987 - val_loss: 0.2774\n",
      "Epoch 3/150\n",
      "24012/24012 [==============================] - 2s 103us/step - loss: 0.2659 - val_loss: 0.2579\n",
      "Epoch 4/150\n",
      "24012/24012 [==============================] - 3s 106us/step - loss: 0.2420 - val_loss: 0.2256\n",
      "Epoch 5/150\n",
      "24012/24012 [==============================] - 2s 101us/step - loss: 0.2174 - val_loss: 0.2110\n",
      "Epoch 6/150\n",
      "24012/24012 [==============================] - 2s 103us/step - loss: 0.2006 - val_loss: 0.2007\n",
      "Epoch 7/150\n",
      "24012/24012 [==============================] - 3s 106us/step - loss: 0.1940 - val_loss: 0.1908\n",
      "Epoch 8/150\n",
      "24012/24012 [==============================] - 3s 107us/step - loss: 0.1870 - val_loss: 0.1882\n",
      "Epoch 9/150\n",
      "24012/24012 [==============================] - 3s 104us/step - loss: 0.1847 - val_loss: 0.1875\n",
      "Epoch 10/150\n",
      "24012/24012 [==============================] - 3s 105us/step - loss: 0.1841 - val_loss: 0.1850\n",
      "Epoch 11/150\n",
      "24012/24012 [==============================] - 2s 104us/step - loss: 0.1821 - val_loss: 0.1836\n",
      "Epoch 12/150\n",
      "24012/24012 [==============================] - 3s 106us/step - loss: 0.1803 - val_loss: 0.1833\n",
      "Epoch 13/150\n",
      "24012/24012 [==============================] - 3s 107us/step - loss: 0.1809 - val_loss: 0.1833\n",
      "Epoch 14/150\n",
      "24012/24012 [==============================] - 2s 100us/step - loss: 0.1782 - val_loss: 0.1794\n",
      "Epoch 15/150\n",
      "24012/24012 [==============================] - 2s 103us/step - loss: 0.1756 - val_loss: 0.1767\n",
      "Epoch 16/150\n",
      "24012/24012 [==============================] - 2s 100us/step - loss: 0.1718 - val_loss: 0.1745\n",
      "Epoch 17/150\n",
      "24012/24012 [==============================] - 3s 104us/step - loss: 0.1687 - val_loss: 0.1670\n",
      "Epoch 18/150\n",
      "24012/24012 [==============================] - 2s 102us/step - loss: 0.1658 - val_loss: 0.1653\n",
      "Epoch 19/150\n",
      "24012/24012 [==============================] - 2s 100us/step - loss: 0.1659 - val_loss: 0.1646\n",
      "Epoch 20/150\n",
      "24012/24012 [==============================] - 2s 96us/step - loss: 0.1643 - val_loss: 0.1661\n",
      "Epoch 21/150\n",
      "24012/24012 [==============================] - 3s 107us/step - loss: 0.1631 - val_loss: 0.1667\n",
      "Epoch 22/150\n",
      "24012/24012 [==============================] - 2s 102us/step - loss: 0.1611 - val_loss: 0.1636\n",
      "Epoch 23/150\n",
      "24012/24012 [==============================] - 2s 101us/step - loss: 0.1617 - val_loss: 0.1606\n",
      "Epoch 24/150\n",
      "24012/24012 [==============================] - 2s 101us/step - loss: 0.1593 - val_loss: 0.1613\n",
      "Epoch 25/150\n",
      "24012/24012 [==============================] - 2s 102us/step - loss: 0.1591 - val_loss: 0.1593\n",
      "Epoch 26/150\n",
      "24012/24012 [==============================] - 2s 99us/step - loss: 0.1581 - val_loss: 0.1600\n",
      "Epoch 27/150\n",
      "24012/24012 [==============================] - 2s 104us/step - loss: 0.1568 - val_loss: 0.1640\n",
      "Epoch 28/150\n",
      "24012/24012 [==============================] - 2s 103us/step - loss: 0.1557 - val_loss: 0.1525\n",
      "Epoch 29/150\n",
      "24012/24012 [==============================] - 2s 98us/step - loss: 0.1478 - val_loss: 0.1459\n",
      "Epoch 30/150\n",
      "24012/24012 [==============================] - 2s 101us/step - loss: 0.1448 - val_loss: 0.1493\n",
      "Epoch 31/150\n",
      "24012/24012 [==============================] - 2s 100us/step - loss: 0.1443 - val_loss: 0.1495\n",
      "Epoch 32/150\n",
      "24012/24012 [==============================] - 2s 99us/step - loss: 0.1447 - val_loss: 0.1471\n",
      "Epoch 33/150\n",
      "24012/24012 [==============================] - 2s 99us/step - loss: 0.1443 - val_loss: 0.1449\n",
      "Epoch 34/150\n",
      "24012/24012 [==============================] - 2s 100us/step - loss: 0.1424 - val_loss: 0.1427\n",
      "Epoch 35/150\n",
      "24012/24012 [==============================] - 2s 100us/step - loss: 0.1399 - val_loss: 0.1412\n",
      "Epoch 36/150\n",
      "24012/24012 [==============================] - 2s 95us/step - loss: 0.1384 - val_loss: 0.1403\n",
      "Epoch 37/150\n",
      "24012/24012 [==============================] - 2s 97us/step - loss: 0.1371 - val_loss: 0.1387\n",
      "Epoch 38/150\n",
      "24012/24012 [==============================] - 2s 100us/step - loss: 0.1374 - val_loss: 0.1379\n",
      "Epoch 39/150\n",
      "24012/24012 [==============================] - 2s 97us/step - loss: 0.1365 - val_loss: 0.1393\n",
      "Epoch 40/150\n",
      "24012/24012 [==============================] - 2s 99us/step - loss: 0.1352 - val_loss: 0.1366\n",
      "Epoch 41/150\n",
      "24012/24012 [==============================] - 2s 98us/step - loss: 0.1351 - val_loss: 0.1376\n",
      "Epoch 42/150\n",
      "24012/24012 [==============================] - 2s 97us/step - loss: 0.1343 - val_loss: 0.1397\n",
      "Epoch 43/150\n",
      "24012/24012 [==============================] - 2s 99us/step - loss: 0.1342 - val_loss: 0.1368\n",
      "Epoch 44/150\n",
      "24012/24012 [==============================] - 2s 98us/step - loss: 0.1350 - val_loss: 0.1352\n",
      "Epoch 45/150\n",
      "24012/24012 [==============================] - 2s 99us/step - loss: 0.1346 - val_loss: 0.1378\n",
      "Epoch 46/150\n",
      "24012/24012 [==============================] - 2s 95us/step - loss: 0.1347 - val_loss: 0.1389\n",
      "Epoch 47/150\n",
      "24012/24012 [==============================] - 2s 102us/step - loss: 0.1330 - val_loss: 0.1362\n",
      "Epoch 48/150\n",
      "24012/24012 [==============================] - 2s 98us/step - loss: 0.1333 - val_loss: 0.1356\n",
      "Evaluating model with testing data...\n",
      "5124/5124 [==============================] - 0s 17us/step\n",
      "Getting distribution of predictions and covariance matrix...\n",
      "      1 of 20\n",
      "      2 of 20\n",
      "      3 of 20\n",
      "      4 of 20\n",
      "      5 of 20\n",
      "      6 of 20\n",
      "      7 of 20\n",
      "      8 of 20\n",
      "      9 of 20\n",
      "      10 of 20\n",
      "      11 of 20\n",
      "      12 of 20\n",
      "      13 of 20\n",
      "      14 of 20\n",
      "      15 of 20\n",
      "      16 of 20\n",
      "      17 of 20\n",
      "      18 of 20\n",
      "      19 of 20\n",
      "      20 of 20\n",
      "Computing ensemble means...\n",
      "Computing mean squared error...\n",
      "Iteration 169\n",
      "Train on 24152 samples, validate on 5154 samples\n",
      "Epoch 1/150\n",
      "24152/24152 [==============================] - 2s 98us/step - loss: 0.3841 - val_loss: 0.2842\n",
      "Epoch 2/150\n",
      "24152/24152 [==============================] - 3s 105us/step - loss: 0.2548 - val_loss: 0.2366\n",
      "Epoch 3/150\n",
      "24152/24152 [==============================] - 3s 112us/step - loss: 0.2220 - val_loss: 0.2116\n",
      "Epoch 4/150\n",
      "24152/24152 [==============================] - 3s 113us/step - loss: 0.2027 - val_loss: 0.1982\n",
      "Epoch 5/150\n",
      "24152/24152 [==============================] - 3s 111us/step - loss: 0.1875 - val_loss: 0.1870\n",
      "Epoch 6/150\n",
      "24152/24152 [==============================] - 3s 112us/step - loss: 0.1801 - val_loss: 0.1769\n",
      "Epoch 7/150\n",
      "24152/24152 [==============================] - 3s 110us/step - loss: 0.1751 - val_loss: 0.1748\n",
      "Epoch 8/150\n",
      "24152/24152 [==============================] - 3s 111us/step - loss: 0.1684 - val_loss: 0.1684\n",
      "Epoch 9/150\n",
      "24152/24152 [==============================] - 3s 107us/step - loss: 0.1656 - val_loss: 0.1657\n",
      "Epoch 10/150\n",
      "24152/24152 [==============================] - 3s 109us/step - loss: 0.1608 - val_loss: 0.1633\n",
      "Epoch 11/150\n",
      "24152/24152 [==============================] - 3s 106us/step - loss: 0.1600 - val_loss: 0.1638\n",
      "Epoch 12/150\n",
      "24152/24152 [==============================] - 3s 109us/step - loss: 0.1580 - val_loss: 0.1616\n",
      "Epoch 13/150\n",
      "24152/24152 [==============================] - 3s 108us/step - loss: 0.1561 - val_loss: 0.1572\n",
      "Epoch 14/150\n",
      "24152/24152 [==============================] - 3s 110us/step - loss: 0.1546 - val_loss: 0.1592\n",
      "Epoch 15/150\n",
      "24152/24152 [==============================] - 3s 109us/step - loss: 0.1570 - val_loss: 0.1564\n",
      "Epoch 16/150\n",
      "24152/24152 [==============================] - 3s 108us/step - loss: 0.1546 - val_loss: 0.1541\n",
      "Epoch 17/150\n",
      "24152/24152 [==============================] - 3s 107us/step - loss: 0.1535 - val_loss: 0.1548\n",
      "Epoch 18/150\n",
      "24152/24152 [==============================] - 3s 109us/step - loss: 0.1521 - val_loss: 0.1568\n",
      "Epoch 19/150\n",
      "24152/24152 [==============================] - 3s 107us/step - loss: 0.1532 - val_loss: 0.1526\n",
      "Epoch 20/150\n",
      "24152/24152 [==============================] - 3s 109us/step - loss: 0.1509 - val_loss: 0.1587\n",
      "Epoch 21/150\n",
      "24152/24152 [==============================] - 3s 107us/step - loss: 0.1504 - val_loss: 0.1539\n",
      "Epoch 22/150\n",
      "24152/24152 [==============================] - 3s 108us/step - loss: 0.1505 - val_loss: 0.1529\n",
      "Epoch 23/150\n",
      "24152/24152 [==============================] - 3s 105us/step - loss: 0.1476 - val_loss: 0.1530\n",
      "Evaluating model with testing data...\n",
      "5154/5154 [==============================] - 0s 16us/step\n",
      "Getting distribution of predictions and covariance matrix...\n",
      "      1 of 20\n",
      "      2 of 20\n",
      "      3 of 20\n",
      "      4 of 20\n",
      "      5 of 20\n",
      "      6 of 20\n",
      "      7 of 20\n",
      "      8 of 20\n",
      "      9 of 20\n",
      "      10 of 20\n",
      "      11 of 20\n",
      "      12 of 20\n",
      "      13 of 20\n",
      "      14 of 20\n",
      "      15 of 20\n",
      "      16 of 20\n",
      "      17 of 20\n",
      "      18 of 20\n",
      "      19 of 20\n",
      "      20 of 20\n",
      "Computing ensemble means...\n",
      "Computing mean squared error...\n",
      "Iteration 170\n",
      "Train on 24292 samples, validate on 5184 samples\n",
      "Epoch 1/150\n",
      "24292/24292 [==============================] - 3s 105us/step - loss: 0.3606 - val_loss: 0.2491\n",
      "Epoch 2/150\n",
      "24292/24292 [==============================] - 2s 102us/step - loss: 0.2219 - val_loss: 0.2090\n",
      "Epoch 3/150\n",
      "24292/24292 [==============================] - 3s 106us/step - loss: 0.1968 - val_loss: 0.1930\n",
      "Epoch 4/150\n",
      "24292/24292 [==============================] - 2s 102us/step - loss: 0.1813 - val_loss: 0.1786\n",
      "Epoch 5/150\n",
      "24292/24292 [==============================] - 3s 104us/step - loss: 0.1686 - val_loss: 0.1701\n",
      "Epoch 6/150\n",
      "24292/24292 [==============================] - 3s 109us/step - loss: 0.1592 - val_loss: 0.1594\n",
      "Epoch 7/150\n",
      "24292/24292 [==============================] - 3s 105us/step - loss: 0.1555 - val_loss: 0.1547\n",
      "Epoch 8/150\n",
      "24292/24292 [==============================] - 2s 101us/step - loss: 0.1501 - val_loss: 0.1530\n",
      "Epoch 9/150\n",
      "24292/24292 [==============================] - 2s 103us/step - loss: 0.1485 - val_loss: 0.1506\n",
      "Epoch 10/150\n",
      "24292/24292 [==============================] - 3s 105us/step - loss: 0.1468 - val_loss: 0.1480\n",
      "Epoch 11/150\n",
      "24292/24292 [==============================] - 2s 101us/step - loss: 0.1444 - val_loss: 0.1481\n",
      "Epoch 12/150\n",
      "24292/24292 [==============================] - 3s 103us/step - loss: 0.1430 - val_loss: 0.1446\n",
      "Epoch 13/150\n",
      "24292/24292 [==============================] - 3s 106us/step - loss: 0.1434 - val_loss: 0.1492\n",
      "Epoch 14/150\n",
      "24292/24292 [==============================] - 2s 101us/step - loss: 0.1411 - val_loss: 0.1443\n",
      "Epoch 15/150\n",
      "24292/24292 [==============================] - 2s 101us/step - loss: 0.1413 - val_loss: 0.1418\n",
      "Epoch 16/150\n",
      "24292/24292 [==============================] - 3s 104us/step - loss: 0.1393 - val_loss: 0.1428\n",
      "Epoch 17/150\n",
      "24292/24292 [==============================] - 3s 105us/step - loss: 0.1384 - val_loss: 0.1429\n",
      "Epoch 18/150\n",
      "24292/24292 [==============================] - 3s 106us/step - loss: 0.1379 - val_loss: 0.1398\n",
      "Epoch 19/150\n",
      "24292/24292 [==============================] - 2s 102us/step - loss: 0.1383 - val_loss: 0.1356\n",
      "Epoch 20/150\n",
      "24292/24292 [==============================] - 3s 104us/step - loss: 0.1363 - val_loss: 0.1414\n",
      "Epoch 21/150\n",
      "24292/24292 [==============================] - 2s 100us/step - loss: 0.1364 - val_loss: 0.1409\n",
      "Epoch 22/150\n",
      "24292/24292 [==============================] - 2s 85us/step - loss: 0.1362 - val_loss: 0.1383\n",
      "Epoch 23/150\n",
      "24292/24292 [==============================] - 2s 69us/step - loss: 0.1347 - val_loss: 0.1375\n",
      "Evaluating model with testing data...\n",
      "5184/5184 [==============================] - 0s 15us/step\n",
      "Getting distribution of predictions and covariance matrix...\n",
      "      1 of 20\n",
      "      2 of 20\n",
      "      3 of 20\n",
      "      4 of 20\n",
      "      5 of 20\n",
      "      6 of 20\n",
      "      7 of 20\n",
      "      8 of 20\n",
      "      9 of 20\n",
      "      10 of 20\n",
      "      11 of 20\n",
      "      12 of 20\n",
      "      13 of 20\n",
      "      14 of 20\n",
      "      15 of 20\n",
      "      16 of 20\n",
      "      17 of 20\n",
      "      18 of 20\n",
      "      19 of 20\n",
      "      20 of 20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|          | 0/20 [00:00<?, ?it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing ensemble means...\n",
      "Computing mean squared error...\n",
      "Getting distribution of predictions...\n",
      "      1 of 20\n",
      "1600/1600 [==============================] - 0s 28us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  5%|▌         | 1/20 [00:29<09:27, 29.86s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      2 of 20\n",
      "1600/1600 [==============================] - 0s 28us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 10%|█         | 2/20 [00:59<08:56, 29.82s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      3 of 20\n",
      "1600/1600 [==============================] - 0s 31us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 15%|█▌        | 3/20 [01:29<08:27, 29.83s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      4 of 20\n",
      "1600/1600 [==============================] - 0s 28us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 20%|██        | 4/20 [01:58<07:54, 29.66s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      5 of 20\n",
      "1600/1600 [==============================] - 0s 29us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 25%|██▌       | 5/20 [02:28<07:23, 29.60s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      6 of 20\n",
      "1600/1600 [==============================] - 0s 30us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 30%|███       | 6/20 [02:57<06:54, 29.64s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      7 of 20\n",
      "1600/1600 [==============================] - 0s 29us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 35%|███▌      | 7/20 [03:27<06:26, 29.74s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      8 of 20\n",
      "1600/1600 [==============================] - 0s 29us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 40%|████      | 8/20 [03:57<05:55, 29.63s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      9 of 20\n",
      "1600/1600 [==============================] - 0s 30us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 45%|████▌     | 9/20 [04:26<05:25, 29.62s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      10 of 20\n",
      "1600/1600 [==============================] - 0s 29us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 50%|█████     | 10/20 [04:56<04:56, 29.62s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      11 of 20\n",
      "1600/1600 [==============================] - 0s 29us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 55%|█████▌    | 11/20 [05:26<04:26, 29.65s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      12 of 20\n",
      "1600/1600 [==============================] - 0s 29us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 60%|██████    | 12/20 [05:55<03:57, 29.69s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      13 of 20\n",
      "1600/1600 [==============================] - 0s 28us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 65%|██████▌   | 13/20 [06:25<03:27, 29.60s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      14 of 20\n",
      "1600/1600 [==============================] - 0s 29us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 70%|███████   | 14/20 [06:55<02:58, 29.68s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      15 of 20\n",
      "1600/1600 [==============================] - 0s 29us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 75%|███████▌  | 15/20 [07:24<02:28, 29.68s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      16 of 20\n",
      "1600/1600 [==============================] - 0s 29us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 80%|████████  | 16/20 [07:54<01:58, 29.63s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      17 of 20\n",
      "1600/1600 [==============================] - 0s 30us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 85%|████████▌ | 17/20 [08:23<01:28, 29.57s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      18 of 20\n",
      "1600/1600 [==============================] - 0s 29us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 90%|█████████ | 18/20 [08:53<00:59, 29.61s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      19 of 20\n",
      "1600/1600 [==============================] - 0s 29us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 95%|█████████▌| 19/20 [09:23<00:29, 29.70s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      20 of 20\n",
      "1600/1600 [==============================] - 0s 30us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 20/20 [09:52<00:00, 29.65s/it]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing ensemble predictions...\n",
      "Iteration 171\n",
      "Train on 24432 samples, validate on 5214 samples\n",
      "Epoch 1/150\n",
      "24432/24432 [==============================] - 2s 90us/step - loss: 0.3856 - val_loss: 0.2618\n",
      "Epoch 2/150\n",
      "24432/24432 [==============================] - 2s 66us/step - loss: 0.2287 - val_loss: 0.2126\n",
      "Epoch 3/150\n",
      "24432/24432 [==============================] - 3s 107us/step - loss: 0.1965 - val_loss: 0.1946\n",
      "Epoch 4/150\n",
      "24432/24432 [==============================] - 3s 111us/step - loss: 0.1803 - val_loss: 0.1790\n",
      "Epoch 5/150\n",
      "24432/24432 [==============================] - 3s 107us/step - loss: 0.1665 - val_loss: 0.1651\n",
      "Epoch 6/150\n",
      "24432/24432 [==============================] - 3s 108us/step - loss: 0.1608 - val_loss: 0.1628\n",
      "Epoch 7/150\n",
      "24432/24432 [==============================] - 3s 104us/step - loss: 0.1587 - val_loss: 0.1609\n",
      "Epoch 8/150\n",
      "24432/24432 [==============================] - 3s 110us/step - loss: 0.1556 - val_loss: 0.1585\n",
      "Epoch 9/150\n",
      "24432/24432 [==============================] - 3s 110us/step - loss: 0.1541 - val_loss: 0.1579\n",
      "Epoch 10/150\n",
      "24432/24432 [==============================] - 3s 104us/step - loss: 0.1542 - val_loss: 0.1575\n",
      "Epoch 11/150\n",
      "24432/24432 [==============================] - 3s 107us/step - loss: 0.1512 - val_loss: 0.1540\n",
      "Epoch 12/150\n",
      "24432/24432 [==============================] - 3s 105us/step - loss: 0.1514 - val_loss: 0.1558\n",
      "Epoch 13/150\n",
      "24432/24432 [==============================] - 3s 105us/step - loss: 0.1486 - val_loss: 0.1524\n",
      "Epoch 14/150\n",
      "24432/24432 [==============================] - 2s 101us/step - loss: 0.1487 - val_loss: 0.1503\n",
      "Epoch 15/150\n",
      "24432/24432 [==============================] - 3s 108us/step - loss: 0.1465 - val_loss: 0.1461\n",
      "Epoch 16/150\n",
      "24432/24432 [==============================] - 3s 111us/step - loss: 0.1435 - val_loss: 0.1469\n",
      "Epoch 17/150\n",
      "24432/24432 [==============================] - 3s 104us/step - loss: 0.1417 - val_loss: 0.1452\n",
      "Epoch 18/150\n",
      "24432/24432 [==============================] - 3s 109us/step - loss: 0.1398 - val_loss: 0.1421\n",
      "Epoch 19/150\n",
      "24432/24432 [==============================] - 3s 106us/step - loss: 0.1387 - val_loss: 0.1406\n",
      "Epoch 20/150\n",
      "24432/24432 [==============================] - 3s 107us/step - loss: 0.1361 - val_loss: 0.1375\n",
      "Epoch 21/150\n",
      "24432/24432 [==============================] - 3s 109us/step - loss: 0.1350 - val_loss: 0.1394\n",
      "Epoch 22/150\n",
      "24432/24432 [==============================] - 3s 103us/step - loss: 0.1337 - val_loss: 0.1376\n",
      "Epoch 23/150\n",
      "24432/24432 [==============================] - 3s 105us/step - loss: 0.1308 - val_loss: 0.1368\n",
      "Epoch 24/150\n",
      "24432/24432 [==============================] - 3s 107us/step - loss: 0.1324 - val_loss: 0.1353\n",
      "Epoch 25/150\n",
      "24432/24432 [==============================] - 3s 108us/step - loss: 0.1301 - val_loss: 0.1318\n",
      "Epoch 26/150\n",
      "24432/24432 [==============================] - 3s 106us/step - loss: 0.1315 - val_loss: 0.1341\n",
      "Epoch 27/150\n",
      "24432/24432 [==============================] - 3s 107us/step - loss: 0.1303 - val_loss: 0.1326\n",
      "Epoch 28/150\n",
      "24432/24432 [==============================] - 2s 102us/step - loss: 0.1287 - val_loss: 0.1320\n",
      "Epoch 29/150\n",
      "24432/24432 [==============================] - 3s 105us/step - loss: 0.1284 - val_loss: 0.1325\n",
      "Evaluating model with testing data...\n",
      "5214/5214 [==============================] - 0s 19us/step\n",
      "Getting distribution of predictions and covariance matrix...\n",
      "      1 of 20\n",
      "      2 of 20\n",
      "      3 of 20\n",
      "      4 of 20\n",
      "      5 of 20\n",
      "      6 of 20\n",
      "      7 of 20\n",
      "      8 of 20\n",
      "      9 of 20\n",
      "      10 of 20\n",
      "      11 of 20\n",
      "      12 of 20\n",
      "      13 of 20\n",
      "      14 of 20\n",
      "      15 of 20\n",
      "      16 of 20\n",
      "      17 of 20\n",
      "      18 of 20\n",
      "      19 of 20\n",
      "      20 of 20\n",
      "Computing ensemble means...\n",
      "Computing mean squared error...\n",
      "Iteration 172\n",
      "Train on 24572 samples, validate on 5244 samples\n",
      "Epoch 1/150\n",
      "24572/24572 [==============================] - 3s 104us/step - loss: 0.3927 - val_loss: 0.2775\n",
      "Epoch 2/150\n",
      "24572/24572 [==============================] - 3s 106us/step - loss: 0.2474 - val_loss: 0.2248\n",
      "Epoch 3/150\n",
      "24572/24572 [==============================] - 3s 107us/step - loss: 0.2128 - val_loss: 0.2053\n",
      "Epoch 4/150\n",
      "24572/24572 [==============================] - 2s 101us/step - loss: 0.1932 - val_loss: 0.1906\n",
      "Epoch 5/150\n",
      "24572/24572 [==============================] - 2s 101us/step - loss: 0.1807 - val_loss: 0.1826\n",
      "Epoch 6/150\n",
      "24572/24572 [==============================] - 3s 103us/step - loss: 0.1723 - val_loss: 0.1711\n",
      "Epoch 7/150\n",
      "24572/24572 [==============================] - 3s 103us/step - loss: 0.1667 - val_loss: 0.1703\n",
      "Epoch 8/150\n",
      "24572/24572 [==============================] - 2s 99us/step - loss: 0.1628 - val_loss: 0.1661\n",
      "Epoch 9/150\n",
      "24572/24572 [==============================] - 2s 101us/step - loss: 0.1562 - val_loss: 0.1578\n",
      "Epoch 10/150\n",
      "24572/24572 [==============================] - 3s 103us/step - loss: 0.1536 - val_loss: 0.1578\n",
      "Epoch 11/150\n",
      "24572/24572 [==============================] - 2s 101us/step - loss: 0.1522 - val_loss: 0.1551\n",
      "Epoch 12/150\n",
      "24572/24572 [==============================] - 2s 100us/step - loss: 0.1515 - val_loss: 0.1537\n",
      "Epoch 13/150\n",
      "24572/24572 [==============================] - 2s 101us/step - loss: 0.1501 - val_loss: 0.1528\n",
      "Epoch 14/150\n",
      "24572/24572 [==============================] - 2s 95us/step - loss: 0.1499 - val_loss: 0.1503\n",
      "Epoch 15/150\n",
      "24572/24572 [==============================] - 3s 103us/step - loss: 0.1478 - val_loss: 0.1544\n",
      "Epoch 16/150\n",
      "24572/24572 [==============================] - 2s 101us/step - loss: 0.1486 - val_loss: 0.1485\n",
      "Epoch 17/150\n",
      "24572/24572 [==============================] - 3s 103us/step - loss: 0.1461 - val_loss: 0.1521\n",
      "Epoch 18/150\n",
      "24572/24572 [==============================] - 2s 86us/step - loss: 0.1474 - val_loss: 0.1538\n",
      "Epoch 19/150\n",
      "24572/24572 [==============================] - 2s 62us/step - loss: 0.1438 - val_loss: 0.1441\n",
      "Epoch 20/150\n",
      "24572/24572 [==============================] - 2s 99us/step - loss: 0.1443 - val_loss: 0.1461\n",
      "Epoch 21/150\n",
      "24572/24572 [==============================] - 3s 105us/step - loss: 0.1405 - val_loss: 0.1466\n",
      "Epoch 22/150\n",
      "24572/24572 [==============================] - 3s 103us/step - loss: 0.1413 - val_loss: 0.1440\n",
      "Epoch 23/150\n",
      "24572/24572 [==============================] - 2s 100us/step - loss: 0.1402 - val_loss: 0.1462\n",
      "Epoch 24/150\n",
      "24572/24572 [==============================] - 2s 99us/step - loss: 0.1410 - val_loss: 0.1461\n",
      "Epoch 25/150\n",
      "24572/24572 [==============================] - 2s 97us/step - loss: 0.1396 - val_loss: 0.1396\n",
      "Epoch 26/150\n",
      "24572/24572 [==============================] - 2s 98us/step - loss: 0.1383 - val_loss: 0.1408\n",
      "Epoch 27/150\n",
      "24572/24572 [==============================] - 2s 100us/step - loss: 0.1371 - val_loss: 0.1421\n",
      "Epoch 28/150\n",
      "24572/24572 [==============================] - 3s 102us/step - loss: 0.1371 - val_loss: 0.1380\n",
      "Epoch 29/150\n",
      "24572/24572 [==============================] - 3s 103us/step - loss: 0.1379 - val_loss: 0.1397\n",
      "Epoch 30/150\n",
      "24572/24572 [==============================] - 2s 99us/step - loss: 0.1352 - val_loss: 0.1376\n",
      "Epoch 31/150\n",
      "24572/24572 [==============================] - 2s 97us/step - loss: 0.1363 - val_loss: 0.1404\n",
      "Epoch 32/150\n",
      "24572/24572 [==============================] - 2s 95us/step - loss: 0.1347 - val_loss: 0.1371\n",
      "Epoch 33/150\n",
      "24572/24572 [==============================] - 2s 99us/step - loss: 0.1344 - val_loss: 0.1368\n",
      "Epoch 34/150\n",
      "24572/24572 [==============================] - 2s 96us/step - loss: 0.1339 - val_loss: 0.1384\n",
      "Epoch 35/150\n",
      "24572/24572 [==============================] - 2s 93us/step - loss: 0.1344 - val_loss: 0.1381\n",
      "Epoch 36/150\n",
      "24572/24572 [==============================] - 2s 94us/step - loss: 0.1343 - val_loss: 0.1345\n",
      "Epoch 37/150\n",
      "24572/24572 [==============================] - 2s 97us/step - loss: 0.1338 - val_loss: 0.1388\n",
      "Epoch 38/150\n",
      "24572/24572 [==============================] - 2s 96us/step - loss: 0.1345 - val_loss: 0.1371\n",
      "Epoch 39/150\n",
      "24572/24572 [==============================] - 2s 95us/step - loss: 0.1329 - val_loss: 0.1355\n",
      "Epoch 40/150\n",
      "24572/24572 [==============================] - 2s 97us/step - loss: 0.1340 - val_loss: 0.1355\n",
      "Evaluating model with testing data...\n",
      "5244/5244 [==============================] - 0s 16us/step\n",
      "Getting distribution of predictions and covariance matrix...\n",
      "      1 of 20\n",
      "      2 of 20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      3 of 20\n",
      "      4 of 20\n",
      "      5 of 20\n",
      "      6 of 20\n",
      "      7 of 20\n",
      "      8 of 20\n",
      "      9 of 20\n",
      "      10 of 20\n",
      "      11 of 20\n",
      "      12 of 20\n",
      "      13 of 20\n",
      "      14 of 20\n",
      "      15 of 20\n",
      "      16 of 20\n",
      "      17 of 20\n",
      "      18 of 20\n",
      "      19 of 20\n",
      "      20 of 20\n",
      "Computing ensemble means...\n",
      "Computing mean squared error...\n",
      "Iteration 173\n",
      "Train on 24712 samples, validate on 5274 samples\n",
      "Epoch 1/150\n",
      "24712/24712 [==============================] - 3s 105us/step - loss: 0.4188 - val_loss: 0.2944\n",
      "Epoch 2/150\n",
      "24712/24712 [==============================] - 3s 108us/step - loss: 0.2576 - val_loss: 0.2358\n",
      "Epoch 3/150\n",
      "24712/24712 [==============================] - 3s 109us/step - loss: 0.2149 - val_loss: 0.2013\n",
      "Epoch 4/150\n",
      "24712/24712 [==============================] - 3s 109us/step - loss: 0.1925 - val_loss: 0.1883\n",
      "Epoch 5/150\n",
      "24712/24712 [==============================] - 3s 109us/step - loss: 0.1841 - val_loss: 0.1835\n",
      "Epoch 6/150\n",
      "24712/24712 [==============================] - 3s 107us/step - loss: 0.1770 - val_loss: 0.1787\n",
      "Epoch 7/150\n",
      "24712/24712 [==============================] - 3s 109us/step - loss: 0.1692 - val_loss: 0.1717\n",
      "Epoch 8/150\n",
      "24712/24712 [==============================] - 3s 108us/step - loss: 0.1660 - val_loss: 0.1672\n",
      "Epoch 9/150\n",
      "24712/24712 [==============================] - 3s 108us/step - loss: 0.1640 - val_loss: 0.1649\n",
      "Epoch 10/150\n",
      "24712/24712 [==============================] - 3s 112us/step - loss: 0.1606 - val_loss: 0.1645\n",
      "Epoch 11/150\n",
      "24712/24712 [==============================] - 3s 104us/step - loss: 0.1622 - val_loss: 0.1673\n",
      "Epoch 12/150\n",
      "24712/24712 [==============================] - 3s 108us/step - loss: 0.1603 - val_loss: 0.1641\n",
      "Epoch 13/150\n",
      "24712/24712 [==============================] - 3s 108us/step - loss: 0.1597 - val_loss: 0.1594\n",
      "Epoch 14/150\n",
      "24712/24712 [==============================] - 3s 109us/step - loss: 0.1568 - val_loss: 0.1578\n",
      "Epoch 15/150\n",
      "24712/24712 [==============================] - 3s 108us/step - loss: 0.1550 - val_loss: 0.1576\n",
      "Epoch 16/150\n",
      "24712/24712 [==============================] - 3s 108us/step - loss: 0.1541 - val_loss: 0.1558\n",
      "Epoch 17/150\n",
      "24712/24712 [==============================] - 3s 107us/step - loss: 0.1525 - val_loss: 0.1556\n",
      "Epoch 18/150\n",
      "24712/24712 [==============================] - 3s 107us/step - loss: 0.1530 - val_loss: 0.1583\n",
      "Epoch 19/150\n",
      "24712/24712 [==============================] - 3s 109us/step - loss: 0.1536 - val_loss: 0.1555\n",
      "Epoch 20/150\n",
      "24712/24712 [==============================] - 3s 107us/step - loss: 0.1517 - val_loss: 0.1558\n",
      "Epoch 21/150\n",
      "24712/24712 [==============================] - 2s 99us/step - loss: 0.1493 - val_loss: 0.1542\n",
      "Epoch 22/150\n",
      "24712/24712 [==============================] - 3s 107us/step - loss: 0.1507 - val_loss: 0.1521\n",
      "Epoch 23/150\n",
      "24712/24712 [==============================] - 3s 102us/step - loss: 0.1486 - val_loss: 0.1482\n",
      "Epoch 24/150\n",
      "24712/24712 [==============================] - 3s 106us/step - loss: 0.1488 - val_loss: 0.1517\n",
      "Epoch 25/150\n",
      "24712/24712 [==============================] - 2s 69us/step - loss: 0.1475 - val_loss: 0.1516\n",
      "Epoch 26/150\n",
      "24712/24712 [==============================] - 2s 88us/step - loss: 0.1468 - val_loss: 0.1510\n",
      "Epoch 27/150\n",
      "24712/24712 [==============================] - 3s 103us/step - loss: 0.1472 - val_loss: 0.1497\n",
      "Evaluating model with testing data...\n",
      "5274/5274 [==============================] - 0s 16us/step\n",
      "Getting distribution of predictions and covariance matrix...\n",
      "      1 of 20\n",
      "      2 of 20\n",
      "      3 of 20\n",
      "      4 of 20\n",
      "      5 of 20\n",
      "      6 of 20\n",
      "      7 of 20\n",
      "      8 of 20\n",
      "      9 of 20\n",
      "      10 of 20\n",
      "      11 of 20\n",
      "      12 of 20\n",
      "      13 of 20\n",
      "      14 of 20\n",
      "      15 of 20\n",
      "      16 of 20\n",
      "      17 of 20\n",
      "      18 of 20\n",
      "      19 of 20\n",
      "      20 of 20\n",
      "Computing ensemble means...\n",
      "Computing mean squared error...\n",
      "Iteration 174\n",
      "Train on 24852 samples, validate on 5304 samples\n",
      "Epoch 1/150\n",
      "24852/24852 [==============================] - 3s 107us/step - loss: 0.3732 - val_loss: 0.2725\n",
      "Epoch 2/150\n",
      "24852/24852 [==============================] - 3s 109us/step - loss: 0.2487 - val_loss: 0.2340\n",
      "Epoch 3/150\n",
      "24852/24852 [==============================] - 3s 102us/step - loss: 0.2174 - val_loss: 0.2053\n",
      "Epoch 4/150\n",
      "24852/24852 [==============================] - 3s 105us/step - loss: 0.1957 - val_loss: 0.1968\n",
      "Epoch 5/150\n",
      "24852/24852 [==============================] - 3s 105us/step - loss: 0.1877 - val_loss: 0.1870\n",
      "Epoch 6/150\n",
      "24852/24852 [==============================] - 3s 101us/step - loss: 0.1835 - val_loss: 0.1836\n",
      "Epoch 7/150\n",
      "24852/24852 [==============================] - 3s 103us/step - loss: 0.1816 - val_loss: 0.1823\n",
      "Epoch 8/150\n",
      "24852/24852 [==============================] - 2s 101us/step - loss: 0.1786 - val_loss: 0.1896\n",
      "Epoch 9/150\n",
      "24852/24852 [==============================] - 3s 101us/step - loss: 0.1783 - val_loss: 0.1800\n",
      "Epoch 10/150\n",
      "24852/24852 [==============================] - 3s 101us/step - loss: 0.1762 - val_loss: 0.1893\n",
      "Epoch 11/150\n",
      "24852/24852 [==============================] - 3s 103us/step - loss: 0.1767 - val_loss: 0.1803\n",
      "Epoch 12/150\n",
      "24852/24852 [==============================] - 2s 99us/step - loss: 0.1750 - val_loss: 0.1788\n",
      "Epoch 13/150\n",
      "24852/24852 [==============================] - 3s 105us/step - loss: 0.1752 - val_loss: 0.1763\n",
      "Epoch 14/150\n",
      "24852/24852 [==============================] - 3s 101us/step - loss: 0.1730 - val_loss: 0.1789\n",
      "Epoch 15/150\n",
      "24852/24852 [==============================] - 2s 97us/step - loss: 0.1729 - val_loss: 0.1794\n",
      "Epoch 16/150\n",
      "24852/24852 [==============================] - 2s 98us/step - loss: 0.1726 - val_loss: 0.1747\n",
      "Epoch 17/150\n",
      "24852/24852 [==============================] - 3s 101us/step - loss: 0.1717 - val_loss: 0.1754\n",
      "Epoch 18/150\n",
      "24852/24852 [==============================] - 2s 98us/step - loss: 0.1697 - val_loss: 0.1711\n",
      "Epoch 19/150\n",
      "24852/24852 [==============================] - 2s 98us/step - loss: 0.1723 - val_loss: 0.1754\n",
      "Epoch 20/150\n",
      "24852/24852 [==============================] - 2s 95us/step - loss: 0.1707 - val_loss: 0.1746\n",
      "Epoch 21/150\n",
      "24852/24852 [==============================] - 2s 100us/step - loss: 0.1700 - val_loss: 0.1723\n",
      "Epoch 22/150\n",
      "24852/24852 [==============================] - 2s 97us/step - loss: 0.1681 - val_loss: 0.1729\n",
      "Evaluating model with testing data...\n",
      "5304/5304 [==============================] - 0s 15us/step\n",
      "Getting distribution of predictions and covariance matrix...\n",
      "      1 of 20\n",
      "      2 of 20\n",
      "      3 of 20\n",
      "      4 of 20\n",
      "      5 of 20\n",
      "      6 of 20\n",
      "      7 of 20\n",
      "      8 of 20\n",
      "      9 of 20\n",
      "      10 of 20\n",
      "      11 of 20\n",
      "      12 of 20\n",
      "      13 of 20\n",
      "      14 of 20\n",
      "      15 of 20\n",
      "      16 of 20\n",
      "      17 of 20\n",
      "      18 of 20\n",
      "      19 of 20\n",
      "      20 of 20\n",
      "Computing ensemble means...\n",
      "Computing mean squared error...\n",
      "Iteration 175\n",
      "Train on 24992 samples, validate on 5334 samples\n",
      "Epoch 1/150\n",
      "24992/24992 [==============================] - 2s 98us/step - loss: 0.3474 - val_loss: 0.2265\n",
      "Epoch 2/150\n",
      "24992/24992 [==============================] - 2s 99us/step - loss: 0.1942 - val_loss: 0.1790\n",
      "Epoch 3/150\n",
      "24992/24992 [==============================] - 2s 96us/step - loss: 0.1689 - val_loss: 0.1604\n",
      "Epoch 4/150\n",
      "24992/24992 [==============================] - 3s 101us/step - loss: 0.1557 - val_loss: 0.1528\n",
      "Epoch 5/150\n",
      "24992/24992 [==============================] - 2s 98us/step - loss: 0.1494 - val_loss: 0.1552\n",
      "Epoch 6/150\n",
      "24992/24992 [==============================] - 2s 99us/step - loss: 0.1416 - val_loss: 0.1399\n",
      "Epoch 7/150\n",
      "24992/24992 [==============================] - 2s 96us/step - loss: 0.1369 - val_loss: 0.1381\n",
      "Epoch 8/150\n",
      "24992/24992 [==============================] - 2s 92us/step - loss: 0.1347 - val_loss: 0.1356\n",
      "Epoch 9/150\n",
      "24992/24992 [==============================] - 2s 98us/step - loss: 0.1312 - val_loss: 0.1321\n",
      "Epoch 10/150\n",
      "24992/24992 [==============================] - 2s 96us/step - loss: 0.1305 - val_loss: 0.1328\n",
      "Epoch 11/150\n",
      "24992/24992 [==============================] - 2s 97us/step - loss: 0.1279 - val_loss: 0.1296\n",
      "Epoch 12/150\n",
      "24992/24992 [==============================] - 2s 97us/step - loss: 0.1278 - val_loss: 0.1309\n",
      "Epoch 13/150\n",
      "24992/24992 [==============================] - 2s 96us/step - loss: 0.1267 - val_loss: 0.1254\n",
      "Epoch 14/150\n",
      "24992/24992 [==============================] - 3s 108us/step - loss: 0.1250 - val_loss: 0.1250\n",
      "Epoch 15/150\n",
      "24992/24992 [==============================] - 3s 111us/step - loss: 0.1244 - val_loss: 0.1300\n",
      "Epoch 16/150\n",
      "24992/24992 [==============================] - 3s 115us/step - loss: 0.1239 - val_loss: 0.1242\n",
      "Epoch 17/150\n",
      "24992/24992 [==============================] - 3s 109us/step - loss: 0.1224 - val_loss: 0.1212\n",
      "Epoch 18/150\n",
      "24992/24992 [==============================] - 3s 109us/step - loss: 0.1213 - val_loss: 0.1228\n",
      "Epoch 19/150\n",
      "24992/24992 [==============================] - 3s 108us/step - loss: 0.1209 - val_loss: 0.1236\n",
      "Epoch 20/150\n",
      "24992/24992 [==============================] - 3s 111us/step - loss: 0.1196 - val_loss: 0.1229\n",
      "Epoch 21/150\n",
      "24992/24992 [==============================] - 2s 90us/step - loss: 0.1206 - val_loss: 0.1232\n",
      "Evaluating model with testing data...\n",
      "5334/5334 [==============================] - 0s 15us/step\n",
      "Getting distribution of predictions and covariance matrix...\n",
      "      1 of 20\n",
      "      2 of 20\n",
      "      3 of 20\n",
      "      4 of 20\n",
      "      5 of 20\n",
      "      6 of 20\n",
      "      7 of 20\n",
      "      8 of 20\n",
      "      9 of 20\n",
      "      10 of 20\n",
      "      11 of 20\n",
      "      12 of 20\n",
      "      13 of 20\n",
      "      14 of 20\n",
      "      15 of 20\n",
      "      16 of 20\n",
      "      17 of 20\n",
      "      18 of 20\n",
      "      19 of 20\n",
      "      20 of 20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|          | 0/20 [00:00<?, ?it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing ensemble means...\n",
      "Computing mean squared error...\n",
      "Getting distribution of predictions...\n",
      "      1 of 20\n",
      "1600/1600 [==============================] - 0s 27us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  5%|▌         | 1/20 [00:29<09:22, 29.62s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      2 of 20\n",
      "1600/1600 [==============================] - 0s 29us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 10%|█         | 2/20 [00:59<08:54, 29.69s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      3 of 20\n",
      "1600/1600 [==============================] - 0s 29us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 15%|█▌        | 3/20 [01:29<08:25, 29.76s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      4 of 20\n",
      "1600/1600 [==============================] - 0s 28us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 20%|██        | 4/20 [01:58<07:54, 29.63s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      5 of 20\n",
      "1600/1600 [==============================] - 0s 29us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 25%|██▌       | 5/20 [02:28<07:23, 29.57s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      6 of 20\n",
      "1600/1600 [==============================] - 0s 29us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 30%|███       | 6/20 [02:57<06:53, 29.56s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      7 of 20\n",
      "1600/1600 [==============================] - 0s 28us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 35%|███▌      | 7/20 [03:27<06:24, 29.58s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      8 of 20\n",
      "1600/1600 [==============================] - 0s 29us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 40%|████      | 8/20 [03:56<05:54, 29.56s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      9 of 20\n",
      "1600/1600 [==============================] - 0s 29us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 45%|████▌     | 9/20 [04:26<05:24, 29.51s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      10 of 20\n",
      "1600/1600 [==============================] - 0s 29us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 50%|█████     | 10/20 [04:56<04:56, 29.61s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      11 of 20\n",
      "1600/1600 [==============================] - 0s 28us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 55%|█████▌    | 11/20 [05:25<04:25, 29.48s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      12 of 20\n",
      "1600/1600 [==============================] - 0s 29us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 60%|██████    | 12/20 [05:54<03:56, 29.54s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      13 of 20\n",
      "1600/1600 [==============================] - 0s 29us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 65%|██████▌   | 13/20 [06:24<03:26, 29.55s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      14 of 20\n",
      "1600/1600 [==============================] - 0s 29us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 70%|███████   | 14/20 [06:53<02:57, 29.50s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      15 of 20\n",
      "1600/1600 [==============================] - 0s 29us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 75%|███████▌  | 15/20 [07:23<02:28, 29.62s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      16 of 20\n",
      "1600/1600 [==============================] - 0s 29us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 80%|████████  | 16/20 [07:53<01:58, 29.64s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      17 of 20\n",
      "1600/1600 [==============================] - 0s 29us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 85%|████████▌ | 17/20 [08:22<01:28, 29.49s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      18 of 20\n",
      "1600/1600 [==============================] - 0s 29us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 90%|█████████ | 18/20 [08:51<00:58, 29.46s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      19 of 20\n",
      "1600/1600 [==============================] - 0s 30us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 95%|█████████▌| 19/20 [09:21<00:29, 29.50s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      20 of 20\n",
      "1600/1600 [==============================] - 0s 30us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 20/20 [09:51<00:00, 29.56s/it]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing ensemble predictions...\n",
      "Iteration 176\n",
      "Train on 25132 samples, validate on 5364 samples\n",
      "Epoch 1/150\n",
      "25132/25132 [==============================] - 3s 105us/step - loss: 0.3915 - val_loss: 0.2740\n",
      "Epoch 2/150\n",
      "25132/25132 [==============================] - 3s 105us/step - loss: 0.2438 - val_loss: 0.2303\n",
      "Epoch 3/150\n",
      "25132/25132 [==============================] - 1s 59us/step - loss: 0.2127 - val_loss: 0.2040\n",
      "Epoch 4/150\n",
      "25132/25132 [==============================] - 2s 99us/step - loss: 0.1911 - val_loss: 0.1878\n",
      "Epoch 5/150\n",
      "25132/25132 [==============================] - 3s 109us/step - loss: 0.1783 - val_loss: 0.1842\n",
      "Epoch 6/150\n",
      "25132/25132 [==============================] - 3s 109us/step - loss: 0.1721 - val_loss: 0.1768\n",
      "Epoch 7/150\n",
      "25132/25132 [==============================] - 3s 108us/step - loss: 0.1692 - val_loss: 0.1751\n",
      "Epoch 8/150\n",
      "25132/25132 [==============================] - 3s 108us/step - loss: 0.1671 - val_loss: 0.1717\n",
      "Epoch 9/150\n",
      "25132/25132 [==============================] - 3s 109us/step - loss: 0.1656 - val_loss: 0.1686\n",
      "Epoch 10/150\n",
      "25132/25132 [==============================] - 3s 106us/step - loss: 0.1620 - val_loss: 0.1621\n",
      "Epoch 11/150\n",
      "25132/25132 [==============================] - 3s 109us/step - loss: 0.1591 - val_loss: 0.1610\n",
      "Epoch 12/150\n",
      "25132/25132 [==============================] - 3s 107us/step - loss: 0.1577 - val_loss: 0.1603\n",
      "Epoch 13/150\n",
      "25132/25132 [==============================] - 3s 109us/step - loss: 0.1572 - val_loss: 0.1593\n",
      "Epoch 14/150\n",
      "25132/25132 [==============================] - 3s 106us/step - loss: 0.1556 - val_loss: 0.1589\n",
      "Epoch 15/150\n",
      "25132/25132 [==============================] - 3s 107us/step - loss: 0.1525 - val_loss: 0.1600\n",
      "Epoch 16/150\n",
      "25132/25132 [==============================] - 3s 107us/step - loss: 0.1516 - val_loss: 0.1560\n",
      "Epoch 17/150\n",
      "25132/25132 [==============================] - 3s 103us/step - loss: 0.1472 - val_loss: 0.1457\n",
      "Epoch 18/150\n",
      "25132/25132 [==============================] - 3s 107us/step - loss: 0.1452 - val_loss: 0.1476\n",
      "Epoch 19/150\n",
      "25132/25132 [==============================] - 3s 102us/step - loss: 0.1407 - val_loss: 0.1431\n",
      "Epoch 20/150\n",
      "25132/25132 [==============================] - 3s 109us/step - loss: 0.1379 - val_loss: 0.1427\n",
      "Epoch 21/150\n",
      "25132/25132 [==============================] - 3s 102us/step - loss: 0.1357 - val_loss: 0.1376\n",
      "Epoch 22/150\n",
      "25132/25132 [==============================] - 3s 105us/step - loss: 0.1340 - val_loss: 0.1346\n",
      "Epoch 23/150\n",
      "25132/25132 [==============================] - 3s 107us/step - loss: 0.1334 - val_loss: 0.1324\n",
      "Epoch 24/150\n",
      "25132/25132 [==============================] - 3s 100us/step - loss: 0.1321 - val_loss: 0.1334\n",
      "Epoch 25/150\n",
      "25132/25132 [==============================] - 3s 107us/step - loss: 0.1304 - val_loss: 0.1314\n",
      "Epoch 26/150\n",
      "25132/25132 [==============================] - 3s 103us/step - loss: 0.1294 - val_loss: 0.1304\n",
      "Epoch 27/150\n",
      "25132/25132 [==============================] - 3s 104us/step - loss: 0.1263 - val_loss: 0.1287\n",
      "Epoch 28/150\n",
      "25132/25132 [==============================] - 3s 108us/step - loss: 0.1250 - val_loss: 0.1290\n",
      "Epoch 29/150\n",
      "25132/25132 [==============================] - 3s 105us/step - loss: 0.1254 - val_loss: 0.1261\n",
      "Epoch 30/150\n",
      "25132/25132 [==============================] - 3s 103us/step - loss: 0.1242 - val_loss: 0.1264\n",
      "Epoch 31/150\n",
      "25132/25132 [==============================] - 3s 106us/step - loss: 0.1240 - val_loss: 0.1271\n",
      "Epoch 32/150\n",
      "25132/25132 [==============================] - 3s 104us/step - loss: 0.1240 - val_loss: 0.1243\n",
      "Epoch 33/150\n",
      "25132/25132 [==============================] - 2s 98us/step - loss: 0.1199 - val_loss: 0.1224\n",
      "Epoch 34/150\n",
      "25132/25132 [==============================] - 3s 104us/step - loss: 0.1190 - val_loss: 0.1221\n",
      "Epoch 35/150\n",
      "25132/25132 [==============================] - 3s 100us/step - loss: 0.1170 - val_loss: 0.1170\n",
      "Epoch 36/150\n",
      "25132/25132 [==============================] - 3s 105us/step - loss: 0.1162 - val_loss: 0.1165\n",
      "Epoch 37/150\n",
      "25132/25132 [==============================] - 3s 104us/step - loss: 0.1153 - val_loss: 0.1155\n",
      "Epoch 38/150\n",
      "25132/25132 [==============================] - 3s 105us/step - loss: 0.1147 - val_loss: 0.1183\n",
      "Epoch 39/150\n",
      "25132/25132 [==============================] - 3s 103us/step - loss: 0.1143 - val_loss: 0.1158\n",
      "Epoch 40/150\n",
      "25132/25132 [==============================] - 2s 99us/step - loss: 0.1149 - val_loss: 0.1190\n",
      "Epoch 41/150\n",
      "25132/25132 [==============================] - 3s 102us/step - loss: 0.1122 - val_loss: 0.1192\n",
      "Evaluating model with testing data...\n",
      "5364/5364 [==============================] - 0s 16us/step\n",
      "Getting distribution of predictions and covariance matrix...\n",
      "      1 of 20\n",
      "      2 of 20\n",
      "      3 of 20\n",
      "      4 of 20\n",
      "      5 of 20\n",
      "      6 of 20\n",
      "      7 of 20\n",
      "      8 of 20\n",
      "      9 of 20\n",
      "      10 of 20\n",
      "      11 of 20\n",
      "      12 of 20\n",
      "      13 of 20\n",
      "      14 of 20\n",
      "      15 of 20\n",
      "      16 of 20\n",
      "      17 of 20\n",
      "      18 of 20\n",
      "      19 of 20\n",
      "      20 of 20\n",
      "Computing ensemble means...\n",
      "Computing mean squared error...\n",
      "Iteration 177\n",
      "Train on 25272 samples, validate on 5394 samples\n",
      "Epoch 1/150\n",
      "25272/25272 [==============================] - 3s 103us/step - loss: 0.3271 - val_loss: 0.2396\n",
      "Epoch 2/150\n",
      "25272/25272 [==============================] - 3s 103us/step - loss: 0.2185 - val_loss: 0.2092\n",
      "Epoch 3/150\n",
      "25272/25272 [==============================] - 3s 102us/step - loss: 0.2000 - val_loss: 0.1947\n",
      "Epoch 4/150\n",
      "25272/25272 [==============================] - 3s 104us/step - loss: 0.1878 - val_loss: 0.1833\n",
      "Epoch 5/150\n",
      "25272/25272 [==============================] - 2s 97us/step - loss: 0.1760 - val_loss: 0.1745\n",
      "Epoch 6/150\n",
      "25272/25272 [==============================] - 2s 89us/step - loss: 0.1623 - val_loss: 0.1614\n",
      "Epoch 7/150\n",
      "25272/25272 [==============================] - 1s 58us/step - loss: 0.1551 - val_loss: 0.1597\n",
      "Epoch 8/150\n",
      "25272/25272 [==============================] - 2s 91us/step - loss: 0.1516 - val_loss: 0.1555\n",
      "Epoch 9/150\n",
      "25272/25272 [==============================] - 2s 98us/step - loss: 0.1491 - val_loss: 0.1514\n",
      "Epoch 10/150\n",
      "25272/25272 [==============================] - 2s 97us/step - loss: 0.1468 - val_loss: 0.1475\n",
      "Epoch 11/150\n",
      "25272/25272 [==============================] - 3s 101us/step - loss: 0.1422 - val_loss: 0.1448\n",
      "Epoch 12/150\n",
      "25272/25272 [==============================] - 2s 99us/step - loss: 0.1386 - val_loss: 0.1442\n",
      "Epoch 13/150\n",
      "25272/25272 [==============================] - 3s 101us/step - loss: 0.1353 - val_loss: 0.1347\n",
      "Epoch 14/150\n",
      "25272/25272 [==============================] - 2s 96us/step - loss: 0.1304 - val_loss: 0.1323\n",
      "Epoch 15/150\n",
      "25272/25272 [==============================] - 3s 100us/step - loss: 0.1296 - val_loss: 0.1336\n",
      "Epoch 16/150\n",
      "25272/25272 [==============================] - 3s 101us/step - loss: 0.1275 - val_loss: 0.1321\n",
      "Epoch 17/150\n",
      "25272/25272 [==============================] - 3s 101us/step - loss: 0.1268 - val_loss: 0.1319\n",
      "Epoch 18/150\n",
      "25272/25272 [==============================] - 3s 100us/step - loss: 0.1258 - val_loss: 0.1289\n",
      "Epoch 19/150\n",
      "25272/25272 [==============================] - 3s 99us/step - loss: 0.1254 - val_loss: 0.1278\n",
      "Epoch 20/150\n",
      "25272/25272 [==============================] - 3s 100us/step - loss: 0.1244 - val_loss: 0.1237\n",
      "Epoch 21/150\n",
      "25272/25272 [==============================] - 2s 99us/step - loss: 0.1216 - val_loss: 0.1239\n",
      "Epoch 22/150\n",
      "25272/25272 [==============================] - 3s 99us/step - loss: 0.1220 - val_loss: 0.1253\n",
      "Epoch 23/150\n",
      "25272/25272 [==============================] - 3s 99us/step - loss: 0.1217 - val_loss: 0.1212\n",
      "Epoch 24/150\n",
      "25272/25272 [==============================] - 2s 98us/step - loss: 0.1210 - val_loss: 0.1225\n",
      "Epoch 25/150\n",
      "25272/25272 [==============================] - 3s 100us/step - loss: 0.1194 - val_loss: 0.1209\n",
      "Epoch 26/150\n",
      "25272/25272 [==============================] - 2s 93us/step - loss: 0.1181 - val_loss: 0.1203\n",
      "Epoch 27/150\n",
      "25272/25272 [==============================] - 2s 96us/step - loss: 0.1189 - val_loss: 0.1189\n",
      "Epoch 28/150\n",
      "25272/25272 [==============================] - 2s 98us/step - loss: 0.1175 - val_loss: 0.1169\n",
      "Epoch 29/150\n",
      "25272/25272 [==============================] - 2s 96us/step - loss: 0.1174 - val_loss: 0.1200\n",
      "Epoch 30/150\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25272/25272 [==============================] - 3s 111us/step - loss: 0.1164 - val_loss: 0.1225\n",
      "Epoch 31/150\n",
      "25272/25272 [==============================] - 3s 104us/step - loss: 0.1152 - val_loss: 0.1160\n",
      "Epoch 32/150\n",
      "25272/25272 [==============================] - 3s 111us/step - loss: 0.1155 - val_loss: 0.1176\n",
      "Epoch 33/150\n",
      "25272/25272 [==============================] - 3s 109us/step - loss: 0.1147 - val_loss: 0.1174\n",
      "Epoch 34/150\n",
      "25272/25272 [==============================] - 3s 112us/step - loss: 0.1126 - val_loss: 0.1145\n",
      "Epoch 35/150\n",
      "25272/25272 [==============================] - 3s 111us/step - loss: 0.1131 - val_loss: 0.1149\n",
      "Epoch 36/150\n",
      "25272/25272 [==============================] - 3s 109us/step - loss: 0.1131 - val_loss: 0.1153\n",
      "Epoch 37/150\n",
      "25272/25272 [==============================] - 3s 106us/step - loss: 0.1125 - val_loss: 0.1120\n",
      "Epoch 38/150\n",
      "25272/25272 [==============================] - 3s 110us/step - loss: 0.1115 - val_loss: 0.1151\n",
      "Epoch 39/150\n",
      "25272/25272 [==============================] - 3s 106us/step - loss: 0.1111 - val_loss: 0.1151\n",
      "Epoch 40/150\n",
      "25272/25272 [==============================] - 3s 110us/step - loss: 0.1115 - val_loss: 0.1131\n",
      "Epoch 41/150\n",
      "25272/25272 [==============================] - 3s 102us/step - loss: 0.1113 - val_loss: 0.1134\n",
      "Evaluating model with testing data...\n",
      "5394/5394 [==============================] - 0s 15us/step\n",
      "Getting distribution of predictions and covariance matrix...\n",
      "      1 of 20\n",
      "      2 of 20\n",
      "      3 of 20\n",
      "      4 of 20\n",
      "      5 of 20\n",
      "      6 of 20\n",
      "      7 of 20\n",
      "      8 of 20\n",
      "      9 of 20\n",
      "      10 of 20\n",
      "      11 of 20\n",
      "      12 of 20\n",
      "      13 of 20\n",
      "      14 of 20\n",
      "      15 of 20\n",
      "      16 of 20\n",
      "      17 of 20\n",
      "      18 of 20\n",
      "      19 of 20\n",
      "      20 of 20\n",
      "Computing ensemble means...\n",
      "Computing mean squared error...\n",
      "Iteration 178\n",
      "Train on 25412 samples, validate on 5424 samples\n",
      "Epoch 1/150\n",
      "25412/25412 [==============================] - 3s 106us/step - loss: 0.3818 - val_loss: 0.2733\n",
      "Epoch 2/150\n",
      "25412/25412 [==============================] - 3s 108us/step - loss: 0.2313 - val_loss: 0.2112\n",
      "Epoch 3/150\n",
      "25412/25412 [==============================] - 3s 108us/step - loss: 0.1952 - val_loss: 0.1870\n",
      "Epoch 4/150\n",
      "25412/25412 [==============================] - 3s 105us/step - loss: 0.1800 - val_loss: 0.1788\n",
      "Epoch 5/150\n",
      "25412/25412 [==============================] - 3s 111us/step - loss: 0.1698 - val_loss: 0.1694\n",
      "Epoch 6/150\n",
      "25412/25412 [==============================] - 3s 109us/step - loss: 0.1656 - val_loss: 0.1636\n",
      "Epoch 7/150\n",
      "25412/25412 [==============================] - 3s 103us/step - loss: 0.1579 - val_loss: 0.1575\n",
      "Epoch 8/150\n",
      "25412/25412 [==============================] - 3s 106us/step - loss: 0.1532 - val_loss: 0.1537\n",
      "Epoch 9/150\n",
      "25412/25412 [==============================] - 3s 106us/step - loss: 0.1495 - val_loss: 0.1528\n",
      "Epoch 10/150\n",
      "25412/25412 [==============================] - 3s 106us/step - loss: 0.1479 - val_loss: 0.1489\n",
      "Epoch 11/150\n",
      "25412/25412 [==============================] - 2s 64us/step - loss: 0.1454 - val_loss: 0.1480\n",
      "Epoch 12/150\n",
      "25412/25412 [==============================] - 2s 90us/step - loss: 0.1423 - val_loss: 0.1466\n",
      "Epoch 13/150\n",
      "25412/25412 [==============================] - 3s 102us/step - loss: 0.1408 - val_loss: 0.1454\n",
      "Epoch 14/150\n",
      "25412/25412 [==============================] - 3s 100us/step - loss: 0.1377 - val_loss: 0.1384\n",
      "Epoch 15/150\n",
      "25412/25412 [==============================] - 3s 101us/step - loss: 0.1341 - val_loss: 0.1377\n",
      "Epoch 16/150\n",
      "25412/25412 [==============================] - 3s 101us/step - loss: 0.1328 - val_loss: 0.1360\n",
      "Epoch 17/150\n",
      "25412/25412 [==============================] - 3s 102us/step - loss: 0.1313 - val_loss: 0.1321\n",
      "Epoch 18/150\n",
      "25412/25412 [==============================] - 3s 104us/step - loss: 0.1293 - val_loss: 0.1332\n",
      "Epoch 19/150\n",
      "25412/25412 [==============================] - 3s 100us/step - loss: 0.1287 - val_loss: 0.1298\n",
      "Epoch 20/150\n",
      "25412/25412 [==============================] - 3s 102us/step - loss: 0.1290 - val_loss: 0.1328\n",
      "Epoch 21/150\n",
      "25412/25412 [==============================] - 3s 108us/step - loss: 0.1271 - val_loss: 0.1279\n",
      "Epoch 22/150\n",
      "25412/25412 [==============================] - 3s 104us/step - loss: 0.1262 - val_loss: 0.1290\n",
      "Epoch 23/150\n",
      "25412/25412 [==============================] - 3s 103us/step - loss: 0.1259 - val_loss: 0.1303\n",
      "Epoch 24/150\n",
      "25412/25412 [==============================] - 3s 101us/step - loss: 0.1255 - val_loss: 0.1295\n",
      "Epoch 25/150\n",
      "25412/25412 [==============================] - 3s 101us/step - loss: 0.1247 - val_loss: 0.1241\n",
      "Epoch 26/150\n",
      "25412/25412 [==============================] - 3s 105us/step - loss: 0.1240 - val_loss: 0.1280\n",
      "Epoch 27/150\n",
      "25412/25412 [==============================] - 3s 101us/step - loss: 0.1229 - val_loss: 0.1268\n",
      "Epoch 28/150\n",
      "25412/25412 [==============================] - 2s 98us/step - loss: 0.1234 - val_loss: 0.1256\n",
      "Epoch 29/150\n",
      "25412/25412 [==============================] - 3s 99us/step - loss: 0.1241 - val_loss: 0.1248\n",
      "Evaluating model with testing data...\n",
      "5424/5424 [==============================] - 0s 15us/step\n",
      "Getting distribution of predictions and covariance matrix...\n",
      "      1 of 20\n",
      "      2 of 20\n",
      "      3 of 20\n",
      "      4 of 20\n",
      "      5 of 20\n",
      "      6 of 20\n",
      "      7 of 20\n",
      "      8 of 20\n",
      "      9 of 20\n",
      "      10 of 20\n",
      "      11 of 20\n",
      "      12 of 20\n",
      "      13 of 20\n",
      "      14 of 20\n",
      "      15 of 20\n",
      "      16 of 20\n",
      "      17 of 20\n",
      "      18 of 20\n",
      "      19 of 20\n",
      "      20 of 20\n",
      "Computing ensemble means...\n",
      "Computing mean squared error...\n",
      "Iteration 179\n",
      "Train on 25552 samples, validate on 5454 samples\n",
      "Epoch 1/150\n",
      "25552/25552 [==============================] - 3s 100us/step - loss: 0.2973 - val_loss: 0.2062\n",
      "Epoch 2/150\n",
      "25552/25552 [==============================] - 3s 99us/step - loss: 0.1895 - val_loss: 0.1811\n",
      "Epoch 3/150\n",
      "25552/25552 [==============================] - 3s 100us/step - loss: 0.1705 - val_loss: 0.1680\n",
      "Epoch 4/150\n",
      "25552/25552 [==============================] - 3s 102us/step - loss: 0.1564 - val_loss: 0.1527\n",
      "Epoch 5/150\n",
      "25552/25552 [==============================] - 2s 97us/step - loss: 0.1484 - val_loss: 0.1510\n",
      "Epoch 6/150\n",
      "25552/25552 [==============================] - 3s 100us/step - loss: 0.1423 - val_loss: 0.1449\n",
      "Epoch 7/150\n",
      "25552/25552 [==============================] - 3s 102us/step - loss: 0.1383 - val_loss: 0.1420\n",
      "Epoch 8/150\n",
      "25552/25552 [==============================] - 3s 101us/step - loss: 0.1342 - val_loss: 0.1358\n",
      "Epoch 9/150\n",
      "25552/25552 [==============================] - 3s 102us/step - loss: 0.1309 - val_loss: 0.1322\n",
      "Epoch 10/150\n",
      "25552/25552 [==============================] - 2s 94us/step - loss: 0.1290 - val_loss: 0.1350\n",
      "Epoch 11/150\n",
      "25552/25552 [==============================] - 2s 96us/step - loss: 0.1270 - val_loss: 0.1297\n",
      "Epoch 12/150\n",
      "25552/25552 [==============================] - 2s 96us/step - loss: 0.1254 - val_loss: 0.1257\n",
      "Epoch 13/150\n",
      "25552/25552 [==============================] - 3s 99us/step - loss: 0.1243 - val_loss: 0.1262\n",
      "Epoch 14/150\n",
      "25552/25552 [==============================] - 2s 97us/step - loss: 0.1233 - val_loss: 0.1227\n",
      "Epoch 15/150\n",
      "25552/25552 [==============================] - 2s 96us/step - loss: 0.1205 - val_loss: 0.1216\n",
      "Epoch 16/150\n",
      "25552/25552 [==============================] - 2s 96us/step - loss: 0.1193 - val_loss: 0.1230\n",
      "Epoch 17/150\n",
      "25552/25552 [==============================] - 2s 94us/step - loss: 0.1182 - val_loss: 0.1222\n",
      "Epoch 18/150\n",
      "25552/25552 [==============================] - 2s 95us/step - loss: 0.1168 - val_loss: 0.1195\n",
      "Epoch 19/150\n",
      "25552/25552 [==============================] - 2s 98us/step - loss: 0.1152 - val_loss: 0.1199\n",
      "Epoch 20/150\n",
      "25552/25552 [==============================] - 2s 96us/step - loss: 0.1156 - val_loss: 0.1155\n",
      "Epoch 21/150\n",
      "25552/25552 [==============================] - 2s 96us/step - loss: 0.1139 - val_loss: 0.1156\n",
      "Epoch 22/150\n",
      "25552/25552 [==============================] - 3s 99us/step - loss: 0.1139 - val_loss: 0.1177\n",
      "Epoch 23/150\n",
      "25552/25552 [==============================] - 3s 101us/step - loss: 0.1130 - val_loss: 0.1141\n",
      "Epoch 24/150\n",
      "25552/25552 [==============================] - 2s 94us/step - loss: 0.1142 - val_loss: 0.1143\n",
      "Epoch 25/150\n",
      "25552/25552 [==============================] - 3s 106us/step - loss: 0.1109 - val_loss: 0.1136\n",
      "Epoch 26/150\n",
      "25552/25552 [==============================] - 3s 112us/step - loss: 0.1100 - val_loss: 0.1079\n",
      "Epoch 27/150\n",
      "25552/25552 [==============================] - 3s 113us/step - loss: 0.1095 - val_loss: 0.1130\n",
      "Epoch 28/150\n",
      "25552/25552 [==============================] - 2s 69us/step - loss: 0.1092 - val_loss: 0.1109\n",
      "Epoch 29/150\n",
      "25552/25552 [==============================] - 2s 93us/step - loss: 0.1084 - val_loss: 0.1093\n",
      "Epoch 30/150\n",
      "25552/25552 [==============================] - 3s 109us/step - loss: 0.1072 - val_loss: 0.1088\n",
      "Evaluating model with testing data...\n",
      "5454/5454 [==============================] - 0s 16us/step\n",
      "Getting distribution of predictions and covariance matrix...\n",
      "      1 of 20\n",
      "      2 of 20\n",
      "      3 of 20\n",
      "      4 of 20\n",
      "      5 of 20\n",
      "      6 of 20\n",
      "      7 of 20\n",
      "      8 of 20\n",
      "      9 of 20\n",
      "      10 of 20\n",
      "      11 of 20\n",
      "      12 of 20\n",
      "      13 of 20\n",
      "      14 of 20\n",
      "      15 of 20\n",
      "      16 of 20\n",
      "      17 of 20\n",
      "      18 of 20\n",
      "      19 of 20\n",
      "      20 of 20\n",
      "Computing ensemble means...\n",
      "Computing mean squared error...\n",
      "Iteration 180\n",
      "Train on 25692 samples, validate on 5484 samples\n",
      "Epoch 1/150\n",
      "25692/25692 [==============================] - 3s 109us/step - loss: 0.4959 - val_loss: 0.4079\n",
      "Epoch 2/150\n",
      "25692/25692 [==============================] - 3s 107us/step - loss: 0.3753 - val_loss: 0.3498\n",
      "Epoch 3/150\n",
      "25692/25692 [==============================] - 3s 105us/step - loss: 0.3349 - val_loss: 0.3251\n",
      "Epoch 4/150\n",
      "25692/25692 [==============================] - 3s 106us/step - loss: 0.3192 - val_loss: 0.3170\n",
      "Epoch 5/150\n",
      "25692/25692 [==============================] - 3s 114us/step - loss: 0.3145 - val_loss: 0.3150\n",
      "Epoch 6/150\n",
      "25692/25692 [==============================] - 3s 109us/step - loss: 0.3135 - val_loss: 0.3146\n",
      "Epoch 7/150\n",
      "25692/25692 [==============================] - 3s 106us/step - loss: 0.3133 - val_loss: 0.3146\n",
      "Epoch 8/150\n",
      "25692/25692 [==============================] - 3s 106us/step - loss: 0.3132 - val_loss: 0.3146\n",
      "Epoch 9/150\n",
      "25692/25692 [==============================] - 3s 105us/step - loss: 0.3132 - val_loss: 0.3146\n",
      "Epoch 10/150\n",
      "25692/25692 [==============================] - 3s 106us/step - loss: 0.3132 - val_loss: 0.3146\n",
      "Epoch 11/150\n",
      "25692/25692 [==============================] - 3s 109us/step - loss: 0.3132 - val_loss: 0.3146\n",
      "Evaluating model with testing data...\n",
      "5484/5484 [==============================] - 0s 16us/step\n",
      "Getting distribution of predictions and covariance matrix...\n",
      "      1 of 20\n",
      "      2 of 20\n",
      "      3 of 20\n",
      "      4 of 20\n",
      "      5 of 20\n",
      "      6 of 20\n",
      "      7 of 20\n",
      "      8 of 20\n",
      "      9 of 20\n",
      "      10 of 20\n",
      "      11 of 20\n",
      "      12 of 20\n",
      "      13 of 20\n",
      "      14 of 20\n",
      "      15 of 20\n",
      "      16 of 20\n",
      "      17 of 20\n",
      "      18 of 20\n",
      "      19 of 20\n",
      "      20 of 20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|          | 0/20 [00:00<?, ?it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing ensemble means...\n",
      "Computing mean squared error...\n",
      "Getting distribution of predictions...\n",
      "      1 of 20\n",
      "1600/1600 [==============================] - 0s 28us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  5%|▌         | 1/20 [00:29<09:15, 29.24s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      2 of 20\n",
      "1600/1600 [==============================] - 0s 29us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 10%|█         | 2/20 [00:58<08:46, 29.23s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      3 of 20\n",
      "1600/1600 [==============================] - 0s 29us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 15%|█▌        | 3/20 [01:27<08:16, 29.22s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      4 of 20\n",
      "1600/1600 [==============================] - 0s 28us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 20%|██        | 4/20 [01:57<07:49, 29.33s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      5 of 20\n",
      "1600/1600 [==============================] - 0s 29us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 25%|██▌       | 5/20 [02:26<07:20, 29.39s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      6 of 20\n",
      "1600/1600 [==============================] - 0s 29us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 30%|███       | 6/20 [02:56<06:51, 29.40s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      7 of 20\n",
      "1600/1600 [==============================] - 0s 32us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 35%|███▌      | 7/20 [03:25<06:21, 29.37s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      8 of 20\n",
      "1600/1600 [==============================] - 0s 29us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 40%|████      | 8/20 [03:54<05:52, 29.37s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      9 of 20\n",
      "1600/1600 [==============================] - 0s 29us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 45%|████▌     | 9/20 [04:24<05:23, 29.41s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      10 of 20\n",
      "1600/1600 [==============================] - 0s 28us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 50%|█████     | 10/20 [04:54<04:54, 29.49s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      11 of 20\n",
      "1600/1600 [==============================] - 0s 30us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 55%|█████▌    | 11/20 [05:23<04:25, 29.47s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      12 of 20\n",
      "1600/1600 [==============================] - 0s 29us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 60%|██████    | 12/20 [05:53<03:56, 29.60s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      13 of 20\n",
      "1600/1600 [==============================] - 0s 29us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 65%|██████▌   | 13/20 [06:22<03:27, 29.57s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      14 of 20\n",
      "1600/1600 [==============================] - 0s 30us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 70%|███████   | 14/20 [06:52<02:57, 29.58s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      15 of 20\n",
      "1600/1600 [==============================] - 0s 29us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 75%|███████▌  | 15/20 [07:21<02:27, 29.54s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      16 of 20\n",
      "1600/1600 [==============================] - 0s 29us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 80%|████████  | 16/20 [07:51<01:57, 29.50s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      17 of 20\n",
      "1600/1600 [==============================] - 0s 29us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 85%|████████▌ | 17/20 [08:20<01:28, 29.52s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      18 of 20\n",
      "1600/1600 [==============================] - 0s 29us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 90%|█████████ | 18/20 [08:50<00:58, 29.50s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      19 of 20\n",
      "1600/1600 [==============================] - 0s 29us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 95%|█████████▌| 19/20 [09:19<00:29, 29.48s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      20 of 20\n",
      "1600/1600 [==============================] - 0s 29us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 20/20 [09:49<00:00, 29.48s/it]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing ensemble predictions...\n",
      "Iteration 181\n",
      "Train on 25832 samples, validate on 5514 samples\n",
      "Epoch 1/150\n",
      "25832/25832 [==============================] - 3s 109us/step - loss: 0.3445 - val_loss: 0.2345\n",
      "Epoch 2/150\n",
      "25832/25832 [==============================] - 3s 98us/step - loss: 0.2069 - val_loss: 0.1948\n",
      "Epoch 3/150\n",
      "25832/25832 [==============================] - 3s 110us/step - loss: 0.1804 - val_loss: 0.1724\n",
      "Epoch 4/150\n",
      "25832/25832 [==============================] - 3s 102us/step - loss: 0.1667 - val_loss: 0.1696\n",
      "Epoch 5/150\n",
      "25832/25832 [==============================] - 3s 106us/step - loss: 0.1577 - val_loss: 0.1585\n",
      "Epoch 6/150\n",
      "25832/25832 [==============================] - 3s 103us/step - loss: 0.1514 - val_loss: 0.1514\n",
      "Epoch 7/150\n",
      "25832/25832 [==============================] - 3s 98us/step - loss: 0.1500 - val_loss: 0.1502\n",
      "Epoch 8/150\n",
      "25832/25832 [==============================] - 3s 102us/step - loss: 0.1474 - val_loss: 0.1496\n",
      "Epoch 9/150\n",
      "25832/25832 [==============================] - 3s 109us/step - loss: 0.1468 - val_loss: 0.1491\n",
      "Epoch 10/150\n",
      "25832/25832 [==============================] - 3s 109us/step - loss: 0.1441 - val_loss: 0.1471\n",
      "Epoch 11/150\n",
      "25832/25832 [==============================] - 3s 105us/step - loss: 0.1440 - val_loss: 0.1456\n",
      "Epoch 12/150\n",
      "25832/25832 [==============================] - 3s 100us/step - loss: 0.1408 - val_loss: 0.1414\n",
      "Epoch 13/150\n",
      "25832/25832 [==============================] - 3s 109us/step - loss: 0.1386 - val_loss: 0.1415\n",
      "Epoch 14/150\n",
      "25832/25832 [==============================] - 3s 103us/step - loss: 0.1359 - val_loss: 0.1342\n",
      "Epoch 15/150\n",
      "25832/25832 [==============================] - 3s 105us/step - loss: 0.1345 - val_loss: 0.1352\n",
      "Epoch 16/150\n",
      "25832/25832 [==============================] - 3s 100us/step - loss: 0.1325 - val_loss: 0.1349\n",
      "Epoch 17/150\n",
      "25832/25832 [==============================] - 3s 108us/step - loss: 0.1301 - val_loss: 0.1298\n",
      "Epoch 18/150\n",
      "25832/25832 [==============================] - 3s 103us/step - loss: 0.1274 - val_loss: 0.1294\n",
      "Epoch 19/150\n",
      "25832/25832 [==============================] - 3s 104us/step - loss: 0.1276 - val_loss: 0.1315\n",
      "Epoch 20/150\n",
      "25832/25832 [==============================] - 3s 102us/step - loss: 0.1259 - val_loss: 0.1303\n",
      "Epoch 21/150\n",
      "25832/25832 [==============================] - 3s 106us/step - loss: 0.1256 - val_loss: 0.1240\n",
      "Epoch 22/150\n",
      "25832/25832 [==============================] - 3s 101us/step - loss: 0.1245 - val_loss: 0.1279\n",
      "Epoch 23/150\n",
      "25832/25832 [==============================] - 3s 102us/step - loss: 0.1233 - val_loss: 0.1245\n",
      "Epoch 24/150\n",
      "25832/25832 [==============================] - 3s 100us/step - loss: 0.1229 - val_loss: 0.1236\n",
      "Epoch 25/150\n",
      "25832/25832 [==============================] - 3s 98us/step - loss: 0.1223 - val_loss: 0.1242\n",
      "Epoch 26/150\n",
      "25832/25832 [==============================] - 3s 103us/step - loss: 0.1205 - val_loss: 0.1227\n",
      "Epoch 27/150\n",
      "25832/25832 [==============================] - 3s 100us/step - loss: 0.1200 - val_loss: 0.1215\n",
      "Epoch 28/150\n",
      "25832/25832 [==============================] - 3s 97us/step - loss: 0.1189 - val_loss: 0.1194\n",
      "Epoch 29/150\n",
      "25832/25832 [==============================] - 3s 103us/step - loss: 0.1180 - val_loss: 0.1202\n",
      "Epoch 30/150\n",
      "25832/25832 [==============================] - 3s 101us/step - loss: 0.1183 - val_loss: 0.1180\n",
      "Epoch 31/150\n",
      "25832/25832 [==============================] - 3s 105us/step - loss: 0.1162 - val_loss: 0.1172\n",
      "Epoch 32/150\n",
      "25832/25832 [==============================] - 3s 97us/step - loss: 0.1147 - val_loss: 0.1164\n",
      "Epoch 33/150\n",
      "25832/25832 [==============================] - 2s 88us/step - loss: 0.1138 - val_loss: 0.1152\n",
      "Epoch 34/150\n",
      "25832/25832 [==============================] - 2s 67us/step - loss: 0.1123 - val_loss: 0.1147\n",
      "Epoch 35/150\n",
      "25832/25832 [==============================] - 2s 85us/step - loss: 0.1109 - val_loss: 0.1114\n",
      "Epoch 36/150\n",
      "25832/25832 [==============================] - 2s 97us/step - loss: 0.1096 - val_loss: 0.1095\n",
      "Epoch 37/150\n",
      "25832/25832 [==============================] - 3s 104us/step - loss: 0.1091 - val_loss: 0.1095\n",
      "Epoch 38/150\n",
      "25832/25832 [==============================] - 3s 103us/step - loss: 0.1091 - val_loss: 0.1098\n",
      "Epoch 39/150\n",
      "25832/25832 [==============================] - 3s 105us/step - loss: 0.1077 - val_loss: 0.1099\n",
      "Epoch 40/150\n",
      "25832/25832 [==============================] - 2s 95us/step - loss: 0.1070 - val_loss: 0.1060\n",
      "Epoch 41/150\n",
      "25832/25832 [==============================] - 3s 98us/step - loss: 0.1055 - val_loss: 0.1064\n",
      "Epoch 42/150\n",
      "25832/25832 [==============================] - 3s 99us/step - loss: 0.1056 - val_loss: 0.1064\n",
      "Epoch 43/150\n",
      "25832/25832 [==============================] - 3s 100us/step - loss: 0.1048 - val_loss: 0.1072\n",
      "Epoch 44/150\n",
      "25832/25832 [==============================] - 3s 99us/step - loss: 0.1046 - val_loss: 0.1060\n",
      "Epoch 45/150\n",
      "25832/25832 [==============================] - 3s 99us/step - loss: 0.1040 - val_loss: 0.1075\n",
      "Epoch 46/150\n",
      "25832/25832 [==============================] - 3s 99us/step - loss: 0.1034 - val_loss: 0.1040\n",
      "Epoch 47/150\n",
      "25832/25832 [==============================] - 3s 98us/step - loss: 0.1033 - val_loss: 0.1054\n",
      "Epoch 48/150\n",
      "25832/25832 [==============================] - 3s 97us/step - loss: 0.1026 - val_loss: 0.1060\n",
      "Epoch 49/150\n",
      "25832/25832 [==============================] - 3s 100us/step - loss: 0.1019 - val_loss: 0.1039\n",
      "Epoch 50/150\n",
      "25832/25832 [==============================] - 3s 101us/step - loss: 0.1016 - val_loss: 0.1030\n",
      "Epoch 51/150\n",
      "25832/25832 [==============================] - 3s 98us/step - loss: 0.1015 - val_loss: 0.1023\n",
      "Epoch 52/150\n",
      "25832/25832 [==============================] - 3s 99us/step - loss: 0.1014 - val_loss: 0.1024\n",
      "Epoch 53/150\n",
      "25832/25832 [==============================] - 3s 100us/step - loss: 0.1006 - val_loss: 0.1025\n",
      "Epoch 54/150\n",
      "25832/25832 [==============================] - 2s 95us/step - loss: 0.1005 - val_loss: 0.1025\n",
      "Epoch 55/150\n",
      "25832/25832 [==============================] - 2s 97us/step - loss: 0.0990 - val_loss: 0.1000\n",
      "Epoch 56/150\n",
      "25832/25832 [==============================] - 2s 96us/step - loss: 0.0993 - val_loss: 0.1011\n",
      "Epoch 57/150\n",
      "25832/25832 [==============================] - 3s 99us/step - loss: 0.0988 - val_loss: 0.0991\n",
      "Epoch 58/150\n",
      "25832/25832 [==============================] - 3s 99us/step - loss: 0.0983 - val_loss: 0.0992\n",
      "Epoch 59/150\n",
      "25832/25832 [==============================] - 3s 97us/step - loss: 0.0976 - val_loss: 0.0990\n",
      "Epoch 60/150\n",
      "25832/25832 [==============================] - 2s 96us/step - loss: 0.0979 - val_loss: 0.1000\n",
      "Epoch 61/150\n",
      "25832/25832 [==============================] - 2s 94us/step - loss: 0.0972 - val_loss: 0.0983\n",
      "Epoch 62/150\n",
      "25832/25832 [==============================] - 3s 100us/step - loss: 0.0958 - val_loss: 0.1007\n",
      "Epoch 63/150\n",
      "25832/25832 [==============================] - 2s 96us/step - loss: 0.0964 - val_loss: 0.0978\n",
      "Epoch 64/150\n",
      "25832/25832 [==============================] - 3s 98us/step - loss: 0.0971 - val_loss: 0.0993\n",
      "Epoch 65/150\n",
      "25832/25832 [==============================] - 2s 92us/step - loss: 0.0959 - val_loss: 0.0981\n",
      "Epoch 66/150\n",
      "25832/25832 [==============================] - 3s 98us/step - loss: 0.0962 - val_loss: 0.0972\n",
      "Epoch 67/150\n",
      "25832/25832 [==============================] - 3s 99us/step - loss: 0.0955 - val_loss: 0.0955\n",
      "Epoch 68/150\n",
      "25832/25832 [==============================] - 3s 99us/step - loss: 0.0940 - val_loss: 0.0940\n",
      "Epoch 69/150\n",
      "25832/25832 [==============================] - 2s 96us/step - loss: 0.0950 - val_loss: 0.0968\n",
      "Epoch 70/150\n",
      "25832/25832 [==============================] - 3s 98us/step - loss: 0.0938 - val_loss: 0.0934\n",
      "Epoch 71/150\n",
      "25832/25832 [==============================] - 2s 97us/step - loss: 0.0934 - val_loss: 0.0955\n",
      "Epoch 72/150\n",
      "25832/25832 [==============================] - 2s 96us/step - loss: 0.0933 - val_loss: 0.0949\n",
      "Epoch 73/150\n",
      "25832/25832 [==============================] - 3s 98us/step - loss: 0.0920 - val_loss: 0.0959\n",
      "Epoch 74/150\n",
      "25832/25832 [==============================] - 2s 93us/step - loss: 0.0930 - val_loss: 0.0933\n",
      "Epoch 75/150\n",
      "25832/25832 [==============================] - 2s 94us/step - loss: 0.0919 - val_loss: 0.0930\n",
      "Epoch 76/150\n",
      "25832/25832 [==============================] - 3s 108us/step - loss: 0.0922 - val_loss: 0.0935\n",
      "Epoch 77/150\n",
      "25832/25832 [==============================] - 3s 108us/step - loss: 0.0915 - val_loss: 0.0961\n",
      "Epoch 78/150\n",
      "25832/25832 [==============================] - 3s 109us/step - loss: 0.0921 - val_loss: 0.0952\n",
      "Epoch 79/150\n",
      "25832/25832 [==============================] - 3s 103us/step - loss: 0.0916 - val_loss: 0.0933\n",
      "Evaluating model with testing data...\n",
      "5514/5514 [==============================] - 0s 16us/step\n",
      "Getting distribution of predictions and covariance matrix...\n",
      "      1 of 20\n",
      "      2 of 20\n",
      "      3 of 20\n",
      "      4 of 20\n",
      "      5 of 20\n",
      "      6 of 20\n",
      "      7 of 20\n",
      "      8 of 20\n",
      "      9 of 20\n",
      "      10 of 20\n",
      "      11 of 20\n",
      "      12 of 20\n",
      "      13 of 20\n",
      "      14 of 20\n",
      "      15 of 20\n",
      "      16 of 20\n",
      "      17 of 20\n",
      "      18 of 20\n",
      "      19 of 20\n",
      "      20 of 20\n",
      "Computing ensemble means...\n",
      "Computing mean squared error...\n",
      "Iteration 182\n",
      "Train on 25972 samples, validate on 5544 samples\n",
      "Epoch 1/150\n",
      "25972/25972 [==============================] - 2s 65us/step - loss: 0.3363 - val_loss: 0.2356\n",
      "Epoch 2/150\n",
      "25972/25972 [==============================] - 3s 105us/step - loss: 0.2114 - val_loss: 0.2003\n",
      "Epoch 3/150\n",
      "25972/25972 [==============================] - 3s 106us/step - loss: 0.1857 - val_loss: 0.1794\n",
      "Epoch 4/150\n",
      "25972/25972 [==============================] - 3s 108us/step - loss: 0.1703 - val_loss: 0.1632\n",
      "Epoch 5/150\n",
      "25972/25972 [==============================] - 3s 99us/step - loss: 0.1584 - val_loss: 0.1585\n",
      "Epoch 6/150\n",
      "25972/25972 [==============================] - 3s 102us/step - loss: 0.1540 - val_loss: 0.1532\n",
      "Epoch 7/150\n",
      "25972/25972 [==============================] - 3s 107us/step - loss: 0.1487 - val_loss: 0.1502\n",
      "Epoch 8/150\n",
      "25972/25972 [==============================] - 3s 104us/step - loss: 0.1469 - val_loss: 0.1536\n",
      "Epoch 9/150\n",
      "25972/25972 [==============================] - 3s 104us/step - loss: 0.1448 - val_loss: 0.1458\n",
      "Epoch 10/150\n",
      "25972/25972 [==============================] - 3s 106us/step - loss: 0.1431 - val_loss: 0.1467\n",
      "Epoch 11/150\n",
      "25972/25972 [==============================] - 3s 103us/step - loss: 0.1423 - val_loss: 0.1467\n",
      "Epoch 12/150\n",
      "25972/25972 [==============================] - 3s 102us/step - loss: 0.1402 - val_loss: 0.1415\n",
      "Epoch 13/150\n",
      "25972/25972 [==============================] - 3s 104us/step - loss: 0.1404 - val_loss: 0.1459\n",
      "Epoch 14/150\n",
      "25972/25972 [==============================] - 3s 105us/step - loss: 0.1390 - val_loss: 0.1410\n",
      "Epoch 15/150\n",
      "25972/25972 [==============================] - 3s 104us/step - loss: 0.1371 - val_loss: 0.1384\n",
      "Epoch 16/150\n",
      "25972/25972 [==============================] - 3s 103us/step - loss: 0.1389 - val_loss: 0.1389\n",
      "Epoch 17/150\n",
      "25972/25972 [==============================] - 3s 99us/step - loss: 0.1367 - val_loss: 0.1389\n",
      "Epoch 18/150\n",
      "25972/25972 [==============================] - 3s 103us/step - loss: 0.1356 - val_loss: 0.1354\n",
      "Epoch 19/150\n",
      "25972/25972 [==============================] - 3s 98us/step - loss: 0.1339 - val_loss: 0.1363\n",
      "Epoch 20/150\n",
      "25972/25972 [==============================] - 3s 103us/step - loss: 0.1345 - val_loss: 0.1362\n",
      "Epoch 21/150\n",
      "25972/25972 [==============================] - 3s 104us/step - loss: 0.1339 - val_loss: 0.1364\n",
      "Epoch 22/150\n",
      "25972/25972 [==============================] - 3s 105us/step - loss: 0.1327 - val_loss: 0.1348\n",
      "Epoch 23/150\n",
      "25972/25972 [==============================] - 3s 103us/step - loss: 0.1339 - val_loss: 0.1331\n",
      "Epoch 24/150\n",
      "25972/25972 [==============================] - 3s 103us/step - loss: 0.1327 - val_loss: 0.1346\n",
      "Epoch 25/150\n",
      "25972/25972 [==============================] - 3s 98us/step - loss: 0.1307 - val_loss: 0.1330\n",
      "Epoch 26/150\n",
      "25972/25972 [==============================] - 3s 99us/step - loss: 0.1317 - val_loss: 0.1341\n",
      "Epoch 27/150\n",
      "25972/25972 [==============================] - 3s 103us/step - loss: 0.1272 - val_loss: 0.1273\n",
      "Epoch 28/150\n",
      "25972/25972 [==============================] - 3s 104us/step - loss: 0.1256 - val_loss: 0.1289\n",
      "Epoch 29/150\n",
      "25972/25972 [==============================] - 3s 99us/step - loss: 0.1252 - val_loss: 0.1255\n",
      "Epoch 30/150\n",
      "25972/25972 [==============================] - 2s 95us/step - loss: 0.1250 - val_loss: 0.1275\n",
      "Epoch 31/150\n",
      "25972/25972 [==============================] - 3s 98us/step - loss: 0.1251 - val_loss: 0.1276\n",
      "Epoch 32/150\n",
      "25972/25972 [==============================] - 3s 104us/step - loss: 0.1245 - val_loss: 0.1239\n",
      "Epoch 33/150\n",
      "25972/25972 [==============================] - 2s 96us/step - loss: 0.1245 - val_loss: 0.1266\n",
      "Epoch 34/150\n",
      "25972/25972 [==============================] - 3s 101us/step - loss: 0.1230 - val_loss: 0.1246\n",
      "Epoch 35/150\n",
      "25972/25972 [==============================] - 3s 97us/step - loss: 0.1228 - val_loss: 0.1263\n",
      "Epoch 36/150\n",
      "25972/25972 [==============================] - 3s 102us/step - loss: 0.1223 - val_loss: 0.1246\n",
      "Evaluating model with testing data...\n",
      "5544/5544 [==============================] - 0s 15us/step\n",
      "Getting distribution of predictions and covariance matrix...\n",
      "      1 of 20\n",
      "      2 of 20\n",
      "      3 of 20\n",
      "      4 of 20\n",
      "      5 of 20\n",
      "      6 of 20\n",
      "      7 of 20\n",
      "      8 of 20\n",
      "      9 of 20\n",
      "      10 of 20\n",
      "      11 of 20\n",
      "      12 of 20\n",
      "      13 of 20\n",
      "      14 of 20\n",
      "      15 of 20\n",
      "      16 of 20\n",
      "      17 of 20\n",
      "      18 of 20\n",
      "      19 of 20\n",
      "      20 of 20\n",
      "Computing ensemble means...\n",
      "Computing mean squared error...\n",
      "Iteration 183\n",
      "Train on 26112 samples, validate on 5574 samples\n",
      "Epoch 1/150\n",
      "26112/26112 [==============================] - 3s 101us/step - loss: 0.3916 - val_loss: 0.2995\n",
      "Epoch 2/150\n",
      "26112/26112 [==============================] - 3s 99us/step - loss: 0.2645 - val_loss: 0.2447\n",
      "Epoch 3/150\n",
      "26112/26112 [==============================] - 3s 98us/step - loss: 0.2297 - val_loss: 0.2236\n",
      "Epoch 4/150\n",
      "26112/26112 [==============================] - 3s 100us/step - loss: 0.2134 - val_loss: 0.2081\n",
      "Epoch 5/150\n",
      "26112/26112 [==============================] - 3s 98us/step - loss: 0.1945 - val_loss: 0.1900\n",
      "Epoch 6/150\n",
      "26112/26112 [==============================] - 3s 103us/step - loss: 0.1829 - val_loss: 0.1848\n",
      "Epoch 7/150\n",
      "26112/26112 [==============================] - 3s 99us/step - loss: 0.1800 - val_loss: 0.1812\n",
      "Epoch 8/150\n",
      "26112/26112 [==============================] - 3s 102us/step - loss: 0.1782 - val_loss: 0.1841\n",
      "Epoch 9/150\n",
      "26112/26112 [==============================] - 2s 75us/step - loss: 0.1774 - val_loss: 0.1791\n",
      "Epoch 10/150\n",
      "26112/26112 [==============================] - 2s 80us/step - loss: 0.1749 - val_loss: 0.1785\n",
      "Epoch 11/150\n",
      "26112/26112 [==============================] - 3s 98us/step - loss: 0.1751 - val_loss: 0.1794\n",
      "Epoch 12/150\n",
      "26112/26112 [==============================] - 3s 102us/step - loss: 0.1729 - val_loss: 0.1721\n",
      "Epoch 13/150\n",
      "26112/26112 [==============================] - 3s 100us/step - loss: 0.1675 - val_loss: 0.1689\n",
      "Epoch 14/150\n",
      "26112/26112 [==============================] - 3s 98us/step - loss: 0.1671 - val_loss: 0.1681\n",
      "Epoch 15/150\n",
      "26112/26112 [==============================] - 3s 100us/step - loss: 0.1646 - val_loss: 0.1649\n",
      "Epoch 16/150\n",
      "26112/26112 [==============================] - 3s 98us/step - loss: 0.1637 - val_loss: 0.1670\n",
      "Epoch 17/150\n",
      "26112/26112 [==============================] - 3s 96us/step - loss: 0.1647 - val_loss: 0.1676\n",
      "Epoch 18/150\n",
      "26112/26112 [==============================] - 2s 94us/step - loss: 0.1621 - val_loss: 0.1656\n",
      "Epoch 19/150\n",
      "26112/26112 [==============================] - 2s 93us/step - loss: 0.1619 - val_loss: 0.1663\n",
      "Evaluating model with testing data...\n",
      "5574/5574 [==============================] - 0s 15us/step\n",
      "Getting distribution of predictions and covariance matrix...\n",
      "      1 of 20\n",
      "      2 of 20\n",
      "      3 of 20\n",
      "      4 of 20\n",
      "      5 of 20\n",
      "      6 of 20\n",
      "      7 of 20\n",
      "      8 of 20\n",
      "      9 of 20\n",
      "      10 of 20\n",
      "      11 of 20\n",
      "      12 of 20\n",
      "      13 of 20\n",
      "      14 of 20\n",
      "      15 of 20\n",
      "      16 of 20\n",
      "      17 of 20\n",
      "      18 of 20\n",
      "      19 of 20\n",
      "      20 of 20\n",
      "Computing ensemble means...\n",
      "Computing mean squared error...\n",
      "Iteration 184\n",
      "Train on 26252 samples, validate on 5604 samples\n",
      "Epoch 1/150\n",
      "26252/26252 [==============================] - 3s 100us/step - loss: 0.3726 - val_loss: 0.2559\n",
      "Epoch 2/150\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "26252/26252 [==============================] - 3s 108us/step - loss: 0.2211 - val_loss: 0.2036\n",
      "Epoch 3/150\n",
      "26252/26252 [==============================] - 3s 114us/step - loss: 0.1889 - val_loss: 0.1879\n",
      "Epoch 4/150\n",
      "26252/26252 [==============================] - 3s 108us/step - loss: 0.1750 - val_loss: 0.1722\n",
      "Epoch 5/150\n",
      "26252/26252 [==============================] - 3s 111us/step - loss: 0.1663 - val_loss: 0.1672\n",
      "Epoch 6/150\n",
      "26252/26252 [==============================] - 3s 110us/step - loss: 0.1617 - val_loss: 0.1632\n",
      "Epoch 7/150\n",
      "26252/26252 [==============================] - 3s 112us/step - loss: 0.1600 - val_loss: 0.1616\n",
      "Epoch 8/150\n",
      "26252/26252 [==============================] - 3s 109us/step - loss: 0.1585 - val_loss: 0.1618\n",
      "Epoch 9/150\n",
      "26252/26252 [==============================] - 3s 111us/step - loss: 0.1559 - val_loss: 0.1620\n",
      "Epoch 10/150\n",
      "26252/26252 [==============================] - 3s 107us/step - loss: 0.1552 - val_loss: 0.1581\n",
      "Epoch 11/150\n",
      "26252/26252 [==============================] - 3s 111us/step - loss: 0.1540 - val_loss: 0.1587\n",
      "Epoch 12/150\n",
      "26252/26252 [==============================] - 3s 109us/step - loss: 0.1532 - val_loss: 0.1537\n",
      "Epoch 13/150\n",
      "26252/26252 [==============================] - 3s 111us/step - loss: 0.1504 - val_loss: 0.1485\n",
      "Epoch 14/150\n",
      "26252/26252 [==============================] - 3s 108us/step - loss: 0.1477 - val_loss: 0.1496\n",
      "Epoch 15/150\n",
      "26252/26252 [==============================] - 3s 104us/step - loss: 0.1475 - val_loss: 0.1518\n",
      "Epoch 16/150\n",
      "26252/26252 [==============================] - 3s 113us/step - loss: 0.1444 - val_loss: 0.1489\n",
      "Epoch 17/150\n",
      "26252/26252 [==============================] - 3s 107us/step - loss: 0.1432 - val_loss: 0.1448\n",
      "Epoch 18/150\n",
      "26252/26252 [==============================] - 3s 107us/step - loss: 0.1416 - val_loss: 0.1427\n",
      "Epoch 19/150\n",
      "26252/26252 [==============================] - 3s 108us/step - loss: 0.1400 - val_loss: 0.1384\n",
      "Epoch 20/150\n",
      "26252/26252 [==============================] - 3s 110us/step - loss: 0.1358 - val_loss: 0.1390\n",
      "Epoch 21/150\n",
      "26252/26252 [==============================] - 3s 109us/step - loss: 0.1343 - val_loss: 0.1377\n",
      "Epoch 22/150\n",
      "26252/26252 [==============================] - 3s 111us/step - loss: 0.1338 - val_loss: 0.1364\n",
      "Epoch 23/150\n",
      "26252/26252 [==============================] - 3s 108us/step - loss: 0.1328 - val_loss: 0.1314\n",
      "Epoch 24/150\n",
      "26252/26252 [==============================] - 3s 103us/step - loss: 0.1310 - val_loss: 0.1331\n",
      "Epoch 25/150\n",
      "26252/26252 [==============================] - 3s 106us/step - loss: 0.1304 - val_loss: 0.1308\n",
      "Epoch 26/150\n",
      "26252/26252 [==============================] - 3s 103us/step - loss: 0.1260 - val_loss: 0.1296\n",
      "Epoch 27/150\n",
      "26252/26252 [==============================] - 3s 107us/step - loss: 0.1225 - val_loss: 0.1201\n",
      "Epoch 28/150\n",
      "26252/26252 [==============================] - 3s 108us/step - loss: 0.1196 - val_loss: 0.1200\n",
      "Epoch 29/150\n",
      "26252/26252 [==============================] - 3s 102us/step - loss: 0.1170 - val_loss: 0.1170\n",
      "Epoch 30/150\n",
      "26252/26252 [==============================] - 3s 104us/step - loss: 0.1141 - val_loss: 0.1161\n",
      "Epoch 31/150\n",
      "26252/26252 [==============================] - 3s 104us/step - loss: 0.1147 - val_loss: 0.1173\n",
      "Epoch 32/150\n",
      "26252/26252 [==============================] - 3s 103us/step - loss: 0.1126 - val_loss: 0.1145\n",
      "Epoch 33/150\n",
      "26252/26252 [==============================] - 2s 64us/step - loss: 0.1124 - val_loss: 0.1128\n",
      "Epoch 34/150\n",
      "26252/26252 [==============================] - 2s 92us/step - loss: 0.1117 - val_loss: 0.1147\n",
      "Epoch 35/150\n",
      "26252/26252 [==============================] - 3s 108us/step - loss: 0.1106 - val_loss: 0.1135\n",
      "Epoch 36/150\n",
      "26252/26252 [==============================] - 3s 103us/step - loss: 0.1119 - val_loss: 0.1109\n",
      "Epoch 37/150\n",
      "26252/26252 [==============================] - 3s 104us/step - loss: 0.1097 - val_loss: 0.1122\n",
      "Epoch 38/150\n",
      "26252/26252 [==============================] - 3s 101us/step - loss: 0.1116 - val_loss: 0.1116\n",
      "Epoch 39/150\n",
      "26252/26252 [==============================] - 3s 101us/step - loss: 0.1099 - val_loss: 0.1123\n",
      "Epoch 40/150\n",
      "26252/26252 [==============================] - 3s 101us/step - loss: 0.1101 - val_loss: 0.1131\n",
      "Evaluating model with testing data...\n",
      "5604/5604 [==============================] - 0s 16us/step\n",
      "Getting distribution of predictions and covariance matrix...\n",
      "      1 of 20\n",
      "      2 of 20\n",
      "      3 of 20\n",
      "      4 of 20\n",
      "      5 of 20\n",
      "      6 of 20\n",
      "      7 of 20\n",
      "      8 of 20\n",
      "      9 of 20\n",
      "      10 of 20\n",
      "      11 of 20\n",
      "      12 of 20\n",
      "      13 of 20\n",
      "      14 of 20\n",
      "      15 of 20\n",
      "      16 of 20\n",
      "      17 of 20\n",
      "      18 of 20\n",
      "      19 of 20\n",
      "      20 of 20\n",
      "Computing ensemble means...\n",
      "Computing mean squared error...\n",
      "Iteration 185\n",
      "Train on 26392 samples, validate on 5634 samples\n",
      "Epoch 1/150\n",
      "26392/26392 [==============================] - 3s 106us/step - loss: 0.3193 - val_loss: 0.2092\n",
      "Epoch 2/150\n",
      "26392/26392 [==============================] - 3s 104us/step - loss: 0.1959 - val_loss: 0.1902\n",
      "Epoch 3/150\n",
      "26392/26392 [==============================] - 3s 102us/step - loss: 0.1762 - val_loss: 0.1731\n",
      "Epoch 4/150\n",
      "26392/26392 [==============================] - 3s 99us/step - loss: 0.1643 - val_loss: 0.1677\n",
      "Epoch 5/150\n",
      "26392/26392 [==============================] - 3s 98us/step - loss: 0.1582 - val_loss: 0.1600\n",
      "Epoch 6/150\n",
      "26392/26392 [==============================] - 3s 101us/step - loss: 0.1531 - val_loss: 0.1538\n",
      "Epoch 7/150\n",
      "26392/26392 [==============================] - 3s 99us/step - loss: 0.1490 - val_loss: 0.1512\n",
      "Epoch 8/150\n",
      "26392/26392 [==============================] - 3s 97us/step - loss: 0.1444 - val_loss: 0.1453\n",
      "Epoch 9/150\n",
      "26392/26392 [==============================] - 3s 99us/step - loss: 0.1379 - val_loss: 0.1386\n",
      "Epoch 10/150\n",
      "26392/26392 [==============================] - 3s 102us/step - loss: 0.1337 - val_loss: 0.1373\n",
      "Epoch 11/150\n",
      "26392/26392 [==============================] - 3s 97us/step - loss: 0.1315 - val_loss: 0.1311\n",
      "Epoch 12/150\n",
      "26392/26392 [==============================] - 3s 100us/step - loss: 0.1284 - val_loss: 0.1277\n",
      "Epoch 13/150\n",
      "26392/26392 [==============================] - 3s 100us/step - loss: 0.1272 - val_loss: 0.1258\n",
      "Epoch 14/150\n",
      "26392/26392 [==============================] - 3s 98us/step - loss: 0.1257 - val_loss: 0.1250\n",
      "Epoch 15/150\n",
      "26392/26392 [==============================] - 3s 96us/step - loss: 0.1238 - val_loss: 0.1270\n",
      "Epoch 16/150\n",
      "26392/26392 [==============================] - 3s 96us/step - loss: 0.1218 - val_loss: 0.1242\n",
      "Epoch 17/150\n",
      "26392/26392 [==============================] - 3s 98us/step - loss: 0.1209 - val_loss: 0.1214\n",
      "Epoch 18/150\n",
      "26392/26392 [==============================] - 3s 99us/step - loss: 0.1185 - val_loss: 0.1189\n",
      "Epoch 19/150\n",
      "26392/26392 [==============================] - 3s 100us/step - loss: 0.1171 - val_loss: 0.1196\n",
      "Epoch 20/150\n",
      "26392/26392 [==============================] - 2s 93us/step - loss: 0.1161 - val_loss: 0.1200\n",
      "Epoch 21/150\n",
      "26392/26392 [==============================] - 3s 98us/step - loss: 0.1139 - val_loss: 0.1148\n",
      "Epoch 22/150\n",
      "26392/26392 [==============================] - 3s 98us/step - loss: 0.1130 - val_loss: 0.1133\n",
      "Epoch 23/150\n",
      "26392/26392 [==============================] - 3s 101us/step - loss: 0.1120 - val_loss: 0.1152\n",
      "Epoch 24/150\n",
      "26392/26392 [==============================] - 3s 95us/step - loss: 0.1132 - val_loss: 0.1133\n",
      "Epoch 25/150\n",
      "26392/26392 [==============================] - 3s 96us/step - loss: 0.1119 - val_loss: 0.1126\n",
      "Epoch 26/150\n",
      "26392/26392 [==============================] - 3s 97us/step - loss: 0.1098 - val_loss: 0.1126\n",
      "Epoch 27/150\n",
      "26392/26392 [==============================] - 3s 97us/step - loss: 0.1103 - val_loss: 0.1114\n",
      "Epoch 28/150\n",
      "26392/26392 [==============================] - 3s 95us/step - loss: 0.1093 - val_loss: 0.1096\n",
      "Epoch 29/150\n",
      "26392/26392 [==============================] - 3s 101us/step - loss: 0.1090 - val_loss: 0.1121\n",
      "Epoch 30/150\n",
      "26392/26392 [==============================] - 3s 98us/step - loss: 0.1091 - val_loss: 0.1102\n",
      "Epoch 31/150\n",
      "26392/26392 [==============================] - 3s 95us/step - loss: 0.1088 - val_loss: 0.1132\n",
      "Epoch 32/150\n",
      "26392/26392 [==============================] - 3s 97us/step - loss: 0.1074 - val_loss: 0.1099\n",
      "Evaluating model with testing data...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5634/5634 [==============================] - 0s 15us/step\n",
      "Getting distribution of predictions and covariance matrix...\n",
      "      1 of 20\n",
      "      2 of 20\n",
      "      3 of 20\n",
      "      4 of 20\n",
      "      5 of 20\n",
      "      6 of 20\n",
      "      7 of 20\n",
      "      8 of 20\n",
      "      9 of 20\n",
      "      10 of 20\n",
      "      11 of 20\n",
      "      12 of 20\n",
      "      13 of 20\n",
      "      14 of 20\n",
      "      15 of 20\n",
      "      16 of 20\n",
      "      17 of 20\n",
      "      18 of 20\n",
      "      19 of 20\n",
      "      20 of 20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|          | 0/20 [00:00<?, ?it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing ensemble means...\n",
      "Computing mean squared error...\n",
      "Getting distribution of predictions...\n",
      "      1 of 20\n",
      "1600/1600 [==============================] - 0s 27us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  5%|▌         | 1/20 [00:29<09:12, 29.09s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      2 of 20\n",
      "1600/1600 [==============================] - 0s 29us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 10%|█         | 2/20 [00:58<08:46, 29.26s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      3 of 20\n",
      "1600/1600 [==============================] - 0s 28us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 15%|█▌        | 3/20 [01:28<08:17, 29.27s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      4 of 20\n",
      "1600/1600 [==============================] - 0s 33us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 20%|██        | 4/20 [01:57<07:50, 29.44s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      5 of 20\n",
      "1600/1600 [==============================] - 0s 29us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 25%|██▌       | 5/20 [02:27<07:21, 29.43s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      6 of 20\n",
      "1600/1600 [==============================] - 0s 29us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 30%|███       | 6/20 [02:56<06:52, 29.48s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      7 of 20\n",
      "1600/1600 [==============================] - 0s 30us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 35%|███▌      | 7/20 [03:26<06:24, 29.55s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      8 of 20\n",
      "1600/1600 [==============================] - 0s 30us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 40%|████      | 8/20 [03:56<05:55, 29.63s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      9 of 20\n",
      "1600/1600 [==============================] - 0s 29us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 45%|████▌     | 9/20 [04:25<05:24, 29.52s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      10 of 20\n",
      "1600/1600 [==============================] - 0s 29us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 50%|█████     | 10/20 [04:55<04:55, 29.55s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      11 of 20\n",
      "1600/1600 [==============================] - 0s 29us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 55%|█████▌    | 11/20 [05:24<04:26, 29.57s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      12 of 20\n",
      "1600/1600 [==============================] - 0s 29us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 60%|██████    | 12/20 [05:54<03:56, 29.60s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      13 of 20\n",
      "1600/1600 [==============================] - 0s 29us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 65%|██████▌   | 13/20 [06:24<03:27, 29.68s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      14 of 20\n",
      "1600/1600 [==============================] - 0s 29us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 70%|███████   | 14/20 [06:54<02:58, 29.71s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      15 of 20\n",
      "1600/1600 [==============================] - 0s 29us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 75%|███████▌  | 15/20 [07:23<02:28, 29.71s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      16 of 20\n",
      "1600/1600 [==============================] - 0s 29us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 80%|████████  | 16/20 [07:53<01:58, 29.72s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      17 of 20\n",
      "1600/1600 [==============================] - 0s 29us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 85%|████████▌ | 17/20 [08:22<01:28, 29.53s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      18 of 20\n",
      "1600/1600 [==============================] - 0s 29us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 90%|█████████ | 18/20 [08:52<00:59, 29.52s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      19 of 20\n",
      "1600/1600 [==============================] - 0s 29us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 95%|█████████▌| 19/20 [09:22<00:29, 29.68s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      20 of 20\n",
      "1600/1600 [==============================] - 0s 29us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 20/20 [09:52<00:00, 29.60s/it]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing ensemble predictions...\n",
      "Iteration 186\n",
      "Train on 26532 samples, validate on 5664 samples\n",
      "Epoch 1/150\n",
      "26532/26532 [==============================] - 3s 110us/step - loss: 0.4013 - val_loss: 0.2982\n",
      "Epoch 2/150\n",
      "26532/26532 [==============================] - 3s 111us/step - loss: 0.2620 - val_loss: 0.2417\n",
      "Epoch 3/150\n",
      "26532/26532 [==============================] - 3s 104us/step - loss: 0.2172 - val_loss: 0.2058\n",
      "Epoch 4/150\n",
      "26532/26532 [==============================] - 3s 111us/step - loss: 0.1941 - val_loss: 0.1882\n",
      "Epoch 5/150\n",
      "26532/26532 [==============================] - 3s 108us/step - loss: 0.1784 - val_loss: 0.1757\n",
      "Epoch 6/150\n",
      "26532/26532 [==============================] - 3s 109us/step - loss: 0.1719 - val_loss: 0.1710\n",
      "Epoch 7/150\n",
      "26532/26532 [==============================] - 2s 70us/step - loss: 0.1660 - val_loss: 0.1679\n",
      "Epoch 8/150\n",
      "26532/26532 [==============================] - 2s 89us/step - loss: 0.1630 - val_loss: 0.1575\n",
      "Epoch 9/150\n",
      "26532/26532 [==============================] - 3s 110us/step - loss: 0.1570 - val_loss: 0.1567\n",
      "Epoch 10/150\n",
      "26532/26532 [==============================] - 3s 107us/step - loss: 0.1532 - val_loss: 0.1558\n",
      "Epoch 11/150\n",
      "26532/26532 [==============================] - 3s 105us/step - loss: 0.1530 - val_loss: 0.1556\n",
      "Epoch 12/150\n",
      "26532/26532 [==============================] - 3s 110us/step - loss: 0.1509 - val_loss: 0.1529\n",
      "Epoch 13/150\n",
      "26532/26532 [==============================] - 3s 109us/step - loss: 0.1490 - val_loss: 0.1559\n",
      "Epoch 14/150\n",
      "26532/26532 [==============================] - 3s 102us/step - loss: 0.1493 - val_loss: 0.1479\n",
      "Epoch 15/150\n",
      "26532/26532 [==============================] - 3s 97us/step - loss: 0.1476 - val_loss: 0.1477\n",
      "Epoch 16/150\n",
      "26532/26532 [==============================] - 3s 102us/step - loss: 0.1454 - val_loss: 0.1479\n",
      "Epoch 17/150\n",
      "26532/26532 [==============================] - 3s 106us/step - loss: 0.1462 - val_loss: 0.1463\n",
      "Epoch 18/150\n",
      "26532/26532 [==============================] - 2s 90us/step - loss: 0.1448 - val_loss: 0.1453\n",
      "Epoch 19/150\n",
      "26532/26532 [==============================] - 3s 101us/step - loss: 0.1444 - val_loss: 0.1439\n",
      "Epoch 20/150\n",
      "26532/26532 [==============================] - 3s 104us/step - loss: 0.1417 - val_loss: 0.1399\n",
      "Epoch 21/150\n",
      "26532/26532 [==============================] - 2s 89us/step - loss: 0.1391 - val_loss: 0.1443\n",
      "Epoch 22/150\n",
      "26532/26532 [==============================] - 3s 97us/step - loss: 0.1391 - val_loss: 0.1400\n",
      "Epoch 23/150\n",
      "26532/26532 [==============================] - 3s 95us/step - loss: 0.1378 - val_loss: 0.1424\n",
      "Epoch 24/150\n",
      "26532/26532 [==============================] - 2s 91us/step - loss: 0.1371 - val_loss: 0.1372\n",
      "Epoch 25/150\n",
      "26532/26532 [==============================] - 3s 95us/step - loss: 0.1355 - val_loss: 0.1357\n",
      "Epoch 26/150\n",
      "26532/26532 [==============================] - 2s 88us/step - loss: 0.1350 - val_loss: 0.1350\n",
      "Epoch 27/150\n",
      "26532/26532 [==============================] - 2s 94us/step - loss: 0.1340 - val_loss: 0.1370\n",
      "Epoch 28/150\n",
      "26532/26532 [==============================] - 3s 95us/step - loss: 0.1345 - val_loss: 0.1367\n",
      "Epoch 29/150\n",
      "26532/26532 [==============================] - 2s 91us/step - loss: 0.1329 - val_loss: 0.1344\n",
      "Epoch 30/150\n",
      "26532/26532 [==============================] - 2s 92us/step - loss: 0.1333 - val_loss: 0.1361\n",
      "Epoch 31/150\n",
      "26532/26532 [==============================] - 2s 93us/step - loss: 0.1330 - val_loss: 0.1337\n",
      "Epoch 32/150\n",
      "26532/26532 [==============================] - 3s 95us/step - loss: 0.1317 - val_loss: 0.1339\n",
      "Epoch 33/150\n",
      "26532/26532 [==============================] - 2s 93us/step - loss: 0.1317 - val_loss: 0.1339\n",
      "Epoch 34/150\n",
      "26532/26532 [==============================] - 2s 91us/step - loss: 0.1310 - val_loss: 0.1305\n",
      "Epoch 35/150\n",
      "26532/26532 [==============================] - 3s 97us/step - loss: 0.1301 - val_loss: 0.1326\n",
      "Epoch 36/150\n",
      "26532/26532 [==============================] - 3s 96us/step - loss: 0.1311 - val_loss: 0.1322\n",
      "Epoch 37/150\n",
      "26532/26532 [==============================] - 3s 99us/step - loss: 0.1300 - val_loss: 0.1325\n",
      "Epoch 38/150\n",
      "26532/26532 [==============================] - 3s 97us/step - loss: 0.1295 - val_loss: 0.1314\n",
      "Evaluating model with testing data...\n",
      "5664/5664 [==============================] - 0s 16us/step\n",
      "Getting distribution of predictions and covariance matrix...\n",
      "      1 of 20\n",
      "      2 of 20\n",
      "      3 of 20\n",
      "      4 of 20\n",
      "      5 of 20\n",
      "      6 of 20\n",
      "      7 of 20\n",
      "      8 of 20\n",
      "      9 of 20\n",
      "      10 of 20\n",
      "      11 of 20\n",
      "      12 of 20\n",
      "      13 of 20\n",
      "      14 of 20\n",
      "      15 of 20\n",
      "      16 of 20\n",
      "      17 of 20\n",
      "      18 of 20\n",
      "      19 of 20\n",
      "      20 of 20\n",
      "Computing ensemble means...\n",
      "Computing mean squared error...\n",
      "Iteration 187\n",
      "Train on 26672 samples, validate on 5694 samples\n",
      "Epoch 1/150\n",
      "26672/26672 [==============================] - 3s 96us/step - loss: 0.3929 - val_loss: 0.3064\n",
      "Epoch 2/150\n",
      "26672/26672 [==============================] - 3s 98us/step - loss: 0.2817 - val_loss: 0.2674\n",
      "Epoch 3/150\n",
      "26672/26672 [==============================] - 3s 96us/step - loss: 0.2424 - val_loss: 0.2134\n",
      "Epoch 4/150\n",
      "26672/26672 [==============================] - 3s 96us/step - loss: 0.2036 - val_loss: 0.1955\n",
      "Epoch 5/150\n",
      "26672/26672 [==============================] - 3s 96us/step - loss: 0.1906 - val_loss: 0.1915\n",
      "Epoch 6/150\n",
      "26672/26672 [==============================] - 2s 94us/step - loss: 0.1844 - val_loss: 0.1836\n",
      "Epoch 7/150\n",
      "26672/26672 [==============================] - 3s 94us/step - loss: 0.1802 - val_loss: 0.1859\n",
      "Epoch 8/150\n",
      "26672/26672 [==============================] - 3s 97us/step - loss: 0.1758 - val_loss: 0.1719\n",
      "Epoch 9/150\n",
      "26672/26672 [==============================] - 3s 95us/step - loss: 0.1708 - val_loss: 0.1715\n",
      "Epoch 10/150\n",
      "26672/26672 [==============================] - 3s 96us/step - loss: 0.1698 - val_loss: 0.1720\n",
      "Epoch 11/150\n",
      "26672/26672 [==============================] - 2s 91us/step - loss: 0.1622 - val_loss: 0.1619\n",
      "Epoch 12/150\n",
      "26672/26672 [==============================] - 2s 91us/step - loss: 0.1572 - val_loss: 0.1587\n",
      "Epoch 13/150\n",
      "26672/26672 [==============================] - 3s 95us/step - loss: 0.1559 - val_loss: 0.1555\n",
      "Epoch 14/150\n",
      "26672/26672 [==============================] - 2s 93us/step - loss: 0.1537 - val_loss: 0.1520\n",
      "Epoch 15/150\n",
      "26672/26672 [==============================] - 2s 59us/step - loss: 0.1523 - val_loss: 0.1525\n",
      "Epoch 16/150\n",
      "26672/26672 [==============================] - 2s 91us/step - loss: 0.1511 - val_loss: 0.1526\n",
      "Epoch 17/150\n",
      "26672/26672 [==============================] - 3s 96us/step - loss: 0.1501 - val_loss: 0.1513\n",
      "Epoch 18/150\n",
      "26672/26672 [==============================] - 3s 97us/step - loss: 0.1463 - val_loss: 0.1479\n",
      "Epoch 19/150\n",
      "26672/26672 [==============================] - 2s 94us/step - loss: 0.1441 - val_loss: 0.1441\n",
      "Epoch 20/150\n",
      "26672/26672 [==============================] - 3s 100us/step - loss: 0.1419 - val_loss: 0.1412\n",
      "Epoch 21/150\n",
      "26672/26672 [==============================] - 2s 91us/step - loss: 0.1388 - val_loss: 0.1384\n",
      "Epoch 22/150\n",
      "26672/26672 [==============================] - 3s 94us/step - loss: 0.1365 - val_loss: 0.1368\n",
      "Epoch 23/150\n",
      "26672/26672 [==============================] - 2s 93us/step - loss: 0.1346 - val_loss: 0.1362\n",
      "Epoch 24/150\n",
      "26672/26672 [==============================] - 3s 95us/step - loss: 0.1350 - val_loss: 0.1345\n",
      "Epoch 25/150\n",
      "26672/26672 [==============================] - 2s 93us/step - loss: 0.1336 - val_loss: 0.1333\n",
      "Epoch 26/150\n",
      "26672/26672 [==============================] - 3s 95us/step - loss: 0.1325 - val_loss: 0.1350\n",
      "Epoch 27/150\n",
      "26672/26672 [==============================] - 2s 93us/step - loss: 0.1336 - val_loss: 0.1329\n",
      "Epoch 28/150\n",
      "26672/26672 [==============================] - 2s 93us/step - loss: 0.1328 - val_loss: 0.1331\n",
      "Epoch 29/150\n",
      "26672/26672 [==============================] - 2s 93us/step - loss: 0.1327 - val_loss: 0.1325\n",
      "Epoch 30/150\n",
      "26672/26672 [==============================] - 2s 91us/step - loss: 0.1320 - val_loss: 0.1320\n",
      "Epoch 31/150\n",
      "26672/26672 [==============================] - 2s 94us/step - loss: 0.1311 - val_loss: 0.1356\n",
      "Epoch 32/150\n",
      "26672/26672 [==============================] - 3s 95us/step - loss: 0.1306 - val_loss: 0.1318\n",
      "Epoch 33/150\n",
      "26672/26672 [==============================] - 3s 112us/step - loss: 0.1307 - val_loss: 0.1310\n",
      "Epoch 34/150\n",
      "26672/26672 [==============================] - 3s 110us/step - loss: 0.1282 - val_loss: 0.1301\n",
      "Epoch 35/150\n",
      "26672/26672 [==============================] - 3s 107us/step - loss: 0.1260 - val_loss: 0.1268\n",
      "Epoch 36/150\n",
      "26672/26672 [==============================] - 3s 111us/step - loss: 0.1259 - val_loss: 0.1295\n",
      "Epoch 37/150\n",
      "26672/26672 [==============================] - 3s 111us/step - loss: 0.1266 - val_loss: 0.1262\n",
      "Epoch 38/150\n",
      "26672/26672 [==============================] - 3s 108us/step - loss: 0.1262 - val_loss: 0.1282\n",
      "Epoch 39/150\n",
      "26672/26672 [==============================] - 3s 109us/step - loss: 0.1239 - val_loss: 0.1281\n",
      "Epoch 40/150\n",
      "26672/26672 [==============================] - 3s 106us/step - loss: 0.1247 - val_loss: 0.1265\n",
      "Epoch 41/150\n",
      "26672/26672 [==============================] - 3s 109us/step - loss: 0.1251 - val_loss: 0.1252\n",
      "Epoch 42/150\n",
      "26672/26672 [==============================] - 3s 111us/step - loss: 0.1240 - val_loss: 0.1248\n",
      "Epoch 43/150\n",
      "26672/26672 [==============================] - 3s 112us/step - loss: 0.1227 - val_loss: 0.1239\n",
      "Epoch 44/150\n",
      "26672/26672 [==============================] - 3s 106us/step - loss: 0.1247 - val_loss: 0.1246\n",
      "Epoch 45/150\n",
      "26672/26672 [==============================] - 3s 108us/step - loss: 0.1240 - val_loss: 0.1241\n",
      "Epoch 46/150\n",
      "26672/26672 [==============================] - 3s 106us/step - loss: 0.1234 - val_loss: 0.1272\n",
      "Epoch 47/150\n",
      "26672/26672 [==============================] - 3s 109us/step - loss: 0.1233 - val_loss: 0.1229\n",
      "Epoch 48/150\n",
      "26672/26672 [==============================] - 3s 105us/step - loss: 0.1223 - val_loss: 0.1265\n",
      "Epoch 49/150\n",
      "26672/26672 [==============================] - 3s 107us/step - loss: 0.1222 - val_loss: 0.1240\n",
      "Epoch 50/150\n",
      "26672/26672 [==============================] - 3s 106us/step - loss: 0.1214 - val_loss: 0.1230\n",
      "Epoch 51/150\n",
      "26672/26672 [==============================] - 3s 105us/step - loss: 0.1208 - val_loss: 0.1228\n",
      "Epoch 52/150\n",
      "26672/26672 [==============================] - 3s 110us/step - loss: 0.1226 - val_loss: 0.1255\n",
      "Epoch 53/150\n",
      "26672/26672 [==============================] - 3s 107us/step - loss: 0.1218 - val_loss: 0.1218\n",
      "Epoch 54/150\n",
      "26672/26672 [==============================] - 3s 106us/step - loss: 0.1204 - val_loss: 0.1228\n",
      "Epoch 55/150\n",
      "26672/26672 [==============================] - 3s 109us/step - loss: 0.1211 - val_loss: 0.1227\n",
      "Epoch 56/150\n",
      "26672/26672 [==============================] - 3s 105us/step - loss: 0.1207 - val_loss: 0.1221\n",
      "Epoch 57/150\n",
      "26672/26672 [==============================] - 3s 104us/step - loss: 0.1207 - val_loss: 0.1204\n",
      "Epoch 58/150\n",
      "26672/26672 [==============================] - 3s 108us/step - loss: 0.1206 - val_loss: 0.1233\n",
      "Epoch 59/150\n",
      "26672/26672 [==============================] - 2s 72us/step - loss: 0.1192 - val_loss: 0.1208\n",
      "Epoch 60/150\n",
      "26672/26672 [==============================] - 2s 90us/step - loss: 0.1193 - val_loss: 0.1227\n",
      "Epoch 61/150\n",
      "26672/26672 [==============================] - 3s 103us/step - loss: 0.1184 - val_loss: 0.1227\n",
      "Evaluating model with testing data...\n",
      "5694/5694 [==============================] - 0s 16us/step\n",
      "Getting distribution of predictions and covariance matrix...\n",
      "      1 of 20\n",
      "      2 of 20\n",
      "      3 of 20\n",
      "      4 of 20\n",
      "      5 of 20\n",
      "      6 of 20\n",
      "      7 of 20\n",
      "      8 of 20\n",
      "      9 of 20\n",
      "      10 of 20\n",
      "      11 of 20\n",
      "      12 of 20\n",
      "      13 of 20\n",
      "      14 of 20\n",
      "      15 of 20\n",
      "      16 of 20\n",
      "      17 of 20\n",
      "      18 of 20\n",
      "      19 of 20\n",
      "      20 of 20\n",
      "Computing ensemble means...\n",
      "Computing mean squared error...\n",
      "Iteration 188\n",
      "Train on 26812 samples, validate on 5724 samples\n",
      "Epoch 1/150\n",
      "26812/26812 [==============================] - 3s 101us/step - loss: 0.2789 - val_loss: 0.1911\n",
      "Epoch 2/150\n",
      "26812/26812 [==============================] - 3s 104us/step - loss: 0.1755 - val_loss: 0.1635\n",
      "Epoch 3/150\n",
      "26812/26812 [==============================] - 3s 101us/step - loss: 0.1578 - val_loss: 0.1514\n",
      "Epoch 4/150\n",
      "26812/26812 [==============================] - 3s 102us/step - loss: 0.1471 - val_loss: 0.1417\n",
      "Epoch 5/150\n",
      "26812/26812 [==============================] - 3s 104us/step - loss: 0.1373 - val_loss: 0.1323\n",
      "Epoch 6/150\n",
      "26812/26812 [==============================] - 3s 102us/step - loss: 0.1316 - val_loss: 0.1321\n",
      "Epoch 7/150\n",
      "26812/26812 [==============================] - 3s 100us/step - loss: 0.1279 - val_loss: 0.1271\n",
      "Epoch 8/150\n",
      "26812/26812 [==============================] - 3s 103us/step - loss: 0.1260 - val_loss: 0.1261\n",
      "Epoch 9/150\n",
      "26812/26812 [==============================] - 3s 99us/step - loss: 0.1226 - val_loss: 0.1208\n",
      "Epoch 10/150\n",
      "26812/26812 [==============================] - 3s 102us/step - loss: 0.1205 - val_loss: 0.1186\n",
      "Epoch 11/150\n",
      "26812/26812 [==============================] - 3s 102us/step - loss: 0.1197 - val_loss: 0.1169\n",
      "Epoch 12/150\n",
      "26812/26812 [==============================] - 3s 100us/step - loss: 0.1175 - val_loss: 0.1164\n",
      "Epoch 13/150\n",
      "26812/26812 [==============================] - 3s 103us/step - loss: 0.1166 - val_loss: 0.1172\n",
      "Epoch 14/150\n",
      "26812/26812 [==============================] - 3s 95us/step - loss: 0.1146 - val_loss: 0.1154\n",
      "Epoch 15/150\n",
      "26812/26812 [==============================] - 3s 97us/step - loss: 0.1145 - val_loss: 0.1144\n",
      "Epoch 16/150\n",
      "26812/26812 [==============================] - 3s 102us/step - loss: 0.1113 - val_loss: 0.1120\n",
      "Epoch 17/150\n",
      "26812/26812 [==============================] - 3s 99us/step - loss: 0.1109 - val_loss: 0.1119\n",
      "Epoch 18/150\n",
      "26812/26812 [==============================] - 3s 99us/step - loss: 0.1091 - val_loss: 0.1094\n",
      "Epoch 19/150\n",
      "26812/26812 [==============================] - 3s 101us/step - loss: 0.1065 - val_loss: 0.1074\n",
      "Epoch 20/150\n",
      "26812/26812 [==============================] - 3s 100us/step - loss: 0.1058 - val_loss: 0.1065\n",
      "Epoch 21/150\n",
      "26812/26812 [==============================] - 3s 101us/step - loss: 0.1053 - val_loss: 0.1052\n",
      "Epoch 22/150\n",
      "26812/26812 [==============================] - 3s 98us/step - loss: 0.1034 - val_loss: 0.1055\n",
      "Epoch 23/150\n",
      "26812/26812 [==============================] - 3s 99us/step - loss: 0.1042 - val_loss: 0.1080\n",
      "Epoch 24/150\n",
      "26812/26812 [==============================] - 3s 102us/step - loss: 0.1030 - val_loss: 0.1030\n",
      "Epoch 25/150\n",
      "26812/26812 [==============================] - 3s 98us/step - loss: 0.1013 - val_loss: 0.1041\n",
      "Epoch 26/150\n",
      "26812/26812 [==============================] - 3s 102us/step - loss: 0.1015 - val_loss: 0.1008\n",
      "Epoch 27/150\n",
      "26812/26812 [==============================] - 3s 100us/step - loss: 0.1011 - val_loss: 0.1028\n",
      "Epoch 28/150\n",
      "26812/26812 [==============================] - 3s 98us/step - loss: 0.0988 - val_loss: 0.0991\n",
      "Epoch 29/150\n",
      "26812/26812 [==============================] - 3s 96us/step - loss: 0.0989 - val_loss: 0.0986\n",
      "Epoch 30/150\n",
      "26812/26812 [==============================] - 3s 103us/step - loss: 0.0975 - val_loss: 0.0986\n",
      "Epoch 31/150\n",
      "26812/26812 [==============================] - 3s 97us/step - loss: 0.0975 - val_loss: 0.0970\n",
      "Epoch 32/150\n",
      "26812/26812 [==============================] - 3s 97us/step - loss: 0.0969 - val_loss: 0.0964\n",
      "Epoch 33/150\n",
      "26812/26812 [==============================] - 3s 96us/step - loss: 0.0971 - val_loss: 0.0980\n",
      "Epoch 34/150\n",
      "26812/26812 [==============================] - 3s 95us/step - loss: 0.0967 - val_loss: 0.0939\n",
      "Epoch 35/150\n",
      "26812/26812 [==============================] - 3s 98us/step - loss: 0.0953 - val_loss: 0.0953\n",
      "Epoch 36/150\n",
      "26812/26812 [==============================] - 3s 98us/step - loss: 0.0962 - val_loss: 0.0972\n",
      "Epoch 37/150\n",
      "26812/26812 [==============================] - 3s 95us/step - loss: 0.0950 - val_loss: 0.0953\n",
      "Epoch 38/150\n",
      "26812/26812 [==============================] - 2s 92us/step - loss: 0.0951 - val_loss: 0.0942\n",
      "Evaluating model with testing data...\n",
      "5724/5724 [==============================] - 0s 16us/step\n",
      "Getting distribution of predictions and covariance matrix...\n",
      "      1 of 20\n",
      "      2 of 20\n",
      "      3 of 20\n",
      "      4 of 20\n",
      "      5 of 20\n",
      "      6 of 20\n",
      "      7 of 20\n",
      "      8 of 20\n",
      "      9 of 20\n",
      "      10 of 20\n",
      "      11 of 20\n",
      "      12 of 20\n",
      "      13 of 20\n",
      "      14 of 20\n",
      "      15 of 20\n",
      "      16 of 20\n",
      "      17 of 20\n",
      "      18 of 20\n",
      "      19 of 20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      20 of 20\n",
      "Computing ensemble means...\n",
      "Computing mean squared error...\n",
      "Iteration 189\n",
      "Train on 26952 samples, validate on 5754 samples\n",
      "Epoch 1/150\n",
      "26952/26952 [==============================] - 3s 110us/step - loss: 0.4035 - val_loss: 0.2814\n",
      "Epoch 2/150\n",
      "26952/26952 [==============================] - 3s 108us/step - loss: 0.2476 - val_loss: 0.2300\n",
      "Epoch 3/150\n",
      "26952/26952 [==============================] - 2s 60us/step - loss: 0.2167 - val_loss: 0.2092\n",
      "Epoch 4/150\n",
      "26952/26952 [==============================] - 3s 101us/step - loss: 0.1981 - val_loss: 0.1978\n",
      "Epoch 5/150\n",
      "26952/26952 [==============================] - 3s 100us/step - loss: 0.1902 - val_loss: 0.1858\n",
      "Epoch 6/150\n",
      "26952/26952 [==============================] - 3s 100us/step - loss: 0.1848 - val_loss: 0.1897\n",
      "Epoch 7/150\n",
      "26952/26952 [==============================] - 3s 103us/step - loss: 0.1821 - val_loss: 0.1810\n",
      "Epoch 8/150\n",
      "26952/26952 [==============================] - 3s 96us/step - loss: 0.1809 - val_loss: 0.1812\n",
      "Epoch 9/150\n",
      "26952/26952 [==============================] - 3s 100us/step - loss: 0.1795 - val_loss: 0.1830\n",
      "Epoch 10/150\n",
      "26952/26952 [==============================] - 3s 107us/step - loss: 0.1773 - val_loss: 0.1837\n",
      "Epoch 11/150\n",
      "26952/26952 [==============================] - 3s 106us/step - loss: 0.1770 - val_loss: 0.1774\n",
      "Epoch 12/150\n",
      "26952/26952 [==============================] - 3s 110us/step - loss: 0.1755 - val_loss: 0.1797\n",
      "Epoch 13/150\n",
      "26952/26952 [==============================] - 3s 108us/step - loss: 0.1722 - val_loss: 0.1682\n",
      "Epoch 14/150\n",
      "26952/26952 [==============================] - 3s 105us/step - loss: 0.1670 - val_loss: 0.1690\n",
      "Epoch 15/150\n",
      "26952/26952 [==============================] - 3s 109us/step - loss: 0.1658 - val_loss: 0.1687\n",
      "Epoch 16/150\n",
      "26952/26952 [==============================] - 3s 106us/step - loss: 0.1629 - val_loss: 0.1633\n",
      "Epoch 17/150\n",
      "26952/26952 [==============================] - 3s 106us/step - loss: 0.1645 - val_loss: 0.1668\n",
      "Epoch 18/150\n",
      "26952/26952 [==============================] - 3s 109us/step - loss: 0.1614 - val_loss: 0.1635\n",
      "Epoch 19/150\n",
      "26952/26952 [==============================] - 3s 106us/step - loss: 0.1614 - val_loss: 0.1656\n",
      "Epoch 20/150\n",
      "26952/26952 [==============================] - 3s 107us/step - loss: 0.1604 - val_loss: 0.1647\n",
      "Evaluating model with testing data...\n",
      "5754/5754 [==============================] - 0s 15us/step\n",
      "Getting distribution of predictions and covariance matrix...\n",
      "      1 of 20\n",
      "      2 of 20\n",
      "      3 of 20\n",
      "      4 of 20\n",
      "      5 of 20\n",
      "      6 of 20\n",
      "      7 of 20\n",
      "      8 of 20\n",
      "      9 of 20\n",
      "      10 of 20\n",
      "      11 of 20\n",
      "      12 of 20\n",
      "      13 of 20\n",
      "      14 of 20\n",
      "      15 of 20\n",
      "      16 of 20\n",
      "      17 of 20\n",
      "      18 of 20\n",
      "      19 of 20\n",
      "      20 of 20\n",
      "Computing ensemble means...\n",
      "Computing mean squared error...\n",
      "Iteration 190\n",
      "Train on 27092 samples, validate on 5784 samples\n",
      "Epoch 1/150\n",
      "27092/27092 [==============================] - 3s 97us/step - loss: 0.3134 - val_loss: 0.2051\n",
      "Epoch 2/150\n",
      "27092/27092 [==============================] - 3s 102us/step - loss: 0.1886 - val_loss: 0.1784\n",
      "Epoch 3/150\n",
      "27092/27092 [==============================] - 3s 106us/step - loss: 0.1663 - val_loss: 0.1569\n",
      "Epoch 4/150\n",
      "27092/27092 [==============================] - 3s 103us/step - loss: 0.1545 - val_loss: 0.1508\n",
      "Epoch 5/150\n",
      "27092/27092 [==============================] - 3s 104us/step - loss: 0.1460 - val_loss: 0.1424\n",
      "Epoch 6/150\n",
      "27092/27092 [==============================] - 3s 104us/step - loss: 0.1416 - val_loss: 0.1415\n",
      "Epoch 7/150\n",
      "27092/27092 [==============================] - 3s 102us/step - loss: 0.1381 - val_loss: 0.1389\n",
      "Epoch 8/150\n",
      "27092/27092 [==============================] - 3s 101us/step - loss: 0.1363 - val_loss: 0.1360\n",
      "Epoch 9/150\n",
      "27092/27092 [==============================] - 3s 101us/step - loss: 0.1331 - val_loss: 0.1368\n",
      "Epoch 10/150\n",
      "27092/27092 [==============================] - 3s 107us/step - loss: 0.1313 - val_loss: 0.1313\n",
      "Epoch 11/150\n",
      "27092/27092 [==============================] - 3s 102us/step - loss: 0.1307 - val_loss: 0.1313\n",
      "Epoch 12/150\n",
      "27092/27092 [==============================] - 3s 99us/step - loss: 0.1289 - val_loss: 0.1310\n",
      "Epoch 13/150\n",
      "27092/27092 [==============================] - 3s 106us/step - loss: 0.1254 - val_loss: 0.1266\n",
      "Epoch 14/150\n",
      "27092/27092 [==============================] - 3s 107us/step - loss: 0.1250 - val_loss: 0.1248\n",
      "Epoch 15/150\n",
      "27092/27092 [==============================] - 3s 103us/step - loss: 0.1234 - val_loss: 0.1247\n",
      "Epoch 16/150\n",
      "27092/27092 [==============================] - 3s 107us/step - loss: 0.1215 - val_loss: 0.1223\n",
      "Epoch 17/150\n",
      "27092/27092 [==============================] - 3s 103us/step - loss: 0.1220 - val_loss: 0.1208\n",
      "Epoch 18/150\n",
      "27092/27092 [==============================] - 3s 100us/step - loss: 0.1208 - val_loss: 0.1214\n",
      "Epoch 19/150\n",
      "27092/27092 [==============================] - 3s 98us/step - loss: 0.1200 - val_loss: 0.1213\n",
      "Epoch 20/150\n",
      "27092/27092 [==============================] - 3s 105us/step - loss: 0.1193 - val_loss: 0.1181\n",
      "Epoch 21/150\n",
      "27092/27092 [==============================] - 3s 101us/step - loss: 0.1186 - val_loss: 0.1224\n",
      "Epoch 22/150\n",
      "27092/27092 [==============================] - 3s 103us/step - loss: 0.1180 - val_loss: 0.1181\n",
      "Epoch 23/150\n",
      "27092/27092 [==============================] - 3s 100us/step - loss: 0.1169 - val_loss: 0.1192\n",
      "Epoch 24/150\n",
      "27092/27092 [==============================] - 3s 102us/step - loss: 0.1170 - val_loss: 0.1194\n",
      "Epoch 25/150\n",
      "27092/27092 [==============================] - 2s 62us/step - loss: 0.1156 - val_loss: 0.1169\n",
      "Epoch 26/150\n",
      "27092/27092 [==============================] - 2s 90us/step - loss: 0.1157 - val_loss: 0.1161\n",
      "Epoch 27/150\n",
      "27092/27092 [==============================] - 3s 101us/step - loss: 0.1145 - val_loss: 0.1182\n",
      "Epoch 28/150\n",
      "27092/27092 [==============================] - 3s 102us/step - loss: 0.1143 - val_loss: 0.1167\n",
      "Epoch 29/150\n",
      "27092/27092 [==============================] - 3s 100us/step - loss: 0.1140 - val_loss: 0.1148\n",
      "Epoch 30/150\n",
      "27092/27092 [==============================] - 3s 99us/step - loss: 0.1136 - val_loss: 0.1147\n",
      "Epoch 31/150\n",
      "27092/27092 [==============================] - 3s 99us/step - loss: 0.1124 - val_loss: 0.1154\n",
      "Epoch 32/150\n",
      "27092/27092 [==============================] - 3s 100us/step - loss: 0.1127 - val_loss: 0.1128\n",
      "Epoch 33/150\n",
      "27092/27092 [==============================] - 3s 97us/step - loss: 0.1108 - val_loss: 0.1114\n",
      "Epoch 34/150\n",
      "27092/27092 [==============================] - 3s 97us/step - loss: 0.1099 - val_loss: 0.1119\n",
      "Epoch 35/150\n",
      "27092/27092 [==============================] - 3s 100us/step - loss: 0.1090 - val_loss: 0.1119\n",
      "Epoch 36/150\n",
      "27092/27092 [==============================] - 3s 102us/step - loss: 0.1082 - val_loss: 0.1093\n",
      "Epoch 37/150\n",
      "27092/27092 [==============================] - 3s 100us/step - loss: 0.1078 - val_loss: 0.1079\n",
      "Epoch 38/150\n",
      "27092/27092 [==============================] - 3s 96us/step - loss: 0.1079 - val_loss: 0.1098\n",
      "Epoch 39/150\n",
      "27092/27092 [==============================] - 3s 96us/step - loss: 0.1077 - val_loss: 0.1075\n",
      "Epoch 40/150\n",
      "27092/27092 [==============================] - 3s 98us/step - loss: 0.1072 - val_loss: 0.1071\n",
      "Epoch 41/150\n",
      "27092/27092 [==============================] - 3s 99us/step - loss: 0.1078 - val_loss: 0.1075\n",
      "Epoch 42/150\n",
      "27092/27092 [==============================] - 3s 99us/step - loss: 0.1058 - val_loss: 0.1083\n",
      "Epoch 43/150\n",
      "27092/27092 [==============================] - 3s 99us/step - loss: 0.1069 - val_loss: 0.1088\n",
      "Epoch 44/150\n",
      "27092/27092 [==============================] - 3s 96us/step - loss: 0.1068 - val_loss: 0.1066\n",
      "Epoch 45/150\n",
      "27092/27092 [==============================] - 3s 97us/step - loss: 0.1055 - val_loss: 0.1076\n",
      "Epoch 46/150\n",
      "27092/27092 [==============================] - 3s 94us/step - loss: 0.1047 - val_loss: 0.1092\n",
      "Epoch 47/150\n",
      "27092/27092 [==============================] - 3s 94us/step - loss: 0.1061 - val_loss: 0.1068\n",
      "Epoch 48/150\n",
      "27092/27092 [==============================] - 3s 96us/step - loss: 0.1047 - val_loss: 0.1054\n",
      "Epoch 49/150\n",
      "27092/27092 [==============================] - 3s 96us/step - loss: 0.1046 - val_loss: 0.1074\n",
      "Epoch 50/150\n",
      "27092/27092 [==============================] - 3s 111us/step - loss: 0.1034 - val_loss: 0.1053\n",
      "Epoch 51/150\n",
      "27092/27092 [==============================] - 3s 109us/step - loss: 0.1035 - val_loss: 0.1066\n",
      "Epoch 52/150\n",
      "27092/27092 [==============================] - 3s 113us/step - loss: 0.1033 - val_loss: 0.1057\n",
      "Epoch 53/150\n",
      "27092/27092 [==============================] - 3s 101us/step - loss: 0.1039 - val_loss: 0.1049\n",
      "Epoch 54/150\n",
      "27092/27092 [==============================] - 3s 110us/step - loss: 0.1034 - val_loss: 0.1047\n",
      "Epoch 55/150\n",
      "27092/27092 [==============================] - 3s 108us/step - loss: 0.1028 - val_loss: 0.1052\n",
      "Epoch 56/150\n",
      "27092/27092 [==============================] - 3s 109us/step - loss: 0.1037 - val_loss: 0.1036\n",
      "Epoch 57/150\n",
      "27092/27092 [==============================] - 3s 111us/step - loss: 0.1030 - val_loss: 0.1033\n",
      "Epoch 58/150\n",
      "27092/27092 [==============================] - 3s 107us/step - loss: 0.1040 - val_loss: 0.1053\n",
      "Epoch 59/150\n",
      "27092/27092 [==============================] - 3s 113us/step - loss: 0.1019 - val_loss: 0.1046\n",
      "Epoch 60/150\n",
      "27092/27092 [==============================] - 3s 113us/step - loss: 0.1031 - val_loss: 0.1048\n",
      "Epoch 61/150\n",
      "27092/27092 [==============================] - 3s 103us/step - loss: 0.1030 - val_loss: 0.1029\n",
      "Epoch 62/150\n",
      "27092/27092 [==============================] - 3s 105us/step - loss: 0.1027 - val_loss: 0.1016\n",
      "Epoch 63/150\n",
      "27092/27092 [==============================] - 3s 109us/step - loss: 0.1018 - val_loss: 0.1017\n",
      "Epoch 64/150\n",
      "27092/27092 [==============================] - 3s 104us/step - loss: 0.1018 - val_loss: 0.1041\n",
      "Epoch 65/150\n",
      "27092/27092 [==============================] - 3s 102us/step - loss: 0.1019 - val_loss: 0.1056\n",
      "Epoch 66/150\n",
      "27092/27092 [==============================] - 3s 105us/step - loss: 0.1016 - val_loss: 0.1035\n",
      "Evaluating model with testing data...\n",
      "5784/5784 [==============================] - 0s 16us/step\n",
      "Getting distribution of predictions and covariance matrix...\n",
      "      1 of 20\n",
      "      2 of 20\n",
      "      3 of 20\n",
      "      4 of 20\n",
      "      5 of 20\n",
      "      6 of 20\n",
      "      7 of 20\n",
      "      8 of 20\n",
      "      9 of 20\n",
      "      10 of 20\n",
      "      11 of 20\n",
      "      12 of 20\n",
      "      13 of 20\n",
      "      14 of 20\n",
      "      15 of 20\n",
      "      16 of 20\n",
      "      17 of 20\n",
      "      18 of 20\n",
      "      19 of 20\n",
      "      20 of 20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|          | 0/20 [00:00<?, ?it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing ensemble means...\n",
      "Computing mean squared error...\n",
      "Getting distribution of predictions...\n",
      "      1 of 20\n",
      "1600/1600 [==============================] - 0s 27us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  5%|▌         | 1/20 [00:29<09:13, 29.13s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      2 of 20\n",
      "1600/1600 [==============================] - 0s 30us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 10%|█         | 2/20 [00:58<08:46, 29.26s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      3 of 20\n",
      "1600/1600 [==============================] - 0s 31us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 15%|█▌        | 3/20 [01:28<08:17, 29.29s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      4 of 20\n",
      "1600/1600 [==============================] - 0s 29us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 20%|██        | 4/20 [01:57<07:49, 29.34s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      5 of 20\n",
      "1600/1600 [==============================] - 0s 30us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 25%|██▌       | 5/20 [02:26<07:18, 29.23s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      6 of 20\n",
      "1600/1600 [==============================] - 0s 30us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 30%|███       | 6/20 [02:56<06:51, 29.37s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      7 of 20\n",
      "1600/1600 [==============================] - 0s 29us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 35%|███▌      | 7/20 [03:25<06:22, 29.45s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      8 of 20\n",
      "1600/1600 [==============================] - 0s 29us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 40%|████      | 8/20 [03:55<05:54, 29.54s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      9 of 20\n",
      "1600/1600 [==============================] - 0s 30us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 45%|████▌     | 9/20 [04:24<05:24, 29.49s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      10 of 20\n",
      "1600/1600 [==============================] - 0s 29us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 50%|█████     | 10/20 [04:54<04:55, 29.53s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      11 of 20\n",
      "1600/1600 [==============================] - 0s 30us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 55%|█████▌    | 11/20 [05:24<04:26, 29.58s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      12 of 20\n",
      "1600/1600 [==============================] - 0s 29us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 60%|██████    | 12/20 [05:53<03:56, 29.53s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      13 of 20\n",
      "1600/1600 [==============================] - 0s 29us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 65%|██████▌   | 13/20 [06:22<03:26, 29.44s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      14 of 20\n",
      "1600/1600 [==============================] - 0s 29us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 70%|███████   | 14/20 [06:52<02:56, 29.46s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      15 of 20\n",
      "1600/1600 [==============================] - 0s 29us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 75%|███████▌  | 15/20 [07:21<02:27, 29.48s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      16 of 20\n",
      "1600/1600 [==============================] - 0s 29us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 80%|████████  | 16/20 [07:51<01:58, 29.54s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      17 of 20\n",
      "1600/1600 [==============================] - 0s 29us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 85%|████████▌ | 17/20 [08:20<01:28, 29.43s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      18 of 20\n",
      "1600/1600 [==============================] - 0s 28us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 90%|█████████ | 18/20 [08:50<00:58, 29.48s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      19 of 20\n",
      "1600/1600 [==============================] - 0s 29us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 95%|█████████▌| 19/20 [09:19<00:29, 29.41s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      20 of 20\n",
      "1600/1600 [==============================] - 0s 29us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 20/20 [09:49<00:00, 29.47s/it]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing ensemble predictions...\n",
      "Iteration 191\n",
      "Train on 27232 samples, validate on 5814 samples\n",
      "Epoch 1/150\n",
      "27232/27232 [==============================] - 3s 102us/step - loss: 0.2851 - val_loss: 0.1962\n",
      "Epoch 2/150\n",
      "27232/27232 [==============================] - 3s 110us/step - loss: 0.1741 - val_loss: 0.1669\n",
      "Epoch 3/150\n",
      "27232/27232 [==============================] - 3s 107us/step - loss: 0.1533 - val_loss: 0.1486\n",
      "Epoch 4/150\n",
      "27232/27232 [==============================] - 3s 109us/step - loss: 0.1408 - val_loss: 0.1391\n",
      "Epoch 5/150\n",
      "27232/27232 [==============================] - 2s 71us/step - loss: 0.1337 - val_loss: 0.1314\n",
      "Epoch 6/150\n",
      "27232/27232 [==============================] - 2s 87us/step - loss: 0.1277 - val_loss: 0.1287\n",
      "Epoch 7/150\n",
      "27232/27232 [==============================] - 3s 105us/step - loss: 0.1253 - val_loss: 0.1260\n",
      "Epoch 8/150\n",
      "27232/27232 [==============================] - 3s 108us/step - loss: 0.1221 - val_loss: 0.1239\n",
      "Epoch 9/150\n",
      "27232/27232 [==============================] - 3s 110us/step - loss: 0.1204 - val_loss: 0.1215\n",
      "Epoch 10/150\n",
      "27232/27232 [==============================] - 3s 107us/step - loss: 0.1195 - val_loss: 0.1215\n",
      "Epoch 11/150\n",
      "27232/27232 [==============================] - 3s 106us/step - loss: 0.1177 - val_loss: 0.1167\n",
      "Epoch 12/150\n",
      "27232/27232 [==============================] - 3s 110us/step - loss: 0.1159 - val_loss: 0.1161\n",
      "Epoch 13/150\n",
      "27232/27232 [==============================] - 3s 109us/step - loss: 0.1152 - val_loss: 0.1163\n",
      "Epoch 14/150\n",
      "27232/27232 [==============================] - 3s 103us/step - loss: 0.1122 - val_loss: 0.1144\n",
      "Epoch 15/150\n",
      "27232/27232 [==============================] - 3s 105us/step - loss: 0.1108 - val_loss: 0.1111\n",
      "Epoch 16/150\n",
      "27232/27232 [==============================] - 3s 104us/step - loss: 0.1089 - val_loss: 0.1090\n",
      "Epoch 17/150\n",
      "27232/27232 [==============================] - 3s 104us/step - loss: 0.1068 - val_loss: 0.1084\n",
      "Epoch 18/150\n",
      "27232/27232 [==============================] - 3s 104us/step - loss: 0.1057 - val_loss: 0.1081\n",
      "Epoch 19/150\n",
      "27232/27232 [==============================] - 3s 104us/step - loss: 0.1048 - val_loss: 0.1059\n",
      "Epoch 20/150\n",
      "27232/27232 [==============================] - 3s 106us/step - loss: 0.1031 - val_loss: 0.1044\n",
      "Epoch 21/150\n",
      "27232/27232 [==============================] - 3s 109us/step - loss: 0.1032 - val_loss: 0.1022\n",
      "Epoch 22/150\n",
      "27232/27232 [==============================] - 3s 109us/step - loss: 0.1011 - val_loss: 0.1018\n",
      "Epoch 23/150\n",
      "27232/27232 [==============================] - 3s 103us/step - loss: 0.1002 - val_loss: 0.1003\n",
      "Epoch 24/150\n",
      "27232/27232 [==============================] - 3s 100us/step - loss: 0.0987 - val_loss: 0.1004\n",
      "Epoch 25/150\n",
      "27232/27232 [==============================] - 3s 105us/step - loss: 0.0985 - val_loss: 0.0983\n",
      "Epoch 26/150\n",
      "27232/27232 [==============================] - 3s 106us/step - loss: 0.0967 - val_loss: 0.0946\n",
      "Epoch 27/150\n",
      "27232/27232 [==============================] - 3s 106us/step - loss: 0.0952 - val_loss: 0.0933\n",
      "Epoch 28/150\n",
      "27232/27232 [==============================] - 3s 107us/step - loss: 0.0932 - val_loss: 0.0945\n",
      "Epoch 29/150\n",
      "27232/27232 [==============================] - 3s 104us/step - loss: 0.0928 - val_loss: 0.0934\n",
      "Epoch 30/150\n",
      "27232/27232 [==============================] - 3s 106us/step - loss: 0.0916 - val_loss: 0.0927\n",
      "Epoch 31/150\n",
      "27232/27232 [==============================] - 3s 106us/step - loss: 0.0911 - val_loss: 0.0906\n",
      "Epoch 32/150\n",
      "27232/27232 [==============================] - 3s 100us/step - loss: 0.0901 - val_loss: 0.0915\n",
      "Epoch 33/150\n",
      "27232/27232 [==============================] - 3s 103us/step - loss: 0.0905 - val_loss: 0.0933\n",
      "Epoch 34/150\n",
      "27232/27232 [==============================] - 3s 102us/step - loss: 0.0892 - val_loss: 0.0887\n",
      "Epoch 35/150\n",
      "27232/27232 [==============================] - 3s 103us/step - loss: 0.0885 - val_loss: 0.0909\n",
      "Epoch 36/150\n",
      "27232/27232 [==============================] - 3s 102us/step - loss: 0.0877 - val_loss: 0.0883\n",
      "Epoch 37/150\n",
      "27232/27232 [==============================] - 3s 96us/step - loss: 0.0869 - val_loss: 0.0883\n",
      "Epoch 38/150\n",
      "27232/27232 [==============================] - 3s 104us/step - loss: 0.0881 - val_loss: 0.0883\n",
      "Epoch 39/150\n",
      "27232/27232 [==============================] - 3s 104us/step - loss: 0.0870 - val_loss: 0.0860\n",
      "Epoch 40/150\n",
      "27232/27232 [==============================] - 3s 101us/step - loss: 0.0860 - val_loss: 0.0888\n",
      "Epoch 41/150\n",
      "27232/27232 [==============================] - 3s 101us/step - loss: 0.0864 - val_loss: 0.0857\n",
      "Epoch 42/150\n",
      "27232/27232 [==============================] - 3s 102us/step - loss: 0.0858 - val_loss: 0.0858\n",
      "Epoch 43/150\n",
      "27232/27232 [==============================] - 3s 101us/step - loss: 0.0858 - val_loss: 0.0866\n",
      "Epoch 44/150\n",
      "27232/27232 [==============================] - 3s 103us/step - loss: 0.0868 - val_loss: 0.0876\n",
      "Epoch 45/150\n",
      "27232/27232 [==============================] - 3s 100us/step - loss: 0.0847 - val_loss: 0.0860\n",
      "Evaluating model with testing data...\n",
      "5814/5814 [==============================] - 0s 15us/step\n",
      "Getting distribution of predictions and covariance matrix...\n",
      "      1 of 20\n",
      "      2 of 20\n",
      "      3 of 20\n",
      "      4 of 20\n",
      "      5 of 20\n",
      "      6 of 20\n",
      "      7 of 20\n",
      "      8 of 20\n",
      "      9 of 20\n",
      "      10 of 20\n",
      "      11 of 20\n",
      "      12 of 20\n",
      "      13 of 20\n",
      "      14 of 20\n",
      "      15 of 20\n",
      "      16 of 20\n",
      "      17 of 20\n",
      "      18 of 20\n",
      "      19 of 20\n",
      "      20 of 20\n",
      "Computing ensemble means...\n",
      "Computing mean squared error...\n",
      "Iteration 192\n",
      "Train on 27372 samples, validate on 5844 samples\n",
      "Epoch 1/150\n",
      "27372/27372 [==============================] - 3s 93us/step - loss: 0.3150 - val_loss: 0.2073\n",
      "Epoch 2/150\n",
      "27372/27372 [==============================] - 2s 59us/step - loss: 0.1894 - val_loss: 0.1767\n",
      "Epoch 3/150\n",
      "27372/27372 [==============================] - 3s 96us/step - loss: 0.1676 - val_loss: 0.1592\n",
      "Epoch 4/150\n",
      "27372/27372 [==============================] - 3s 95us/step - loss: 0.1516 - val_loss: 0.1418\n",
      "Epoch 5/150\n",
      "27372/27372 [==============================] - 3s 95us/step - loss: 0.1403 - val_loss: 0.1419\n",
      "Epoch 6/150\n",
      "27372/27372 [==============================] - 3s 95us/step - loss: 0.1377 - val_loss: 0.1331\n",
      "Epoch 7/150\n",
      "27372/27372 [==============================] - 3s 101us/step - loss: 0.1306 - val_loss: 0.1286\n",
      "Epoch 8/150\n",
      "27372/27372 [==============================] - 3s 96us/step - loss: 0.1285 - val_loss: 0.1310\n",
      "Epoch 9/150\n",
      "27372/27372 [==============================] - 3s 95us/step - loss: 0.1270 - val_loss: 0.1254\n",
      "Epoch 10/150\n",
      "27372/27372 [==============================] - 3s 100us/step - loss: 0.1239 - val_loss: 0.1250\n",
      "Epoch 11/150\n",
      "27372/27372 [==============================] - 3s 96us/step - loss: 0.1215 - val_loss: 0.1270\n",
      "Epoch 12/150\n",
      "27372/27372 [==============================] - 3s 101us/step - loss: 0.1213 - val_loss: 0.1210\n",
      "Epoch 13/150\n",
      "27372/27372 [==============================] - 3s 97us/step - loss: 0.1195 - val_loss: 0.1196\n",
      "Epoch 14/150\n",
      "27372/27372 [==============================] - 3s 100us/step - loss: 0.1181 - val_loss: 0.1187\n",
      "Epoch 15/150\n",
      "27372/27372 [==============================] - 3s 95us/step - loss: 0.1171 - val_loss: 0.1183\n",
      "Epoch 16/150\n",
      "27372/27372 [==============================] - 3s 99us/step - loss: 0.1161 - val_loss: 0.1175\n",
      "Epoch 17/150\n",
      "27372/27372 [==============================] - 3s 96us/step - loss: 0.1151 - val_loss: 0.1149\n",
      "Epoch 18/150\n",
      "27372/27372 [==============================] - 3s 99us/step - loss: 0.1144 - val_loss: 0.1175\n",
      "Epoch 19/150\n",
      "27372/27372 [==============================] - 3s 96us/step - loss: 0.1139 - val_loss: 0.1144\n",
      "Epoch 20/150\n",
      "27372/27372 [==============================] - 3s 95us/step - loss: 0.1122 - val_loss: 0.1143\n",
      "Epoch 21/150\n",
      "27372/27372 [==============================] - 3s 97us/step - loss: 0.1117 - val_loss: 0.1118\n",
      "Epoch 22/150\n",
      "27372/27372 [==============================] - 3s 99us/step - loss: 0.1113 - val_loss: 0.1119\n",
      "Epoch 23/150\n",
      "27372/27372 [==============================] - 3s 95us/step - loss: 0.1096 - val_loss: 0.1129\n",
      "Epoch 24/150\n",
      "27372/27372 [==============================] - 3s 97us/step - loss: 0.1086 - val_loss: 0.1105\n",
      "Epoch 25/150\n",
      "27372/27372 [==============================] - 3s 96us/step - loss: 0.1089 - val_loss: 0.1087\n",
      "Epoch 26/150\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "27372/27372 [==============================] - 3s 110us/step - loss: 0.1087 - val_loss: 0.1089\n",
      "Epoch 27/150\n",
      "27372/27372 [==============================] - 3s 111us/step - loss: 0.1083 - val_loss: 0.1085\n",
      "Epoch 28/150\n",
      "27372/27372 [==============================] - 3s 105us/step - loss: 0.1065 - val_loss: 0.1081\n",
      "Epoch 29/150\n",
      "27372/27372 [==============================] - 3s 113us/step - loss: 0.1067 - val_loss: 0.1088\n",
      "Epoch 30/150\n",
      "27372/27372 [==============================] - 3s 110us/step - loss: 0.1058 - val_loss: 0.1093\n",
      "Epoch 31/150\n",
      "27372/27372 [==============================] - 3s 106us/step - loss: 0.1054 - val_loss: 0.1080\n",
      "Epoch 32/150\n",
      "27372/27372 [==============================] - 3s 104us/step - loss: 0.1063 - val_loss: 0.1064\n",
      "Epoch 33/150\n",
      "27372/27372 [==============================] - 3s 102us/step - loss: 0.1053 - val_loss: 0.1049\n",
      "Epoch 34/150\n",
      "27372/27372 [==============================] - 3s 108us/step - loss: 0.1049 - val_loss: 0.1069\n",
      "Epoch 35/150\n",
      "27372/27372 [==============================] - 3s 108us/step - loss: 0.1044 - val_loss: 0.1062\n",
      "Epoch 36/150\n",
      "27372/27372 [==============================] - 3s 110us/step - loss: 0.1041 - val_loss: 0.1051\n",
      "Epoch 37/150\n",
      "27372/27372 [==============================] - 3s 109us/step - loss: 0.1039 - val_loss: 0.1057\n",
      "Evaluating model with testing data...\n",
      "5844/5844 [==============================] - 0s 15us/step\n",
      "Getting distribution of predictions and covariance matrix...\n",
      "      1 of 20\n",
      "      2 of 20\n",
      "      3 of 20\n",
      "      4 of 20\n",
      "      5 of 20\n",
      "      6 of 20\n",
      "      7 of 20\n",
      "      8 of 20\n",
      "      9 of 20\n",
      "      10 of 20\n",
      "      11 of 20\n",
      "      12 of 20\n",
      "      13 of 20\n",
      "      14 of 20\n",
      "      15 of 20\n",
      "      16 of 20\n",
      "      17 of 20\n",
      "      18 of 20\n",
      "      19 of 20\n",
      "      20 of 20\n",
      "Computing ensemble means...\n",
      "Computing mean squared error...\n",
      "Iteration 193\n",
      "Train on 27512 samples, validate on 5874 samples\n",
      "Epoch 1/150\n",
      "27512/27512 [==============================] - 3s 104us/step - loss: 0.4194 - val_loss: 0.3014\n",
      "Epoch 2/150\n",
      "27512/27512 [==============================] - 3s 106us/step - loss: 0.2571 - val_loss: 0.2303\n",
      "Epoch 3/150\n",
      "27512/27512 [==============================] - 3s 106us/step - loss: 0.2173 - val_loss: 0.2103\n",
      "Epoch 4/150\n",
      "27512/27512 [==============================] - 3s 104us/step - loss: 0.2010 - val_loss: 0.1964\n",
      "Epoch 5/150\n",
      "27512/27512 [==============================] - 3s 104us/step - loss: 0.1918 - val_loss: 0.1897\n",
      "Epoch 6/150\n",
      "27512/27512 [==============================] - 3s 103us/step - loss: 0.1867 - val_loss: 0.1898\n",
      "Epoch 7/150\n",
      "27512/27512 [==============================] - 2s 73us/step - loss: 0.1803 - val_loss: 0.1783\n",
      "Epoch 8/150\n",
      "27512/27512 [==============================] - 2s 80us/step - loss: 0.1730 - val_loss: 0.1737\n",
      "Epoch 9/150\n",
      "27512/27512 [==============================] - 3s 101us/step - loss: 0.1632 - val_loss: 0.1594\n",
      "Epoch 10/150\n",
      "27512/27512 [==============================] - 3s 108us/step - loss: 0.1595 - val_loss: 0.1595\n",
      "Epoch 11/150\n",
      "27512/27512 [==============================] - 3s 103us/step - loss: 0.1570 - val_loss: 0.1559\n",
      "Epoch 12/150\n",
      "27512/27512 [==============================] - 3s 101us/step - loss: 0.1573 - val_loss: 0.1566\n",
      "Epoch 13/150\n",
      "27512/27512 [==============================] - 3s 104us/step - loss: 0.1546 - val_loss: 0.1564\n",
      "Epoch 14/150\n",
      "27512/27512 [==============================] - 3s 105us/step - loss: 0.1542 - val_loss: 0.1553\n",
      "Epoch 15/150\n",
      "27512/27512 [==============================] - 3s 105us/step - loss: 0.1523 - val_loss: 0.1537\n",
      "Epoch 16/150\n",
      "27512/27512 [==============================] - 3s 106us/step - loss: 0.1507 - val_loss: 0.1518\n",
      "Epoch 17/150\n",
      "27512/27512 [==============================] - 3s 106us/step - loss: 0.1501 - val_loss: 0.1512\n",
      "Epoch 18/150\n",
      "27512/27512 [==============================] - 3s 106us/step - loss: 0.1487 - val_loss: 0.1522\n",
      "Epoch 19/150\n",
      "27512/27512 [==============================] - 3s 102us/step - loss: 0.1481 - val_loss: 0.1501\n",
      "Epoch 20/150\n",
      "27512/27512 [==============================] - 3s 104us/step - loss: 0.1477 - val_loss: 0.1503\n",
      "Epoch 21/150\n",
      "27512/27512 [==============================] - 3s 108us/step - loss: 0.1477 - val_loss: 0.1493\n",
      "Epoch 22/150\n",
      "27512/27512 [==============================] - 3s 101us/step - loss: 0.1456 - val_loss: 0.1446\n",
      "Epoch 23/150\n",
      "27512/27512 [==============================] - 3s 101us/step - loss: 0.1468 - val_loss: 0.1461\n",
      "Epoch 24/150\n",
      "27512/27512 [==============================] - 3s 103us/step - loss: 0.1459 - val_loss: 0.1489\n",
      "Epoch 25/150\n",
      "27512/27512 [==============================] - 3s 95us/step - loss: 0.1446 - val_loss: 0.1444\n",
      "Epoch 26/150\n",
      "27512/27512 [==============================] - 3s 105us/step - loss: 0.1441 - val_loss: 0.1462\n",
      "Epoch 27/150\n",
      "27512/27512 [==============================] - 3s 99us/step - loss: 0.1444 - val_loss: 0.1438\n",
      "Epoch 28/150\n",
      "27512/27512 [==============================] - 3s 102us/step - loss: 0.1435 - val_loss: 0.1434\n",
      "Epoch 29/150\n",
      "27512/27512 [==============================] - 3s 97us/step - loss: 0.1425 - val_loss: 0.1402\n",
      "Epoch 30/150\n",
      "27512/27512 [==============================] - 3s 101us/step - loss: 0.1431 - val_loss: 0.1444\n",
      "Epoch 31/150\n",
      "27512/27512 [==============================] - 3s 103us/step - loss: 0.1419 - val_loss: 0.1410\n",
      "Epoch 32/150\n",
      "27512/27512 [==============================] - 3s 101us/step - loss: 0.1426 - val_loss: 0.1413\n",
      "Epoch 33/150\n",
      "27512/27512 [==============================] - 3s 99us/step - loss: 0.1407 - val_loss: 0.1428\n",
      "Evaluating model with testing data...\n",
      "5874/5874 [==============================] - 0s 15us/step\n",
      "Getting distribution of predictions and covariance matrix...\n",
      "      1 of 20\n",
      "      2 of 20\n",
      "      3 of 20\n",
      "      4 of 20\n",
      "      5 of 20\n",
      "      6 of 20\n",
      "      7 of 20\n",
      "      8 of 20\n",
      "      9 of 20\n",
      "      10 of 20\n",
      "      11 of 20\n",
      "      12 of 20\n",
      "      13 of 20\n",
      "      14 of 20\n",
      "      15 of 20\n",
      "      16 of 20\n",
      "      17 of 20\n",
      "      18 of 20\n",
      "      19 of 20\n",
      "      20 of 20\n",
      "Computing ensemble means...\n",
      "Computing mean squared error...\n",
      "Iteration 194\n",
      "Train on 27652 samples, validate on 5904 samples\n",
      "Epoch 1/150\n",
      "27652/27652 [==============================] - 3s 97us/step - loss: 0.3156 - val_loss: 0.2279\n",
      "Epoch 2/150\n",
      "27652/27652 [==============================] - 3s 101us/step - loss: 0.2104 - val_loss: 0.2003\n",
      "Epoch 3/150\n",
      "27652/27652 [==============================] - 3s 98us/step - loss: 0.1886 - val_loss: 0.1824\n",
      "Epoch 4/150\n",
      "27652/27652 [==============================] - 3s 100us/step - loss: 0.1793 - val_loss: 0.1800\n",
      "Epoch 5/150\n",
      "27652/27652 [==============================] - 3s 97us/step - loss: 0.1710 - val_loss: 0.1656\n",
      "Epoch 6/150\n",
      "27652/27652 [==============================] - 3s 96us/step - loss: 0.1621 - val_loss: 0.1663\n",
      "Epoch 7/150\n",
      "27652/27652 [==============================] - 3s 100us/step - loss: 0.1622 - val_loss: 0.1566\n",
      "Epoch 8/150\n",
      "27652/27652 [==============================] - 3s 98us/step - loss: 0.1554 - val_loss: 0.1546\n",
      "Epoch 9/150\n",
      "27652/27652 [==============================] - 3s 99us/step - loss: 0.1486 - val_loss: 0.1513\n",
      "Epoch 10/150\n",
      "27652/27652 [==============================] - 3s 95us/step - loss: 0.1461 - val_loss: 0.1496\n",
      "Epoch 11/150\n",
      "27652/27652 [==============================] - 3s 98us/step - loss: 0.1457 - val_loss: 0.1507\n",
      "Epoch 12/150\n",
      "27652/27652 [==============================] - 3s 98us/step - loss: 0.1434 - val_loss: 0.1413\n",
      "Epoch 13/150\n",
      "27652/27652 [==============================] - 3s 96us/step - loss: 0.1406 - val_loss: 0.1408\n",
      "Epoch 14/150\n",
      "27652/27652 [==============================] - 3s 97us/step - loss: 0.1383 - val_loss: 0.1407\n",
      "Epoch 15/150\n",
      "27652/27652 [==============================] - 3s 96us/step - loss: 0.1369 - val_loss: 0.1396\n",
      "Epoch 16/150\n",
      "27652/27652 [==============================] - 2s 89us/step - loss: 0.1349 - val_loss: 0.1435\n",
      "Epoch 17/150\n",
      "27652/27652 [==============================] - 2s 59us/step - loss: 0.1384 - val_loss: 0.1359\n",
      "Epoch 18/150\n",
      "27652/27652 [==============================] - 3s 92us/step - loss: 0.1364 - val_loss: 0.1334\n",
      "Epoch 19/150\n",
      "27652/27652 [==============================] - 3s 94us/step - loss: 0.1327 - val_loss: 0.1342\n",
      "Epoch 20/150\n",
      "27652/27652 [==============================] - 3s 94us/step - loss: 0.1314 - val_loss: 0.1361\n",
      "Epoch 21/150\n",
      "27652/27652 [==============================] - 3s 98us/step - loss: 0.1297 - val_loss: 0.1333\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 22/150\n",
      "27652/27652 [==============================] - 3s 111us/step - loss: 0.1295 - val_loss: 0.1302\n",
      "Epoch 23/150\n",
      "27652/27652 [==============================] - 3s 103us/step - loss: 0.1268 - val_loss: 0.1303\n",
      "Epoch 24/150\n",
      "27652/27652 [==============================] - 3s 111us/step - loss: 0.1275 - val_loss: 0.1283\n",
      "Epoch 25/150\n",
      "27652/27652 [==============================] - 3s 109us/step - loss: 0.1252 - val_loss: 0.1247\n",
      "Epoch 26/150\n",
      "27652/27652 [==============================] - 3s 106us/step - loss: 0.1266 - val_loss: 0.1284\n",
      "Epoch 27/150\n",
      "27652/27652 [==============================] - 3s 108us/step - loss: 0.1258 - val_loss: 0.1258\n",
      "Epoch 28/150\n",
      "27652/27652 [==============================] - 3s 111us/step - loss: 0.1242 - val_loss: 0.1240\n",
      "Epoch 29/150\n",
      "27652/27652 [==============================] - 3s 107us/step - loss: 0.1248 - val_loss: 0.1239\n",
      "Epoch 30/150\n",
      "27652/27652 [==============================] - 3s 107us/step - loss: 0.1252 - val_loss: 0.1266\n",
      "Epoch 31/150\n",
      "27652/27652 [==============================] - 3s 103us/step - loss: 0.1223 - val_loss: 0.1191\n",
      "Epoch 32/150\n",
      "27652/27652 [==============================] - 3s 108us/step - loss: 0.1205 - val_loss: 0.1220\n",
      "Epoch 33/150\n",
      "27652/27652 [==============================] - 3s 106us/step - loss: 0.1205 - val_loss: 0.1208\n",
      "Epoch 34/150\n",
      "27652/27652 [==============================] - 3s 106us/step - loss: 0.1196 - val_loss: 0.1207\n",
      "Epoch 35/150\n",
      "27652/27652 [==============================] - 3s 106us/step - loss: 0.1186 - val_loss: 0.1213\n",
      "Evaluating model with testing data...\n",
      "5904/5904 [==============================] - 0s 15us/step\n",
      "Getting distribution of predictions and covariance matrix...\n",
      "      1 of 20\n",
      "      2 of 20\n",
      "      3 of 20\n",
      "      4 of 20\n",
      "      5 of 20\n",
      "      6 of 20\n",
      "      7 of 20\n",
      "      8 of 20\n",
      "      9 of 20\n",
      "      10 of 20\n",
      "      11 of 20\n",
      "      12 of 20\n",
      "      13 of 20\n",
      "      14 of 20\n",
      "      15 of 20\n",
      "      16 of 20\n",
      "      17 of 20\n",
      "      18 of 20\n",
      "      19 of 20\n",
      "      20 of 20\n",
      "Computing ensemble means...\n",
      "Computing mean squared error...\n",
      "Iteration 195\n",
      "Train on 27792 samples, validate on 5934 samples\n",
      "Epoch 1/150\n",
      "27792/27792 [==============================] - 3s 105us/step - loss: 0.3395 - val_loss: 0.2380\n",
      "Epoch 2/150\n",
      "27792/27792 [==============================] - 3s 107us/step - loss: 0.2210 - val_loss: 0.2037\n",
      "Epoch 3/150\n",
      "27792/27792 [==============================] - 3s 99us/step - loss: 0.1917 - val_loss: 0.1804\n",
      "Epoch 4/150\n",
      "27792/27792 [==============================] - 3s 107us/step - loss: 0.1704 - val_loss: 0.1626\n",
      "Epoch 5/150\n",
      "27792/27792 [==============================] - 3s 107us/step - loss: 0.1581 - val_loss: 0.1547\n",
      "Epoch 6/150\n",
      "27792/27792 [==============================] - 3s 105us/step - loss: 0.1485 - val_loss: 0.1447\n",
      "Epoch 7/150\n",
      "27792/27792 [==============================] - 3s 104us/step - loss: 0.1424 - val_loss: 0.1430\n",
      "Epoch 8/150\n",
      "27792/27792 [==============================] - 3s 111us/step - loss: 0.1371 - val_loss: 0.1349\n",
      "Epoch 9/150\n",
      "27792/27792 [==============================] - 3s 106us/step - loss: 0.1342 - val_loss: 0.1330\n",
      "Epoch 10/150\n",
      "27792/27792 [==============================] - 3s 106us/step - loss: 0.1328 - val_loss: 0.1333\n",
      "Epoch 11/150\n",
      "27792/27792 [==============================] - 3s 105us/step - loss: 0.1307 - val_loss: 0.1290\n",
      "Epoch 12/150\n",
      "27792/27792 [==============================] - 3s 100us/step - loss: 0.1281 - val_loss: 0.1300\n",
      "Epoch 13/150\n",
      "27792/27792 [==============================] - 3s 105us/step - loss: 0.1286 - val_loss: 0.1265\n",
      "Epoch 14/150\n",
      "27792/27792 [==============================] - 3s 104us/step - loss: 0.1265 - val_loss: 0.1278\n",
      "Epoch 15/150\n",
      "27792/27792 [==============================] - 3s 110us/step - loss: 0.1259 - val_loss: 0.1277\n",
      "Epoch 16/150\n",
      "27792/27792 [==============================] - 3s 100us/step - loss: 0.1249 - val_loss: 0.1239\n",
      "Epoch 17/150\n",
      "27792/27792 [==============================] - 3s 105us/step - loss: 0.1227 - val_loss: 0.1258\n",
      "Epoch 18/150\n",
      "27792/27792 [==============================] - 3s 103us/step - loss: 0.1215 - val_loss: 0.1210\n",
      "Epoch 19/150\n",
      "27792/27792 [==============================] - 3s 101us/step - loss: 0.1194 - val_loss: 0.1204\n",
      "Epoch 20/150\n",
      "27792/27792 [==============================] - 3s 102us/step - loss: 0.1186 - val_loss: 0.1193\n",
      "Epoch 21/150\n",
      "27792/27792 [==============================] - 3s 106us/step - loss: 0.1182 - val_loss: 0.1195\n",
      "Epoch 22/150\n",
      "27792/27792 [==============================] - 2s 87us/step - loss: 0.1168 - val_loss: 0.1154\n",
      "Epoch 23/150\n",
      "27792/27792 [==============================] - 2s 73us/step - loss: 0.1157 - val_loss: 0.1158\n",
      "Epoch 24/150\n",
      "27792/27792 [==============================] - 3s 103us/step - loss: 0.1152 - val_loss: 0.1137\n",
      "Epoch 25/150\n",
      "27792/27792 [==============================] - 3s 103us/step - loss: 0.1147 - val_loss: 0.1143\n",
      "Epoch 26/150\n",
      "27792/27792 [==============================] - 3s 102us/step - loss: 0.1152 - val_loss: 0.1102\n",
      "Epoch 27/150\n",
      "27792/27792 [==============================] - 3s 100us/step - loss: 0.1131 - val_loss: 0.1119\n",
      "Epoch 28/150\n",
      "27792/27792 [==============================] - 3s 101us/step - loss: 0.1126 - val_loss: 0.1102\n",
      "Epoch 29/150\n",
      "27792/27792 [==============================] - 3s 97us/step - loss: 0.1116 - val_loss: 0.1144\n",
      "Epoch 30/150\n",
      "27792/27792 [==============================] - 3s 104us/step - loss: 0.1114 - val_loss: 0.1116\n",
      "Epoch 31/150\n",
      "27792/27792 [==============================] - 3s 99us/step - loss: 0.1106 - val_loss: 0.1102\n",
      "Epoch 32/150\n",
      "27792/27792 [==============================] - 3s 97us/step - loss: 0.1105 - val_loss: 0.1122\n",
      "Epoch 33/150\n",
      "27792/27792 [==============================] - 3s 97us/step - loss: 0.1107 - val_loss: 0.1114\n",
      "Epoch 34/150\n",
      "27792/27792 [==============================] - 3s 98us/step - loss: 0.1092 - val_loss: 0.1102\n",
      "Epoch 35/150\n",
      "27792/27792 [==============================] - 3s 102us/step - loss: 0.1089 - val_loss: 0.1109\n",
      "Evaluating model with testing data...\n",
      "5934/5934 [==============================] - 0s 16us/step\n",
      "Getting distribution of predictions and covariance matrix...\n",
      "      1 of 20\n",
      "      2 of 20\n",
      "      3 of 20\n",
      "      4 of 20\n",
      "      5 of 20\n",
      "      6 of 20\n",
      "      7 of 20\n",
      "      8 of 20\n",
      "      9 of 20\n",
      "      10 of 20\n",
      "      11 of 20\n",
      "      12 of 20\n",
      "      13 of 20\n",
      "      14 of 20\n",
      "      15 of 20\n",
      "      16 of 20\n",
      "      17 of 20\n",
      "      18 of 20\n",
      "      19 of 20\n",
      "      20 of 20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|          | 0/20 [00:00<?, ?it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing ensemble means...\n",
      "Computing mean squared error...\n",
      "Getting distribution of predictions...\n",
      "      1 of 20\n",
      "1600/1600 [==============================] - 0s 27us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  5%|▌         | 1/20 [00:29<09:15, 29.25s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      2 of 20\n",
      "1600/1600 [==============================] - 0s 29us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 10%|█         | 2/20 [00:58<08:48, 29.38s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      3 of 20\n",
      "1600/1600 [==============================] - 0s 29us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 15%|█▌        | 3/20 [01:28<08:18, 29.32s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      4 of 20\n",
      "1600/1600 [==============================] - 0s 29us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 20%|██        | 4/20 [01:57<07:51, 29.46s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      5 of 20\n",
      "1600/1600 [==============================] - 0s 36us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 25%|██▌       | 5/20 [02:27<07:22, 29.51s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      6 of 20\n",
      "1600/1600 [==============================] - 0s 28us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 30%|███       | 6/20 [02:57<06:53, 29.52s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      7 of 20\n",
      "1600/1600 [==============================] - 0s 29us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 35%|███▌      | 7/20 [03:26<06:22, 29.42s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      8 of 20\n",
      "1600/1600 [==============================] - 0s 29us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 40%|████      | 8/20 [03:55<05:53, 29.46s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      9 of 20\n",
      "1600/1600 [==============================] - 0s 29us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 45%|████▌     | 9/20 [04:25<05:25, 29.55s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      10 of 20\n",
      "1600/1600 [==============================] - 0s 30us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 50%|█████     | 10/20 [04:55<04:56, 29.61s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      11 of 20\n",
      "1600/1600 [==============================] - 0s 29us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 55%|█████▌    | 11/20 [05:24<04:25, 29.53s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      12 of 20\n",
      "1600/1600 [==============================] - 0s 29us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 60%|██████    | 12/20 [05:54<03:57, 29.67s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      13 of 20\n",
      "1600/1600 [==============================] - 0s 29us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 65%|██████▌   | 13/20 [06:24<03:27, 29.70s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      14 of 20\n",
      "1600/1600 [==============================] - 0s 28us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 70%|███████   | 14/20 [06:53<02:57, 29.64s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      15 of 20\n",
      "1600/1600 [==============================] - 0s 29us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 75%|███████▌  | 15/20 [07:23<02:27, 29.50s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      16 of 20\n",
      "1600/1600 [==============================] - 0s 29us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 80%|████████  | 16/20 [07:52<01:58, 29.56s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      17 of 20\n",
      "1600/1600 [==============================] - 0s 29us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 85%|████████▌ | 17/20 [08:22<01:28, 29.61s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      18 of 20\n",
      "1600/1600 [==============================] - 0s 29us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 90%|█████████ | 18/20 [08:52<00:59, 29.60s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      19 of 20\n",
      "1600/1600 [==============================] - 0s 30us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 95%|█████████▌| 19/20 [09:21<00:29, 29.59s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      20 of 20\n",
      "1600/1600 [==============================] - 0s 29us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 20/20 [09:51<00:00, 29.55s/it]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing ensemble predictions...\n",
      "Iteration 196\n",
      "Train on 27932 samples, validate on 5964 samples\n",
      "Epoch 1/150\n",
      "27932/27932 [==============================] - 3s 105us/step - loss: 0.3766 - val_loss: 0.2873\n",
      "Epoch 2/150\n",
      "27932/27932 [==============================] - 3s 103us/step - loss: 0.2689 - val_loss: 0.2484\n",
      "Epoch 3/150\n",
      "27932/27932 [==============================] - 3s 107us/step - loss: 0.2390 - val_loss: 0.2240\n",
      "Epoch 4/150\n",
      "27932/27932 [==============================] - 3s 103us/step - loss: 0.2136 - val_loss: 0.2060\n",
      "Epoch 5/150\n",
      "27932/27932 [==============================] - 3s 109us/step - loss: 0.1968 - val_loss: 0.1919\n",
      "Epoch 6/150\n",
      "27932/27932 [==============================] - 3s 103us/step - loss: 0.1834 - val_loss: 0.1799\n",
      "Epoch 7/150\n",
      "27932/27932 [==============================] - 3s 104us/step - loss: 0.1772 - val_loss: 0.1801\n",
      "Epoch 8/150\n",
      "27932/27932 [==============================] - 3s 109us/step - loss: 0.1755 - val_loss: 0.1756\n",
      "Epoch 9/150\n",
      "27932/27932 [==============================] - 3s 107us/step - loss: 0.1743 - val_loss: 0.1742\n",
      "Epoch 10/150\n",
      "27932/27932 [==============================] - 3s 107us/step - loss: 0.1715 - val_loss: 0.1716\n",
      "Epoch 11/150\n",
      "27932/27932 [==============================] - 3s 106us/step - loss: 0.1698 - val_loss: 0.1709\n",
      "Epoch 12/150\n",
      "27932/27932 [==============================] - 3s 108us/step - loss: 0.1697 - val_loss: 0.1690\n",
      "Epoch 13/150\n",
      "27932/27932 [==============================] - 3s 109us/step - loss: 0.1685 - val_loss: 0.1689\n",
      "Epoch 14/150\n",
      "27932/27932 [==============================] - 3s 106us/step - loss: 0.1690 - val_loss: 0.1679\n",
      "Epoch 15/150\n",
      "27932/27932 [==============================] - 3s 102us/step - loss: 0.1674 - val_loss: 0.1679\n",
      "Epoch 16/150\n",
      "27932/27932 [==============================] - 3s 104us/step - loss: 0.1662 - val_loss: 0.1665\n",
      "Epoch 17/150\n",
      "27932/27932 [==============================] - 3s 106us/step - loss: 0.1661 - val_loss: 0.1675\n",
      "Epoch 18/150\n",
      "27932/27932 [==============================] - 3s 108us/step - loss: 0.1647 - val_loss: 0.1643\n",
      "Epoch 19/150\n",
      "27932/27932 [==============================] - 3s 108us/step - loss: 0.1642 - val_loss: 0.1676\n",
      "Epoch 20/150\n",
      "27932/27932 [==============================] - 3s 104us/step - loss: 0.1645 - val_loss: 0.1665\n",
      "Epoch 21/150\n",
      "27932/27932 [==============================] - 3s 104us/step - loss: 0.1625 - val_loss: 0.1635\n",
      "Epoch 22/150\n",
      "27932/27932 [==============================] - 3s 100us/step - loss: 0.1576 - val_loss: 0.1587\n",
      "Epoch 23/150\n",
      "27932/27932 [==============================] - 3s 104us/step - loss: 0.1549 - val_loss: 0.1542\n",
      "Epoch 24/150\n",
      "27932/27932 [==============================] - 3s 98us/step - loss: 0.1545 - val_loss: 0.1559\n",
      "Epoch 25/150\n",
      "27932/27932 [==============================] - 3s 101us/step - loss: 0.1541 - val_loss: 0.1552\n",
      "Epoch 26/150\n",
      "27932/27932 [==============================] - 3s 105us/step - loss: 0.1532 - val_loss: 0.1543\n",
      "Epoch 27/150\n",
      "27932/27932 [==============================] - 3s 95us/step - loss: 0.1527 - val_loss: 0.1567\n",
      "Evaluating model with testing data...\n",
      "5964/5964 [==============================] - 0s 16us/step\n",
      "Getting distribution of predictions and covariance matrix...\n",
      "      1 of 20\n",
      "      2 of 20\n",
      "      3 of 20\n",
      "      4 of 20\n",
      "      5 of 20\n",
      "      6 of 20\n",
      "      7 of 20\n",
      "      8 of 20\n",
      "      9 of 20\n",
      "      10 of 20\n",
      "      11 of 20\n",
      "      12 of 20\n",
      "      13 of 20\n",
      "      14 of 20\n",
      "      15 of 20\n",
      "      16 of 20\n",
      "      17 of 20\n",
      "      18 of 20\n",
      "      19 of 20\n",
      "      20 of 20\n",
      "Computing ensemble means...\n",
      "Computing mean squared error...\n",
      "Iteration 197\n",
      "Train on 28072 samples, validate on 5994 samples\n",
      "Epoch 1/150\n",
      "28072/28072 [==============================] - 3s 101us/step - loss: 0.4329 - val_loss: 0.2814\n",
      "Epoch 2/150\n",
      "28072/28072 [==============================] - 3s 99us/step - loss: 0.2536 - val_loss: 0.2294\n",
      "Epoch 3/150\n",
      "28072/28072 [==============================] - 2s 79us/step - loss: 0.2117 - val_loss: 0.2001\n",
      "Epoch 4/150\n",
      "28072/28072 [==============================] - 2s 76us/step - loss: 0.1879 - val_loss: 0.1807\n",
      "Epoch 5/150\n",
      "28072/28072 [==============================] - 3s 99us/step - loss: 0.1733 - val_loss: 0.1660\n",
      "Epoch 6/150\n",
      "28072/28072 [==============================] - 3s 100us/step - loss: 0.1701 - val_loss: 0.1724\n",
      "Epoch 7/150\n",
      "28072/28072 [==============================] - 3s 99us/step - loss: 0.1662 - val_loss: 0.1655\n",
      "Epoch 8/150\n",
      "28072/28072 [==============================] - 3s 100us/step - loss: 0.1627 - val_loss: 0.1655\n",
      "Epoch 9/150\n",
      "28072/28072 [==============================] - 3s 103us/step - loss: 0.1629 - val_loss: 0.1644\n",
      "Epoch 10/150\n",
      "28072/28072 [==============================] - 3s 97us/step - loss: 0.1616 - val_loss: 0.1615\n",
      "Epoch 11/150\n",
      "28072/28072 [==============================] - 3s 99us/step - loss: 0.1616 - val_loss: 0.1627\n",
      "Epoch 12/150\n",
      "28072/28072 [==============================] - 3s 98us/step - loss: 0.1608 - val_loss: 0.1610\n",
      "Epoch 13/150\n",
      "28072/28072 [==============================] - 3s 97us/step - loss: 0.1599 - val_loss: 0.1603\n",
      "Epoch 14/150\n",
      "28072/28072 [==============================] - 3s 104us/step - loss: 0.1604 - val_loss: 0.1606\n",
      "Epoch 15/150\n",
      "28072/28072 [==============================] - 3s 100us/step - loss: 0.1585 - val_loss: 0.1616\n",
      "Epoch 16/150\n",
      "28072/28072 [==============================] - 3s 97us/step - loss: 0.1572 - val_loss: 0.1565\n",
      "Epoch 17/150\n",
      "28072/28072 [==============================] - 3s 102us/step - loss: 0.1549 - val_loss: 0.1549\n",
      "Epoch 18/150\n",
      "28072/28072 [==============================] - 3s 96us/step - loss: 0.1535 - val_loss: 0.1584\n",
      "Epoch 19/150\n",
      "28072/28072 [==============================] - 3s 97us/step - loss: 0.1519 - val_loss: 0.1533\n",
      "Epoch 20/150\n",
      "28072/28072 [==============================] - 3s 101us/step - loss: 0.1510 - val_loss: 0.1522\n",
      "Epoch 21/150\n",
      "28072/28072 [==============================] - 3s 95us/step - loss: 0.1496 - val_loss: 0.1497\n",
      "Epoch 22/150\n",
      "28072/28072 [==============================] - 3s 99us/step - loss: 0.1470 - val_loss: 0.1481\n",
      "Epoch 23/150\n",
      "28072/28072 [==============================] - 3s 97us/step - loss: 0.1463 - val_loss: 0.1448\n",
      "Epoch 24/150\n",
      "28072/28072 [==============================] - 3s 99us/step - loss: 0.1440 - val_loss: 0.1442\n",
      "Epoch 25/150\n",
      "28072/28072 [==============================] - 3s 99us/step - loss: 0.1421 - val_loss: 0.1453\n",
      "Epoch 26/150\n",
      "28072/28072 [==============================] - 3s 97us/step - loss: 0.1437 - val_loss: 0.1429\n",
      "Epoch 27/150\n",
      "28072/28072 [==============================] - 3s 97us/step - loss: 0.1414 - val_loss: 0.1431\n",
      "Epoch 28/150\n",
      "28072/28072 [==============================] - 3s 99us/step - loss: 0.1414 - val_loss: 0.1411\n",
      "Epoch 29/150\n",
      "28072/28072 [==============================] - 3s 97us/step - loss: 0.1396 - val_loss: 0.1434\n",
      "Epoch 30/150\n",
      "28072/28072 [==============================] - 3s 96us/step - loss: 0.1406 - val_loss: 0.1406\n",
      "Epoch 31/150\n",
      "28072/28072 [==============================] - 2s 84us/step - loss: 0.1396 - val_loss: 0.1411\n",
      "Epoch 32/150\n",
      "28072/28072 [==============================] - 3s 97us/step - loss: 0.1389 - val_loss: 0.1414\n",
      "Epoch 33/150\n",
      "28072/28072 [==============================] - 3s 98us/step - loss: 0.1374 - val_loss: 0.1401\n",
      "Epoch 34/150\n",
      "28072/28072 [==============================] - 3s 96us/step - loss: 0.1368 - val_loss: 0.1393\n",
      "Epoch 35/150\n",
      "28072/28072 [==============================] - 3s 96us/step - loss: 0.1383 - val_loss: 0.1398\n",
      "Epoch 36/150\n",
      "28072/28072 [==============================] - 3s 100us/step - loss: 0.1365 - val_loss: 0.1406\n",
      "Epoch 37/150\n",
      "28072/28072 [==============================] - 3s 95us/step - loss: 0.1374 - val_loss: 0.1371\n",
      "Epoch 38/150\n",
      "28072/28072 [==============================] - 3s 99us/step - loss: 0.1360 - val_loss: 0.1358\n",
      "Epoch 39/150\n",
      "28072/28072 [==============================] - 3s 98us/step - loss: 0.1356 - val_loss: 0.1344\n",
      "Epoch 40/150\n",
      "28072/28072 [==============================] - 3s 92us/step - loss: 0.1370 - val_loss: 0.1377\n",
      "Epoch 41/150\n",
      "28072/28072 [==============================] - 3s 99us/step - loss: 0.1355 - val_loss: 0.1360\n",
      "Epoch 42/150\n",
      "28072/28072 [==============================] - 3s 95us/step - loss: 0.1352 - val_loss: 0.1362\n",
      "Epoch 43/150\n",
      "28072/28072 [==============================] - 3s 95us/step - loss: 0.1342 - val_loss: 0.1350\n",
      "Evaluating model with testing data...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5994/5994 [==============================] - 0s 15us/step\n",
      "Getting distribution of predictions and covariance matrix...\n",
      "      1 of 20\n",
      "      2 of 20\n",
      "      3 of 20\n",
      "      4 of 20\n",
      "      5 of 20\n",
      "      6 of 20\n",
      "      7 of 20\n",
      "      8 of 20\n",
      "      9 of 20\n",
      "      10 of 20\n",
      "      11 of 20\n",
      "      12 of 20\n",
      "      13 of 20\n",
      "      14 of 20\n",
      "      15 of 20\n",
      "      16 of 20\n",
      "      17 of 20\n",
      "      18 of 20\n",
      "      19 of 20\n",
      "      20 of 20\n",
      "Computing ensemble means...\n",
      "Computing mean squared error...\n",
      "Iteration 198\n",
      "Train on 28212 samples, validate on 6024 samples\n",
      "Epoch 1/150\n",
      "28212/28212 [==============================] - 3s 107us/step - loss: 0.4266 - val_loss: 0.3135\n",
      "Epoch 2/150\n",
      "28212/28212 [==============================] - 3s 108us/step - loss: 0.2830 - val_loss: 0.2543\n",
      "Epoch 3/150\n",
      "28212/28212 [==============================] - 2s 69us/step - loss: 0.2385 - val_loss: 0.2250\n",
      "Epoch 4/150\n",
      "28212/28212 [==============================] - 3s 92us/step - loss: 0.2140 - val_loss: 0.2046\n",
      "Epoch 5/150\n",
      "28212/28212 [==============================] - 3s 110us/step - loss: 0.1975 - val_loss: 0.1915\n",
      "Epoch 6/150\n",
      "28212/28212 [==============================] - 3s 104us/step - loss: 0.1841 - val_loss: 0.1818\n",
      "Epoch 7/150\n",
      "28212/28212 [==============================] - 3s 109us/step - loss: 0.1780 - val_loss: 0.1785\n",
      "Epoch 8/150\n",
      "28212/28212 [==============================] - 3s 105us/step - loss: 0.1751 - val_loss: 0.1774\n",
      "Epoch 9/150\n",
      "28212/28212 [==============================] - 3s 109us/step - loss: 0.1700 - val_loss: 0.1683\n",
      "Epoch 10/150\n",
      "28212/28212 [==============================] - 3s 105us/step - loss: 0.1674 - val_loss: 0.1659\n",
      "Epoch 11/150\n",
      "28212/28212 [==============================] - 3s 108us/step - loss: 0.1646 - val_loss: 0.1639\n",
      "Epoch 12/150\n",
      "28212/28212 [==============================] - 3s 105us/step - loss: 0.1630 - val_loss: 0.1639\n",
      "Epoch 13/150\n",
      "28212/28212 [==============================] - 3s 108us/step - loss: 0.1617 - val_loss: 0.1638\n",
      "Epoch 14/150\n",
      "28212/28212 [==============================] - 3s 104us/step - loss: 0.1601 - val_loss: 0.1622\n",
      "Epoch 15/150\n",
      "28212/28212 [==============================] - 3s 107us/step - loss: 0.1603 - val_loss: 0.1587\n",
      "Epoch 16/150\n",
      "28212/28212 [==============================] - 3s 106us/step - loss: 0.1593 - val_loss: 0.1625\n",
      "Epoch 17/150\n",
      "28212/28212 [==============================] - 3s 108us/step - loss: 0.1588 - val_loss: 0.1645\n",
      "Epoch 18/150\n",
      "28212/28212 [==============================] - 3s 106us/step - loss: 0.1583 - val_loss: 0.1549\n",
      "Epoch 19/150\n",
      "28212/28212 [==============================] - 3s 103us/step - loss: 0.1526 - val_loss: 0.1500\n",
      "Epoch 20/150\n",
      "28212/28212 [==============================] - 3s 109us/step - loss: 0.1473 - val_loss: 0.1481\n",
      "Epoch 21/150\n",
      "28212/28212 [==============================] - 3s 107us/step - loss: 0.1467 - val_loss: 0.1472\n",
      "Epoch 22/150\n",
      "28212/28212 [==============================] - 3s 108us/step - loss: 0.1446 - val_loss: 0.1473\n",
      "Epoch 23/150\n",
      "28212/28212 [==============================] - 3s 106us/step - loss: 0.1442 - val_loss: 0.1444\n",
      "Epoch 24/150\n",
      "28212/28212 [==============================] - 3s 109us/step - loss: 0.1432 - val_loss: 0.1479\n",
      "Epoch 25/150\n",
      "28212/28212 [==============================] - 3s 107us/step - loss: 0.1430 - val_loss: 0.1429\n",
      "Epoch 26/150\n",
      "28212/28212 [==============================] - 3s 105us/step - loss: 0.1433 - val_loss: 0.1445\n",
      "Epoch 27/150\n",
      "28212/28212 [==============================] - 3s 106us/step - loss: 0.1424 - val_loss: 0.1432\n",
      "Epoch 28/150\n",
      "28212/28212 [==============================] - 3s 104us/step - loss: 0.1420 - val_loss: 0.1429\n",
      "Epoch 29/150\n",
      "28212/28212 [==============================] - 3s 103us/step - loss: 0.1413 - val_loss: 0.1421\n",
      "Epoch 30/150\n",
      "28212/28212 [==============================] - 3s 97us/step - loss: 0.1403 - val_loss: 0.1414\n",
      "Epoch 31/150\n",
      "28212/28212 [==============================] - 3s 103us/step - loss: 0.1372 - val_loss: 0.1374\n",
      "Epoch 32/150\n",
      "28212/28212 [==============================] - 3s 100us/step - loss: 0.1352 - val_loss: 0.1346\n",
      "Epoch 33/150\n",
      "28212/28212 [==============================] - 3s 102us/step - loss: 0.1345 - val_loss: 0.1358\n",
      "Epoch 34/150\n",
      "28212/28212 [==============================] - 3s 102us/step - loss: 0.1344 - val_loss: 0.1369\n",
      "Epoch 35/150\n",
      "28212/28212 [==============================] - 3s 102us/step - loss: 0.1332 - val_loss: 0.1342\n",
      "Epoch 36/150\n",
      "28212/28212 [==============================] - 3s 98us/step - loss: 0.1325 - val_loss: 0.1324\n",
      "Epoch 37/150\n",
      "28212/28212 [==============================] - 3s 99us/step - loss: 0.1324 - val_loss: 0.1330\n",
      "Epoch 38/150\n",
      "28212/28212 [==============================] - 3s 104us/step - loss: 0.1313 - val_loss: 0.1354\n",
      "Epoch 39/150\n",
      "28212/28212 [==============================] - 3s 102us/step - loss: 0.1315 - val_loss: 0.1336\n",
      "Epoch 40/150\n",
      "28212/28212 [==============================] - 3s 104us/step - loss: 0.1317 - val_loss: 0.1311\n",
      "Epoch 41/150\n",
      "28212/28212 [==============================] - 3s 102us/step - loss: 0.1303 - val_loss: 0.1341\n",
      "Epoch 42/150\n",
      "28212/28212 [==============================] - 3s 103us/step - loss: 0.1298 - val_loss: 0.1304\n",
      "Epoch 43/150\n",
      "28212/28212 [==============================] - 3s 98us/step - loss: 0.1263 - val_loss: 0.1243\n",
      "Epoch 44/150\n",
      "28212/28212 [==============================] - 2s 72us/step - loss: 0.1237 - val_loss: 0.1216\n",
      "Epoch 45/150\n",
      "28212/28212 [==============================] - 2s 82us/step - loss: 0.1247 - val_loss: 0.1246\n",
      "Epoch 46/150\n",
      "28212/28212 [==============================] - 3s 100us/step - loss: 0.1212 - val_loss: 0.1235\n",
      "Epoch 47/150\n",
      "28212/28212 [==============================] - 3s 104us/step - loss: 0.1222 - val_loss: 0.1235\n",
      "Epoch 48/150\n",
      "28212/28212 [==============================] - 3s 103us/step - loss: 0.1224 - val_loss: 0.1258\n",
      "Evaluating model with testing data...\n",
      "6024/6024 [==============================] - 0s 15us/step\n",
      "Getting distribution of predictions and covariance matrix...\n",
      "      1 of 20\n",
      "      2 of 20\n",
      "      3 of 20\n",
      "      4 of 20\n",
      "      5 of 20\n",
      "      6 of 20\n",
      "      7 of 20\n",
      "      8 of 20\n",
      "      9 of 20\n",
      "      10 of 20\n",
      "      11 of 20\n",
      "      12 of 20\n",
      "      13 of 20\n",
      "      14 of 20\n",
      "      15 of 20\n",
      "      16 of 20\n",
      "      17 of 20\n",
      "      18 of 20\n",
      "      19 of 20\n",
      "      20 of 20\n",
      "Computing ensemble means...\n",
      "Computing mean squared error...\n",
      "Iteration 199\n",
      "Train on 28352 samples, validate on 6054 samples\n",
      "Epoch 1/150\n",
      "28352/28352 [==============================] - 3s 98us/step - loss: 0.3688 - val_loss: 0.2685\n",
      "Epoch 2/150\n",
      "28352/28352 [==============================] - 3s 95us/step - loss: 0.2438 - val_loss: 0.2279\n",
      "Epoch 3/150\n",
      "28352/28352 [==============================] - 3s 98us/step - loss: 0.2071 - val_loss: 0.1942\n",
      "Epoch 4/150\n",
      "28352/28352 [==============================] - 3s 98us/step - loss: 0.1867 - val_loss: 0.1848\n",
      "Epoch 5/150\n",
      "28352/28352 [==============================] - 3s 96us/step - loss: 0.1787 - val_loss: 0.1721\n",
      "Epoch 6/150\n",
      "28352/28352 [==============================] - 3s 95us/step - loss: 0.1656 - val_loss: 0.1655\n",
      "Epoch 7/150\n",
      "28352/28352 [==============================] - 3s 94us/step - loss: 0.1592 - val_loss: 0.1545\n",
      "Epoch 8/150\n",
      "28352/28352 [==============================] - 3s 96us/step - loss: 0.1540 - val_loss: 0.1547\n",
      "Epoch 9/150\n",
      "28352/28352 [==============================] - 3s 100us/step - loss: 0.1507 - val_loss: 0.1518\n",
      "Epoch 10/150\n",
      "28352/28352 [==============================] - 3s 95us/step - loss: 0.1497 - val_loss: 0.1508\n",
      "Epoch 11/150\n",
      "28352/28352 [==============================] - 3s 93us/step - loss: 0.1486 - val_loss: 0.1485\n",
      "Epoch 12/150\n",
      "28352/28352 [==============================] - 3s 93us/step - loss: 0.1435 - val_loss: 0.1465\n",
      "Epoch 13/150\n",
      "28352/28352 [==============================] - 3s 92us/step - loss: 0.1425 - val_loss: 0.1429\n",
      "Epoch 14/150\n",
      "28352/28352 [==============================] - 3s 94us/step - loss: 0.1409 - val_loss: 0.1395\n",
      "Epoch 15/150\n",
      "28352/28352 [==============================] - 3s 96us/step - loss: 0.1399 - val_loss: 0.1367\n",
      "Epoch 16/150\n",
      "28352/28352 [==============================] - 3s 95us/step - loss: 0.1373 - val_loss: 0.1373\n",
      "Epoch 17/150\n",
      "28352/28352 [==============================] - 3s 92us/step - loss: 0.1349 - val_loss: 0.1365\n",
      "Epoch 18/150\n",
      "28352/28352 [==============================] - 3s 95us/step - loss: 0.1334 - val_loss: 0.1329\n",
      "Epoch 19/150\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "28352/28352 [==============================] - 3s 108us/step - loss: 0.1319 - val_loss: 0.1339\n",
      "Epoch 20/150\n",
      "28352/28352 [==============================] - 3s 105us/step - loss: 0.1296 - val_loss: 0.1317\n",
      "Epoch 21/150\n",
      "28352/28352 [==============================] - 3s 99us/step - loss: 0.1303 - val_loss: 0.1315\n",
      "Epoch 22/150\n",
      "28352/28352 [==============================] - 3s 109us/step - loss: 0.1301 - val_loss: 0.1319\n",
      "Epoch 23/150\n",
      "28352/28352 [==============================] - 3s 108us/step - loss: 0.1295 - val_loss: 0.1289\n",
      "Epoch 24/150\n",
      "28352/28352 [==============================] - 3s 107us/step - loss: 0.1285 - val_loss: 0.1299\n",
      "Epoch 25/150\n",
      "28352/28352 [==============================] - 3s 106us/step - loss: 0.1277 - val_loss: 0.1288\n",
      "Epoch 26/150\n",
      "28352/28352 [==============================] - 3s 113us/step - loss: 0.1271 - val_loss: 0.1281\n",
      "Epoch 27/150\n",
      "28352/28352 [==============================] - 3s 108us/step - loss: 0.1271 - val_loss: 0.1274\n",
      "Epoch 28/150\n",
      "28352/28352 [==============================] - 3s 105us/step - loss: 0.1264 - val_loss: 0.1293\n",
      "Epoch 29/150\n",
      "28352/28352 [==============================] - 3s 108us/step - loss: 0.1256 - val_loss: 0.1258\n",
      "Epoch 30/150\n",
      "28352/28352 [==============================] - 3s 108us/step - loss: 0.1257 - val_loss: 0.1304\n",
      "Epoch 31/150\n",
      "28352/28352 [==============================] - 3s 106us/step - loss: 0.1247 - val_loss: 0.1259\n",
      "Epoch 32/150\n",
      "28352/28352 [==============================] - 3s 109us/step - loss: 0.1250 - val_loss: 0.1263\n",
      "Epoch 33/150\n",
      "28352/28352 [==============================] - 3s 110us/step - loss: 0.1244 - val_loss: 0.1266\n",
      "Evaluating model with testing data...\n",
      "6054/6054 [==============================] - 0s 16us/step\n",
      "Getting distribution of predictions and covariance matrix...\n",
      "      1 of 20\n",
      "      2 of 20\n",
      "      3 of 20\n",
      "      4 of 20\n",
      "      5 of 20\n",
      "      6 of 20\n",
      "      7 of 20\n",
      "      8 of 20\n",
      "      9 of 20\n",
      "      10 of 20\n",
      "      11 of 20\n",
      "      12 of 20\n",
      "      13 of 20\n",
      "      14 of 20\n",
      "      15 of 20\n",
      "      16 of 20\n",
      "      17 of 20\n",
      "      18 of 20\n",
      "      19 of 20\n",
      "      20 of 20\n",
      "Computing ensemble means...\n",
      "Computing mean squared error...\n"
     ]
    }
   ],
   "source": [
    "# how well does the first go generalize?\n",
    "loss, ensemble_loss = modelPredictionsGeneral(mc_model, testFiles)\n",
    "print(\"MSE: {:.3}\".format(loss))\n",
    "print(\"MC-ensemble MSE: {:.3}\".format(ensemble_loss))\n",
    "\n",
    "# keep track of the losses in our three lists\n",
    "mses.append(loss)\n",
    "ensemble_mses.append(ensemble_loss)\n",
    "\n",
    "# number of iterations\n",
    "n = 200\n",
    "\n",
    "# when to check how well we generalize\n",
    "check = np.arange(0,n,5)\n",
    "check = np.append(check,n)\n",
    "\n",
    "# exploration vs. exploitation probability\n",
    "x = np.linspace(0,1,num=n)\n",
    "p = np.exp(-2.75*x)\n",
    "\n",
    "for i in range(n):\n",
    "\n",
    "    print(\"Iteration\", i)\n",
    "    \n",
    "    # how many instances to get in our next batch\n",
    "    batchSize = 100\n",
    "    phiStepSize = 1.\n",
    "    thetaStepSize = 1.\n",
    "    y0RStepSize = 1.\n",
    "    \n",
    "    #####################\n",
    "    ### Determinant\n",
    "    #####################\n",
    "        \n",
    "    startTime = time.time()\n",
    "    \n",
    "    # clear the previous model and session\n",
    "    keras.backend.clear_session()\n",
    "    gc.collect()\n",
    "    del h_mc\n",
    "    del mc_model\n",
    "    \n",
    "    # get the next set of data - determinant\n",
    "    batch = nextBatch(yTest, determinant, batchSize, p[i], phiStepSize, thetaStepSize, y0RStepSize)\n",
    "    newX, newY = getMoreFluxRopes( batch )\n",
    "    \n",
    "    # train the next batch\n",
    "    mc_model = get_model(act=\"relu\")\n",
    "    xTrain, yTrain, xTest, yTest, xVal, yVal = trainTestValidationSplit( dataX,dataY )\n",
    "    xTrain = np.concatenate( (xTrain, newX) )\n",
    "    yTrain = np.concatenate( (yTrain, newY) )\n",
    "    h_mc = mc_model.fit(xTrain, yTrain, \n",
    "                    epochs=150, batch_size=128, verbose=1, \n",
    "                    callbacks=callbacks_list,\n",
    "                    validation_data=(xVal, yVal))\n",
    "\n",
    "    dataX = np.concatenate( (xTrain, xTest, xVal, newX) )\n",
    "    dataY = np.concatenate( (yTrain, yTest, yVal, newY) )\n",
    "    \n",
    "    stopTime = time.time()\n",
    "\n",
    "    duration = stopTime-startTime\n",
    "    training_times.append(duration)\n",
    "    \n",
    "    # how well did we do?\n",
    "    duration, loss, ensemble_loss, mc_ensemble_pred, t, determinant = modelPredictionsActiveLearning(mc_model, \n",
    "                                                                                                 xTest, \n",
    "                                                                                                 yTest,\n",
    "                                                                                                 batch_size=3072)\n",
    "    training_times.append(duration)\n",
    "    \n",
    "    # are we generalizing better?\n",
    "    if ( i in check ):\n",
    "        loss, ensemble_loss = modelPredictionsGeneral(mc_model, testFiles, batch_size=64)\n",
    "        mses.append(loss)\n",
    "        ensemble_mses.append(ensemble_loss)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYgAAAEWCAYAAAB8LwAVAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy8li6FKAAAgAElEQVR4nOydd3hb1f3/X0feluQV23FiO7GznA3ZEMKGJJQAKYWyCy0t8KMUOumg5VtoaSmFlpbRlraUtuyWUUYgjLAD2XuR7cRZ3pZsy1rn98fRlWVb07Fsyz6v5/Ej6epe3eN13/ezhZQSjUaj0Wg6Y+rrBWg0Go2mf6IFQqPRaDRB0QKh0Wg0mqBogdBoNBpNULRAaDQajSYoWiA0Go1GExQtEBpNHyOEuEoI8VZfr0Oj6YwWCM2AQwixTwjRKoSwCSEahBDLhRA3CSEi/r0LIc4QQhzsjXUaSCmfklLOj/d5+uJ70yQ2WiA0A5ULpJRWYCRwL/BD4O/xPqkQIjne59BoegstEJoBjZSyUUr5CnAZcK0QYrIQIk0Icb8QolIIcVQI8WchRIYQwgy8AQwXQth9X8OFECYhxI+EELuFELVCiOeFEHkAQogyIYQUQlwvhKgElgVs+6oQ4oAQot5nwcwSQmz0WTUPG2sUQlwnhPg44LX07b/Tt+8jQgjhe2+0EGKZbx01QoinhBA5AcfuE0J833eeRiHEc0KI9FDfW6/8EjQJixYIzaBASrkSOAicirIoxgEnAmOAYuBOKWUzcB5wSEpp8X0dAr4FLAZOB4YD9cAjnU5xOjABWBCwbQ4wFiVODwJ3AOcAk4AvCyFOD7PkRcAsYCrw5YDPFcCvfeuYAJQCP+907JeBhUC57/jrwnxvGk1ItEBoBhOHgDzgBuA7Uso6KaUN+BVweZjjbgLukFIelFK2oS7Il3RyJ/1cStkspWwN2PYLKaVDSvkW0Aw8I6U8JqWsAj4CpoU5571SygYpZSXwHkrMkFLuklK+LaVsk1JWA79DiVMgf5RSHpJS1gGvGsdqNLGi/aWawUQx6m8+E1jj89qAuitPCnPcSOAlIYQ3YJsHGBrw+kCQ444GPG8N8toS5pxHAp63GPsKIYYCf0BZQlbUTV59hGO1K0nTLbQFoRkUCCFmoQTiZdTFeZKUMsf3lS2lNC7WwdobHwDOC9g/R0qZ7rMECHNcPPiV71xTpJRZwNUogYsG3bpZExNaIDQDGiFElhBiEfAs8KSUcgPwV+D3QohC3z7FQgjDx38UGCKEyA74mD8D9wghRvr2LxBCXNR730UHrIAdaBRCFAM/iOHYYN+bRhMSLRCagcqrQggb6u7/DpSv/qu+934I7AI+E0I0Ae8AFQBSyu3AM8AeXwbRcJRL5xXgLd9nfoYKQPcFdwHTgUbgdeDFaA8M8b1pNCERemCQRqPRaIKhLQiNRqPRBEULhEaj0WiCogVCo9FoNEHRAqHRaDSaoMS1UE4IsRCVAZIE/E1KeW+n928CvokqOrIDN0gptwohyoBtwA7frp9JKW8Kd678/HxZVlbWo+vXaDSagc6aNWtqpJQFwd6LWxaTECIJ+Bw4F9UDZxVwhZRya8A+WVLKJt/zC4GbpZQLfQLxmpRycrTnmzlzply9enUPfgcajUYz8BFCrJFSzgz2XjxdTLOBXVLKPVJKJ6pQqUNxkSEOPszoSk+NRqPpN8RTIIrp2J/moG9bB4QQ3xRC7AbuA24NeKtcCLFOCPGBEOLUYCcQQtwghFgthFhdXV3dk2vXaDSaQU+fB6mllI9IKUejqlt/6tt8GBghpZwGfBd4WgiRFeTYx6SUM6WUMwsKgrrQNBqNRtNN4ikQVahe9QYlvm2heBbVcx9fK+Na3/M1wG5U/36NRqPR9BLxFIhVwFghRLkQIhXVb/+VwB2EEGMDXp4P7PRtL/AFuRFCjEINXdkTx7VqNBqNphNxS3OVUrqFELcAS1Fpro9LKbcIIe4GVvvGQN4ihDgHcKF62l/rO/w04G4hhAvwAjf5hp9oNBqNppcYMM36dJqrRqPRxE5fpbkOCI41OXhtox7dq9FoBh9aICLw2Id7uOXpddTY2/p6KRqNRtOraIGIwJpKNe53xxFbH69Eo9FoehctEGFwuDxsrmoEYLsWCI1GM8jQAhGGLYcacXlUEH/HkaYIe2s0Gs3AQgtEGNbsV+6liqFW7WLSaDSDDi0QYVizv56RQzKZO2YInx+14/UOjJRgjUajiQYtECGQUrJmfwMzRuQyoSiLVpeHyrqWvl6WRqPR9BpaIEJwoK6VGnsb00fmUlFkBXSgWqPRDC60QIRgTaXq7DFjZC7jhloRArbrQLVGoxlExHXkaCKzdn8DlrRkxg21kmQSjMzL1IFqjUYzqNAWRAjW7K/nxNIckkwCgIoincmk0WgGF1oggmBvc7P9SBPTR+b6t1UUZbGvthmHy9OHK9NoNJreQwtEEDYcaMArVfzBYHyRFa+EnUftfbgyjUaj6T20QARhzf56hIATS3P828b7M5l0oFqj0QwOtEAEYc3+esYVWsnOSPFvGznETHqKScchNBrNoEELRCe8Xsm6ynqmj8zpsD3JJBhbaNW1EBqNZtCgBaITu6vtNDncTB+R2+W9iiItEBqNZvCgBaITRoO+wAC1wfgiKzX2Nmr18CCNRjMI0ALRiTX768nNTKE839zlPaPlho5DaDSawYAWiE6sqaxnxshchBBd3tM9mTQazWBCC0QA9c1O9lQ3dyiQC6TAksYQc6q2IDQaTUw8ce+/OPebj/f1MmJGC0QA6w6o+EOwADWAEEIFqo9qgdBoNNGz45idndaheD3evl5KTGiBCGDN/nqSTIITSnJC7lNRZOXzIzY9PEij0USNzaNc1s225j5eSWxogQhgzf56Jg3PIiM1KeQ+44useniQRqOJCZtXXWrtdYnViUELhA+Xx8uGA40h3UsGFUVZgA5UazSa6LFJddNpb0is64YWCB/bD9todXmC1j8EMm6oBSF0qqtGo4meJpNq22Nr0i6mhGTNfjVBLlQGk0FmajIj8jLZcTSxTEWNRtN32EypANibEss1HVeBEEIsFELsEELsEkL8KMj7NwkhNgkh1gshPhZCTAx478e+43YIIRbEc50AaysbKMpKZ3h2esR9x+uWGxqNJgZsyWkA2O2OPl5JbMRNIIQQScAjwHnAROCKQAHw8bSUcoqU8kTgPuB3vmMnApcDk4CFwKO+z4sba/aHLpDrTEVRFvtq9PAgjUYTGbfHS4tPIGzNWiAMZgO7pJR7pJRO4FngosAdpJSBfhozYOSOXgQ8K6Vsk1LuBXb5Pi8uHGl0UNXQGtG9ZKCHB2k0mmixt7n9z22tzj5cSezEUyCKgQMBrw/6tnVACPFNIcRulAVxa4zH3iCEWC2EWF1dXd3tha6tDN2gLxgVeniQRqOJElury//c7nCF2bP/0edBainlI1LK0cAPgZ/GeOxjUsqZUsqZBQUF3V7Dmv31pCWbmDgsK6r9y4aYSUvWw4M0Gk1kmhrbPQ12hzvMnv2PeApEFVAa8LrEty0UzwKLu3nscbG2sp6pJdmkJkf340gyCcYOtbBDt9zQaDQRsNW3XyfsLt1qw2AVMFYIUS6ESEUFnV8J3EEIMTbg5fnATt/zV4DLhRBpQohyYCywMh6LdLg8bK5qDB1/OHwYnn++y+aKoVk6k0mj0UTE1the+2DTAqGQUrqBW4ClwDbgeSnlFiHE3UKIC3273SKE2CKEWA98F7jWd+wW4HlgK/Am8E0pZVxShppaXZwzYSjzxuQH3+GBB+Cyy+DQoQ6bJwyzUm3Tw4M0Gk14bLZWAHJam7AnWOJjcjw/XEq5BFjSadudAc9vC3PsPcA98VudojArnT9dPSP0DitXtj8uXuzfHDg8aO6YtHguUaPRJDBNdiUQw5pqsOdGF+fsL/R5kLpf43bDmjXq+cqOHi49PEij0USDrVl5GYbbarAT13KuHkcLRDi2boUWX2n8ihUd3iqwpJGnhwdpNJoI2FqdpLnayHXYsMfXadPjaIEIh2E1nHMOrFoF3vYAkxCCiqF6eJBGowmPzeHG2taCJam9aV+ioAUiHCtXQk4OXHUV2GywfXuHtyuKrOw8qocHaTSa0DS1echqa8aamoQ9KQ0pE+d6oQUiHCtXwuzZMGdO++sAxhdZaXF6OFCfWB0aNRpN72FzebG2NWPJSEEKQYszcVKZtECEorkZNm9WAlFRAVlZXeIQ44fp4UEajSY8NjdktTVjyfR1dG1LnGpqLRChWLcOPB4lECYTzJrVxYIwhgdtO6x7Mmk0muDYvAKruw1rugpQ2xKo3YYWiFAYYjBrlnqcMwc2boTWVv8umanJTBqexaPv7eaBt3bQmkCmo0aj6R1sMgmr1+UXCG1BDARWroQRI6CoSL2ePVvVRaxb12G3x6+dxRemFPHQsl2c87sPeHPzkYQKQmk0mvhiIwkrbizpKoPJnkAzIbRAhMIIUBsYzzvFIQqz0nnw8mk8e8NJWNKSuenJNVz7j1XsqdazIjSawY7b46XFlIJVeNpjEI2JM5daC0Qwqqth796OAjFsGJSWdolDGJw0agiv3TqPny2ayLr99Sx88CPue3M7Lc7EMSc1Gk3PYsQbrCYvFrMaZ2yzaYFIbFatUo9GeqvB7NldLIhAUpJMXD+vnHe/fzqLpg7j0fd3c+7vPtQN/TSaQYpfIJIFVkuG2mZrDXdIv0ILRDBWrlSZS9Ond9w+Z46yLCJMryu0pvO7y07kz1dPp6qhlVX76uK4WI2m96m1t1FZq+t/ItHkmyBnTRGYs8wA2O06BpHYrFwJkyaBxdJxu+FyCuFm6szJo1QL8QN1iXPHoNFEw31v7uC6J+IyomVAYVgQWalJpFjNpLsc2BNoLrUWiM5I2TVAbTBjhrIsohSI7MwUrOnJutJaM+A41NjKgboW3WYmAjbDgkhPBosFS1srNi0QCczevVBbG1wgLBZlWYSJQ3SmNDeTA3VaIDQDi/oWJy6PpLY5cS52fYHfgshIAbOZrLZmXQeR0BjWQTCBABWHWLlSWRpRUJqXwYF67WLSDCzqm9Wd8dGmxPGn9wWGtWDNTAOzGYuzBXtb4hTUaoHozMqVkJGhLIVgzJ4N9fWwe3dUH1eam8nB+hZdPKcZUNS3qAvfkUYtEOGw+abJWS3pfheT3ZU41wItEJ1ZuVJlL6WE6NtupL5G6WYqzcvE4fJSrVNdNQMEh8vj70h6RFsQYbHZWkl3OUixWvwWhC1xDAgtEB1wuWDt2tDuJYCJEyEzM+pAdWmeyn3WmUyagYJhPYC2ICJha27D2tYCZjNkZCgXkxaIBGXLFtWML5xAJCfDzJnRWxC5mQAc1JlMmgGCEX8AbUFEoqmlDWtbs0pwMZmwel3YZeLMpdYCEUikALXB7NmqaZ8zcgZHiU8gdFGRZqBgWBAmoYPUkWhqdSkLwldTZZFubCQlTExSC0QgK1fCkCFQXh5+vzlzlDhs2BDxIzNSk8i3pOlaCM2Aoc6X2lqWb9YupgjYfONGMasqaovw4hEmHC5vhCP7B1ogAjEK5IQIv1+MFdWleRk6BqEZMDT4LIgJw7K0QETA5vR2tCBMShhsba5wh/UbtEAY2O0qBhHJvQSqq2tRUUxxCG1BaAYKdb4YxIQiK7Y2N80JVPjV29jcsj0GAVjVzCDsCTJVTguEwdq14PVGJxBCqP1isCAONzpwexLDrNRowlHf4sSankxxrsrQ04Hq0Ng8tGcxobq6QuJMldMCYdB5xGgk5syBHTtU0VwESnMz8Xglh7U5rhkA1Lc4yTOnUpSlBOKo/rsOisvjpVWaVAzCcDGlqgwmbUEkGitXquB0QUF0+xuWxurVEXctzVOZTLonk2YgUNfsJDczlaJsNQBH3/gExxABa1uzqp0CLGlKIGzagkgwQnVwDYVhaUQRhzBqIXQcQjMQqG9xkpuZQlGWEgjtYgqOf1iQdKsu0IDVmEutLQgQQiwUQuwQQuwSQvwoyPvfFUJsFUJsFEK8K4QYGfCeRwix3vf1SjzXydGjsH9/bAKRnQ3jx0cVhxiWk45J6GpqzcCgvtlFrjmVjNQkstKTdS1ECPzDgkztsUf/XOrBbkEIIZKAR4DzgInAFUKIiZ12WwfMlFJOBf4L3BfwXquU8kTf14XxWifQPmI0FoEAFYdYsSJiZ9eUJBPDsjO0BaEZENS3OMnLTAWgKDtdp7qGwG9BBBROmw2BcOg019nALinlHimlE3gWuChwBynle1JK46r5GVASx/WEZuVKSEqCadNiO272bDh2DCorI+6qaiG0QGgSG6NRX67ZEIgMbUGEwBgWlJXcvi3NaibV7aQpQeZSx1MgioEDAa8P+raF4nrgjYDX6UKI1UKIz4QQi4MdIIS4wbfP6uoIc6LDsnIlTJ7sT0WLGsPiiDIOoedCaBIdo81GrsMGa9dSlJWmg9QhaDIsiNSAy6zZjLWtBXtzYvzM+kWQWghxNTAT+G3A5pFSypnAlcCDQojRnY+TUj4mpZwppZxZEG32UdcPiT1AbTB1KqSlwRtvRHQzleZlUm1rw+FKoFaOGk0njEZ9eS//By69lKKsdGrsbbrGJwj+caNpASaEMTSoJTHa/8dTIKqA0oDXJb5tHRBCnAPcAVwopfT/1KSUVb7HPcD7QIz+nyg5cAAaG9vnPMRCaip89avwxBPw/e+rQrsQGG2/dVdXTSLjtyBqjsChQwzNSscr0fNOguCPQaQHCITFoiyIBJlLnRx5l26zChgrhChHCcPlKGvAjxBiGvAXYKGU8ljA9lygRUrZJoTIB06hYwC75xgxApqaun/8I48oofjd71Q84vHHgw4b8qe61rUyptDa/fNpNH2I0agvt+4YOBwMUzFXjjQ6GJad0Ycr63/YHC7S3U5SLAGua7MZS1uLXzz6O3ETCCmlWwhxC7AUSAIel1JuEULcDayWUr6CcilZgP8I1SCv0pexNAH4ixDCi7Jy7pVSbo3XWmOOPQRiMsGDD8LQoXDHHVBbC//5T5fP9BfLaQtCk8A0+C2IQwAMdTUDenBQMGwON1Zne6M+QI0ddbZwKEHmUsfTgkBKuQRY0mnbnQHPzwlx3HJgSjzX1qMIAT/5CRQWwo03wjnnwGuvqdbhPgosaaQmm3QmkyahMRr15RxVAlHU2gDoYrlg2BxushzNkNXRgrC2tWDX7b4HIV//OrzwghomdOqpKr7hw2QSlOTqtt+axMZo1JdSVwNAXkMNqUkmLRBBaHK4sDpsHS0II0jt1gODBieLF8PSpVBVBXPnwrZt/rd0229NolPf4iQvIxk8ykUiaqopzErTDfuCYGtp6zALAlAuprZW7J4IM2f6CVog4sHpp8MHH4DLBfPmweHDgC6W0yQ+dc1OclMCLm7HjjEsO13XQgTB1urqME0O8FsQTgRt7v4fh9ACES9OPFEFq+vq4LPPAGVBNDncNLYmRpm9RtOZ+hYnuUkB/vNjxxiala6rqYNgc7i7WhC+GITxfn9HC0Q8qahQj75YhG77rUl06ptd5IqAC9uxYxRlpXOkyYGMUCw62LC1eTpMkwMgJQWLV2WCJUJHVy0Q8aSgQFVaGwLhq4XQxXKaRKW+xUme11cUl5kJ1dUUZafjcHlpau3/F7zewuXx0uqRHabJGVhMSkgToaOrFoh4IgSUlARYEKqQSGcyaRIRf6M+p+8GZ9w4ZUEYg4Oa9N+1gS1wWFCgBUF7+2/tYtJAaalfILIzUrCmJetMJk1C4m+z0WZXGyoq/C4m0MVygfj7MAUTiASaS60FIt6MGOFvBy6EoCQvU8cgNAmJv1FfS6Nqjz9qFFRXMzRL9dvQgep22i2IIC4mYy51W/9PVtECEW9KS+HQIXCrP5jS3Azd9luTkBgWRI6tHnJzVecAt5uhXiUMRxp1wz6DpjAWhF8gtItJQ2mp6vLqr4XI5GB9i8740CQcRqO+vMYayMtTAgGk1tYwxJyqq6kDMCyILEcQgchQzTxt2sWkodTX8dyfyZSBw+XV7ZE1CYe/UV/d0XYLAvyB6iON2jI28AtEWzNkdOxym5aZTorXrS0IDV0FIq+97bdGk0j4G/XVHOkqEFnpHGnSNz0G/iB1MqrjcwDCbMbidOggtYaQAqFrITSJhr9RX22NEghjimN1NUOzdTV1IIYFYUlJ6vqmr+W3TnPVQHa28kH6BKIk16iF0AKhSSzqW5zkmVOh3hekzs9Xb/gsiLpmpx6p68PmcJHhdZOSmd71TbMZi6NZC4QGVSwXUAuRmZpMviVVu5g0CUdds5PczBRoaFACkZKigtUBxXLHtJsJ8PVh8rZ1CVADauyow54QY0e1QPQGAQIBUKLbfmsSkPoWJ7mpJpWVl5urNhYWdiyW024mwDcLwhVCIMxmrM7WxBcIIcTVAc9P6fTeLfFa1ICjk0CU5mmB0CQe9c2u9k6ueXnqsaCggwWhBUJhc7ixulqDjzP2zaW2OxK/UO67Ac8f6vTe13p4LQOX0lI4ehTalPldmpvBoQYHbk9ijB3UaMAXg8DnNw+0IKqrGeqzIPTgIEWTwx20SA7wB6ntCTCXOpJAiBDPg73WhMLIZKqqUi/zMvF4pR6yokkY/I36jE6unVxMWenJZKQk6b9pHzaHiyyHPaSLydLWgs2Z+AIhQzwP9loTihEj1GOntt/azaRJFPyN+ly+v9lAgaitRXg8DNOprn5sDjfWFltwF5PFgtXZQpsXnO7+7UVIjvD+eCHERpS1MNr3HN/rUXFd2UDCsCB8TfuMtt8H61phdF8tqvusraxndL6F7MyUvl6KppfwN+pz+Dq5GgJRUABSQm0tQ32DgzQ+C6K5ESxZXd/0WRAAzW1uUpNTe3l10RNJICb0yioGOp2K5YbnZGASiWlBOFweLvvLp3zl5DJ+tmhiXy9H00v4G/W1NKoNgRYE+AcHrdxb1wer61+4PF4cLi9WeyNYhnfdwReDANXyO9ecoAIhpdwf+FoIMQQ4DaiUUq6J58IGFJmZKuvDJxApSSaGZWckZLHcvtpmXB7Jir21fb0UTS/ib9Rnq4fk5HbXSUC7jaFZwzna5MDrlZhMgzdE2WFYUMgsJlUH1dTPM5kipbm+JoSY7Hs+DNiMyl76txDi272wvoFDl1TXxGz7vbe6GYCth5r8/WY0Ax9/o77GanWzI3wCECAQw7LTcXsltc39P78/nrQPC2oJUwfhsyD6eTV1pCB1uZRys+/5V4G3pZQXAHPQaa6x0VkgchNzcNCeGiUQXglrKxv6eDWa3sLfqK/uWLt7CTpZEL5U10Eehwg3bhRQQeo29X/U3xv2RRKIwFvEs4ElAFJKG9C/w+/9jSDFcsdsbQnXu2ZPdTO5mSkkmQSrtL950OBv1FdX21EgcnPVdDlfDAL06NGmQAsimIspPR2LU3kP+rtARApSHxBCfAs4CEwH3gQQQmQAOoUlFkpLVZOzZuWX9Gcy1bcypjDIXUY/ZU+NnfFFWTQ73azcpwVisNChUZ9hNYBqZZ2fr9ttBNDUGsGCEAKLby51f2/YF8mCuB6YBFwHXCalNHwKJwH/iPThQoiFQogdQohdQogfBXn/u0KIrUKIjUKId4UQIwPeu1YIsdP3dW3U31F/pcvgoMSshdhb00x5gZnZZXmsP9BAmzuxLCBN91CN+gI6uQbiK5bLt6RiEtqCMGIQWaEEArCmqEtvf7cgwgqElPKYlPImKeVFUsq3Ara/J6W8P9yxQogk4BHgPGAicIUQonNe5DpgppRyKvBf4D7fsXnA/6FiHbOB/xNCdPqrTDBCzYVIoDhEfbOThhYXo/LNzCrPw+n2svFgY18vS9ML1Lf4OrmGEYjkJBOFVl0L0R6DCOFiAtLTU0iS3n4fpA7rYhJCvBLufSnlhWHeng3sklLu8X3Ws8BFwNaA498L2P8zwGgOuAAVEK/zHfs2sBB4Jtx6+jWdBKLAkkZqsimhMpn21KgiqVEFZk4sVReJlXvrmFWW15fL0vQC9c0uxhVaVavvvE6/74ICWKOy3vXgoIBhQc4QWUyAsFiweJ393oKIFIM4GTiAujCvILb+S8W+Yw0OoiyCUFwPvBHm2OLOBwghbgBuABhhtLPorxT7lu8TCJNJUJKbWLUQe3wpruX5FvLMqYwptLBKxyHC4vZ4+c7zGzh9XAGXzCjp6+V0m/oWJ3nJUlVNh7AgAIqy0vx/J4MVm8NFhvCS4vWEFAjMZizutoSPQRQBPwEmA38AzgVqpJQfSCk/6KlF+NqKzwR+G8txUsrHpJQzpZQzC4zxh/2VtDQYOrRLqutne2q5+9WtPL/qABsONNAaZQMvr1f2ejfYPTXNJJsEpb6peLPK8lizrx6PV7flCsVDy3bx6oZDPPnZ/sg791P8jfqMpMZgAtHYCG1tajb1oI9BuMnC938cwsWExYLV5cDe1r9riSJVUntQmUtvCiHSgCuA94UQd0kpH47w2VVAacDrEt+2DgghzgHuAE6XUrYFHHtGp2Pfj3C+/s+IER0E4orZI6hvcfL0yv04XOpiLwSMzMukosjKuKFWvFJS1+yivtlJXYuT+mYn9S1O6ltcZKYk8fMLJ/GlXroz3VvdzIghmSQnqfuK2eW5PLOyku1Hmpg0PLtX1pBIrNlfx0PLdmJNT2bjwQYaW11kZyRe8p+/UV/nTq4GHdptZGBrc9Pc5sacFslBMTCxtbmw4lb/zBkZwXcym7E4W/u9BRHxN+gThvNR4lAG/BF4KYrPXgWMFUKUoy74lwNXdvrsacBfgIVSymMBby0FfhUQmJ4P/DiKc/ZvSkthqz8Ew8LJRSycXITHKzlQ18L2IzZ2HLGx42gT24/YeHvrUYQQ5GamkmdOITdTuXVyzankZaaycl8d3/vPBj7ZVcPdiydjifM/5J4aO6Py201mI/awam+dFohO2Bwuvv3ceopzM/i/RZP4+r9Ws2JPLfMnFfX10mLG36ivcydXA8N6r66mKFs9P9LkYHRB4qRv9yQ2hxurx6la7JhCOGl8c6nrEjkGIYT4F8q9tAS4K6CqOiJSSrdv6txSIAl4XEq5RQhxN7BaSvkKyqVkAf4jVOl+pZTyQillnRDiF65b3jgAACAASURBVCiRAbjbCFgnNKWlsHSp8uOK9nBOkklQlm+mLN/MwsntFxCXx0uySSBE8NCPxyt5eNku/vDu56w70MBDV0xjcnF8LtQer2RfbQtnVLTnwJfkZjI8O51V++q57pTyuJw3Ufn5K1upqm/l+RtPZkpJNukpJpbvTlCBMBr1de7kahBYTT1GOQ2ONg5egWhyuMn2hBg3amCxYK21UZngFsTVQDNwG3BrwIVKAFJKGaSXbTtSyiX4qq8Dtt0Z8PycMMc+DjweYX2JRWmpKpQzhr5HICUpfIgoySS47ZyxnDQqj28/t54vPvoJPz5vAl89pSykqHSXQw2tON1eRuV39KnOKs9j+e5apJQ9fs5E5bWNh3hh7UFuPWsMM31W1qyyPD7ZVdPHK+se/kZ9nTu5GgQIRNF0VSw3mAcH2RwuSlyt4QXCbMZSacPWzy2ISHUQJiml1feVFfBljSQOmiB0SnXtKeaMGsKSW0/l9HGF3P3aVr7+z9X+f+qewujBVN5ZIMryqLa1sb82cbKx4smhhlZ+8uImTizN4Vtnj/Vvnzcmn53H7AmZAupv1GfzGfGd01wDBULPplZBamfoGghAWRAtTf2+DiJSFpOmJ4mTQADkmlP561dm8PMLJvLRzhrO+8OHrKus77HP31Nt1EB0vCuaXa4uFrrthsos+97zG3B7JQ9edmIHC/CUMfkALN+deFaEv1FfYy2kpnYNvFqtant1NZmpyWSlJyekEPYUTa0urI7QVdSAP0jd6vL069n0WiB6kzgKBIAQgutOKefFm+diEoK7X9sa+aAo2VvTjDUtmXxLx+EmYwos5GSm6MZ9wF8/2sOne2r5+QWTKOtkaU0clkVOZgqf7Eq8ORpdGvV1diUK0bEWInvwpro63V7a3F6srSHmURtYLAFT5fpvuxotEL3JsGGq82WcBMJgcnE2l80qZf2BBmrtbZEPiAKjB1PnOIPJJJg5Mm/QF8xtrmrk/rd2cN7kIi6d2TXt2GQSnDxqCJ/sqkHKxKob6dCoL1TsLEAgBvPoUf8siJam8C4ms9k/Vc7Wj2shtED0JklJMHx43AUC4MyKQqSEDz6v7pHP21Pd3CVAbTC7PJd9tS0cs0W+KLy15QhvbTnSI2vqL7Q6Pdz27DryzKn86otTQgbrTxmTz+FGB3trEqvSuK7ZSU6oRn0GHaqpB68F4e/DZG+M6GKytrWPHe2vaIHobTrNhYgXU4qzybek8d6O4xcIh8tDVUMr5fnB/+Db6yHCxzx2HbNzy9PruOHfa3hmZeVxr6s/sP1IE1f+7TN2VzfzwKUnhp0vbMQhPtmdWG6m+hYneaEa9RkUFPgFYlh2OjX2tn7tW48XfoGw1Ud2MSXAVDktEL1NLwmEySQ4o6KAD3YcO+5/VOOOd1RBcAticnE2GSlJYd1MUkrueGkT6SkmTh2bz49f3MTTKxJXJFqdHn7z5nYW/fFj9te28IfLT2Te2Pywx5QNUXUjyxMs3bW+2aWEL5IFUa1uRoZmp+OVUN1D7s1Ewt/qu7E2sovJZ0H052pqLRC9TWkpHDyoiuXizJkVhTQ53Mc9GnRviBRXg5QkE9NG5LAiTKD6P6sPsmJvHT/5wgT++pWZnFlRwE9e2sRTKxKvR9GHn1ez4MEP+dP7u1k8rZh3vns6F53YpZdkF4QQzB2Tz/LdtQnVv0q1+vYJROcUV4PCQmhpgebm9sFBg9DN1GRYEE11kQvlDIHQLiaNn9JSaGvz323Fk1PH5ZNsEry341jkncNgpLiGEghQbqbtR5pobO0acKuxt3HPkm3MLsvjyzNLSU9J4s/XzODMigLueGlzwjSyq7a1cduz6/jK4ytJNgme+cZJ3H/pCSqAGyXzxuTT2Opi66GmOK605zAa9eVlJIcv8Awym3owCkT7sKDQrb4BFYPQLiZNF4y25L3gZspKT2FmWS7vbT9OgahRd4Xhmq/NLs9DSli7v2sc4pevbaXF6eZXF0/GZFIB3LRkJRJnjS/kpy/3b5GQUvL8qgOc87sPeGPTEW47eyxLbjuVk0cPifmz5vqO+SRB6iH8jfqELxUzXAwCOhTLDcZq6vZhQc1Ru5j6c0dXLRC9TZxrITpzZkUh24/YqGro/mCiPdXNIeMPBtNG5JBsEl0K5j7aWc3L6w/x/04fzZhCa4f30pKT+NPV0znbJxL/7qci8ej7u7n9hY1UFFlZctupfOfccaSnJHXrswqz0hlbaEmYthv+Rn2hOrkaBHR0HWJOJc+cyuZDg2/aoH9YUCQLwmIh0+VAILUFoQnAEIjK3gnQnjVe/eO+3003k5SSPdX2sO4lgMzUZCYXZ3comGt1erjjpc2Myjdz85ljgh6XlpzEoz6R+NnLm/n3p/u6tU5QRUo9zdMrKvnt0h1cdOJwnv3GSYwpPP4GdKeMyWfVvrqEmOftb9QXqpOrQYCLSQjBrLJcVg7C4kmbw0VmsiBZeiO6mARgwaNjEJoACgrU8KBesiDGFFooyc3otpupvsVFk8PdpcVGMGaX57HxYCMOl7rw/XHZTirrWvjlFyeHveM2ROKcCYX87H9beHvr0ZjX2djq4ozfvsc3/rW6xy68r288zB0vb+LMigLuv/QEv3vseDllTD4Ol5e1+48veaA38Dfqc9jUhihcTABzyodwsL71uCzXRKTJ4cJq/KmHczElJUF6Olbp1haEJgAhoKSk1wRCCMGZFYV8sqvWf+GOBX8PpggWBKhAtdPjZcOBBrYfaeKvH+7hkhklzB0dPv0TlEg8ctV0xhZa+MVrW2O+yD+8bCeHmxy8vfUoN/xrTbe+10A+/Lyabz+3jpkjc3n0qhkRO+vGwpxReZhEYvRl8jfqMzq5hspiysxUF0SfQPh7dO1NrJqP48XmcGNN8mWohbMgQMUhvC5dKKfpRC/VQhicNb6QVpcnbBpqKEJ1cQ3GzJHq7nLF3jp+/OImsjJSuOMLE6I+V1pyEj9bNJHKuhb+8cm+qI/bV9PME8v3cemMEu770lQ+3FnN9f9cRYuze/94ayvrufHfaxhdYOFv184iI7V78YZQZKWnMLUkh48TIA7hb9Rn8yUfhGtTH1ALMWFYFtb05EHnZrI53FiFz9UZjUB42rRAaDrRywJx8ughpCWbuuVm2lPdTEqSoCQ3xOjEAHLNqYwbauEvH+xmXWUDPz1/QtjK4mCcNq6As8YX8vCyXVTboiu0+tWSbaQmmfj+/Aq+PKuUBy49gU9313LdP1bF/M+344iNr/5jFYVZafzr+tlxGxE6b0w+Gw82+tMi+yv+Rn31vgt9JIHwWRBJJsGssjxW7BlsAuEbNwrhXUygqqldDl0op+lEaSkcOgSe3glSpqckMXf0EJZtPxZzo7i9NXZG5LXPoY7ErLI8mp0eThkzhC9Oi1w8Fow7zp+Aw+Xhgbd2RNx3+e4a3tp6lJvPHEOhL//+4uklPHj5NNbsr+fax1dGfRE+UNfCNX9fQVqyiSevn0OhNb1b64+GuWOG4PHKfn8B7dCoLy0t9Ixl6CAQAHPK89hT0xxVj66Bgs3hxip9f29RWBBWZ2u/vknQAtEXlJYqcTh8uNdOedb4QirrWvwuo2hRKa7RZ+4smFREoTWNexaHbloXidEFFq6dW8Zzqw+wJUyqpMcr+cVr2yjOyeD6eR1Hnl54wnAevmIaGw40cPXfV9LYEv6f8FiTg6v/voI2t5d/Xz+H0rzMbq09WqaPyCUt2dSnbqaNBxs4UBd+0FNUjfoMAvoxQWAcondE0On2smTTYZb2YTPIJoebLI/P8o0kEBYL1rZm7WLSdKKXayEAzvSlu8biZvJ4JftrW6IKUBucNq6AlXec02UeQqzcetZYcjJSuPvVrSGtnv+sPsC2w0386LzxQbOkzpsyjD9dPYOthxq56u+fUe/LyKm1t/HRzmr+/MFubn1mHWc/8D4n/fpdjjW18fh1s6gosnb5rJ4mPSWJWWV5fRaollLy9X+u5rZn14XdL6pGfQZGDML3+5pcnE1malLcBeJAXQu/Xbqdufcu4+an1nLrM+v6rFGgzeEiy+VQySjhrC1QMQiHvV9nMUWaSa2JB4ECcfLJvXLKktxMxg21sGz7Mb5+6qiojqmqb8Xp8UYskosH2ZkpfHd+BT97eTNLtxxh4eRhHd63OVzc/9bnzBiZy6Kpw0J8Cpw7cSiPXTOTG59cw/l//AiPlBxtao9tFOdkMGFYFudPHc7CSUVMHN57k3RPGZPPb97czjGbI67urGAcbWrjmE19bT/SxPii4N93fbOLcUOt0QuEywWNjZCTQ0qSiRkjc+PiRvN4Je/vOMZTKyp5b8cxBMpKLsnN5Inl+9h5zM6EYb07Fdk/LMjTquIPkSxoiwVLs51mpwePV5LUQ2nUPYkWiL6gDywIUFXVj3+yVwXS0iMHX/fUGD2Yjr84rDtcMauUJz/dzz1LtnFGRWEHK+HR93dTY2/j79fOjOjKOnN8IY9fO4s/LttJcU4GE4dlMWl4FhOGZcUcRO9JThmj2m58urs2qmZ/PcnGg+01GM+uPMDPL5wUdL8OjfqKI6wxoFiOnBxAxSHuf+tz6pudPfKz9nglj324h39/uo9DjQ4KrWl868wxXDZ7BMU5GeyutvPE8n1sOtjY6wLhHxbUFmHcqIHZjKVa9eRqdrrJiuJ/srfRLqa+ICdH/QH1tkCML8TlkVG3eYjU5jveJCeZ+OmiCRyoa+2Q9nqgroW/f7SXi6cVc0JpTlSfNW9sPs/feDK/v+xEvnHaKOaOye9TcQCYNDybrPRkPt7Z+26mzVWNmATMnziUF9YepNXZNWHC36jPnAp1ddHFIKBTHEKJYE/NLH9t4yF+8+Z2Rg4x86erpvPJj87iu/MrKM5R7pzyIWYsaclsqur9Nh/+Pkyt9sgZTKCC1DYl1P3VzaQFoi8QotdTXQFmjMzFmp7MsijjEHuqm7GmJzOkDy+kp44t4JwJhTy8bKc/G+beN7aTZBL8YGFFn62rJ0gyCU4ePYTlu2t7fQzppqpGxhZa+dq8cmwON69v6pow4W/UF22QOqAfk8EJpdmkJpt6LA7xj0/2MSrfzFNfn8N5U4Z1KWA0mQSThmexsU8FwhadBWGxYPHVl/TXQLUWiL6iDwQiJcnEaWMLeG9HdVQXpL01asxod7OReoo7zp+I0+PlgaWfs3JvHa9vOsyNp49iWHbk2oz+zrwx+VQ1tLK/Nnw2UU8ipWRTVSOTi7OZU57HqAJz0Al/RqO+3PQkaGqKXiACLIi05CSmleawogcqqtdV1rP+QAPXzi0L2/Zkakk22w434erlQHWT4WKKNG7UwGzG4lBWen+thdAC0VeUlvZaw75AzhxfSLWtjS1RzCPYU22PKcU1XpTnm7n25DKeX3OAH/x3A8Oy07nxtNF9vawewWgZ/tme3mtJcaTJQY3dyZTiLIQQXDl7BGv217PjiK3Dfn4LQqrHiAKR72upcqyjhTpn1BC2HmryX0C7yz+X78OSlsyXZpSE3W9ycTZOt5edR+3Hdb5Y8ccg7A3RuZgsloCW31ogNIGUlsLRo2p4UC9yRoXyE0dyM7U6PRxqdHRtseHxQEUF/OUv8VpiUL519lhyM1PZX9vC7Qsrerz9RV8xusBCviW1VwVi00HlfplSouI3F08vITXJ1MWK8Dfqi9TJ1SA1VcXXOgtEeR5eCWuCzAqJlmNNDl7fdJhLZ5ZgCTOXBNQ8doBNVb3bDNGYJpfVFGEetUECDA3SAtFXGJlMVVW9etp8SxonlGRHnDIXMkC9axd8/jk880y8lhiU7IwU7r90KtfNLeOiE3o34yeeCCGYUz6EFXvrei0OsckXoJ7oy/LJM6eycHIRL3YKVhuN+nIidXINJKAfk8H0Ebkkm8Rxpbs+taISt1dy7cllEfctG2LG2geBan8MorE2eoFoM1xM/bOaWgtEX9FHqa6g3EzrDzRQG2aofMg51Bs2qMfly8Fmozc5a/xQfn7hpB5ru91fmDMqj8ONDg7U9U5rbCNAHWiFXTlnBE2dgtVGo75cu+9OPFQn10A6tdsAyEhNYmpJdrc7u7a5PTy1opIzKwqjKsA0mQSTirPYVNW7Y12Ni7ylvka7mKJBCLFQCLFDCLFLCPGjIO+fJoRYK4RwCyEu6fSeRwix3vf1SjzX2Sf0oUAsmFSElPD9/2wI2VY75Bzq9evVo8sF778fx1UOHub4UkE/64XW2FJKNlc1MqUku9Maugar/Y36Gn0CEa0FcayrdTpn1BA2HmzsVofdJZsOU2Nv47q5ZVEfM6W49wPVNocbc2oSyfYos5jMZsxOh//Y/kjcBEIIkQQ8ApwHTASuEEJM7LRbJXAd8HSQj2iVUp7o+7owXuvsM/pQICYMy+LXF0/hvR3V/L8n1wYVib01zQzLTicztZO/d8MGFYPIzIS33uqlFQ9sxhZayDP3ThzicKMRoO4oEMGC1R0a9UF0AtGpH5PB7PI83F7JusrY4gJSSv7xyT5GF5g5dWzkuSIGU0pycLq9fH6096xcVYCaDK2tUae5mpBYkuSgtCBmA7uklHuklE7gWeCiwB2klPuklBuBvmmc0peYzeofrg8EAuCK2SP41RensGz7MW4OIhJ7akLMod6wAWbNgjPO0ALRQ5hMgtm91Brb8Mt3tiCga7C6Q6M+iN6CqKnp0ql45shcTAJWxCiC6w40sPFgI9fNLYsp3dofqD7Ye3EIm8ON1XDbRVkoB2Ax9d+51PEUiGIg8Op30LctWtKFEKuFEJ8JIRYH20EIcYNvn9XVnQJjCUEf1EIEcuWcEfxy8WTe3X6Mbz611j/TOeQc6poaFVQ/8USYP18Fq/ft6/2FD0DmjMqjqqGVg/XxrYfYdLCRJJPwB6gD6Rys7tCoLz1dfUWisFA166vrKHbW9BQmDc+OeWjVE5/sw5qWzMXTw6e2dmZkXibW9J4LVDc5XPxqyTYeencnXm/wZAKbw401xSdiUbqYACzC228tiP7ci2mklLJKCDEKWCaE2CSl3B24g5TyMeAxgJkzZ/ZuKWpPUFoKy5bBjBkqRTAtTT0az9PT4Zxz4PLLI3eG7CZXnzQSKSU/+98Wvvn0Wh65cjo2h28OdeceTEaA+oQT1NhUgLffhm98Iy5rGzAsXw5lZTB8eMhdjDjEij11lMyIvtX47mo7I2OY16EC1JaQM8KvnDOCVzYcYsmmw7E16jMILJYzWm/4mFOex78+24/D5Qk7o9zgaJODJZsOc+3cMswRUls7YzIJJg/PZvNxCoSUklc3HuYXr231D7DaVW3nvkumkpbc8XuwOVzkRDtuNGAfi3Rj66cCEU8LogooDXhd4tsWFVLKKt/jHuB9YFpPLq5fcMstsHAhDBsGVl+LabtdzYn4/HP44AP42tfUxfiHP4zb3fo1J5dx90WTeHvrUW55ei07fH7b8s4upkCBqKhQArd0aVzWNGB4/nmYNw++9a2wu40vspKdkRJTHKKytoX5v/+Qv3+8N6r9/QHq4q7uJYM55XmMyjfz9MrKjo36ohWIIP2YDGaX5+F0e9kYpdvnqRWVeKTkKyePjO7cnZhSks22wza/ZRwr+2qa+crjK7n1mXUUZaXzyi2ncPvCCv63/hBf/ceqLoV/HcaNxuBisnpd2Ptpmms8LYhVwFghRDlKGC4HrozmQCFELtAipWwTQuQDpwD3xW2lfcXCheorFFIqkXj4YXjgAfjtb+GCC5SwnH02mAL0vbkZNm1SF/ENG9TzL3854oXJ4Csnl+H1Sn7+6lY2+Dp9dpkDsX69ugs2LgLz58MLL4DbDcn92RjtI957D665Rv2e3nlHZX6lBO/YaTIJZpfnxeSCeXl9FR6v5JUNh7jx9MiV5YcaHdQ2O4PGHwyEEFwxewT3LNkG0N6oL5oUVwjabsPAGCC0Yk+t/3ko2twenl6xn7PHFzJySPeaRU4pzsbpUYHqyWFEMdi5//z+Hh55fxdpSSbuunASV580kiSTYGpJDkVZ6dz+3418+c+f8sRXZ1OUrVxvTQ4XVsP4i8aCSEuDpCQsHidHB5sFIaV0A7cAS4FtwPNSyi1CiLuFEBcCCCFmCSEOApcCfxFCbPEdPgFYLYTYALwH3Cul3BqvtfZbhFDB4P/+F/buhZ/8BD77TF2YJ05UVsWll8K4ccoCOflkuOkmeOop2L4d7rvPP7wlGq47pZw7F03kaFObbw51J1fHhg3KejCYPx8aGmD16p75fgcS69fDRRfB2LHwpz+pXkYrV4Y9ZE55HpV1LRxqiFwPIaXk5XVVJJkEWw41sS+KSYFGwDbSxfJLM1SwGmJo1GcQpGGfQU5mKuOLrFF1dn1942Fq7E6um1secd9QGJZSLG6mT3bVcN6DH/H7dz5nwaQi3v3e6Vw7t6zDrIaLp5fwj6/O4mB9Kxc/+ok/U6rJ4SYr2nGjoP6/zWYsbsegDFIjpVwipRwnpRwtpbzHt+1OKeUrvuerpJQlUkqzlHKIlHKSb/tyKeUUKeUJvse/x3OdCUFpKfzyl6p/05NPqn/Y++6DdetgyhT4+c/h5ZeVkDQ0wG9+AwcPwsaNMZ3ma/PK+dUXp/C1eeUdB5i0tcHWrSpAbXD22eqPXGczdWTvXjjvPMjOhjffhEsuUVZEBHfcSaN8cYgo6iE2HmxkT00zt5w5BiBoN9bObK4KHaAOxAhWA+RGO03Of3Ce+l6DWBCgRHDN/vqw9QlGauuYQot/ZkZ3GDlEBaqj7ey6dMsRrvrbCjxS8q+vzeahK6b555x35tSxBTx340m4vZJL/rScj3ZW43R7sXp8fauicTGBGjvqah18dRCaOJGWBlddBZ9+Ck6nan3xwgtw553qjrWsTF20v/AFtf9rr8V8iivnjODH503ouHHbNuVKCrQghgyBmTO1QARSXQ0LFihBXbpUxY9yc2HOnIgCMWFYFtb05KjSXV9aV0VqsomvzStn+ogcXt8YWSA2RghQB3Lt3DJSk0yMLrTEJhBJServIoRAzC4fQovTE/aufm1lA5uqYk9t7YwQginF0Qeqn/hkH6V5GSz99mmcNq4g4v6Thmfz4s1zKbCmcd0/VgFgjXYetYHZjKWtBbvTHTI7qi/RApHIhPBnA1BUpOoVuiEQQQkMUAeyYIFyezX2fv/9fkdzMyxapFKXX31VuQEN5s+HVau6pH8GkmTUQ0SIQ7g8Xl7dcIhzJhSSnZHC+VOHs/Vwk789SjCiCVAHMmNkLpvvWsC4IRmqpUq0AgEhq6mhPQ4RbD5Eta2Nl9Yd5K5Xt2BNT+bi6cffc2tKcTbbowhU76tp5tM9tVw+a0RUAmpQkpvJC/9vLtNHqMaH2S6fezAGgbA67EgJLa7gXQ36Ei0QA5lFi2DFipD/rDGxfr1KtR07tuP2+fNVUdSyZdF9zrZtsHPn8a+nv+FyqXjQ6tXw3HNwyikd31+wQMWD3nkn7MfMGZXH3ppmjjY5Qu7z8a4aapudLPaNKf3CFOUOWhLGzXSo0UFds5OpYQLUnUlNNil3JcQuECHqkgqsaYwqMLNibx1Ot5flu2u4943tfOEPHzHrnnf4znMbqKpv5afnT+haxd8NJgcEqsPx3OoDJJkEl0RoJR6MnMxU/n39HH6xeDJneX3fdwwuJkuramvTH+MQWiAGMosWqYvSG28c/2dt2KBiHUmd7q5OOkndLUXjZqqvh1NPVe6W3bsj758oSKlqQd54A/78Z7gwSGeYWbNUK+wo4xDh0l1fXldFTmYKZ1SogPCw7IyIbqZNvsy0WLJ5gHaLJ9osJghrQYCq+fh4Zw3T7n6LK/+6gr99tAdLejI/WFDBa9+ax6o7zuGyWSNiW2cIDEEMVzDn8nj575qDnFlRyNAQMYdIpKckcc1JI8lqsSkXb7R1S2YzlmbVVNDe1v9SXbVADGSmTVNpqcfrZpKyawaTQUoKnHVWdAJx113qguP1wuLFquZjIPDTn8I//6m+v1BFg8nJKqj/1lthM8smDsvCkpYc0s1kb3OzdMsRzp8yTN3h+4jkZtrkC1BPiBCg7kIsbTYMIgjE4hOHM3aohS9OL+axa2aw7s5zef7Gk/nmmWOYXJzdo916R+RlkpWeHLb2Ytn2Y1Tb2rh8VmnIfaLGblc3TNHGTiwWLM1qbf0xUK0FYiAjBJx/vrooOZ3d/5yDB9WFPTCDKZD582HPnvBWwdatqp7jhhtU2u7WrXDttUosEpnHHoNf/UoJw89+Fn7fBQvUz3LbtpC7JCeZmFmWG7Jn0VtbjuBwefnitI7++Uhupk1VTYwbao3Jvw50TyAKCpRrKsTf3JxRQ3j91lP55eIpzJ9UhDU9TCztOBFCMKUkfKD6uVUHGJqV5h+mdVzY7dG7l0DFIJr671xqLRADnfPPVzn4H3/c/c8IFaA2mD9fPYayIqSE73xH3Vn94heqfchvfwsvvgj33NP9dfU1b7wBN9+sMsYefTTyXeOCBeoxCjfT7upmjtm6xiFeWldFSW4GM0Z2vGAPy1bbXgviZpJSsulgA1OKY7QeoPsWBKjeXf2AycXZbD/SFLRr8eHGVt7fcYxLZ5RG3a4kLM3N0QeoQbmYDIHQFoSm1zn7bJUaezxuJmMGxNSpwd8fM0al14a68L32mhKPu+5qr8L+znfg6qtVeu4rCTjuY+1aFZSeOlUFpaOpJB8xAsaPj+iOmxMi0+dYk4NPdtXwxWnFQdM/vzBlGNsON/lneRhUNbRS3+KKOoOpA8cjED2RHNEDTCnOxuWRfH6kq0vzv6sP4pXw5Zk94F6CdhdTtFgsWBqVtdidfkxSSj7ZVcNrGw/FfGw0aIEY6FgscOaZxycQGzbA6NHt/aI6I4S6O162TGXzBNLWpsRgwgR1tx14zGOPqTqKq68O63aJCilV4eCKFcf3OdGwf7+yzIYMUT/XWC4I8+er9imO0FlKk4uzyUxN6lIP8cqGQ3glLJ4WPP0zgimHkwAAG45JREFUlJtps7/Fd0706zQYAAIxtVh9350D1V6v5LnVBzhlzBBGDIm+QWJYjsfFFIMF4fZ4eWXDIS54+GOu+tsKHnlvd1xG1mqBGAwsWqRSSz//vHvHhwpQBzJ/vsqX73yB/sMfVGzi97/vWreRkaHcTBkZqsiv4TiGzD/zjGo9cuWVxxdviURDg3IptbbCkiVhO7QGZcECdexHH4XcJSXJxMyyvC4V1S+vr+KEkmxGFwQXJMPN9PqmIx22bzzYSLJJML4ohMCHo75e/X7S0qI/JkzDvr6gNC+D7IyULgLxye4aDta39ljGFBC7i8liweJUtRPRBKlbnG7+uXwfZ9z/Prc+s46WNg/3XjyFl26ee1xFhaHQAjEYOP989dgdK8JuV9XaoQLUBmedpVosBLpPDh9WMYcLLmj3v3emtFRVgu/bpy7unm4UC9XUwG23qc/as0elmsYDpxMuvliJ7UsvwaRJsX/G6aerdu5RuJk+P2r3zw3fedTG5qqmkNaDwflB3EybqhoZ250ANcTWqM/AsCCOHo39fHFACMHk4iw2VXW8AXl21QFyMlNYMGloz50sVheT2UyS9GJOMfHE8r1c9bfP+PGLG/nT+7t5feNhNlc10tjqotbexu/f/pxT7l3G/72yhUJrGn+5ZgbvfPd0Lp8dW3FfLGiBGAyUlcHkyd0TiE2blPsmkgWRk6PqGwIvfD/5iXIx/e534Y+dNw8eekgFfX/609jX+N3vqjv7JUtUAPzuu3u+sltKuP561aH18ceV2647mM3q+40YqO4Yh3h5vWrMt2hqeIvlvE5uJqOCemp34g8QW5sNg+xsKC7uHXdflEwpzmHHEZs/UF1rb+OtLUe4eFpJl7kOx0U3XEwAd51cwGnjCmhxenhry1F+8+Z2vvn0WhY99DEn3PUWs+55hz+8u5MZI/P4700n8+LNp7BgUlGPpgQHQ/doHiwsWgT3368upDkx+KKNDKZIFgQoN9MvfqHuOnftgieegNtvV0HsSNx4o2o8eO+9KpB77bXRrW/pUvj3v1WK6eTJKg4xfbr6nF//OrrPMPB4lPuntRVaWjo+vvCCapL4y1+qmMnxsGCBcocdOhTSRTWlOIf0FBMr9taxYFIRL687xKlj8ymwhnf1BGYz3XLWWA7WqwD15BgqqDvQHYEQQiVHLFmi0phNfX8fagSqdxyxMbUkh5fWVeHySC6f3UPBaYNuuJgALhmezCVfaP8fszlcHKhrpbKumcq6Fppa3SyeNpwxhd1wEx4Hff+b0/QOixapZnuxNtZbv14JSmkU/0jz56sLwjvvwK23qn5QsVgEf/yjsgCuvz66zKbmZtXevKJCWSugigOvvhoefDD6ca5uN3zpSyoTyWpVLpKyMhVYnzFD3fH//vfw9a+3n+d4MNxtYX4XqckmZo7M47M9tazeX09VQ2uX2odQnD9lGNuP2NhdbW8PUPemBQHK5VhToyzQfkBgRbWUkmdXHWD6iBw1Ma8n6YaLyX9cANb0FCYOz2Lh5GHccNpovr+gotfFAbRADB5OOkn5kmN1MxkB6mgCYLNnK/fCD36g3Au//nXozKdgpKYq3/6MGWrY0fvvh9//zjtV7OKvf+04L/mXv1RCdeed0Z33+99XwfKbb1b1GQ8/DH//uwp8v/yyslJWrIC//CX6CtlwTJ0KQ4dGFYfYfsTGPz7ZS2ZqEudOjM5X7nczbTzMpqrjCFDD8QkEwLvvdu+8PUxJrgpUb65qZG1lPbuO2bm8J4PToCxQhyM2F5MhJs2R53n0BdrFNFhISlIzCpYsUX/InXsqBcPjUfMkop05bbSTePFF1XvoK1+JfZ0Wi1rjaaepnkbvvacEozOrVikr4aabVH+nQEaOVBbMAw+oFNtQ9RsAf/ubyrT69reVldAbCKGsrTfeCOuCmePry/TG5iNcPK046uZ1w7IzmDkyl9c3HabAmta9CmqD7gpEaalq7LhsmYoR9TFG6++NBxtxeSTm1CTOnzqsZ09iXOR7wILoL2gLYjCxaBHU1kacbOZn927lg48UoA7kggvUBe8Pf+i+73nIEHV3nZenRrLu2NHxfZdLuXuKilSsIRg/+Ylyjf3wh6HP89FHympYsEBZDr3JggXKBbN2bchdTijNJs3XbylS9lJnvuBzM63YW9d995LLpS5c3REIUDcLH3zQtTYmnuzeDWvWBH1rSkk2O47YeH3jYS48sRhzWg/fHxsX+W7EIPqrBaEFYjCxYIGyHKJ1M0VqsRGMr3xFuX1OPjnm5XWguBjefluJzLnndown3H+/smweeUS5tIKRm6viH2++GbzF9r59KmW1vByefbb3Z2qfe656DONmSktOYmZZLgXWNOaOjm2y2hemqLtjp9sbdgZ1WIwiuVjTXA3OPltdNFet6t7xseDxKItx8mSVYebuWlMwpTgbt1fS6vL0TGO+zhgC0Y0sJm1BaPqe3FwVcI1WINavVxfOwME3kTCZogtoR8PYseoC39ioLqjV1arY7667VFB58eLwx3/zmyrYfPvtHZsC2u2qMM/tVoN9Ysnq6ikKC1VAPUK6670XT+XJ6+fE3CeoKDudmb5+TccVoIbuWxBnnKEeo50V0l0+/1y5JL//feVetNnab24CMH4O44usMc3FiJrjcTFpC0LTL1i0SN19V1ZG3nfDBpVymt69Hvk9wrRpStD271cxlK9/Xa3noYciH5uWppoBrlsHTz+ttnm9cM01sHmz6qE0blx81x+OBQtg+XLVTDEEpXmZVHQzwHz1SSMpG5LJ+GEhjr/9dtXuJBTHKxD5+So9Ol6Bao9HxY1OOEG1annySWV1QtDmlCW5GcyfOJTbzh4bl6rjbrmYMn0tPvqpQCClHBBfM2bMkJoo2LZNSpDy0Ucj71tSIuXVV8d/TdHw6qtSJiWptT/2WPTHeTxSTp8u5YgRUra2SnnHHeozHnwwfmuNlvfeU2v53/96/9z19ernabFIWVMTfJ8lS9T6li/v/nm+9z0pU1OlbG7u/mcEY+dOKefNU+u74AIpDx1qf2/kSCkvvbRnzxcNxs/r009jOy4jQ/2c+ghgtQxxXdUWxGCjokI13ovkZqqtVbMLYok/xJNFi9QcidtvV3US0WIyqQB0ZSV88YvKorj+epXl1NfMnatcDBHcTHHh3XfVHbjdrmI6wTheCwJUuqvTqSylnkBKZT1OnapqLP75T/jf/2BYQEbSvHnKgohD87qwdMfFZOzfTy0ILRCDDSHUxfbdd8P/UXYnQB1vFi+G3/wm9uyos85S7qk331QXj2hmN/QGqakqoNoXArF0qapR+fKX1QU3WGO9nhCI005TcayecjP9619K3M88E7ZsUUkRnX+Xp5yi+oDt3dsz54yW7riYQN0k6CC1pt9w4YWqR9Itt6jHYBgzIPqTQBwPf/yjil+88IK6MPcXFixQqZm7dvXeOaVUAnHOOao1Smtr8DRfYx718QiExaJ6dPWEQNTWqkD03LkquaA4ROrvvHnq8XiGZHWH7mQxGftrC0LTbzjzTLjjDtUr6eyzg989btigzHajM2eiM2aMqrjub9/PokXq8eWXe++cO3Yol9uCBSpIf801KmX4SMc24dTXq4vX8QrqWWep2oTjaecOyr3Y0KC69YazIidNUunPvS0Q2sWkGRAIodpRPPus+sedNavdYjCIZgaE5vgpK1OV4v/9b++d88031aPRE+pnP1Nxgs5Fh92tou7M2Wer7LEPPuj+Z3z4oeqi+73vwZQp4fc1mZSb6ZNPun++7mC3q3PHmvWnXUyafslll6m7LI9H/UO98ILa7nTC1q3RdXDVHD+XXKJ6PUXbXPB4WbpUWQ5lZer16NFw3XXqzryqqn2/nhKIk05SQ4e662ZyOlVLlbKy6PtrzZun/oZrayPv21MYrb5jjW9pC0LTb5kxQ1W6Tvn/7Z19kFTVlcB/R0aQBIQglCF8CK5EYaX4qOHTgZhsgkhFMDJuiKnSxC2z2VrQuLHisCgg1lBGE1JuxdqAISqGCJKIUJVaRvAjUTfEQRyBCRo+dlxARNbBhDWrDMzZP87r9KN53dPd0/26pc+vqqvfu+/dfqdvv77n3XPuPWekdVSLF9sfq63NRxBxMXu2vT/1VPGv9eGH9iSfmsDprrvsQSEcIr1QCqJbN+uw810w98ADts7hoYeS6wY6IuGHKNTsKbDQKK2t6Y/nGuo7gY8gnLKmf3+LnHrjjclVyuAjiLgYNsyUcRxmphdfNKf09Omnlw8ZYtN/H344uYiyUAoCzMzU3Hymn6Mj9u0zc2htraV6zZbqaktxWyg/xKZN9jtNnJj+aT/XUN8JKtVJLSLTReRNEdkrInURx6eKyHYROSkitSnHbhKRPcEry+wxTt6cd545rX/wA4tT1L27/SGceJg922zmb79d3Os0NJjT+XOfO/NYItfF0qX23tpaWAUBuY0iVC2Y4rnnWvDHXOje3ZREZ/0QquabmTHDcm3v2QPz50efm2s2uQQ9elTeCEJEugAPAVcDI4CviUhqUJ//Br4B/CKlbh9gETABGA8sEpEC3alOWkTMCfjsszbfPJuQ4E5hqK21zmj9+uJeZ9MmC48e1ZENHmxTgVeutIeEY8fyD9SXypgxFvMqFwWxdq0FM6yvT5t5LyM1NWY+/fDD3OuCPdXPmWMK4frrLWTLbbfZupEof0pnTEwffBD/wr4sKOYIYjywV1X3q+oJYA0wK3yCqrao6g6gPaXuVcBmVW1V1WPAZiBlTOwUjSuvtA7LiY/hwy0oYjHNTAcPmpkn1f8QZv58ezBYuNBCvRdqBNGli91X2Tqq33/fcnRUV9soIh9qaszBvW1b7nX377eIxOvW2QhizRrryJcuNQf/zTefmfc8XxNTjx6mHPJVZEWkmApiABCelnEwKCtYXRH5lohsE5FtR48ezVtQxykLamttOmfUupQojhwx38ETT2R3fiK0eKr/IczAgZYf/PHHbb9QCgLMzNTSYp1vR8yfb9F7ly/PfyQ7ebK95+qH2LLFpn4fOGBJne68Mzkz6ROfsPAeBw9aMqow+ZqYyjjk98faSa2qK1S1WlWr+/XrV2pxHKdzzJ5t6wWyXTRXX29Rbu+8M7unz4YGM9Vcfnnm8+rqknP5C6kgEmlIOzIzbd1qiuHWW2Hs2Pyv17evRSPOVkGomg/uqqts4kZjY/Roa+JEa6NHHrEV3QnyNTGVcdKgYiqIQ0A4McDAoKzYdR3n48nIkTYxIBszU0uLrVtIPOkuX575/FOnLBT2tGkdz9Pv3z9p1imkghg+3D47k5np5ZctPtSAAbBkSeevWVNjU13bU63YEaxcafnUr73WlNQll6Q/d+FCCxh4yy3JtRadmcWUqF9mFFNBNALDRGSoiHQF5gAbs6zbAEwTkU8FzulpQZnjnL2ImJnpuec6XuC1aJGZXtavN9NNfX3mDqax0ZzOmfwPYRYsMBNKYj1BIRCxUcRzz53pkD150r7T1Kk2a+nppy2YYGepqbHvvXt35vNOnLC4VBMnmoLuqKPv1s0mcrS2JpVpZ01MlTSCUNWTwFysY98NPKmqzSKyRERmAojIOBE5CFwPLBeR5qBuK3AvpmQagSVBmeOc3dTW2tP+hg3pz9m1y3wE8+bZk3Z9vdnrM00FbWiwDjqR6rQj+vSBZcsK00mH+cIXzMfS3Jws27fPOvIlS2wtTlOTLeAsBNkG7nv0UVv/sXhx9iuhR42y8598ElavtsCXZ5mJqeSJfgr18oRBzllBe7vq0KGqM2akP2fmTNVevVTfey9ZNmvWmWVhJk1SHT++sLLmQ0tLMmFTe7vqI49Y0qLevVXXri389drbVT/96cyJrz76yBJKTZhg5+dCW5vV69nTvteyZbnL2NhYusRR6gmDHOfjg4g5qzdvjo5++rvfwcaNFtk0vEbh3nstden9959Z59gxi/WUrXmpmFx0kcV+2rDBYoF985s2Wtixw3wPhUbE4oxlGkE89piNHhYtyj2OUlWV1W9rs/18F8pBWY4gXEE4TrlRW2sdTniGDJjdvq4OLrzQFmyFGTkSbrjB8l4cPnz6sS1bzElbDgoCzMz0/PPmP7nvPnNaDxrUcb18qakxp/6hiHkuJ06YiW78+MzTfzNx6aXJSLi9e+dev0Kd1I7j5MP48dZhps5mamiwdRJ33x39pLp4sSmW+voz6/XqZYl7yoFbbjFltXWrTdEt9or9hB8iKuzGqlU2VTif0UOYefNsVHTNNbnXrUQnteM4eZIwMzU0wPHjVtbebovHhg61DjaKSy6xgHsrViTTbYazx1VVxSN/R4wbZyE/CuWI7ojRo60TTjUzJZRpdbWlpO0M55xjmRq7d8+9bsLElM8IQtXiQ73ySu51s8AVhOOUI7W1Nivm17+2/XXrbHbPkiWZM7zdfbd1VvfcY/u7d9uq33IxL5WCqiqbvpqqIFatMtNTLjOXikHXriZjU5ONct56K+nTSOX4cTPJ1ddbNsJ+/Sz0R77hSDpAtAwDROVDdXW1bssn5orjlCPt7Rb2YvJkC6UxYoQ9nb72WscmmTvugB/9CHbutCf1737XOp3Bg+ORvRxZtMjChr//vk3dbWsz38EFF9jTdykVBNgiwjfeSO6L2KLCgQPN3Nizp2V/3LUruYZk+HBTfJMm2aujFfJpEJFXVbU66liZjDkdxzmNc86B666zNJs//jHs3WtO62zs9XV1ZmZauNCeOIcPr2zlAOaHaG83v8eXvgQ//7mZ4R58sPTKAWD7dotRdeCAjfjC783NpthGjbJ7YtIk81MVcpV7GnwE4TjlygsvwOc/b0phwgQzkWTbmd1zj5lOqqpg7lwbUVQyx4/bDKO77rLXZZfZ/rZt5aEgSkimEYT7IBynXJkyxWzMp07ZNMpcOrLbbzfzycmTle1/SNCzpzmrX3rJVj3v39/5mUsVgJuYHKdc6dLFzEX795uyyIXzzzeb+9KlFt/IMTPTT39q/pgxY/KbklphuInJcZzKYN265Grt9estaqvjJibHcRyuuMLeR4+GWbMyn+sAbmJyHKdS+MxnzOyWTU4MB3AF4ThOJbFgQakl+FjhJibHcRwnElcQjuM4TiSuIBzHcZxIXEE4juM4kbiCcBzHcSJxBeE4juNE4grCcRzHicQVhOM4jhPJWROLSUSOAm914iP6Av9TIHEKicuVGy5XbrhcuXE2ynWRqvaLOnDWKIjOIiLb0gWsKiUuV264XLnhcuVGpcnlJibHcRwnElcQjuM4TiSuIJKsKLUAaXC5csPlyg2XKzcqSi73QTiO4ziR+AjCcRzHicQVhOM4jhNJxSsIEZkuIm+KyF4RqSuhHINE5HkR+YOINIvIbUH5YhE5JCJNwWtGCWRrEZGdwfW3BWV9RGSziOwJ3j8Vs0yXhtqkSUT+LCLfKVV7icjPRORdEdkVKotsIzH+LbjndojI2BhlekBE3giuu15EegflQ0Tk/0Lt9pNiyNSBbGl/OxGZH7TXmyJyVcxyrQ3J1CIiTUF5LG2WoW8o/v2lqhX7AroA+4CLga7A68CIEsnSHxgbbPcE/giMABYDd5S4nVqAvill9wN1wXYd8P0S/47vABeVqr2AqcBYYFdHbQTMAP4DEGAi8PsYZZoGVAXb3w/JNCR8XonaK/K3C/4HrwPdgKHBf7ZLXHKlHP8hsDDONsvQNxT9/qr0EcR4YK+q7lfVE8AaoCTZzFX1sKpuD7aPA7uBAaWQJUtmAY8F248B15ZQlr8D9qlqZ1bSdwpV/S3QmlKcro1mAavU2Ar0FpH+ccikqs+o6slgdyswsNDXzYY07ZWOWcAaVf1IVf8L2Iv9d2OVS0QE+HvgiWJcO4NM6fqGot9fla4gBgAHQvsHKYNOWUSGAGOA3wdFc4Oh4s/iNuUEKPCMiLwqIt8Kyi5U1cPB9jvAhSWQK8EcTv/Tlrq9EqRro3K5727GnjQTDBWR10TkNyIypQTyQPRvVy7tNQU4oqp7QmWxtllK31D0+6vSFUTZISI9gF8B31HVPwP/DvwNMBo4jA1x46ZGVccCVwP/LCJTwwfVxrUlmS8tIl2BmcC6oKgc2usMStlGUYjIAuAksDooOgwMVtUxwL8AvxCR82MWqyx/uxBf4/QHkVjbLKJv+CvFur8qXUEcAgaF9gcGZSVBRM7FboDVqvoUgKoeUdVTqtoOPEyRhtaZUNVDwfu7wPpAhiOJYWvw/m7ccgVcDWxX1SOBjCVvrxDp2qik952IfAP4MvD1oGMhMN+8F2y/itn5PxuXTMF10/12Jf+fikgVcB2wNlEWZ5tF9Q3EcH9VuoJoBIaJyNDgSXQOsLEUggT2zZXAblVdFioP2w6/AuxKrVtkuT4pIj0T25iTcxfWTjcFp90EbIhTrhCnPdWVur1SSNdGG4Ebg9kmE4E/hUwFRUVEpgPfA2aq6l9C5f1EpEuwfTEwDNgfh0whGdL9dhuBOSLSTUSGBrK9EqdswBeBN1T1YKIgrjZL1zcQx/1VbA98ub8wj/8fMe2/oIRy1GBDxB1AU/CaATwO7AzKNwL9Y5brYmwGyetAc6KNgAuAZ4E9wBagTwna7JPAe0CvUFlJ2gtTUoeBNszm+w/p2gibXfJQcM/tBKpjlGkvZp9O3GM/Cc6dHfy+TcB24JoStFfa3w5YELTXm8DVccoVlD8KfDvl3FjaLEPfUPT7y0NtOI7jOJFUuonJcRzHSYMrCMdxHCcSVxCO4zhOJK4gHMdxnEhcQTiO4ziRuIJwnAhE5H+D9yEickOBP/tfU/b/s5Cf7ziFwhWE42RmCJCTgghW3WbiNAWhqpNzlMlxYsEVhONk5j5gShDv/3YR6SKWU6ExCCr3jwAicqWIvCgiG4E/BGVPBwEOmxNBDkXkPqB78Hmrg7LEaEWCz94lln/jq6HPfkFEfimWy2F1sLrWcYpKR086jlPp1GE5Cr4MEHT0f1LVcSLSDXhZRJ4Jzh0LXK4WkhrgZlVtFZHuQKOI/EpV60RkrqqOjrjWdVigulFA36DOb4NjY4C/Bd4GXgauAF4q/Nd1nCQ+gnCc3JiGxblpwkIuX4DF4AF4JaQcAG4VkdexvAuDQuelowZ4Qi1g3RHgN8C40GcfVAtk14SZvhynqPgIwnFyQ4B5qtpwWqHIlcAHKftfBCap6l9E5AXgvE5c96PQ9in8v+vEgI8gHCczx7E0jwkagH8Kwi8jIp8Notym0gs4FiiHy7DUjwnaEvVTeBH4auDn6Ielv4w7aqnj/BV/CnGczOwATgWmokeBBzHzzvbAUXyU6HSrm4Bvi8huLALp1tCxFcAOEdmuql8Pla8HJmGRcxX4nqq+EygYx4kdj+bqOI7jROImJsdxHCcSVxCO4zhOJK4gHMdxnEhcQTiO4ziRuIJwHMdxInEF4TiO40TiCsJxHMeJ5P8B/BLZQsSSB2wAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# write results to a file\n",
    "xa = np.arange(41)\n",
    "plt.plot(xa*5, ensemble_mses, color='red')\n",
    "plt.plot(xa*5, mses)\n",
    "plt.ylabel('MSE')\n",
    "plt.xlabel('Iteration')\n",
    "plt.title('Determinant')\n",
    "\n",
    "file = open(\"/home/narock/data/fluxropes_results/determinant.txt\", \"w\")\n",
    "for i in range( len(mses) ):\n",
    "    line = str(mses[i]) + ',' + str(ensemble_mses[i]) + '\\n'\n",
    "    file.write(line)\n",
    "file.close()\n",
    "\n",
    "file = open(\"/home/narock/data/fluxropes_results/determinant_times.txt\", \"w\")\n",
    "for i in range( len(training_times) ):\n",
    "    line =  str(training_times[i]) + '\\n'\n",
    "    file.write(line)\n",
    "file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.07577573478067802\n",
      "0.08568093414581171\n"
     ]
    }
   ],
   "source": [
    "print( np.min(ensemble_mses) )\n",
    "print( ensemble_mses[-1] )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.collections.PathCollection at 0x7fe6d83762b0>"
      ]
     },
     "execution_count": 151,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.scatter(dataY[:,0],dataY[:,1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 699,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 0\n",
      "Train on 492 samples, validate on 84 samples\n",
      "Epoch 1/150\n",
      "492/492 [==============================] - 0s 506us/step - loss: 2.7201 - regression_loss: 1.9543 - handedness_loss: 0.7041 - val_loss: 1.1768 - val_regression_loss: 0.4562 - val_handedness_loss: 0.7207\n",
      "Epoch 2/150\n",
      "492/492 [==============================] - 0s 81us/step - loss: 1.0907 - regression_loss: 0.4014 - handedness_loss: 0.6864 - val_loss: 1.0302 - val_regression_loss: 0.3302 - val_handedness_loss: 0.7000\n",
      "Epoch 3/150\n",
      "492/492 [==============================] - 0s 79us/step - loss: 0.9989 - regression_loss: 0.3240 - handedness_loss: 0.6741 - val_loss: 0.9609 - val_regression_loss: 0.2751 - val_handedness_loss: 0.6858\n",
      "Epoch 4/150\n",
      "492/492 [==============================] - 0s 88us/step - loss: 0.9690 - regression_loss: 0.2891 - handedness_loss: 0.6804 - val_loss: 0.9491 - val_regression_loss: 0.2642 - val_handedness_loss: 0.6849\n",
      "Epoch 5/150\n",
      "492/492 [==============================] - 0s 88us/step - loss: 0.9555 - regression_loss: 0.2789 - handedness_loss: 0.6761 - val_loss: 0.9366 - val_regression_loss: 0.2583 - val_handedness_loss: 0.6783\n",
      "Epoch 6/150\n",
      "492/492 [==============================] - 0s 86us/step - loss: 0.9424 - regression_loss: 0.2740 - handedness_loss: 0.6682 - val_loss: 0.9459 - val_regression_loss: 0.2596 - val_handedness_loss: 0.6863\n",
      "Epoch 7/150\n",
      "492/492 [==============================] - 0s 85us/step - loss: 0.9291 - regression_loss: 0.2657 - handedness_loss: 0.6635 - val_loss: 0.9382 - val_regression_loss: 0.2508 - val_handedness_loss: 0.6874\n",
      "Epoch 8/150\n",
      "492/492 [==============================] - 0s 85us/step - loss: 0.9220 - regression_loss: 0.2570 - handedness_loss: 0.6655 - val_loss: 0.9249 - val_regression_loss: 0.2350 - val_handedness_loss: 0.6900\n",
      "Epoch 9/150\n",
      "492/492 [==============================] - 0s 80us/step - loss: 0.9072 - regression_loss: 0.2490 - handedness_loss: 0.6579 - val_loss: 0.9244 - val_regression_loss: 0.2350 - val_handedness_loss: 0.6894\n",
      "Evaluating model with testing data...\n",
      "84/84 [==============================] - 0s 35us/step\n",
      "Getting distribution of predictions and covariance matrix...\n",
      "      1 of 20\n",
      "      2 of 20\n",
      "      3 of 20\n",
      "      4 of 20\n",
      "      5 of 20\n",
      "      6 of 20\n",
      "      7 of 20\n",
      "      8 of 20\n",
      "      9 of 20\n",
      "      10 of 20\n",
      "      11 of 20\n",
      "      12 of 20\n",
      "      13 of 20\n",
      "      14 of 20\n",
      "      15 of 20\n",
      "      16 of 20\n",
      "      17 of 20\n",
      "      18 of 20\n",
      "      19 of 20\n",
      "      20 of 20\n",
      "Computing ensemble means...\n",
      "Computing mean squared error...\n",
      "Iteration 1\n",
      "Train on 632 samples, validate on 114 samples\n",
      "Epoch 1/150\n",
      "632/632 [==============================] - 0s 376us/step - loss: 3.0643 - regression_loss: 2.2707 - handedness_loss: 0.7690 - val_loss: 1.0808 - val_regression_loss: 0.4043 - val_handedness_loss: 0.6765\n",
      "Epoch 2/150\n",
      "632/632 [==============================] - 0s 69us/step - loss: 0.9934 - regression_loss: 0.3103 - handedness_loss: 0.6826 - val_loss: 1.0019 - val_regression_loss: 0.3233 - val_handedness_loss: 0.6786\n",
      "Epoch 3/150\n",
      "632/632 [==============================] - 0s 73us/step - loss: 0.9686 - regression_loss: 0.2862 - handedness_loss: 0.6821 - val_loss: 1.0059 - val_regression_loss: 0.3235 - val_handedness_loss: 0.6824\n",
      "Epoch 4/150\n",
      "632/632 [==============================] - 0s 77us/step - loss: 0.9598 - regression_loss: 0.2821 - handedness_loss: 0.6775 - val_loss: 0.9799 - val_regression_loss: 0.3138 - val_handedness_loss: 0.6661\n",
      "Epoch 5/150\n",
      "632/632 [==============================] - 0s 79us/step - loss: 0.9504 - regression_loss: 0.2774 - handedness_loss: 0.6731 - val_loss: 0.9825 - val_regression_loss: 0.3127 - val_handedness_loss: 0.6697\n",
      "Epoch 6/150\n",
      "632/632 [==============================] - 0s 81us/step - loss: 0.9357 - regression_loss: 0.2714 - handedness_loss: 0.6640 - val_loss: 0.9532 - val_regression_loss: 0.3022 - val_handedness_loss: 0.6510\n",
      "Epoch 7/150\n",
      "632/632 [==============================] - 0s 80us/step - loss: 0.9260 - regression_loss: 0.2668 - handedness_loss: 0.6589 - val_loss: 0.9599 - val_regression_loss: 0.3006 - val_handedness_loss: 0.6593\n",
      "Epoch 8/150\n",
      "632/632 [==============================] - 0s 78us/step - loss: 0.9094 - regression_loss: 0.2582 - handedness_loss: 0.6508 - val_loss: 0.9348 - val_regression_loss: 0.2901 - val_handedness_loss: 0.6448\n",
      "Epoch 9/150\n",
      "632/632 [==============================] - 0s 79us/step - loss: 0.9124 - regression_loss: 0.2547 - handedness_loss: 0.6576 - val_loss: 0.9191 - val_regression_loss: 0.2781 - val_handedness_loss: 0.6410\n",
      "Epoch 10/150\n",
      "632/632 [==============================] - 0s 84us/step - loss: 0.9017 - regression_loss: 0.2485 - handedness_loss: 0.6536 - val_loss: 0.9076 - val_regression_loss: 0.2726 - val_handedness_loss: 0.6350\n",
      "Epoch 11/150\n",
      "632/632 [==============================] - 0s 84us/step - loss: 0.8955 - regression_loss: 0.2438 - handedness_loss: 0.6517 - val_loss: 0.8942 - val_regression_loss: 0.2627 - val_handedness_loss: 0.6315\n",
      "Epoch 12/150\n",
      "632/632 [==============================] - 0s 90us/step - loss: 0.8682 - regression_loss: 0.2337 - handedness_loss: 0.6346 - val_loss: 0.8494 - val_regression_loss: 0.2448 - val_handedness_loss: 0.6046\n",
      "Epoch 13/150\n",
      "632/632 [==============================] - 0s 102us/step - loss: 0.8705 - regression_loss: 0.2279 - handedness_loss: 0.6423 - val_loss: 0.8584 - val_regression_loss: 0.2466 - val_handedness_loss: 0.6119\n",
      "Epoch 14/150\n",
      "632/632 [==============================] - 0s 102us/step - loss: 0.8572 - regression_loss: 0.2197 - handedness_loss: 0.6371 - val_loss: 0.8535 - val_regression_loss: 0.2417 - val_handedness_loss: 0.6119\n",
      "Epoch 15/150\n",
      "632/632 [==============================] - 0s 103us/step - loss: 0.8516 - regression_loss: 0.2193 - handedness_loss: 0.6319 - val_loss: 0.8757 - val_regression_loss: 0.2474 - val_handedness_loss: 0.6283\n",
      "Epoch 16/150\n",
      "632/632 [==============================] - 0s 102us/step - loss: 0.8532 - regression_loss: 0.2153 - handedness_loss: 0.6378 - val_loss: 0.8391 - val_regression_loss: 0.2360 - val_handedness_loss: 0.6031\n",
      "Epoch 17/150\n",
      "632/632 [==============================] - 0s 103us/step - loss: 0.8288 - regression_loss: 0.2063 - handedness_loss: 0.6222 - val_loss: 0.8591 - val_regression_loss: 0.2416 - val_handedness_loss: 0.6175\n",
      "Epoch 18/150\n",
      "632/632 [==============================] - 0s 104us/step - loss: 0.8367 - regression_loss: 0.2039 - handedness_loss: 0.6327 - val_loss: 0.8342 - val_regression_loss: 0.2324 - val_handedness_loss: 0.6018\n",
      "Epoch 19/150\n",
      "632/632 [==============================] - 0s 104us/step - loss: 0.8344 - regression_loss: 0.2048 - handedness_loss: 0.6297 - val_loss: 0.8325 - val_regression_loss: 0.2234 - val_handedness_loss: 0.6091\n",
      "Epoch 20/150\n",
      "632/632 [==============================] - 0s 102us/step - loss: 0.8231 - regression_loss: 0.1981 - handedness_loss: 0.6249 - val_loss: 0.8217 - val_regression_loss: 0.2186 - val_handedness_loss: 0.6031\n",
      "Epoch 21/150\n",
      "632/632 [==============================] - 0s 100us/step - loss: 0.8116 - regression_loss: 0.1913 - handedness_loss: 0.6200 - val_loss: 0.8164 - val_regression_loss: 0.2126 - val_handedness_loss: 0.6037\n",
      "Epoch 22/150\n",
      "632/632 [==============================] - 0s 99us/step - loss: 0.7993 - regression_loss: 0.1869 - handedness_loss: 0.6125 - val_loss: 0.7788 - val_regression_loss: 0.1920 - val_handedness_loss: 0.5869\n",
      "Epoch 23/150\n",
      "632/632 [==============================] - 0s 103us/step - loss: 0.7952 - regression_loss: 0.1828 - handedness_loss: 0.6126 - val_loss: 0.7406 - val_regression_loss: 0.1835 - val_handedness_loss: 0.5571\n",
      "Epoch 24/150\n",
      "632/632 [==============================] - 0s 103us/step - loss: 0.7844 - regression_loss: 0.1800 - handedness_loss: 0.6045 - val_loss: 0.7654 - val_regression_loss: 0.1925 - val_handedness_loss: 0.5729\n",
      "Epoch 25/150\n",
      "632/632 [==============================] - 0s 103us/step - loss: 0.7685 - regression_loss: 0.1759 - handedness_loss: 0.5926 - val_loss: 0.7894 - val_regression_loss: 0.1941 - val_handedness_loss: 0.5954\n",
      "Epoch 26/150\n",
      "632/632 [==============================] - 0s 102us/step - loss: 0.7738 - regression_loss: 0.1713 - handedness_loss: 0.6024 - val_loss: 0.8122 - val_regression_loss: 0.2011 - val_handedness_loss: 0.6111\n",
      "Epoch 27/150\n",
      "632/632 [==============================] - 0s 103us/step - loss: 0.7663 - regression_loss: 0.1695 - handedness_loss: 0.5970 - val_loss: 0.7433 - val_regression_loss: 0.1786 - val_handedness_loss: 0.5647\n",
      "Evaluating model with testing data...\n",
      "114/114 [==============================] - 0s 39us/step\n",
      "Getting distribution of predictions and covariance matrix...\n",
      "      1 of 20\n",
      "      2 of 20\n",
      "      3 of 20\n",
      "      4 of 20\n",
      "      5 of 20\n",
      "      6 of 20\n",
      "      7 of 20\n",
      "      8 of 20\n",
      "      9 of 20\n",
      "      10 of 20\n",
      "      11 of 20\n",
      "      12 of 20\n",
      "      13 of 20\n",
      "      14 of 20\n",
      "      15 of 20\n",
      "      16 of 20\n",
      "      17 of 20\n",
      "      18 of 20\n",
      "      19 of 20\n",
      "      20 of 20\n",
      "Computing ensemble means...\n",
      "Computing mean squared error...\n",
      "Iteration 2\n",
      "Train on 772 samples, validate on 144 samples\n",
      "Epoch 1/150\n",
      "772/772 [==============================] - 0s 327us/step - loss: 3.1137 - regression_loss: 2.1368 - handedness_loss: 0.7061 - val_loss: 1.1200 - val_regression_loss: 0.4274 - val_handedness_loss: 0.6729\n",
      "Epoch 2/150\n",
      "772/772 [==============================] - 0s 72us/step - loss: 1.0240 - regression_loss: 0.3318 - handedness_loss: 0.6915 - val_loss: 0.9989 - val_regression_loss: 0.3034 - val_handedness_loss: 0.6904\n",
      "Epoch 3/150\n",
      "772/772 [==============================] - 0s 85us/step - loss: 0.9715 - regression_loss: 0.2751 - handedness_loss: 0.6838 - val_loss: 0.9850 - val_regression_loss: 0.2997 - val_handedness_loss: 0.6761\n",
      "Epoch 4/150\n",
      "772/772 [==============================] - 0s 142us/step - loss: 0.9661 - regression_loss: 0.3039 - handedness_loss: 0.6868 - val_loss: 0.9820 - val_regression_loss: 0.2953 - val_handedness_loss: 0.6782\n",
      "Epoch 5/150\n",
      "772/772 [==============================] - 0s 154us/step - loss: 0.9501 - regression_loss: 0.2786 - handedness_loss: 0.6623 - val_loss: 0.9652 - val_regression_loss: 0.2844 - val_handedness_loss: 0.6621\n",
      "Epoch 6/150\n",
      "772/772 [==============================] - 0s 155us/step - loss: 0.9378 - regression_loss: 0.2762 - handedness_loss: 0.6744 - val_loss: 0.9554 - val_regression_loss: 0.2834 - val_handedness_loss: 0.6532\n",
      "Epoch 7/150\n",
      "772/772 [==============================] - 0s 157us/step - loss: 0.9221 - regression_loss: 0.2693 - handedness_loss: 0.6642 - val_loss: 0.9433 - val_regression_loss: 0.2707 - val_handedness_loss: 0.6364\n",
      "Epoch 8/150\n",
      "772/772 [==============================] - 0s 153us/step - loss: 0.9154 - regression_loss: 0.2540 - handedness_loss: 0.6435 - val_loss: 0.9020 - val_regression_loss: 0.2596 - val_handedness_loss: 0.6158\n",
      "Epoch 9/150\n",
      "772/772 [==============================] - 0s 156us/step - loss: 0.9012 - regression_loss: 0.2434 - handedness_loss: 0.6532 - val_loss: 0.8897 - val_regression_loss: 0.2429 - val_handedness_loss: 0.6411\n",
      "Epoch 10/150\n",
      "772/772 [==============================] - 0s 154us/step - loss: 0.8951 - regression_loss: 0.2410 - handedness_loss: 0.6601 - val_loss: 0.8844 - val_regression_loss: 0.2456 - val_handedness_loss: 0.6213\n",
      "Epoch 11/150\n",
      "772/772 [==============================] - 0s 156us/step - loss: 0.8721 - regression_loss: 0.2289 - handedness_loss: 0.6570 - val_loss: 0.8992 - val_regression_loss: 0.2411 - val_handedness_loss: 0.6421\n",
      "Epoch 12/150\n",
      "772/772 [==============================] - 0s 135us/step - loss: 0.8812 - regression_loss: 0.2280 - handedness_loss: 0.6366 - val_loss: 0.8778 - val_regression_loss: 0.2233 - val_handedness_loss: 0.6197\n",
      "Evaluating model with testing data...\n",
      "144/144 [==============================] - 0s 47us/step\n",
      "Getting distribution of predictions and covariance matrix...\n",
      "      1 of 20\n",
      "      2 of 20\n",
      "      3 of 20\n",
      "      4 of 20\n",
      "      5 of 20\n",
      "      6 of 20\n",
      "      7 of 20\n",
      "      8 of 20\n",
      "      9 of 20\n",
      "      10 of 20\n",
      "      11 of 20\n",
      "      12 of 20\n",
      "      13 of 20\n",
      "      14 of 20\n",
      "      15 of 20\n",
      "      16 of 20\n",
      "      17 of 20\n",
      "      18 of 20\n",
      "      19 of 20\n",
      "      20 of 20\n",
      "Computing ensemble means...\n",
      "Computing mean squared error...\n",
      "Iteration 3\n",
      "Train on 912 samples, validate on 174 samples\n",
      "Epoch 1/150\n",
      "912/912 [==============================] - 0s 292us/step - loss: 2.0148 - regression_loss: 1.2059 - handedness_loss: 0.6933 - val_loss: 0.9628 - val_regression_loss: 0.3084 - val_handedness_loss: 0.6481\n",
      "Epoch 2/150\n",
      "912/912 [==============================] - 0s 74us/step - loss: 0.9620 - regression_loss: 0.2927 - handedness_loss: 0.6683 - val_loss: 0.9275 - val_regression_loss: 0.2821 - val_handedness_loss: 0.6486\n",
      "Epoch 3/150\n",
      "912/912 [==============================] - 0s 115us/step - loss: 0.9354 - regression_loss: 0.2849 - handedness_loss: 0.6603 - val_loss: 0.8975 - val_regression_loss: 0.2690 - val_handedness_loss: 0.6337\n",
      "Epoch 4/150\n",
      "912/912 [==============================] - 0s 133us/step - loss: 0.9198 - regression_loss: 0.2713 - handedness_loss: 0.6520 - val_loss: 0.8864 - val_regression_loss: 0.2649 - val_handedness_loss: 0.6342\n",
      "Epoch 5/150\n",
      "912/912 [==============================] - 0s 131us/step - loss: 0.9009 - regression_loss: 0.2702 - handedness_loss: 0.6467 - val_loss: 0.8566 - val_regression_loss: 0.2418 - val_handedness_loss: 0.6136\n",
      "Epoch 6/150\n",
      "912/912 [==============================] - 0s 134us/step - loss: 0.8777 - regression_loss: 0.2384 - handedness_loss: 0.6369 - val_loss: 0.8324 - val_regression_loss: 0.2255 - val_handedness_loss: 0.6113\n",
      "Epoch 7/150\n",
      "912/912 [==============================] - 0s 133us/step - loss: 0.8460 - regression_loss: 0.2199 - handedness_loss: 0.6249 - val_loss: 0.7999 - val_regression_loss: 0.2136 - val_handedness_loss: 0.5921\n",
      "Epoch 8/150\n",
      "912/912 [==============================] - 0s 135us/step - loss: 0.8200 - regression_loss: 0.2126 - handedness_loss: 0.5988 - val_loss: 0.7804 - val_regression_loss: 0.2125 - val_handedness_loss: 0.5839\n",
      "Epoch 9/150\n",
      "912/912 [==============================] - 0s 123us/step - loss: 0.7874 - regression_loss: 0.1928 - handedness_loss: 0.5908 - val_loss: 0.7227 - val_regression_loss: 0.2005 - val_handedness_loss: 0.5426\n",
      "Epoch 10/150\n",
      "912/912 [==============================] - 0s 125us/step - loss: 0.7761 - regression_loss: 0.1831 - handedness_loss: 0.5759 - val_loss: 0.7147 - val_regression_loss: 0.1800 - val_handedness_loss: 0.5476\n",
      "Epoch 11/150\n",
      "912/912 [==============================] - 0s 124us/step - loss: 0.7705 - regression_loss: 0.1854 - handedness_loss: 0.5973 - val_loss: 0.7134 - val_regression_loss: 0.1785 - val_handedness_loss: 0.5457\n",
      "Epoch 12/150\n",
      "912/912 [==============================] - 0s 124us/step - loss: 0.7516 - regression_loss: 0.1782 - handedness_loss: 0.5766 - val_loss: 0.6771 - val_regression_loss: 0.1733 - val_handedness_loss: 0.5176\n",
      "Epoch 13/150\n",
      "912/912 [==============================] - 0s 124us/step - loss: 0.7290 - regression_loss: 0.1714 - handedness_loss: 0.5541 - val_loss: 0.6762 - val_regression_loss: 0.1686 - val_handedness_loss: 0.5310\n",
      "Epoch 14/150\n",
      "912/912 [==============================] - 0s 126us/step - loss: 0.7274 - regression_loss: 0.1681 - handedness_loss: 0.5593 - val_loss: 0.7017 - val_regression_loss: 0.1782 - val_handedness_loss: 0.5310\n",
      "Epoch 15/150\n",
      "912/912 [==============================] - 0s 125us/step - loss: 0.7161 - regression_loss: 0.1676 - handedness_loss: 0.5505 - val_loss: 0.6829 - val_regression_loss: 0.1558 - val_handedness_loss: 0.5329\n",
      "Epoch 16/150\n",
      "912/912 [==============================] - 0s 147us/step - loss: 0.7117 - regression_loss: 0.1684 - handedness_loss: 0.5456 - val_loss: 0.6831 - val_regression_loss: 0.1781 - val_handedness_loss: 0.5181\n",
      "Evaluating model with testing data...\n",
      "174/174 [==============================] - 0s 43us/step\n",
      "Getting distribution of predictions and covariance matrix...\n",
      "      1 of 20\n",
      "      2 of 20\n",
      "      3 of 20\n",
      "      4 of 20\n",
      "      5 of 20\n",
      "      6 of 20\n",
      "      7 of 20\n",
      "      8 of 20\n",
      "      9 of 20\n",
      "      10 of 20\n",
      "      11 of 20\n",
      "      12 of 20\n",
      "      13 of 20\n",
      "      14 of 20\n",
      "      15 of 20\n",
      "      16 of 20\n",
      "      17 of 20\n",
      "      18 of 20\n",
      "      19 of 20\n",
      "      20 of 20\n",
      "Computing ensemble means...\n",
      "Computing mean squared error...\n",
      "Iteration 4\n",
      "Train on 1052 samples, validate on 204 samples\n",
      "Epoch 1/150\n",
      "1052/1052 [==============================] - 0s 269us/step - loss: 2.2591 - regression_loss: 1.4514 - handedness_loss: 0.7018 - val_loss: 0.9876 - val_regression_loss: 0.3209 - val_handedness_loss: 0.6668\n",
      "Epoch 2/150\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1052/1052 [==============================] - 0s 79us/step - loss: 0.9615 - regression_loss: 0.2819 - handedness_loss: 0.6743 - val_loss: 0.9521 - val_regression_loss: 0.2948 - val_handedness_loss: 0.6586\n",
      "Epoch 3/150\n",
      "1052/1052 [==============================] - 0s 105us/step - loss: 0.9303 - regression_loss: 0.2807 - handedness_loss: 0.6419 - val_loss: 0.9382 - val_regression_loss: 0.2946 - val_handedness_loss: 0.6450\n",
      "Epoch 4/150\n",
      "1052/1052 [==============================] - 0s 119us/step - loss: 0.8915 - regression_loss: 0.2678 - handedness_loss: 0.6153 - val_loss: 0.8996 - val_regression_loss: 0.2825 - val_handedness_loss: 0.6194\n",
      "Epoch 5/150\n",
      "1052/1052 [==============================] - 0s 120us/step - loss: 0.8656 - regression_loss: 0.2549 - handedness_loss: 0.6107 - val_loss: 0.8644 - val_regression_loss: 0.2571 - val_handedness_loss: 0.6130\n",
      "Epoch 6/150\n",
      "1052/1052 [==============================] - 0s 120us/step - loss: 0.8394 - regression_loss: 0.2343 - handedness_loss: 0.6035 - val_loss: 0.8188 - val_regression_loss: 0.2388 - val_handedness_loss: 0.5798\n",
      "Epoch 7/150\n",
      "1052/1052 [==============================] - 0s 123us/step - loss: 0.8233 - regression_loss: 0.2234 - handedness_loss: 0.6067 - val_loss: 0.8209 - val_regression_loss: 0.2260 - val_handedness_loss: 0.6016\n",
      "Epoch 8/150\n",
      "1052/1052 [==============================] - 0s 141us/step - loss: 0.7717 - regression_loss: 0.2009 - handedness_loss: 0.5625 - val_loss: 0.7710 - val_regression_loss: 0.1973 - val_handedness_loss: 0.5824\n",
      "Epoch 9/150\n",
      "1052/1052 [==============================] - 0s 143us/step - loss: 0.7541 - regression_loss: 0.1920 - handedness_loss: 0.5622 - val_loss: 0.7333 - val_regression_loss: 0.1852 - val_handedness_loss: 0.5479\n",
      "Epoch 10/150\n",
      "1052/1052 [==============================] - 0s 143us/step - loss: 0.7157 - regression_loss: 0.1859 - handedness_loss: 0.5360 - val_loss: 0.7304 - val_regression_loss: 0.1827 - val_handedness_loss: 0.5463\n",
      "Epoch 11/150\n",
      "1052/1052 [==============================] - 0s 141us/step - loss: 0.7061 - regression_loss: 0.1783 - handedness_loss: 0.5301 - val_loss: 0.6718 - val_regression_loss: 0.1657 - val_handedness_loss: 0.5066\n",
      "Epoch 12/150\n",
      "1052/1052 [==============================] - 0s 144us/step - loss: 0.6848 - regression_loss: 0.1653 - handedness_loss: 0.5195 - val_loss: 0.6812 - val_regression_loss: 0.1626 - val_handedness_loss: 0.5144\n",
      "Epoch 13/150\n",
      "1052/1052 [==============================] - 0s 143us/step - loss: 0.6441 - regression_loss: 0.1513 - handedness_loss: 0.4929 - val_loss: 0.6691 - val_regression_loss: 0.1562 - val_handedness_loss: 0.5158\n",
      "Epoch 14/150\n",
      "1052/1052 [==============================] - 0s 142us/step - loss: 0.6473 - regression_loss: 0.1547 - handedness_loss: 0.4923 - val_loss: 0.6180 - val_regression_loss: 0.1447 - val_handedness_loss: 0.4727\n",
      "Epoch 15/150\n",
      "1052/1052 [==============================] - 0s 143us/step - loss: 0.6219 - regression_loss: 0.1468 - handedness_loss: 0.4728 - val_loss: 0.5957 - val_regression_loss: 0.1447 - val_handedness_loss: 0.4527\n",
      "Epoch 16/150\n",
      "1052/1052 [==============================] - 0s 162us/step - loss: 0.6231 - regression_loss: 0.1454 - handedness_loss: 0.4735 - val_loss: 0.6028 - val_regression_loss: 0.1466 - val_handedness_loss: 0.4654\n",
      "Epoch 17/150\n",
      "1052/1052 [==============================] - 0s 162us/step - loss: 0.5988 - regression_loss: 0.1435 - handedness_loss: 0.4590 - val_loss: 0.5712 - val_regression_loss: 0.1357 - val_handedness_loss: 0.4359\n",
      "Epoch 18/150\n",
      "1052/1052 [==============================] - 0s 162us/step - loss: 0.5939 - regression_loss: 0.1389 - handedness_loss: 0.4570 - val_loss: 0.5873 - val_regression_loss: 0.1423 - val_handedness_loss: 0.4499\n",
      "Epoch 19/150\n",
      "1052/1052 [==============================] - 0s 165us/step - loss: 0.5565 - regression_loss: 0.1357 - handedness_loss: 0.4168 - val_loss: 0.5542 - val_regression_loss: 0.1452 - val_handedness_loss: 0.4119\n",
      "Epoch 20/150\n",
      "1052/1052 [==============================] - 0s 163us/step - loss: 0.5458 - regression_loss: 0.1366 - handedness_loss: 0.4118 - val_loss: 0.5147 - val_regression_loss: 0.1166 - val_handedness_loss: 0.3962\n",
      "Epoch 21/150\n",
      "1052/1052 [==============================] - 0s 163us/step - loss: 0.5482 - regression_loss: 0.1238 - handedness_loss: 0.4208 - val_loss: 0.5377 - val_regression_loss: 0.1326 - val_handedness_loss: 0.4010\n",
      "Epoch 22/150\n",
      "1052/1052 [==============================] - 0s 154us/step - loss: 0.5235 - regression_loss: 0.1253 - handedness_loss: 0.3965 - val_loss: 0.5348 - val_regression_loss: 0.1264 - val_handedness_loss: 0.4067\n",
      "Epoch 23/150\n",
      "1052/1052 [==============================] - 0s 129us/step - loss: 0.5081 - regression_loss: 0.1182 - handedness_loss: 0.3945 - val_loss: 0.5134 - val_regression_loss: 0.1190 - val_handedness_loss: 0.4014\n",
      "Epoch 24/150\n",
      "1052/1052 [==============================] - 0s 130us/step - loss: 0.4938 - regression_loss: 0.1190 - handedness_loss: 0.3823 - val_loss: 0.4794 - val_regression_loss: 0.1229 - val_handedness_loss: 0.3590\n",
      "Evaluating model with testing data...\n",
      "204/204 [==============================] - 0s 35us/step\n",
      "Getting distribution of predictions and covariance matrix...\n",
      "      1 of 20\n",
      "      2 of 20\n",
      "      3 of 20\n",
      "      4 of 20\n",
      "      5 of 20\n",
      "      6 of 20\n",
      "      7 of 20\n",
      "      8 of 20\n",
      "      9 of 20\n",
      "      10 of 20\n",
      "      11 of 20\n",
      "      12 of 20\n",
      "      13 of 20\n",
      "      14 of 20\n",
      "      15 of 20\n",
      "      16 of 20\n",
      "      17 of 20\n",
      "      18 of 20\n",
      "      19 of 20\n",
      "      20 of 20\n",
      "Computing ensemble means...\n",
      "Computing mean squared error...\n",
      "Iteration 5\n",
      "Train on 1192 samples, validate on 234 samples\n",
      "Epoch 1/150\n",
      "1192/1192 [==============================] - 0s 242us/step - loss: 1.7689 - regression_loss: 1.0046 - handedness_loss: 0.7112 - val_loss: 0.9945 - val_regression_loss: 0.3028 - val_handedness_loss: 0.6917\n",
      "Epoch 2/150\n",
      "1192/1192 [==============================] - 0s 90us/step - loss: 0.9731 - regression_loss: 0.2761 - handedness_loss: 0.6943 - val_loss: 0.9827 - val_regression_loss: 0.2864 - val_handedness_loss: 0.6948\n",
      "Epoch 3/150\n",
      "1192/1192 [==============================] - 0s 121us/step - loss: 0.9466 - regression_loss: 0.2602 - handedness_loss: 0.6853 - val_loss: 0.9863 - val_regression_loss: 0.2735 - val_handedness_loss: 0.7115\n",
      "Epoch 4/150\n",
      "1192/1192 [==============================] - 0s 116us/step - loss: 0.9408 - regression_loss: 0.2526 - handedness_loss: 0.6883 - val_loss: 0.9547 - val_regression_loss: 0.2612 - val_handedness_loss: 0.6919\n",
      "Epoch 5/150\n",
      "1192/1192 [==============================] - 0s 104us/step - loss: 0.9192 - regression_loss: 0.2407 - handedness_loss: 0.6786 - val_loss: 0.9464 - val_regression_loss: 0.2497 - val_handedness_loss: 0.6944\n",
      "Evaluating model with testing data...\n",
      "234/234 [==============================] - 0s 26us/step\n",
      "Getting distribution of predictions and covariance matrix...\n",
      "      1 of 20\n",
      "      2 of 20\n",
      "      3 of 20\n",
      "      4 of 20\n",
      "      5 of 20\n",
      "      6 of 20\n",
      "      7 of 20\n",
      "      8 of 20\n",
      "      9 of 20\n",
      "      10 of 20\n",
      "      11 of 20\n",
      "      12 of 20\n",
      "      13 of 20\n",
      "      14 of 20\n",
      "      15 of 20\n",
      "      16 of 20\n",
      "      17 of 20\n",
      "      18 of 20\n",
      "      19 of 20\n",
      "      20 of 20\n",
      "Computing ensemble means...\n",
      "Computing mean squared error...\n",
      "Iteration 6\n",
      "Train on 1332 samples, validate on 264 samples\n",
      "Epoch 1/150\n",
      "1332/1332 [==============================] - 0s 219us/step - loss: 1.0745 - regression_loss: 0.3870 - handedness_loss: 0.6750 - val_loss: 0.8957 - val_regression_loss: 0.2328 - val_handedness_loss: 0.6900\n",
      "Epoch 2/150\n",
      "1332/1332 [==============================] - 0s 76us/step - loss: 0.8518 - regression_loss: 0.1955 - handedness_loss: 0.6554 - val_loss: 0.8202 - val_regression_loss: 0.1557 - val_handedness_loss: 0.6682\n",
      "Epoch 3/150\n",
      "1332/1332 [==============================] - 0s 156us/step - loss: 0.7899 - regression_loss: 0.1612 - handedness_loss: 0.6284 - val_loss: 0.7544 - val_regression_loss: 0.1439 - val_handedness_loss: 0.6330\n",
      "Epoch 4/150\n",
      "1332/1332 [==============================] - 0s 134us/step - loss: 0.7444 - regression_loss: 0.1531 - handedness_loss: 0.5900 - val_loss: 0.6966 - val_regression_loss: 0.1335 - val_handedness_loss: 0.5801\n",
      "Epoch 5/150\n",
      "1332/1332 [==============================] - 0s 114us/step - loss: 0.6977 - regression_loss: 0.1437 - handedness_loss: 0.5502 - val_loss: 0.6543 - val_regression_loss: 0.1429 - val_handedness_loss: 0.4981\n",
      "Epoch 6/150\n",
      "1332/1332 [==============================] - 0s 139us/step - loss: 0.6704 - regression_loss: 0.1412 - handedness_loss: 0.5253 - val_loss: 0.6217 - val_regression_loss: 0.1228 - val_handedness_loss: 0.4817\n",
      "Epoch 7/150\n",
      "1332/1332 [==============================] - 0s 140us/step - loss: 0.6366 - regression_loss: 0.1324 - handedness_loss: 0.5003 - val_loss: 0.5662 - val_regression_loss: 0.1332 - val_handedness_loss: 0.4780\n",
      "Epoch 8/150\n",
      "1332/1332 [==============================] - 0s 140us/step - loss: 0.5909 - regression_loss: 0.1301 - handedness_loss: 0.4513 - val_loss: 0.5210 - val_regression_loss: 0.1133 - val_handedness_loss: 0.3851\n",
      "Epoch 9/150\n",
      "1332/1332 [==============================] - 0s 140us/step - loss: 0.5420 - regression_loss: 0.1227 - handedness_loss: 0.4204 - val_loss: 0.4656 - val_regression_loss: 0.1167 - val_handedness_loss: 0.3176\n",
      "Epoch 10/150\n",
      "1332/1332 [==============================] - 0s 139us/step - loss: 0.5175 - regression_loss: 0.1262 - handedness_loss: 0.3938 - val_loss: 0.4387 - val_regression_loss: 0.1085 - val_handedness_loss: 0.3060\n",
      "Epoch 11/150\n",
      "1332/1332 [==============================] - 0s 140us/step - loss: 0.4857 - regression_loss: 0.1211 - handedness_loss: 0.3646 - val_loss: 0.4190 - val_regression_loss: 0.1220 - val_handedness_loss: 0.3099\n",
      "Epoch 12/150\n",
      "1332/1332 [==============================] - 0s 140us/step - loss: 0.4460 - regression_loss: 0.1174 - handedness_loss: 0.3273 - val_loss: 0.3934 - val_regression_loss: 0.1075 - val_handedness_loss: 0.2530\n",
      "Epoch 13/150\n",
      "1332/1332 [==============================] - 0s 162us/step - loss: 0.4148 - regression_loss: 0.1127 - handedness_loss: 0.3038 - val_loss: 0.3384 - val_regression_loss: 0.1168 - val_handedness_loss: 0.2070\n",
      "Epoch 14/150\n",
      "1332/1332 [==============================] - 0s 160us/step - loss: 0.3813 - regression_loss: 0.1112 - handedness_loss: 0.2720 - val_loss: 0.3519 - val_regression_loss: 0.1057 - val_handedness_loss: 0.2275\n",
      "Epoch 15/150\n",
      "1332/1332 [==============================] - 0s 161us/step - loss: 0.3686 - regression_loss: 0.1044 - handedness_loss: 0.2624 - val_loss: 0.3190 - val_regression_loss: 0.1153 - val_handedness_loss: 0.2258\n",
      "Epoch 16/150\n",
      "1332/1332 [==============================] - 0s 161us/step - loss: 0.3481 - regression_loss: 0.1054 - handedness_loss: 0.2413 - val_loss: 0.3122 - val_regression_loss: 0.0924 - val_handedness_loss: 0.1870\n",
      "Epoch 17/150\n",
      "1332/1332 [==============================] - 0s 161us/step - loss: 0.3470 - regression_loss: 0.0967 - handedness_loss: 0.2542 - val_loss: 0.3005 - val_regression_loss: 0.1080 - val_handedness_loss: 0.2061\n",
      "Epoch 18/150\n",
      "1332/1332 [==============================] - 0s 164us/step - loss: 0.3472 - regression_loss: 0.1013 - handedness_loss: 0.2457 - val_loss: 0.2573 - val_regression_loss: 0.0830 - val_handedness_loss: 0.1658\n",
      "Epoch 19/150\n",
      "1332/1332 [==============================] - 0s 161us/step - loss: 0.3248 - regression_loss: 0.0934 - handedness_loss: 0.2271 - val_loss: 0.2771 - val_regression_loss: 0.0993 - val_handedness_loss: 0.2058\n",
      "Epoch 20/150\n",
      "1332/1332 [==============================] - 0s 121us/step - loss: 0.2984 - regression_loss: 0.0912 - handedness_loss: 0.2056 - val_loss: 0.2438 - val_regression_loss: 0.0786 - val_handedness_loss: 0.1643\n",
      "Epoch 21/150\n",
      "1332/1332 [==============================] - 0s 131us/step - loss: 0.2923 - regression_loss: 0.0897 - handedness_loss: 0.2014 - val_loss: 0.2380 - val_regression_loss: 0.0945 - val_handedness_loss: 0.1228\n",
      "Epoch 22/150\n",
      "1332/1332 [==============================] - 0s 140us/step - loss: 0.2803 - regression_loss: 0.0872 - handedness_loss: 0.1901 - val_loss: 0.2332 - val_regression_loss: 0.0846 - val_handedness_loss: 0.1346\n",
      "Epoch 23/150\n",
      "1332/1332 [==============================] - 0s 142us/step - loss: 0.2796 - regression_loss: 0.0922 - handedness_loss: 0.1858 - val_loss: 0.2364 - val_regression_loss: 0.0850 - val_handedness_loss: 0.1467\n",
      "Epoch 24/150\n",
      "1332/1332 [==============================] - 0s 141us/step - loss: 0.2711 - regression_loss: 0.0865 - handedness_loss: 0.1791 - val_loss: 0.2294 - val_regression_loss: 0.0944 - val_handedness_loss: 0.1451\n",
      "Evaluating model with testing data...\n",
      "264/264 [==============================] - 0s 35us/step\n",
      "Getting distribution of predictions and covariance matrix...\n",
      "      1 of 20\n",
      "      2 of 20\n",
      "      3 of 20\n",
      "      4 of 20\n",
      "      5 of 20\n",
      "      6 of 20\n",
      "      7 of 20\n",
      "      8 of 20\n",
      "      9 of 20\n",
      "      10 of 20\n",
      "      11 of 20\n",
      "      12 of 20\n",
      "      13 of 20\n",
      "      14 of 20\n",
      "      15 of 20\n",
      "      16 of 20\n",
      "      17 of 20\n",
      "      18 of 20\n",
      "      19 of 20\n",
      "      20 of 20\n",
      "Computing ensemble means...\n",
      "Computing mean squared error...\n",
      "Iteration 7\n",
      "Train on 1472 samples, validate on 294 samples\n",
      "Epoch 1/150\n",
      "1472/1472 [==============================] - 0s 210us/step - loss: 1.4585 - regression_loss: 0.7383 - handedness_loss: 0.7030 - val_loss: 1.0022 - val_regression_loss: 0.3297 - val_handedness_loss: 0.6933\n",
      "Epoch 2/150\n",
      "1472/1472 [==============================] - 0s 91us/step - loss: 0.9694 - regression_loss: 0.2727 - handedness_loss: 0.6966 - val_loss: 0.9343 - val_regression_loss: 0.2724 - val_handedness_loss: 0.6827\n",
      "Epoch 3/150\n",
      "1472/1472 [==============================] - 0s 153us/step - loss: 0.9183 - regression_loss: 0.2254 - handedness_loss: 0.6941 - val_loss: 0.8995 - val_regression_loss: 0.2274 - val_handedness_loss: 0.6846\n",
      "Epoch 4/150\n",
      "1472/1472 [==============================] - 0s 117us/step - loss: 0.8890 - regression_loss: 0.2003 - handedness_loss: 0.6859 - val_loss: 0.8775 - val_regression_loss: 0.2015 - val_handedness_loss: 0.6800\n",
      "Epoch 5/150\n",
      "1472/1472 [==============================] - 0s 136us/step - loss: 0.8683 - regression_loss: 0.1859 - handedness_loss: 0.6819 - val_loss: 0.8559 - val_regression_loss: 0.1727 - val_handedness_loss: 0.6879\n",
      "Epoch 6/150\n",
      "1472/1472 [==============================] - 0s 138us/step - loss: 0.8609 - regression_loss: 0.1785 - handedness_loss: 0.6810 - val_loss: 0.8675 - val_regression_loss: 0.1898 - val_handedness_loss: 0.6806\n",
      "Epoch 7/150\n",
      "1472/1472 [==============================] - 0s 137us/step - loss: 0.8511 - regression_loss: 0.1680 - handedness_loss: 0.6811 - val_loss: 0.8412 - val_regression_loss: 0.1839 - val_handedness_loss: 0.6708\n",
      "Epoch 8/150\n",
      "1472/1472 [==============================] - 0s 139us/step - loss: 0.8364 - regression_loss: 0.1600 - handedness_loss: 0.6771 - val_loss: 0.8469 - val_regression_loss: 0.1823 - val_handedness_loss: 0.6760\n",
      "Epoch 9/150\n",
      "1472/1472 [==============================] - 0s 153us/step - loss: 0.8294 - regression_loss: 0.1578 - handedness_loss: 0.6704 - val_loss: 0.8269 - val_regression_loss: 0.1794 - val_handedness_loss: 0.6617\n",
      "Evaluating model with testing data...\n",
      "294/294 [==============================] - 0s 37us/step\n",
      "Getting distribution of predictions and covariance matrix...\n",
      "      1 of 20\n",
      "      2 of 20\n",
      "      3 of 20\n",
      "      4 of 20\n",
      "      5 of 20\n",
      "      6 of 20\n",
      "      7 of 20\n",
      "      8 of 20\n",
      "      9 of 20\n",
      "      10 of 20\n",
      "      11 of 20\n",
      "      12 of 20\n",
      "      13 of 20\n",
      "      14 of 20\n",
      "      15 of 20\n",
      "      16 of 20\n",
      "      17 of 20\n",
      "      18 of 20\n",
      "      19 of 20\n",
      "      20 of 20\n",
      "Computing ensemble means...\n",
      "Computing mean squared error...\n",
      "Iteration 8\n",
      "Train on 1612 samples, validate on 324 samples\n",
      "Epoch 1/150\n",
      "1612/1612 [==============================] - 0s 199us/step - loss: 1.3893 - regression_loss: 0.6833 - handedness_loss: 0.6922 - val_loss: 0.9926 - val_regression_loss: 0.3258 - val_handedness_loss: 0.6683\n",
      "Epoch 2/150\n",
      "1612/1612 [==============================] - 0s 88us/step - loss: 0.9482 - regression_loss: 0.2661 - handedness_loss: 0.6813 - val_loss: 0.9309 - val_regression_loss: 0.2765 - val_handedness_loss: 0.6512\n",
      "Epoch 3/150\n",
      "1612/1612 [==============================] - 0s 103us/step - loss: 0.8917 - regression_loss: 0.2356 - handedness_loss: 0.6559 - val_loss: 0.9026 - val_regression_loss: 0.2617 - val_handedness_loss: 0.6408\n",
      "Epoch 4/150\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1612/1612 [==============================] - 0s 108us/step - loss: 0.8456 - regression_loss: 0.2055 - handedness_loss: 0.6400 - val_loss: 0.8463 - val_regression_loss: 0.2213 - val_handedness_loss: 0.6218\n",
      "Epoch 5/150\n",
      "1612/1612 [==============================] - 0s 118us/step - loss: 0.8053 - regression_loss: 0.1919 - handedness_loss: 0.6135 - val_loss: 0.8260 - val_regression_loss: 0.2054 - val_handedness_loss: 0.6208\n",
      "Epoch 6/150\n",
      "1612/1612 [==============================] - 0s 137us/step - loss: 0.7828 - regression_loss: 0.1834 - handedness_loss: 0.6006 - val_loss: 0.8059 - val_regression_loss: 0.2112 - val_handedness_loss: 0.5925\n",
      "Epoch 7/150\n",
      "1612/1612 [==============================] - 0s 152us/step - loss: 0.7547 - regression_loss: 0.1749 - handedness_loss: 0.5809 - val_loss: 0.7539 - val_regression_loss: 0.1811 - val_handedness_loss: 0.5765\n",
      "Epoch 8/150\n",
      "1612/1612 [==============================] - 0s 151us/step - loss: 0.7263 - regression_loss: 0.1713 - handedness_loss: 0.5543 - val_loss: 0.7309 - val_regression_loss: 0.1766 - val_handedness_loss: 0.5556\n",
      "Epoch 9/150\n",
      "1612/1612 [==============================] - 0s 152us/step - loss: 0.6989 - regression_loss: 0.1605 - handedness_loss: 0.5389 - val_loss: 0.7139 - val_regression_loss: 0.1772 - val_handedness_loss: 0.5349\n",
      "Epoch 10/150\n",
      "1612/1612 [==============================] - 0s 152us/step - loss: 0.6740 - regression_loss: 0.1605 - handedness_loss: 0.5133 - val_loss: 0.6665 - val_regression_loss: 0.1599 - val_handedness_loss: 0.5036\n",
      "Epoch 11/150\n",
      "1612/1612 [==============================] - 0s 151us/step - loss: 0.6472 - regression_loss: 0.1517 - handedness_loss: 0.4948 - val_loss: 0.6396 - val_regression_loss: 0.1655 - val_handedness_loss: 0.4716\n",
      "Epoch 12/150\n",
      "1612/1612 [==============================] - 0s 153us/step - loss: 0.6200 - regression_loss: 0.1455 - handedness_loss: 0.4755 - val_loss: 0.6188 - val_regression_loss: 0.1511 - val_handedness_loss: 0.4641\n",
      "Epoch 13/150\n",
      "1612/1612 [==============================] - 0s 142us/step - loss: 0.5896 - regression_loss: 0.1349 - handedness_loss: 0.4550 - val_loss: 0.5826 - val_regression_loss: 0.1353 - val_handedness_loss: 0.4382\n",
      "Epoch 14/150\n",
      "1612/1612 [==============================] - 0s 93us/step - loss: 0.5521 - regression_loss: 0.1310 - handedness_loss: 0.4214 - val_loss: 0.5644 - val_regression_loss: 0.1396 - val_handedness_loss: 0.4233\n",
      "Epoch 15/150\n",
      "1612/1612 [==============================] - 0s 97us/step - loss: 0.5420 - regression_loss: 0.1278 - handedness_loss: 0.4150 - val_loss: 0.5478 - val_regression_loss: 0.1339 - val_handedness_loss: 0.4128\n",
      "Epoch 16/150\n",
      "1612/1612 [==============================] - 0s 104us/step - loss: 0.5213 - regression_loss: 0.1211 - handedness_loss: 0.4007 - val_loss: 0.5174 - val_regression_loss: 0.1296 - val_handedness_loss: 0.3815\n",
      "Epoch 17/150\n",
      "1612/1612 [==============================] - 0s 153us/step - loss: 0.4903 - regression_loss: 0.1165 - handedness_loss: 0.3737 - val_loss: 0.5016 - val_regression_loss: 0.1335 - val_handedness_loss: 0.3609\n",
      "Epoch 18/150\n",
      "1612/1612 [==============================] - 0s 153us/step - loss: 0.4913 - regression_loss: 0.1122 - handedness_loss: 0.3791 - val_loss: 0.5000 - val_regression_loss: 0.1302 - val_handedness_loss: 0.3648\n",
      "Epoch 19/150\n",
      "1612/1612 [==============================] - 0s 153us/step - loss: 0.4755 - regression_loss: 0.1140 - handedness_loss: 0.3625 - val_loss: 0.4911 - val_regression_loss: 0.1292 - val_handedness_loss: 0.3524\n",
      "Epoch 20/150\n",
      "1612/1612 [==============================] - 0s 151us/step - loss: 0.4515 - regression_loss: 0.1086 - handedness_loss: 0.3431 - val_loss: 0.4535 - val_regression_loss: 0.1203 - val_handedness_loss: 0.3260\n",
      "Epoch 21/150\n",
      "1612/1612 [==============================] - 0s 152us/step - loss: 0.4403 - regression_loss: 0.1096 - handedness_loss: 0.3309 - val_loss: 0.4390 - val_regression_loss: 0.1191 - val_handedness_loss: 0.3219\n",
      "Epoch 22/150\n",
      "1612/1612 [==============================] - 0s 152us/step - loss: 0.4410 - regression_loss: 0.1075 - handedness_loss: 0.3327 - val_loss: 0.4610 - val_regression_loss: 0.1229 - val_handedness_loss: 0.3341\n",
      "Epoch 23/150\n",
      "1612/1612 [==============================] - 0s 153us/step - loss: 0.4353 - regression_loss: 0.1058 - handedness_loss: 0.3268 - val_loss: 0.4222 - val_regression_loss: 0.1092 - val_handedness_loss: 0.3043\n",
      "Epoch 24/150\n",
      "1612/1612 [==============================] - 0s 153us/step - loss: 0.4338 - regression_loss: 0.1087 - handedness_loss: 0.3237 - val_loss: 0.4271 - val_regression_loss: 0.1280 - val_handedness_loss: 0.2945\n",
      "Epoch 25/150\n",
      "1612/1612 [==============================] - 0s 137us/step - loss: 0.4211 - regression_loss: 0.1099 - handedness_loss: 0.3098 - val_loss: 0.4277 - val_regression_loss: 0.1203 - val_handedness_loss: 0.3041\n",
      "Epoch 26/150\n",
      "1612/1612 [==============================] - 0s 124us/step - loss: 0.4134 - regression_loss: 0.1034 - handedness_loss: 0.3108 - val_loss: 0.4048 - val_regression_loss: 0.1060 - val_handedness_loss: 0.2955\n",
      "Epoch 27/150\n",
      "1612/1612 [==============================] - 0s 123us/step - loss: 0.3909 - regression_loss: 0.1028 - handedness_loss: 0.2899 - val_loss: 0.3998 - val_regression_loss: 0.1125 - val_handedness_loss: 0.2747\n",
      "Epoch 28/150\n",
      "1612/1612 [==============================] - 0s 132us/step - loss: 0.4025 - regression_loss: 0.1039 - handedness_loss: 0.2968 - val_loss: 0.4073 - val_regression_loss: 0.1138 - val_handedness_loss: 0.2856\n",
      "Epoch 29/150\n",
      "1612/1612 [==============================] - 0s 142us/step - loss: 0.3729 - regression_loss: 0.1019 - handedness_loss: 0.2716 - val_loss: 0.4076 - val_regression_loss: 0.1183 - val_handedness_loss: 0.2786\n",
      "Epoch 30/150\n",
      "1612/1612 [==============================] - 0s 121us/step - loss: 0.3872 - regression_loss: 0.1001 - handedness_loss: 0.2883 - val_loss: 0.3772 - val_regression_loss: 0.1091 - val_handedness_loss: 0.2563\n",
      "Evaluating model with testing data...\n",
      "324/324 [==============================] - 0s 28us/step\n",
      "Getting distribution of predictions and covariance matrix...\n",
      "      1 of 20\n",
      "      2 of 20\n",
      "      3 of 20\n",
      "      4 of 20\n",
      "      5 of 20\n",
      "      6 of 20\n",
      "      7 of 20\n",
      "      8 of 20\n",
      "      9 of 20\n",
      "      10 of 20\n",
      "      11 of 20\n",
      "      12 of 20\n",
      "      13 of 20\n",
      "      14 of 20\n",
      "      15 of 20\n",
      "      16 of 20\n",
      "      17 of 20\n",
      "      18 of 20\n",
      "      19 of 20\n",
      "      20 of 20\n",
      "Computing ensemble means...\n",
      "Computing mean squared error...\n",
      "Iteration 9\n",
      "Train on 1752 samples, validate on 354 samples\n",
      "Epoch 1/150\n",
      "1752/1752 [==============================] - 0s 198us/step - loss: 1.3446 - regression_loss: 0.6326 - handedness_loss: 0.7042 - val_loss: 1.0279 - val_regression_loss: 0.3333 - val_handedness_loss: 0.6903\n",
      "Epoch 2/150\n",
      "1752/1752 [==============================] - 0s 89us/step - loss: 0.9776 - regression_loss: 0.2896 - handedness_loss: 0.6878 - val_loss: 1.0105 - val_regression_loss: 0.3171 - val_handedness_loss: 0.6899\n",
      "Epoch 3/150\n",
      "1752/1752 [==============================] - 0s 95us/step - loss: 0.9583 - regression_loss: 0.2747 - handedness_loss: 0.6834 - val_loss: 0.9867 - val_regression_loss: 0.3017 - val_handedness_loss: 0.6811\n",
      "Epoch 4/150\n",
      "1752/1752 [==============================] - 0s 96us/step - loss: 0.9359 - regression_loss: 0.2594 - handedness_loss: 0.6768 - val_loss: 0.9653 - val_regression_loss: 0.2788 - val_handedness_loss: 0.6837\n",
      "Epoch 5/150\n",
      "1752/1752 [==============================] - 0s 127us/step - loss: 0.9149 - regression_loss: 0.2392 - handedness_loss: 0.6754 - val_loss: 0.9495 - val_regression_loss: 0.2650 - val_handedness_loss: 0.6809\n",
      "Epoch 6/150\n",
      "1752/1752 [==============================] - 0s 128us/step - loss: 0.8971 - regression_loss: 0.2264 - handedness_loss: 0.6715 - val_loss: 0.9263 - val_regression_loss: 0.2467 - val_handedness_loss: 0.6759\n",
      "Epoch 7/150\n",
      "1752/1752 [==============================] - 0s 131us/step - loss: 0.8765 - regression_loss: 0.2109 - handedness_loss: 0.6649 - val_loss: 0.9096 - val_regression_loss: 0.2321 - val_handedness_loss: 0.6751\n",
      "Epoch 8/150\n",
      "1752/1752 [==============================] - 0s 128us/step - loss: 0.8562 - regression_loss: 0.1958 - handedness_loss: 0.6606 - val_loss: 0.8903 - val_regression_loss: 0.2164 - val_handedness_loss: 0.6728\n",
      "Epoch 9/150\n",
      "1752/1752 [==============================] - 0s 128us/step - loss: 0.8412 - regression_loss: 0.1841 - handedness_loss: 0.6561 - val_loss: 0.8726 - val_regression_loss: 0.2026 - val_handedness_loss: 0.6672\n",
      "Epoch 10/150\n",
      "1752/1752 [==============================] - 0s 126us/step - loss: 0.8199 - regression_loss: 0.1739 - handedness_loss: 0.6469 - val_loss: 0.8606 - val_regression_loss: 0.1952 - val_handedness_loss: 0.6643\n",
      "Epoch 11/150\n",
      "1752/1752 [==============================] - 0s 127us/step - loss: 0.8072 - regression_loss: 0.1634 - handedness_loss: 0.6440 - val_loss: 0.8461 - val_regression_loss: 0.1878 - val_handedness_loss: 0.6562\n",
      "Epoch 12/150\n",
      "1752/1752 [==============================] - 0s 128us/step - loss: 0.7894 - regression_loss: 0.1573 - handedness_loss: 0.6315 - val_loss: 0.8190 - val_regression_loss: 0.1750 - val_handedness_loss: 0.6434\n",
      "Epoch 13/150\n",
      "1752/1752 [==============================] - 0s 128us/step - loss: 0.7837 - regression_loss: 0.1482 - handedness_loss: 0.6353 - val_loss: 0.7988 - val_regression_loss: 0.1607 - val_handedness_loss: 0.6347\n",
      "Epoch 14/150\n",
      "1752/1752 [==============================] - 0s 129us/step - loss: 0.7674 - regression_loss: 0.1427 - handedness_loss: 0.6244 - val_loss: 0.7894 - val_regression_loss: 0.1606 - val_handedness_loss: 0.6245\n",
      "Epoch 15/150\n",
      "1752/1752 [==============================] - 0s 128us/step - loss: 0.7596 - regression_loss: 0.1361 - handedness_loss: 0.6229 - val_loss: 0.7828 - val_regression_loss: 0.1506 - val_handedness_loss: 0.6281\n",
      "Epoch 16/150\n",
      "1752/1752 [==============================] - 0s 127us/step - loss: 0.7543 - regression_loss: 0.1362 - handedness_loss: 0.6189 - val_loss: 0.7993 - val_regression_loss: 0.1466 - val_handedness_loss: 0.6485\n",
      "Epoch 17/150\n",
      "1752/1752 [==============================] - 0s 127us/step - loss: 0.7451 - regression_loss: 0.1287 - handedness_loss: 0.6171 - val_loss: 0.7768 - val_regression_loss: 0.1524 - val_handedness_loss: 0.6208\n",
      "Epoch 18/150\n",
      "1752/1752 [==============================] - 0s 129us/step - loss: 0.7370 - regression_loss: 0.1255 - handedness_loss: 0.6108 - val_loss: 0.7596 - val_regression_loss: 0.1402 - val_handedness_loss: 0.6138\n",
      "Epoch 19/150\n",
      "1752/1752 [==============================] - 0s 131us/step - loss: 0.7415 - regression_loss: 0.1259 - handedness_loss: 0.6159 - val_loss: 0.7447 - val_regression_loss: 0.1310 - val_handedness_loss: 0.6107\n",
      "Epoch 20/150\n",
      "1752/1752 [==============================] - 0s 132us/step - loss: 0.7296 - regression_loss: 0.1220 - handedness_loss: 0.6072 - val_loss: 0.7365 - val_regression_loss: 0.1351 - val_handedness_loss: 0.5994\n",
      "Epoch 21/150\n",
      "1752/1752 [==============================] - 0s 100us/step - loss: 0.7199 - regression_loss: 0.1161 - handedness_loss: 0.6045 - val_loss: 0.7131 - val_regression_loss: 0.1293 - val_handedness_loss: 0.5823\n",
      "Epoch 22/150\n",
      "1752/1752 [==============================] - 0s 102us/step - loss: 0.7150 - regression_loss: 0.1159 - handedness_loss: 0.5985 - val_loss: 0.7486 - val_regression_loss: 0.1271 - val_handedness_loss: 0.6201\n",
      "Epoch 23/150\n",
      "1752/1752 [==============================] - 0s 111us/step - loss: 0.7215 - regression_loss: 0.1132 - handedness_loss: 0.6083 - val_loss: 0.7452 - val_regression_loss: 0.1255 - val_handedness_loss: 0.6171\n",
      "Epoch 24/150\n",
      "1752/1752 [==============================] - 0s 114us/step - loss: 0.7105 - regression_loss: 0.1113 - handedness_loss: 0.5987 - val_loss: 0.7373 - val_regression_loss: 0.1260 - val_handedness_loss: 0.6108\n",
      "Epoch 25/150\n",
      "1752/1752 [==============================] - 0s 150us/step - loss: 0.7113 - regression_loss: 0.1093 - handedness_loss: 0.6023 - val_loss: 0.6920 - val_regression_loss: 0.1203 - val_handedness_loss: 0.5680\n",
      "Epoch 26/150\n",
      "1752/1752 [==============================] - 0s 131us/step - loss: 0.7024 - regression_loss: 0.1077 - handedness_loss: 0.5950 - val_loss: 0.7152 - val_regression_loss: 0.1201 - val_handedness_loss: 0.5896\n",
      "Epoch 27/150\n",
      "1752/1752 [==============================] - 0s 119us/step - loss: 0.7026 - regression_loss: 0.1073 - handedness_loss: 0.5952 - val_loss: 0.7057 - val_regression_loss: 0.1190 - val_handedness_loss: 0.5825\n",
      "Epoch 28/150\n",
      "1752/1752 [==============================] - 0s 121us/step - loss: 0.6977 - regression_loss: 0.1052 - handedness_loss: 0.5916 - val_loss: 0.7273 - val_regression_loss: 0.1112 - val_handedness_loss: 0.6126\n",
      "Epoch 29/150\n",
      "1752/1752 [==============================] - 0s 140us/step - loss: 0.7089 - regression_loss: 0.1020 - handedness_loss: 0.6062 - val_loss: 0.7344 - val_regression_loss: 0.1179 - val_handedness_loss: 0.6139\n",
      "Evaluating model with testing data...\n",
      "354/354 [==============================] - 0s 34us/step\n",
      "Getting distribution of predictions and covariance matrix...\n",
      "      1 of 20\n",
      "      2 of 20\n",
      "      3 of 20\n",
      "      4 of 20\n",
      "      5 of 20\n",
      "      6 of 20\n",
      "      7 of 20\n",
      "      8 of 20\n",
      "      9 of 20\n",
      "      10 of 20\n",
      "      11 of 20\n",
      "      12 of 20\n",
      "      13 of 20\n",
      "      14 of 20\n",
      "      15 of 20\n",
      "      16 of 20\n",
      "      17 of 20\n",
      "      18 of 20\n",
      "      19 of 20\n",
      "      20 of 20\n",
      "Computing ensemble means...\n",
      "Computing mean squared error...\n",
      "Iteration 10\n",
      "Train on 1892 samples, validate on 384 samples\n",
      "Epoch 1/150\n",
      "1892/1892 [==============================] - 0s 189us/step - loss: 1.6089 - regression_loss: 0.9069 - handedness_loss: 0.6930 - val_loss: 1.0264 - val_regression_loss: 0.3437 - val_handedness_loss: 0.6827\n",
      "Epoch 2/150\n",
      "1892/1892 [==============================] - 0s 88us/step - loss: 0.9703 - regression_loss: 0.2935 - handedness_loss: 0.6760 - val_loss: 1.0051 - val_regression_loss: 0.3273 - val_handedness_loss: 0.6778\n",
      "Epoch 3/150\n",
      "1892/1892 [==============================] - 0s 109us/step - loss: 0.9423 - regression_loss: 0.2761 - handedness_loss: 0.6657 - val_loss: 0.9640 - val_regression_loss: 0.3012 - val_handedness_loss: 0.6628\n",
      "Epoch 4/150\n",
      "1892/1892 [==============================] - 0s 99us/step - loss: 0.9118 - regression_loss: 0.2602 - handedness_loss: 0.6508 - val_loss: 0.9414 - val_regression_loss: 0.2864 - val_handedness_loss: 0.6550\n",
      "Epoch 5/150\n",
      "1892/1892 [==============================] - 0s 100us/step - loss: 0.8766 - regression_loss: 0.2422 - handedness_loss: 0.6341 - val_loss: 0.9121 - val_regression_loss: 0.2646 - val_handedness_loss: 0.6475\n",
      "Epoch 6/150\n",
      "1892/1892 [==============================] - 0s 113us/step - loss: 0.8348 - regression_loss: 0.2217 - handedness_loss: 0.6125 - val_loss: 0.8698 - val_regression_loss: 0.2444 - val_handedness_loss: 0.6254\n",
      "Epoch 7/150\n",
      "1892/1892 [==============================] - 0s 92us/step - loss: 0.7780 - regression_loss: 0.1977 - handedness_loss: 0.5797 - val_loss: 0.8101 - val_regression_loss: 0.2056 - val_handedness_loss: 0.6045\n",
      "Epoch 8/150\n",
      "1892/1892 [==============================] - 0s 91us/step - loss: 0.7246 - regression_loss: 0.1742 - handedness_loss: 0.5505 - val_loss: 0.7575 - val_regression_loss: 0.1803 - val_handedness_loss: 0.5772\n",
      "Epoch 9/150\n",
      "1892/1892 [==============================] - 0s 103us/step - loss: 0.6761 - regression_loss: 0.1580 - handedness_loss: 0.5184 - val_loss: 0.7096 - val_regression_loss: 0.1710 - val_handedness_loss: 0.5385\n",
      "Epoch 10/150\n",
      "1892/1892 [==============================] - 0s 102us/step - loss: 0.6585 - regression_loss: 0.1520 - handedness_loss: 0.5061 - val_loss: 0.6668 - val_regression_loss: 0.1630 - val_handedness_loss: 0.5038\n",
      "Epoch 11/150\n",
      "1892/1892 [==============================] - 0s 105us/step - loss: 0.6231 - regression_loss: 0.1473 - handedness_loss: 0.4754 - val_loss: 0.6610 - val_regression_loss: 0.1615 - val_handedness_loss: 0.4995\n",
      "Epoch 12/150\n",
      "1892/1892 [==============================] - 0s 105us/step - loss: 0.5986 - regression_loss: 0.1442 - handedness_loss: 0.4541 - val_loss: 0.6267 - val_regression_loss: 0.1582 - val_handedness_loss: 0.4685\n",
      "Epoch 13/150\n",
      "1892/1892 [==============================] - 0s 104us/step - loss: 0.5802 - regression_loss: 0.1426 - handedness_loss: 0.4375 - val_loss: 0.6424 - val_regression_loss: 0.1638 - val_handedness_loss: 0.4786\n",
      "Epoch 14/150\n",
      "1892/1892 [==============================] - 0s 123us/step - loss: 0.5642 - regression_loss: 0.1414 - handedness_loss: 0.4225 - val_loss: 0.5953 - val_regression_loss: 0.1575 - val_handedness_loss: 0.4379\n",
      "Epoch 15/150\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1892/1892 [==============================] - 0s 109us/step - loss: 0.5461 - regression_loss: 0.1359 - handedness_loss: 0.4092 - val_loss: 0.5962 - val_regression_loss: 0.1488 - val_handedness_loss: 0.4473\n",
      "Epoch 16/150\n",
      "1892/1892 [==============================] - 0s 148us/step - loss: 0.5108 - regression_loss: 0.1280 - handedness_loss: 0.3831 - val_loss: 0.5194 - val_regression_loss: 0.1385 - val_handedness_loss: 0.3809\n",
      "Epoch 17/150\n",
      "1892/1892 [==============================] - 0s 150us/step - loss: 0.4976 - regression_loss: 0.1273 - handedness_loss: 0.3710 - val_loss: 0.5320 - val_regression_loss: 0.1511 - val_handedness_loss: 0.3809\n",
      "Epoch 18/150\n",
      "1892/1892 [==============================] - 0s 134us/step - loss: 0.4867 - regression_loss: 0.1270 - handedness_loss: 0.3596 - val_loss: 0.5172 - val_regression_loss: 0.1448 - val_handedness_loss: 0.3725\n",
      "Epoch 19/150\n",
      "1892/1892 [==============================] - 0s 121us/step - loss: 0.4837 - regression_loss: 0.1267 - handedness_loss: 0.3557 - val_loss: 0.5385 - val_regression_loss: 0.1441 - val_handedness_loss: 0.3945\n",
      "Epoch 20/150\n",
      "1892/1892 [==============================] - 0s 122us/step - loss: 0.4780 - regression_loss: 0.1230 - handedness_loss: 0.3554 - val_loss: 0.5154 - val_regression_loss: 0.1396 - val_handedness_loss: 0.3758\n",
      "Evaluating model with testing data...\n",
      "384/384 [==============================] - 0s 29us/step\n",
      "Getting distribution of predictions and covariance matrix...\n",
      "      1 of 20\n",
      "      2 of 20\n",
      "      3 of 20\n",
      "      4 of 20\n",
      "      5 of 20\n",
      "      6 of 20\n",
      "      7 of 20\n",
      "      8 of 20\n",
      "      9 of 20\n",
      "      10 of 20\n",
      "      11 of 20\n",
      "      12 of 20\n",
      "      13 of 20\n",
      "      14 of 20\n",
      "      15 of 20\n",
      "      16 of 20\n",
      "      17 of 20\n",
      "      18 of 20\n",
      "      19 of 20\n",
      "      20 of 20\n",
      "Computing ensemble means...\n",
      "Computing mean squared error...\n",
      "Iteration 11\n",
      "Train on 2032 samples, validate on 414 samples\n",
      "Epoch 1/150\n",
      "2032/2032 [==============================] - 0s 193us/step - loss: 2.1359 - regression_loss: 1.4285 - handedness_loss: 0.6981 - val_loss: 1.0136 - val_regression_loss: 0.3460 - val_handedness_loss: 0.6732\n",
      "Epoch 2/150\n",
      "2032/2032 [==============================] - 0s 90us/step - loss: 0.9588 - regression_loss: 0.3060 - handedness_loss: 0.6528 - val_loss: 0.9872 - val_regression_loss: 0.3384 - val_handedness_loss: 0.6557\n",
      "Epoch 3/150\n",
      "2032/2032 [==============================] - 0s 109us/step - loss: 0.9250 - regression_loss: 0.2957 - handedness_loss: 0.6294 - val_loss: 0.9609 - val_regression_loss: 0.3234 - val_handedness_loss: 0.6487\n",
      "Epoch 4/150\n",
      "2032/2032 [==============================] - 0s 122us/step - loss: 0.8805 - regression_loss: 0.2744 - handedness_loss: 0.6059 - val_loss: 0.8943 - val_regression_loss: 0.2846 - val_handedness_loss: 0.6308\n",
      "Epoch 5/150\n",
      "2032/2032 [==============================] - 0s 143us/step - loss: 0.8131 - regression_loss: 0.2382 - handedness_loss: 0.5747 - val_loss: 0.8368 - val_regression_loss: 0.2525 - val_handedness_loss: 0.6003\n",
      "Epoch 6/150\n",
      "2032/2032 [==============================] - 0s 74us/step - loss: 0.7725 - regression_loss: 0.2080 - handedness_loss: 0.5644 - val_loss: 0.7923 - val_regression_loss: 0.2248 - val_handedness_loss: 0.5742\n",
      "Epoch 7/150\n",
      "2032/2032 [==============================] - 0s 85us/step - loss: 0.7315 - regression_loss: 0.1824 - handedness_loss: 0.5493 - val_loss: 0.7527 - val_regression_loss: 0.1999 - val_handedness_loss: 0.5668\n",
      "Epoch 8/150\n",
      "2032/2032 [==============================] - 0s 115us/step - loss: 0.6938 - regression_loss: 0.1728 - handedness_loss: 0.5209 - val_loss: 0.7390 - val_regression_loss: 0.1873 - val_handedness_loss: 0.5595\n",
      "Epoch 9/150\n",
      "2032/2032 [==============================] - 0s 118us/step - loss: 0.6685 - regression_loss: 0.1548 - handedness_loss: 0.5135 - val_loss: 0.6737 - val_regression_loss: 0.1681 - val_handedness_loss: 0.5213\n",
      "Epoch 10/150\n",
      "2032/2032 [==============================] - 0s 116us/step - loss: 0.6420 - regression_loss: 0.1511 - handedness_loss: 0.4911 - val_loss: 0.6788 - val_regression_loss: 0.1715 - val_handedness_loss: 0.5180\n",
      "Epoch 11/150\n",
      "2032/2032 [==============================] - 0s 130us/step - loss: 0.6266 - regression_loss: 0.1449 - handedness_loss: 0.4818 - val_loss: 0.6570 - val_regression_loss: 0.1646 - val_handedness_loss: 0.5035\n",
      "Epoch 12/150\n",
      "2032/2032 [==============================] - 0s 137us/step - loss: 0.5880 - regression_loss: 0.1342 - handedness_loss: 0.4538 - val_loss: 0.6421 - val_regression_loss: 0.1564 - val_handedness_loss: 0.4905\n",
      "Epoch 13/150\n",
      "2032/2032 [==============================] - 0s 135us/step - loss: 0.5807 - regression_loss: 0.1321 - handedness_loss: 0.4481 - val_loss: 0.5961 - val_regression_loss: 0.1619 - val_handedness_loss: 0.4657\n",
      "Epoch 14/150\n",
      "2032/2032 [==============================] - 0s 120us/step - loss: 0.5658 - regression_loss: 0.1273 - handedness_loss: 0.4389 - val_loss: 0.5900 - val_regression_loss: 0.1345 - val_handedness_loss: 0.4715\n",
      "Epoch 15/150\n",
      "2032/2032 [==============================] - 0s 107us/step - loss: 0.5572 - regression_loss: 0.1279 - handedness_loss: 0.4295 - val_loss: 0.5873 - val_regression_loss: 0.1472 - val_handedness_loss: 0.4601\n",
      "Epoch 16/150\n",
      "2032/2032 [==============================] - 0s 127us/step - loss: 0.5432 - regression_loss: 0.1227 - handedness_loss: 0.4207 - val_loss: 0.5799 - val_regression_loss: 0.1416 - val_handedness_loss: 0.4621\n",
      "Epoch 17/150\n",
      "2032/2032 [==============================] - 0s 128us/step - loss: 0.5236 - regression_loss: 0.1175 - handedness_loss: 0.4063 - val_loss: 0.5950 - val_regression_loss: 0.1444 - val_handedness_loss: 0.4759\n",
      "Epoch 18/150\n",
      "2032/2032 [==============================] - 0s 117us/step - loss: 0.5146 - regression_loss: 0.1139 - handedness_loss: 0.4007 - val_loss: 0.5351 - val_regression_loss: 0.1289 - val_handedness_loss: 0.4246\n",
      "Epoch 19/150\n",
      "2032/2032 [==============================] - 0s 107us/step - loss: 0.5232 - regression_loss: 0.1207 - handedness_loss: 0.4022 - val_loss: 0.5629 - val_regression_loss: 0.1366 - val_handedness_loss: 0.4401\n",
      "Epoch 20/150\n",
      "2032/2032 [==============================] - 0s 107us/step - loss: 0.5067 - regression_loss: 0.1156 - handedness_loss: 0.3906 - val_loss: 0.5423 - val_regression_loss: 0.1334 - val_handedness_loss: 0.4389\n",
      "Epoch 21/150\n",
      "2032/2032 [==============================] - 0s 109us/step - loss: 0.5013 - regression_loss: 0.1143 - handedness_loss: 0.3871 - val_loss: 0.5292 - val_regression_loss: 0.1327 - val_handedness_loss: 0.4139\n",
      "Epoch 22/150\n",
      "2032/2032 [==============================] - 0s 101us/step - loss: 0.4996 - regression_loss: 0.1102 - handedness_loss: 0.3892 - val_loss: 0.5590 - val_regression_loss: 0.1315 - val_handedness_loss: 0.4455\n",
      "Evaluating model with testing data...\n",
      "414/414 [==============================] - 0s 23us/step\n",
      "Getting distribution of predictions and covariance matrix...\n",
      "      1 of 20\n",
      "      2 of 20\n",
      "      3 of 20\n",
      "      4 of 20\n",
      "      5 of 20\n",
      "      6 of 20\n",
      "      7 of 20\n",
      "      8 of 20\n",
      "      9 of 20\n",
      "      10 of 20\n",
      "      11 of 20\n",
      "      12 of 20\n",
      "      13 of 20\n",
      "      14 of 20\n",
      "      15 of 20\n",
      "      16 of 20\n",
      "      17 of 20\n",
      "      18 of 20\n",
      "      19 of 20\n",
      "      20 of 20\n",
      "Computing ensemble means...\n",
      "Computing mean squared error...\n",
      "Iteration 12\n",
      "Train on 2172 samples, validate on 444 samples\n",
      "Epoch 1/150\n",
      "2172/2172 [==============================] - 0s 172us/step - loss: 1.5944 - regression_loss: 0.9107 - handedness_loss: 0.6825 - val_loss: 0.9575 - val_regression_loss: 0.2858 - val_handedness_loss: 0.6684\n",
      "Epoch 2/150\n",
      "2172/2172 [==============================] - 0s 78us/step - loss: 0.9283 - regression_loss: 0.2716 - handedness_loss: 0.6567 - val_loss: 0.9172 - val_regression_loss: 0.2706 - val_handedness_loss: 0.6459\n",
      "Epoch 3/150\n",
      "2172/2172 [==============================] - 0s 103us/step - loss: 0.8858 - regression_loss: 0.2517 - handedness_loss: 0.6341 - val_loss: 0.8804 - val_regression_loss: 0.2546 - val_handedness_loss: 0.6251\n",
      "Epoch 4/150\n",
      "2172/2172 [==============================] - 0s 102us/step - loss: 0.8511 - regression_loss: 0.2362 - handedness_loss: 0.6150 - val_loss: 0.8378 - val_regression_loss: 0.2334 - val_handedness_loss: 0.6039\n",
      "Epoch 5/150\n",
      "2172/2172 [==============================] - 0s 102us/step - loss: 0.8089 - regression_loss: 0.2171 - handedness_loss: 0.5918 - val_loss: 0.7914 - val_regression_loss: 0.2168 - val_handedness_loss: 0.5711\n",
      "Epoch 6/150\n",
      "2172/2172 [==============================] - 0s 103us/step - loss: 0.7698 - regression_loss: 0.2024 - handedness_loss: 0.5673 - val_loss: 0.7760 - val_regression_loss: 0.2051 - val_handedness_loss: 0.5695\n",
      "Epoch 7/150\n",
      "2172/2172 [==============================] - 0s 102us/step - loss: 0.7340 - regression_loss: 0.1846 - handedness_loss: 0.5495 - val_loss: 0.7151 - val_regression_loss: 0.1880 - val_handedness_loss: 0.5219\n",
      "Epoch 8/150\n",
      "2172/2172 [==============================] - 0s 101us/step - loss: 0.7088 - regression_loss: 0.1772 - handedness_loss: 0.5316 - val_loss: 0.6986 - val_regression_loss: 0.1809 - val_handedness_loss: 0.5182\n",
      "Epoch 9/150\n",
      "2172/2172 [==============================] - 0s 100us/step - loss: 0.6734 - regression_loss: 0.1647 - handedness_loss: 0.5087 - val_loss: 0.6582 - val_regression_loss: 0.1660 - val_handedness_loss: 0.4884\n",
      "Epoch 10/150\n",
      "2172/2172 [==============================] - 0s 98us/step - loss: 0.6609 - regression_loss: 0.1637 - handedness_loss: 0.4972 - val_loss: 0.6267 - val_regression_loss: 0.1586 - val_handedness_loss: 0.4640\n",
      "Epoch 11/150\n",
      "2172/2172 [==============================] - 0s 110us/step - loss: 0.6336 - regression_loss: 0.1548 - handedness_loss: 0.4789 - val_loss: 0.6265 - val_regression_loss: 0.1644 - val_handedness_loss: 0.4556\n",
      "Epoch 12/150\n",
      "2172/2172 [==============================] - 0s 132us/step - loss: 0.6070 - regression_loss: 0.1492 - handedness_loss: 0.4578 - val_loss: 0.5839 - val_regression_loss: 0.1502 - val_handedness_loss: 0.4264\n",
      "Epoch 13/150\n",
      "2172/2172 [==============================] - 0s 134us/step - loss: 0.5902 - regression_loss: 0.1486 - handedness_loss: 0.4417 - val_loss: 0.5604 - val_regression_loss: 0.1465 - val_handedness_loss: 0.4050\n",
      "Epoch 14/150\n",
      "2172/2172 [==============================] - 0s 131us/step - loss: 0.5669 - regression_loss: 0.1411 - handedness_loss: 0.4258 - val_loss: 0.5453 - val_regression_loss: 0.1436 - val_handedness_loss: 0.3950\n",
      "Epoch 15/150\n",
      "2172/2172 [==============================] - 0s 130us/step - loss: 0.5478 - regression_loss: 0.1344 - handedness_loss: 0.4133 - val_loss: 0.5098 - val_regression_loss: 0.1334 - val_handedness_loss: 0.3829\n",
      "Epoch 16/150\n",
      "2172/2172 [==============================] - 0s 115us/step - loss: 0.5382 - regression_loss: 0.1348 - handedness_loss: 0.4035 - val_loss: 0.5109 - val_regression_loss: 0.1314 - val_handedness_loss: 0.3777\n",
      "Epoch 17/150\n",
      "2172/2172 [==============================] - 0s 118us/step - loss: 0.5273 - regression_loss: 0.1302 - handedness_loss: 0.3971 - val_loss: 0.4750 - val_regression_loss: 0.1150 - val_handedness_loss: 0.3571\n",
      "Epoch 18/150\n",
      "2172/2172 [==============================] - 0s 138us/step - loss: 0.4915 - regression_loss: 0.1241 - handedness_loss: 0.3674 - val_loss: 0.4959 - val_regression_loss: 0.1242 - val_handedness_loss: 0.3721\n",
      "Epoch 19/150\n",
      "2172/2172 [==============================] - 0s 114us/step - loss: 0.4895 - regression_loss: 0.1220 - handedness_loss: 0.3676 - val_loss: 0.4905 - val_regression_loss: 0.1237 - val_handedness_loss: 0.3623\n",
      "Epoch 20/150\n",
      "2172/2172 [==============================] - 0s 114us/step - loss: 0.4740 - regression_loss: 0.1190 - handedness_loss: 0.3551 - val_loss: 0.4512 - val_regression_loss: 0.1178 - val_handedness_loss: 0.3324\n",
      "Epoch 21/150\n",
      "2172/2172 [==============================] - 0s 116us/step - loss: 0.4632 - regression_loss: 0.1156 - handedness_loss: 0.3476 - val_loss: 0.4297 - val_regression_loss: 0.1171 - val_handedness_loss: 0.3125\n",
      "Evaluating model with testing data...\n",
      "444/444 [==============================] - 0s 27us/step\n",
      "Getting distribution of predictions and covariance matrix...\n",
      "      1 of 20\n",
      "      2 of 20\n",
      "      3 of 20\n",
      "      4 of 20\n",
      "      5 of 20\n",
      "      6 of 20\n",
      "      7 of 20\n",
      "      8 of 20\n",
      "      9 of 20\n",
      "      10 of 20\n",
      "      11 of 20\n",
      "      12 of 20\n",
      "      13 of 20\n",
      "      14 of 20\n",
      "      15 of 20\n",
      "      16 of 20\n",
      "      17 of 20\n",
      "      18 of 20\n",
      "      19 of 20\n",
      "      20 of 20\n",
      "Computing ensemble means...\n",
      "Computing mean squared error...\n",
      "Iteration 13\n",
      "Train on 2312 samples, validate on 474 samples\n",
      "Epoch 1/150\n",
      "2312/2312 [==============================] - 0s 156us/step - loss: 1.3729 - regression_loss: 0.6658 - handedness_loss: 0.6874 - val_loss: 0.9614 - val_regression_loss: 0.2905 - val_handedness_loss: 0.6731\n",
      "Epoch 2/150\n",
      "2312/2312 [==============================] - 0s 72us/step - loss: 0.9388 - regression_loss: 0.2859 - handedness_loss: 0.6533 - val_loss: 0.9116 - val_regression_loss: 0.2697 - val_handedness_loss: 0.6442\n",
      "Epoch 3/150\n",
      "2312/2312 [==============================] - 0s 96us/step - loss: 0.8835 - regression_loss: 0.2569 - handedness_loss: 0.6290 - val_loss: 0.8563 - val_regression_loss: 0.2489 - val_handedness_loss: 0.6098\n",
      "Epoch 4/150\n",
      "2312/2312 [==============================] - 0s 140us/step - loss: 0.8372 - regression_loss: 0.2356 - handedness_loss: 0.6102 - val_loss: 0.8079 - val_regression_loss: 0.2297 - val_handedness_loss: 0.5802\n",
      "Epoch 5/150\n",
      "2312/2312 [==============================] - 0s 141us/step - loss: 0.7918 - regression_loss: 0.2102 - handedness_loss: 0.5719 - val_loss: 0.7836 - val_regression_loss: 0.2144 - val_handedness_loss: 0.5718\n",
      "Epoch 6/150\n",
      "2312/2312 [==============================] - 0s 141us/step - loss: 0.7416 - regression_loss: 0.1954 - handedness_loss: 0.5431 - val_loss: 0.7371 - val_regression_loss: 0.1977 - val_handedness_loss: 0.5431\n",
      "Epoch 7/150\n",
      "2312/2312 [==============================] - 0s 144us/step - loss: 0.7015 - regression_loss: 0.1856 - handedness_loss: 0.5150 - val_loss: 0.6783 - val_regression_loss: 0.1790 - val_handedness_loss: 0.4991\n",
      "Epoch 8/150\n",
      "2312/2312 [==============================] - 0s 153us/step - loss: 0.6548 - regression_loss: 0.1739 - handedness_loss: 0.4964 - val_loss: 0.6417 - val_regression_loss: 0.1675 - val_handedness_loss: 0.4786\n",
      "Epoch 9/150\n",
      "2312/2312 [==============================] - 0s 115us/step - loss: 0.6114 - regression_loss: 0.1543 - handedness_loss: 0.4606 - val_loss: 0.5715 - val_regression_loss: 0.1465 - val_handedness_loss: 0.4267\n",
      "Epoch 10/150\n",
      "2312/2312 [==============================] - 0s 151us/step - loss: 0.5558 - regression_loss: 0.1402 - handedness_loss: 0.4085 - val_loss: 0.5037 - val_regression_loss: 0.1369 - val_handedness_loss: 0.3680\n",
      "Epoch 11/150\n",
      "2312/2312 [==============================] - 0s 149us/step - loss: 0.5192 - regression_loss: 0.1301 - handedness_loss: 0.3862 - val_loss: 0.5038 - val_regression_loss: 0.1348 - val_handedness_loss: 0.3713\n",
      "Epoch 12/150\n",
      "2312/2312 [==============================] - 0s 107us/step - loss: 0.4894 - regression_loss: 0.1284 - handedness_loss: 0.3651 - val_loss: 0.4832 - val_regression_loss: 0.1271 - val_handedness_loss: 0.3581\n",
      "Epoch 13/150\n",
      "2312/2312 [==============================] - 0s 128us/step - loss: 0.4551 - regression_loss: 0.1190 - handedness_loss: 0.3286 - val_loss: 0.4415 - val_regression_loss: 0.1218 - val_handedness_loss: 0.3252\n",
      "Epoch 14/150\n",
      "2312/2312 [==============================] - 0s 121us/step - loss: 0.4239 - regression_loss: 0.1144 - handedness_loss: 0.2980 - val_loss: 0.4395 - val_regression_loss: 0.1177 - val_handedness_loss: 0.3228\n",
      "Epoch 15/150\n",
      "2312/2312 [==============================] - 0s 142us/step - loss: 0.3999 - regression_loss: 0.1103 - handedness_loss: 0.2857 - val_loss: 0.4228 - val_regression_loss: 0.1121 - val_handedness_loss: 0.3127\n",
      "Epoch 16/150\n",
      "2312/2312 [==============================] - 0s 119us/step - loss: 0.3971 - regression_loss: 0.1091 - handedness_loss: 0.2873 - val_loss: 0.4185 - val_regression_loss: 0.1138 - val_handedness_loss: 0.3045\n",
      "Epoch 17/150\n",
      "2312/2312 [==============================] - 0s 123us/step - loss: 0.3924 - regression_loss: 0.1086 - handedness_loss: 0.2982 - val_loss: 0.3991 - val_regression_loss: 0.1086 - val_handedness_loss: 0.2898\n",
      "Epoch 18/150\n",
      "2312/2312 [==============================] - 0s 130us/step - loss: 0.3841 - regression_loss: 0.1082 - handedness_loss: 0.2907 - val_loss: 0.3646 - val_regression_loss: 0.1075 - val_handedness_loss: 0.2596\n",
      "Epoch 19/150\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2312/2312 [==============================] - 0s 133us/step - loss: 0.3672 - regression_loss: 0.1055 - handedness_loss: 0.2714 - val_loss: 0.3518 - val_regression_loss: 0.1082 - val_handedness_loss: 0.2493\n",
      "Epoch 20/150\n",
      "2312/2312 [==============================] - 0s 134us/step - loss: 0.3661 - regression_loss: 0.1026 - handedness_loss: 0.2626 - val_loss: 0.3676 - val_regression_loss: 0.1056 - val_handedness_loss: 0.2651\n",
      "Epoch 21/150\n",
      "2312/2312 [==============================] - 0s 134us/step - loss: 0.3491 - regression_loss: 0.0982 - handedness_loss: 0.2416 - val_loss: 0.3399 - val_regression_loss: 0.0988 - val_handedness_loss: 0.2430\n",
      "Epoch 22/150\n",
      "2312/2312 [==============================] - 0s 135us/step - loss: 0.3214 - regression_loss: 0.0963 - handedness_loss: 0.2257 - val_loss: 0.3234 - val_regression_loss: 0.0967 - val_handedness_loss: 0.2298\n",
      "Epoch 23/150\n",
      "2312/2312 [==============================] - 0s 135us/step - loss: 0.3400 - regression_loss: 0.0960 - handedness_loss: 0.2419 - val_loss: 0.3281 - val_regression_loss: 0.0982 - val_handedness_loss: 0.2286\n",
      "Epoch 24/150\n",
      "2312/2312 [==============================] - 0s 139us/step - loss: 0.3177 - regression_loss: 0.0917 - handedness_loss: 0.2242 - val_loss: 0.3003 - val_regression_loss: 0.0938 - val_handedness_loss: 0.2115\n",
      "Epoch 25/150\n",
      "2312/2312 [==============================] - 0s 152us/step - loss: 0.3198 - regression_loss: 0.0892 - handedness_loss: 0.2242 - val_loss: 0.3187 - val_regression_loss: 0.0914 - val_handedness_loss: 0.2324\n",
      "Epoch 26/150\n",
      "2312/2312 [==============================] - 0s 153us/step - loss: 0.3023 - regression_loss: 0.0919 - handedness_loss: 0.2125 - val_loss: 0.3080 - val_regression_loss: 0.0934 - val_handedness_loss: 0.2205\n",
      "Epoch 27/150\n",
      "2312/2312 [==============================] - 0s 127us/step - loss: 0.2959 - regression_loss: 0.0903 - handedness_loss: 0.2156 - val_loss: 0.2912 - val_regression_loss: 0.0889 - val_handedness_loss: 0.2074\n",
      "Epoch 28/150\n",
      "2312/2312 [==============================] - 0s 122us/step - loss: 0.2817 - regression_loss: 0.0848 - handedness_loss: 0.2004 - val_loss: 0.2813 - val_regression_loss: 0.0871 - val_handedness_loss: 0.1970\n",
      "Epoch 29/150\n",
      "2312/2312 [==============================] - 0s 120us/step - loss: 0.2845 - regression_loss: 0.0852 - handedness_loss: 0.2060 - val_loss: 0.2783 - val_regression_loss: 0.0870 - val_handedness_loss: 0.1973\n",
      "Epoch 30/150\n",
      "2312/2312 [==============================] - 0s 121us/step - loss: 0.2702 - regression_loss: 0.0829 - handedness_loss: 0.1889 - val_loss: 0.2722 - val_regression_loss: 0.0847 - val_handedness_loss: 0.1896\n",
      "Epoch 31/150\n",
      "2312/2312 [==============================] - 0s 121us/step - loss: 0.2837 - regression_loss: 0.0810 - handedness_loss: 0.2051 - val_loss: 0.2729 - val_regression_loss: 0.0825 - val_handedness_loss: 0.1905\n",
      "Epoch 32/150\n",
      "2312/2312 [==============================] - 0s 124us/step - loss: 0.2783 - regression_loss: 0.0806 - handedness_loss: 0.1948 - val_loss: 0.2497 - val_regression_loss: 0.0793 - val_handedness_loss: 0.1720\n",
      "Epoch 33/150\n",
      "2312/2312 [==============================] - 0s 141us/step - loss: 0.3094 - regression_loss: 0.0784 - handedness_loss: 0.2279 - val_loss: 0.2927 - val_regression_loss: 0.0841 - val_handedness_loss: 0.2135\n",
      "Epoch 34/150\n",
      "2312/2312 [==============================] - 0s 141us/step - loss: 0.2924 - regression_loss: 0.0811 - handedness_loss: 0.2120 - val_loss: 0.2761 - val_regression_loss: 0.0800 - val_handedness_loss: 0.1991\n",
      "Epoch 35/150\n",
      "2312/2312 [==============================] - 0s 143us/step - loss: 0.2793 - regression_loss: 0.0782 - handedness_loss: 0.1991 - val_loss: 0.2708 - val_regression_loss: 0.0801 - val_handedness_loss: 0.1917\n",
      "Epoch 36/150\n",
      "2312/2312 [==============================] - 0s 144us/step - loss: 0.2716 - regression_loss: 0.0770 - handedness_loss: 0.1903 - val_loss: 0.2515 - val_regression_loss: 0.0794 - val_handedness_loss: 0.1724\n",
      "Evaluating model with testing data...\n",
      "474/474 [==============================] - 0s 32us/step\n",
      "Getting distribution of predictions and covariance matrix...\n",
      "      1 of 20\n",
      "      2 of 20\n",
      "      3 of 20\n",
      "      4 of 20\n",
      "      5 of 20\n",
      "      6 of 20\n",
      "      7 of 20\n",
      "      8 of 20\n",
      "      9 of 20\n",
      "      10 of 20\n",
      "      11 of 20\n",
      "      12 of 20\n",
      "      13 of 20\n",
      "      14 of 20\n",
      "      15 of 20\n",
      "      16 of 20\n",
      "      17 of 20\n",
      "      18 of 20\n",
      "      19 of 20\n",
      "      20 of 20\n",
      "Computing ensemble means...\n",
      "Computing mean squared error...\n",
      "Iteration 14\n",
      "Train on 2452 samples, validate on 504 samples\n",
      "Epoch 1/150\n",
      "2452/2452 [==============================] - 0s 171us/step - loss: 1.3920 - regression_loss: 0.6854 - handedness_loss: 0.6911 - val_loss: 0.9688 - val_regression_loss: 0.3022 - val_handedness_loss: 0.6678\n",
      "Epoch 2/150\n",
      "2452/2452 [==============================] - 0s 93us/step - loss: 0.9227 - regression_loss: 0.2747 - handedness_loss: 0.6436 - val_loss: 0.9097 - val_regression_loss: 0.2745 - val_handedness_loss: 0.6363\n",
      "Epoch 3/150\n",
      "2452/2452 [==============================] - 0s 136us/step - loss: 0.8466 - regression_loss: 0.2307 - handedness_loss: 0.6124 - val_loss: 0.8516 - val_regression_loss: 0.2374 - val_handedness_loss: 0.6152\n",
      "Epoch 4/150\n",
      "2452/2452 [==============================] - 0s 154us/step - loss: 0.7855 - regression_loss: 0.2071 - handedness_loss: 0.5776 - val_loss: 0.7915 - val_regression_loss: 0.2051 - val_handedness_loss: 0.5875\n",
      "Epoch 5/150\n",
      "2452/2452 [==============================] - 0s 154us/step - loss: 0.7276 - regression_loss: 0.1776 - handedness_loss: 0.5485 - val_loss: 0.7529 - val_regression_loss: 0.1861 - val_handedness_loss: 0.5678\n",
      "Epoch 6/150\n",
      "2452/2452 [==============================] - 0s 132us/step - loss: 0.6775 - regression_loss: 0.1628 - handedness_loss: 0.5145 - val_loss: 0.6725 - val_regression_loss: 0.1617 - val_handedness_loss: 0.5119\n",
      "Epoch 7/150\n",
      "2452/2452 [==============================] - 0s 154us/step - loss: 0.6463 - regression_loss: 0.1537 - handedness_loss: 0.4938 - val_loss: 0.6315 - val_regression_loss: 0.1592 - val_handedness_loss: 0.4724\n",
      "Epoch 8/150\n",
      "2452/2452 [==============================] - 0s 153us/step - loss: 0.6034 - regression_loss: 0.1451 - handedness_loss: 0.4605 - val_loss: 0.5803 - val_regression_loss: 0.1464 - val_handedness_loss: 0.4346\n",
      "Epoch 9/150\n",
      "2452/2452 [==============================] - 0s 155us/step - loss: 0.5736 - regression_loss: 0.1366 - handedness_loss: 0.4334 - val_loss: 0.5826 - val_regression_loss: 0.1366 - val_handedness_loss: 0.4466\n",
      "Epoch 10/150\n",
      "2452/2452 [==============================] - 0s 153us/step - loss: 0.5456 - regression_loss: 0.1310 - handedness_loss: 0.4067 - val_loss: 0.5357 - val_regression_loss: 0.1385 - val_handedness_loss: 0.3971\n",
      "Epoch 11/150\n",
      "2452/2452 [==============================] - 0s 154us/step - loss: 0.5211 - regression_loss: 0.1260 - handedness_loss: 0.3906 - val_loss: 0.5468 - val_regression_loss: 0.1393 - val_handedness_loss: 0.4074\n",
      "Epoch 12/150\n",
      "2452/2452 [==============================] - 0s 154us/step - loss: 0.5000 - regression_loss: 0.1275 - handedness_loss: 0.3652 - val_loss: 0.5022 - val_regression_loss: 0.1307 - val_handedness_loss: 0.3718\n",
      "Epoch 13/150\n",
      "2452/2452 [==============================] - 0s 107us/step - loss: 0.4858 - regression_loss: 0.1269 - handedness_loss: 0.3525 - val_loss: 0.4705 - val_regression_loss: 0.1355 - val_handedness_loss: 0.3345\n",
      "Epoch 14/150\n",
      "2452/2452 [==============================] - 0s 121us/step - loss: 0.4548 - regression_loss: 0.1228 - handedness_loss: 0.3282 - val_loss: 0.4662 - val_regression_loss: 0.1254 - val_handedness_loss: 0.3402\n",
      "Epoch 15/150\n",
      "2452/2452 [==============================] - 0s 119us/step - loss: 0.4522 - regression_loss: 0.1209 - handedness_loss: 0.3303 - val_loss: 0.4417 - val_regression_loss: 0.1172 - val_handedness_loss: 0.3235\n",
      "Epoch 16/150\n",
      "2452/2452 [==============================] - 0s 119us/step - loss: 0.4112 - regression_loss: 0.1136 - handedness_loss: 0.2921 - val_loss: 0.4310 - val_regression_loss: 0.1160 - val_handedness_loss: 0.3151\n",
      "Epoch 17/150\n",
      "2452/2452 [==============================] - 0s 139us/step - loss: 0.4062 - regression_loss: 0.1141 - handedness_loss: 0.2951 - val_loss: 0.3842 - val_regression_loss: 0.1097 - val_handedness_loss: 0.2743\n",
      "Epoch 18/150\n",
      "2452/2452 [==============================] - 0s 139us/step - loss: 0.3821 - regression_loss: 0.1061 - handedness_loss: 0.2694 - val_loss: 0.4042 - val_regression_loss: 0.1119 - val_handedness_loss: 0.2926\n",
      "Epoch 19/150\n",
      "2452/2452 [==============================] - 0s 141us/step - loss: 0.3800 - regression_loss: 0.1074 - handedness_loss: 0.2705 - val_loss: 0.3662 - val_regression_loss: 0.1123 - val_handedness_loss: 0.2538\n",
      "Epoch 20/150\n",
      "2452/2452 [==============================] - 0s 139us/step - loss: 0.3613 - regression_loss: 0.1037 - handedness_loss: 0.2603 - val_loss: 0.3784 - val_regression_loss: 0.1093 - val_handedness_loss: 0.2687\n",
      "Epoch 21/150\n",
      "2452/2452 [==============================] - 0s 138us/step - loss: 0.3603 - regression_loss: 0.1053 - handedness_loss: 0.2494 - val_loss: 0.3743 - val_regression_loss: 0.1102 - val_handedness_loss: 0.2637\n",
      "Epoch 22/150\n",
      "2452/2452 [==============================] - 0s 141us/step - loss: 0.3345 - regression_loss: 0.1011 - handedness_loss: 0.2355 - val_loss: 0.3239 - val_regression_loss: 0.1020 - val_handedness_loss: 0.2215\n",
      "Epoch 23/150\n",
      "2452/2452 [==============================] - 0s 150us/step - loss: 0.3456 - regression_loss: 0.0979 - handedness_loss: 0.2413 - val_loss: 0.3541 - val_regression_loss: 0.1038 - val_handedness_loss: 0.2502\n",
      "Epoch 24/150\n",
      "2452/2452 [==============================] - 0s 134us/step - loss: 0.3288 - regression_loss: 0.0956 - handedness_loss: 0.2370 - val_loss: 0.3549 - val_regression_loss: 0.1003 - val_handedness_loss: 0.2543\n",
      "Epoch 25/150\n",
      "2452/2452 [==============================] - 0s 141us/step - loss: 0.3520 - regression_loss: 0.0986 - handedness_loss: 0.2549 - val_loss: 0.3559 - val_regression_loss: 0.0980 - val_handedness_loss: 0.2581\n",
      "Epoch 26/150\n",
      "2452/2452 [==============================] - 0s 140us/step - loss: 0.3197 - regression_loss: 0.0924 - handedness_loss: 0.2226 - val_loss: 0.3306 - val_regression_loss: 0.0962 - val_handedness_loss: 0.2337\n",
      "Evaluating model with testing data...\n",
      "504/504 [==============================] - 0s 31us/step\n",
      "Getting distribution of predictions and covariance matrix...\n",
      "      1 of 20\n",
      "      2 of 20\n",
      "      3 of 20\n",
      "      4 of 20\n",
      "      5 of 20\n",
      "      6 of 20\n",
      "      7 of 20\n",
      "      8 of 20\n",
      "      9 of 20\n",
      "      10 of 20\n",
      "      11 of 20\n",
      "      12 of 20\n",
      "      13 of 20\n",
      "      14 of 20\n",
      "      15 of 20\n",
      "      16 of 20\n",
      "      17 of 20\n",
      "      18 of 20\n",
      "      19 of 20\n",
      "      20 of 20\n",
      "Computing ensemble means...\n",
      "Computing mean squared error...\n",
      "Iteration 15\n",
      "Train on 2592 samples, validate on 534 samples\n",
      "Epoch 1/150\n",
      "2592/2592 [==============================] - 0s 172us/step - loss: 1.4893 - regression_loss: 0.7703 - handedness_loss: 0.6990 - val_loss: 1.0048 - val_regression_loss: 0.3308 - val_handedness_loss: 0.6743\n",
      "Epoch 2/150\n",
      "2592/2592 [==============================] - 0s 118us/step - loss: 0.9597 - regression_loss: 0.2934 - handedness_loss: 0.6629 - val_loss: 0.9649 - val_regression_loss: 0.3070 - val_handedness_loss: 0.6597\n",
      "Epoch 3/150\n",
      "2592/2592 [==============================] - 0s 142us/step - loss: 0.9138 - regression_loss: 0.2714 - handedness_loss: 0.6430 - val_loss: 0.9200 - val_regression_loss: 0.2861 - val_handedness_loss: 0.6374\n",
      "Epoch 4/150\n",
      "2592/2592 [==============================] - 0s 132us/step - loss: 0.8634 - regression_loss: 0.2477 - handedness_loss: 0.6137 - val_loss: 0.8834 - val_regression_loss: 0.2660 - val_handedness_loss: 0.6124\n",
      "Epoch 5/150\n",
      "2592/2592 [==============================] - 0s 151us/step - loss: 0.8223 - regression_loss: 0.2333 - handedness_loss: 0.5870 - val_loss: 0.8284 - val_regression_loss: 0.2519 - val_handedness_loss: 0.5739\n",
      "Epoch 6/150\n",
      "2592/2592 [==============================] - 0s 151us/step - loss: 0.7801 - regression_loss: 0.2187 - handedness_loss: 0.5613 - val_loss: 0.7962 - val_regression_loss: 0.2420 - val_handedness_loss: 0.5550\n",
      "Epoch 7/150\n",
      "2592/2592 [==============================] - 0s 133us/step - loss: 0.7415 - regression_loss: 0.2032 - handedness_loss: 0.5351 - val_loss: 0.7436 - val_regression_loss: 0.2252 - val_handedness_loss: 0.5131\n",
      "Epoch 8/150\n",
      "2592/2592 [==============================] - 0s 140us/step - loss: 0.7086 - regression_loss: 0.1892 - handedness_loss: 0.5188 - val_loss: 0.7298 - val_regression_loss: 0.2129 - val_handedness_loss: 0.5183\n",
      "Epoch 9/150\n",
      "2592/2592 [==============================] - 0s 140us/step - loss: 0.6656 - regression_loss: 0.1767 - handedness_loss: 0.4906 - val_loss: 0.7036 - val_regression_loss: 0.2000 - val_handedness_loss: 0.4910\n",
      "Epoch 10/150\n",
      "2592/2592 [==============================] - 0s 142us/step - loss: 0.6334 - regression_loss: 0.1654 - handedness_loss: 0.4670 - val_loss: 0.6391 - val_regression_loss: 0.1813 - val_handedness_loss: 0.4312\n",
      "Epoch 11/150\n",
      "2592/2592 [==============================] - 0s 144us/step - loss: 0.6180 - regression_loss: 0.1561 - handedness_loss: 0.4570 - val_loss: 0.6163 - val_regression_loss: 0.1740 - val_handedness_loss: 0.4377\n",
      "Epoch 12/150\n",
      "2592/2592 [==============================] - 0s 152us/step - loss: 0.5987 - regression_loss: 0.1497 - handedness_loss: 0.4466 - val_loss: 0.6056 - val_regression_loss: 0.1686 - val_handedness_loss: 0.4326\n",
      "Epoch 13/150\n",
      "2592/2592 [==============================] - 0s 153us/step - loss: 0.5707 - regression_loss: 0.1427 - handedness_loss: 0.4265 - val_loss: 0.5811 - val_regression_loss: 0.1584 - val_handedness_loss: 0.4107\n",
      "Epoch 14/150\n",
      "2592/2592 [==============================] - 0s 155us/step - loss: 0.5583 - regression_loss: 0.1375 - handedness_loss: 0.4189 - val_loss: 0.5537 - val_regression_loss: 0.1554 - val_handedness_loss: 0.4002\n",
      "Epoch 15/150\n",
      "2592/2592 [==============================] - 0s 154us/step - loss: 0.5537 - regression_loss: 0.1364 - handedness_loss: 0.4153 - val_loss: 0.5306 - val_regression_loss: 0.1434 - val_handedness_loss: 0.3890\n",
      "Epoch 16/150\n",
      "2592/2592 [==============================] - 0s 154us/step - loss: 0.5205 - regression_loss: 0.1304 - handedness_loss: 0.3856 - val_loss: 0.5496 - val_regression_loss: 0.1473 - val_handedness_loss: 0.4039\n",
      "Epoch 17/150\n",
      "2592/2592 [==============================] - 0s 156us/step - loss: 0.5091 - regression_loss: 0.1241 - handedness_loss: 0.3868 - val_loss: 0.5337 - val_regression_loss: 0.1376 - val_handedness_loss: 0.3794\n",
      "Epoch 18/150\n",
      "2592/2592 [==============================] - 0s 131us/step - loss: 0.4797 - regression_loss: 0.1194 - handedness_loss: 0.3648 - val_loss: 0.4914 - val_regression_loss: 0.1264 - val_handedness_loss: 0.3875\n",
      "Epoch 19/150\n",
      "2592/2592 [==============================] - 0s 142us/step - loss: 0.4644 - regression_loss: 0.1122 - handedness_loss: 0.3562 - val_loss: 0.4647 - val_regression_loss: 0.1215 - val_handedness_loss: 0.3450\n",
      "Epoch 20/150\n",
      "2592/2592 [==============================] - 0s 142us/step - loss: 0.4697 - regression_loss: 0.1084 - handedness_loss: 0.3658 - val_loss: 0.4416 - val_regression_loss: 0.1139 - val_handedness_loss: 0.3268\n",
      "Epoch 21/150\n",
      "2592/2592 [==============================] - 0s 142us/step - loss: 0.4492 - regression_loss: 0.1018 - handedness_loss: 0.3488 - val_loss: 0.4507 - val_regression_loss: 0.1111 - val_handedness_loss: 0.3515\n",
      "Epoch 22/150\n",
      "2592/2592 [==============================] - 0s 141us/step - loss: 0.4309 - regression_loss: 0.0999 - handedness_loss: 0.3318 - val_loss: 0.4683 - val_regression_loss: 0.1159 - val_handedness_loss: 0.3558\n",
      "Epoch 23/150\n",
      "2592/2592 [==============================] - 0s 142us/step - loss: 0.4282 - regression_loss: 0.0980 - handedness_loss: 0.3288 - val_loss: 0.4360 - val_regression_loss: 0.1050 - val_handedness_loss: 0.3156\n",
      "Epoch 24/150\n",
      "2592/2592 [==============================] - 0s 142us/step - loss: 0.4168 - regression_loss: 0.0948 - handedness_loss: 0.3209 - val_loss: 0.4369 - val_regression_loss: 0.1074 - val_handedness_loss: 0.3293\n",
      "Epoch 25/150\n",
      "2592/2592 [==============================] - 0s 144us/step - loss: 0.4089 - regression_loss: 0.0928 - handedness_loss: 0.3186 - val_loss: 0.4372 - val_regression_loss: 0.1059 - val_handedness_loss: 0.3336\n",
      "Epoch 26/150\n",
      "2592/2592 [==============================] - 0s 143us/step - loss: 0.4257 - regression_loss: 0.0937 - handedness_loss: 0.3285 - val_loss: 0.4457 - val_regression_loss: 0.1026 - val_handedness_loss: 0.3346\n",
      "Epoch 27/150\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2592/2592 [==============================] - 0s 144us/step - loss: 0.4000 - regression_loss: 0.0904 - handedness_loss: 0.3117 - val_loss: 0.4209 - val_regression_loss: 0.0997 - val_handedness_loss: 0.3195\n",
      "Evaluating model with testing data...\n",
      "534/534 [==============================] - 0s 30us/step\n",
      "Getting distribution of predictions and covariance matrix...\n",
      "      1 of 20\n",
      "      2 of 20\n",
      "      3 of 20\n",
      "      4 of 20\n",
      "      5 of 20\n",
      "      6 of 20\n",
      "      7 of 20\n",
      "      8 of 20\n",
      "      9 of 20\n",
      "      10 of 20\n",
      "      11 of 20\n",
      "      12 of 20\n",
      "      13 of 20\n",
      "      14 of 20\n",
      "      15 of 20\n",
      "      16 of 20\n",
      "      17 of 20\n",
      "      18 of 20\n",
      "      19 of 20\n",
      "      20 of 20\n",
      "Computing ensemble means...\n",
      "Computing mean squared error...\n",
      "Iteration 16\n",
      "Train on 2732 samples, validate on 564 samples\n",
      "Epoch 1/150\n",
      "2732/2732 [==============================] - 0s 176us/step - loss: 1.5347 - regression_loss: 0.8252 - handedness_loss: 0.6927 - val_loss: 1.0009 - val_regression_loss: 0.3186 - val_handedness_loss: 0.6793\n",
      "Epoch 2/150\n",
      "2732/2732 [==============================] - 0s 103us/step - loss: 0.9509 - regression_loss: 0.2929 - handedness_loss: 0.6557 - val_loss: 0.9577 - val_regression_loss: 0.3031 - val_handedness_loss: 0.6519\n",
      "Epoch 3/150\n",
      "2732/2732 [==============================] - 0s 129us/step - loss: 0.9064 - regression_loss: 0.2741 - handedness_loss: 0.6301 - val_loss: 0.9086 - val_regression_loss: 0.2771 - val_handedness_loss: 0.6330\n",
      "Epoch 4/150\n",
      "2732/2732 [==============================] - 0s 133us/step - loss: 0.8626 - regression_loss: 0.2514 - handedness_loss: 0.6116 - val_loss: 0.8667 - val_regression_loss: 0.2532 - val_handedness_loss: 0.6121\n",
      "Epoch 5/150\n",
      "2732/2732 [==============================] - 0s 133us/step - loss: 0.8294 - regression_loss: 0.2252 - handedness_loss: 0.6027 - val_loss: 0.8373 - val_regression_loss: 0.2302 - val_handedness_loss: 0.6100\n",
      "Epoch 6/150\n",
      "2732/2732 [==============================] - 0s 134us/step - loss: 0.7945 - regression_loss: 0.2072 - handedness_loss: 0.5890 - val_loss: 0.7987 - val_regression_loss: 0.2130 - val_handedness_loss: 0.5923\n",
      "Epoch 7/150\n",
      "2732/2732 [==============================] - 0s 134us/step - loss: 0.7663 - regression_loss: 0.1928 - handedness_loss: 0.5718 - val_loss: 0.7667 - val_regression_loss: 0.2018 - val_handedness_loss: 0.5699\n",
      "Epoch 8/150\n",
      "2732/2732 [==============================] - 0s 134us/step - loss: 0.7296 - regression_loss: 0.1809 - handedness_loss: 0.5487 - val_loss: 0.7378 - val_regression_loss: 0.1876 - val_handedness_loss: 0.5473\n",
      "Epoch 9/150\n",
      "2732/2732 [==============================] - 0s 151us/step - loss: 0.7140 - regression_loss: 0.1725 - handedness_loss: 0.5427 - val_loss: 0.6942 - val_regression_loss: 0.1774 - val_handedness_loss: 0.5215\n",
      "Epoch 10/150\n",
      "2732/2732 [==============================] - 0s 151us/step - loss: 0.6775 - regression_loss: 0.1634 - handedness_loss: 0.5141 - val_loss: 0.6762 - val_regression_loss: 0.1701 - val_handedness_loss: 0.5152\n",
      "Epoch 11/150\n",
      "2732/2732 [==============================] - 0s 135us/step - loss: 0.6453 - regression_loss: 0.1532 - handedness_loss: 0.4930 - val_loss: 0.6573 - val_regression_loss: 0.1639 - val_handedness_loss: 0.5076\n",
      "Epoch 12/150\n",
      "2732/2732 [==============================] - 0s 142us/step - loss: 0.6247 - regression_loss: 0.1490 - handedness_loss: 0.4745 - val_loss: 0.6334 - val_regression_loss: 0.1638 - val_handedness_loss: 0.4840\n",
      "Epoch 13/150\n",
      "2732/2732 [==============================] - 0s 141us/step - loss: 0.5966 - regression_loss: 0.1395 - handedness_loss: 0.4557 - val_loss: 0.6128 - val_regression_loss: 0.1489 - val_handedness_loss: 0.4733\n",
      "Epoch 14/150\n",
      "2732/2732 [==============================] - 0s 111us/step - loss: 0.5773 - regression_loss: 0.1346 - handedness_loss: 0.4409 - val_loss: 0.6050 - val_regression_loss: 0.1443 - val_handedness_loss: 0.4681\n",
      "Epoch 15/150\n",
      "2732/2732 [==============================] - 0s 139us/step - loss: 0.5733 - regression_loss: 0.1299 - handedness_loss: 0.4410 - val_loss: 0.5788 - val_regression_loss: 0.1401 - val_handedness_loss: 0.4517\n",
      "Epoch 16/150\n",
      "2732/2732 [==============================] - 0s 140us/step - loss: 0.5515 - regression_loss: 0.1246 - handedness_loss: 0.4278 - val_loss: 0.5769 - val_regression_loss: 0.1368 - val_handedness_loss: 0.4396\n",
      "Epoch 17/150\n",
      "2732/2732 [==============================] - 0s 139us/step - loss: 0.5465 - regression_loss: 0.1216 - handedness_loss: 0.4247 - val_loss: 0.5617 - val_regression_loss: 0.1305 - val_handedness_loss: 0.4407\n",
      "Epoch 18/150\n",
      "2732/2732 [==============================] - 0s 148us/step - loss: 0.5378 - regression_loss: 0.1170 - handedness_loss: 0.4186 - val_loss: 0.5289 - val_regression_loss: 0.1235 - val_handedness_loss: 0.4164\n",
      "Epoch 19/150\n",
      "2732/2732 [==============================] - 0s 148us/step - loss: 0.5378 - regression_loss: 0.1153 - handedness_loss: 0.4228 - val_loss: 0.5400 - val_regression_loss: 0.1209 - val_handedness_loss: 0.4276\n",
      "Epoch 20/150\n",
      "2732/2732 [==============================] - 0s 150us/step - loss: 0.5053 - regression_loss: 0.1101 - handedness_loss: 0.3979 - val_loss: 0.5005 - val_regression_loss: 0.1154 - val_handedness_loss: 0.3952\n",
      "Epoch 21/150\n",
      "2732/2732 [==============================] - 0s 96us/step - loss: 0.5127 - regression_loss: 0.1081 - handedness_loss: 0.4044 - val_loss: 0.5143 - val_regression_loss: 0.1195 - val_handedness_loss: 0.3914\n",
      "Epoch 22/150\n",
      "2732/2732 [==============================] - 0s 66us/step - loss: 0.4887 - regression_loss: 0.1088 - handedness_loss: 0.3795 - val_loss: 0.5076 - val_regression_loss: 0.1178 - val_handedness_loss: 0.3906\n",
      "Epoch 23/150\n",
      "2732/2732 [==============================] - 0s 65us/step - loss: 0.4564 - regression_loss: 0.1065 - handedness_loss: 0.3493 - val_loss: 0.4469 - val_regression_loss: 0.1150 - val_handedness_loss: 0.3432\n",
      "Epoch 24/150\n",
      "2732/2732 [==============================] - 0s 64us/step - loss: 0.4393 - regression_loss: 0.0991 - handedness_loss: 0.3425 - val_loss: 0.4101 - val_regression_loss: 0.1013 - val_handedness_loss: 0.3191\n",
      "Epoch 25/150\n",
      "2732/2732 [==============================] - 0s 76us/step - loss: 0.4075 - regression_loss: 0.0911 - handedness_loss: 0.3153 - val_loss: 0.4306 - val_regression_loss: 0.0984 - val_handedness_loss: 0.3485\n",
      "Epoch 26/150\n",
      "2732/2732 [==============================] - 0s 117us/step - loss: 0.3913 - regression_loss: 0.0874 - handedness_loss: 0.3038 - val_loss: 0.4061 - val_regression_loss: 0.0948 - val_handedness_loss: 0.3235\n",
      "Epoch 27/150\n",
      "2732/2732 [==============================] - 0s 116us/step - loss: 0.3957 - regression_loss: 0.0869 - handedness_loss: 0.3103 - val_loss: 0.3820 - val_regression_loss: 0.0922 - val_handedness_loss: 0.2889\n",
      "Epoch 28/150\n",
      "2732/2732 [==============================] - 0s 133us/step - loss: 0.3866 - regression_loss: 0.0856 - handedness_loss: 0.2955 - val_loss: 0.3861 - val_regression_loss: 0.0911 - val_handedness_loss: 0.3029\n",
      "Epoch 29/150\n",
      "2732/2732 [==============================] - 0s 133us/step - loss: 0.3755 - regression_loss: 0.0831 - handedness_loss: 0.2887 - val_loss: 0.3798 - val_regression_loss: 0.0917 - val_handedness_loss: 0.2974\n",
      "Epoch 30/150\n",
      "2732/2732 [==============================] - 0s 134us/step - loss: 0.3716 - regression_loss: 0.0814 - handedness_loss: 0.2881 - val_loss: 0.3893 - val_regression_loss: 0.0887 - val_handedness_loss: 0.2978\n",
      "Epoch 31/150\n",
      "2732/2732 [==============================] - 0s 135us/step - loss: 0.3821 - regression_loss: 0.0829 - handedness_loss: 0.3001 - val_loss: 0.3905 - val_regression_loss: 0.0890 - val_handedness_loss: 0.3103\n",
      "Evaluating model with testing data...\n",
      "564/564 [==============================] - 0s 28us/step\n",
      "Getting distribution of predictions and covariance matrix...\n",
      "      1 of 20\n",
      "      2 of 20\n",
      "      3 of 20\n",
      "      4 of 20\n",
      "      5 of 20\n",
      "      6 of 20\n",
      "      7 of 20\n",
      "      8 of 20\n",
      "      9 of 20\n",
      "      10 of 20\n",
      "      11 of 20\n",
      "      12 of 20\n",
      "      13 of 20\n",
      "      14 of 20\n",
      "      15 of 20\n",
      "      16 of 20\n",
      "      17 of 20\n",
      "      18 of 20\n",
      "      19 of 20\n",
      "      20 of 20\n",
      "Computing ensemble means...\n",
      "Computing mean squared error...\n",
      "Iteration 17\n",
      "Train on 2872 samples, validate on 594 samples\n",
      "Epoch 1/150\n",
      "2872/2872 [==============================] - 0s 165us/step - loss: 1.2106 - regression_loss: 0.5412 - handedness_loss: 0.6617 - val_loss: 0.9087 - val_regression_loss: 0.2405 - val_handedness_loss: 0.6664\n",
      "Epoch 2/150\n",
      "2872/2872 [==============================] - 0s 104us/step - loss: 0.8311 - regression_loss: 0.2164 - handedness_loss: 0.6137 - val_loss: 0.7951 - val_regression_loss: 0.2161 - val_handedness_loss: 0.5763\n",
      "Epoch 3/150\n",
      "2872/2872 [==============================] - 0s 145us/step - loss: 0.7476 - regression_loss: 0.1838 - handedness_loss: 0.5630 - val_loss: 0.7182 - val_regression_loss: 0.1753 - val_handedness_loss: 0.5418\n",
      "Epoch 4/150\n",
      "2872/2872 [==============================] - 0s 148us/step - loss: 0.6802 - regression_loss: 0.1651 - handedness_loss: 0.5155 - val_loss: 0.6517 - val_regression_loss: 0.1640 - val_handedness_loss: 0.4885\n",
      "Epoch 5/150\n",
      "2872/2872 [==============================] - 0s 149us/step - loss: 0.6307 - regression_loss: 0.1588 - handedness_loss: 0.4714 - val_loss: 0.6137 - val_regression_loss: 0.1563 - val_handedness_loss: 0.4592\n",
      "Epoch 6/150\n",
      "2872/2872 [==============================] - 0s 132us/step - loss: 0.5854 - regression_loss: 0.1431 - handedness_loss: 0.4411 - val_loss: 0.5864 - val_regression_loss: 0.1466 - val_handedness_loss: 0.4406\n",
      "Epoch 7/150\n",
      "2872/2872 [==============================] - 0s 142us/step - loss: 0.5227 - regression_loss: 0.1314 - handedness_loss: 0.3898 - val_loss: 0.5233 - val_regression_loss: 0.1391 - val_handedness_loss: 0.3843\n",
      "Epoch 8/150\n",
      "2872/2872 [==============================] - 0s 128us/step - loss: 0.4848 - regression_loss: 0.1264 - handedness_loss: 0.3586 - val_loss: 0.4811 - val_regression_loss: 0.1262 - val_handedness_loss: 0.3554\n",
      "Epoch 9/150\n",
      "2872/2872 [==============================] - 0s 152us/step - loss: 0.4477 - regression_loss: 0.1182 - handedness_loss: 0.3288 - val_loss: 0.4391 - val_regression_loss: 0.1208 - val_handedness_loss: 0.3218\n",
      "Epoch 10/150\n",
      "2872/2872 [==============================] - 0s 152us/step - loss: 0.4141 - regression_loss: 0.1092 - handedness_loss: 0.3046 - val_loss: 0.4126 - val_regression_loss: 0.1127 - val_handedness_loss: 0.3034\n",
      "Epoch 11/150\n",
      "2872/2872 [==============================] - 0s 154us/step - loss: 0.3873 - regression_loss: 0.1058 - handedness_loss: 0.2803 - val_loss: 0.3900 - val_regression_loss: 0.1215 - val_handedness_loss: 0.2662\n",
      "Epoch 12/150\n",
      "2872/2872 [==============================] - 0s 140us/step - loss: 0.3620 - regression_loss: 0.1012 - handedness_loss: 0.2608 - val_loss: 0.3641 - val_regression_loss: 0.1152 - val_handedness_loss: 0.2501\n",
      "Epoch 13/150\n",
      "2872/2872 [==============================] - 0s 150us/step - loss: 0.3573 - regression_loss: 0.1036 - handedness_loss: 0.2536 - val_loss: 0.3561 - val_regression_loss: 0.1062 - val_handedness_loss: 0.2452\n",
      "Epoch 14/150\n",
      "2872/2872 [==============================] - 0s 145us/step - loss: 0.3424 - regression_loss: 0.1021 - handedness_loss: 0.2400 - val_loss: 0.3470 - val_regression_loss: 0.1022 - val_handedness_loss: 0.2414\n",
      "Epoch 15/150\n",
      "2872/2872 [==============================] - 0s 131us/step - loss: 0.3209 - regression_loss: 0.0976 - handedness_loss: 0.2258 - val_loss: 0.3324 - val_regression_loss: 0.1040 - val_handedness_loss: 0.2261\n",
      "Epoch 16/150\n",
      "2872/2872 [==============================] - 0s 140us/step - loss: 0.3330 - regression_loss: 0.0963 - handedness_loss: 0.2360 - val_loss: 0.3608 - val_regression_loss: 0.1071 - val_handedness_loss: 0.2509\n",
      "Epoch 17/150\n",
      "2872/2872 [==============================] - 0s 141us/step - loss: 0.3235 - regression_loss: 0.0950 - handedness_loss: 0.2282 - val_loss: 0.3522 - val_regression_loss: 0.1010 - val_handedness_loss: 0.2495\n",
      "Epoch 18/150\n",
      "2872/2872 [==============================] - 0s 140us/step - loss: 0.3087 - regression_loss: 0.0929 - handedness_loss: 0.2173 - val_loss: 0.3146 - val_regression_loss: 0.1021 - val_handedness_loss: 0.2104\n",
      "Epoch 19/150\n",
      "2872/2872 [==============================] - 0s 146us/step - loss: 0.2962 - regression_loss: 0.0899 - handedness_loss: 0.2049 - val_loss: 0.3130 - val_regression_loss: 0.1012 - val_handedness_loss: 0.2140\n",
      "Epoch 20/150\n",
      "2872/2872 [==============================] - 0s 153us/step - loss: 0.2949 - regression_loss: 0.0914 - handedness_loss: 0.2038 - val_loss: 0.2792 - val_regression_loss: 0.0931 - val_handedness_loss: 0.1828\n",
      "Epoch 21/150\n",
      "2872/2872 [==============================] - 0s 115us/step - loss: 0.2862 - regression_loss: 0.0874 - handedness_loss: 0.1983 - val_loss: 0.3002 - val_regression_loss: 0.0968 - val_handedness_loss: 0.2025\n",
      "Epoch 22/150\n",
      "2872/2872 [==============================] - 0s 107us/step - loss: 0.2858 - regression_loss: 0.0867 - handedness_loss: 0.1973 - val_loss: 0.2904 - val_regression_loss: 0.0941 - val_handedness_loss: 0.1949\n",
      "Epoch 23/150\n",
      "2872/2872 [==============================] - 0s 132us/step - loss: 0.2672 - regression_loss: 0.0865 - handedness_loss: 0.1824 - val_loss: 0.2749 - val_regression_loss: 0.0940 - val_handedness_loss: 0.1792\n",
      "Epoch 24/150\n",
      "2872/2872 [==============================] - 0s 128us/step - loss: 0.2641 - regression_loss: 0.0860 - handedness_loss: 0.1786 - val_loss: 0.2744 - val_regression_loss: 0.0895 - val_handedness_loss: 0.1825\n",
      "Epoch 25/150\n",
      "2872/2872 [==============================] - 0s 118us/step - loss: 0.2619 - regression_loss: 0.0833 - handedness_loss: 0.1807 - val_loss: 0.3048 - val_regression_loss: 0.0910 - val_handedness_loss: 0.2096\n",
      "Epoch 26/150\n",
      "2872/2872 [==============================] - 0s 133us/step - loss: 0.2641 - regression_loss: 0.0804 - handedness_loss: 0.1806 - val_loss: 0.2601 - val_regression_loss: 0.0852 - val_handedness_loss: 0.1798\n",
      "Epoch 27/150\n",
      "2872/2872 [==============================] - 0s 133us/step - loss: 0.2576 - regression_loss: 0.0812 - handedness_loss: 0.1759 - val_loss: 0.2641 - val_regression_loss: 0.0837 - val_handedness_loss: 0.1785\n",
      "Epoch 28/150\n",
      "2872/2872 [==============================] - 0s 132us/step - loss: 0.2629 - regression_loss: 0.0801 - handedness_loss: 0.1820 - val_loss: 0.2750 - val_regression_loss: 0.0850 - val_handedness_loss: 0.1863\n",
      "Epoch 29/150\n",
      "2872/2872 [==============================] - 0s 117us/step - loss: 0.2516 - regression_loss: 0.0771 - handedness_loss: 0.1748 - val_loss: 0.2593 - val_regression_loss: 0.0851 - val_handedness_loss: 0.1757\n",
      "Epoch 30/150\n",
      "2872/2872 [==============================] - 0s 150us/step - loss: 0.2443 - regression_loss: 0.0788 - handedness_loss: 0.1658 - val_loss: 0.2379 - val_regression_loss: 0.0826 - val_handedness_loss: 0.1551\n",
      "Epoch 31/150\n",
      "2872/2872 [==============================] - 0s 137us/step - loss: 0.2352 - regression_loss: 0.0757 - handedness_loss: 0.1587 - val_loss: 0.2382 - val_regression_loss: 0.0794 - val_handedness_loss: 0.1563\n",
      "Epoch 32/150\n",
      "2872/2872 [==============================] - 0s 148us/step - loss: 0.2502 - regression_loss: 0.0751 - handedness_loss: 0.1747 - val_loss: 0.2648 - val_regression_loss: 0.0793 - val_handedness_loss: 0.1871\n",
      "Epoch 33/150\n",
      "2872/2872 [==============================] - 0s 125us/step - loss: 0.2489 - regression_loss: 0.0744 - handedness_loss: 0.1742 - val_loss: 0.2214 - val_regression_loss: 0.0754 - val_handedness_loss: 0.1474\n",
      "Epoch 34/150\n",
      "2872/2872 [==============================] - 0s 139us/step - loss: 0.2474 - regression_loss: 0.0724 - handedness_loss: 0.1770 - val_loss: 0.2394 - val_regression_loss: 0.0761 - val_handedness_loss: 0.1641\n",
      "Epoch 35/150\n",
      "2872/2872 [==============================] - 0s 130us/step - loss: 0.2372 - regression_loss: 0.0721 - handedness_loss: 0.1643 - val_loss: 0.2207 - val_regression_loss: 0.0752 - val_handedness_loss: 0.1440\n",
      "Epoch 36/150\n",
      "2872/2872 [==============================] - 0s 132us/step - loss: 0.2303 - regression_loss: 0.0708 - handedness_loss: 0.1574 - val_loss: 0.2336 - val_regression_loss: 0.0755 - val_handedness_loss: 0.1567\n",
      "Epoch 37/150\n",
      "2872/2872 [==============================] - 0s 121us/step - loss: 0.2275 - regression_loss: 0.0711 - handedness_loss: 0.1580 - val_loss: 0.2486 - val_regression_loss: 0.0769 - val_handedness_loss: 0.1684\n",
      "Epoch 38/150\n",
      "2872/2872 [==============================] - 0s 118us/step - loss: 0.2225 - regression_loss: 0.0714 - handedness_loss: 0.1517 - val_loss: 0.2147 - val_regression_loss: 0.0706 - val_handedness_loss: 0.1422\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 39/150\n",
      "2872/2872 [==============================] - 0s 148us/step - loss: 0.2325 - regression_loss: 0.0701 - handedness_loss: 0.1631 - val_loss: 0.2284 - val_regression_loss: 0.0731 - val_handedness_loss: 0.1555\n",
      "Epoch 40/150\n",
      "2872/2872 [==============================] - 0s 150us/step - loss: 0.2249 - regression_loss: 0.0696 - handedness_loss: 0.1562 - val_loss: 0.1934 - val_regression_loss: 0.0713 - val_handedness_loss: 0.1203\n",
      "Epoch 41/150\n",
      "2872/2872 [==============================] - 0s 148us/step - loss: 0.2207 - regression_loss: 0.0692 - handedness_loss: 0.1528 - val_loss: 0.2080 - val_regression_loss: 0.0719 - val_handedness_loss: 0.1337\n",
      "Epoch 42/150\n",
      "2872/2872 [==============================] - 0s 149us/step - loss: 0.2195 - regression_loss: 0.0697 - handedness_loss: 0.1516 - val_loss: 0.2150 - val_regression_loss: 0.0717 - val_handedness_loss: 0.1405\n",
      "Evaluating model with testing data...\n",
      "594/594 [==============================] - 0s 26us/step\n",
      "Getting distribution of predictions and covariance matrix...\n",
      "      1 of 20\n",
      "      2 of 20\n",
      "      3 of 20\n",
      "      4 of 20\n",
      "      5 of 20\n",
      "      6 of 20\n",
      "      7 of 20\n",
      "      8 of 20\n",
      "      9 of 20\n",
      "      10 of 20\n",
      "      11 of 20\n",
      "      12 of 20\n",
      "      13 of 20\n",
      "      14 of 20\n",
      "      15 of 20\n",
      "      16 of 20\n",
      "      17 of 20\n",
      "      18 of 20\n",
      "      19 of 20\n",
      "      20 of 20\n",
      "Computing ensemble means...\n",
      "Computing mean squared error...\n",
      "Iteration 18\n",
      "Train on 3012 samples, validate on 624 samples\n",
      "Epoch 1/150\n",
      "3012/3012 [==============================] - 1s 187us/step - loss: 1.2010 - regression_loss: 0.5073 - handedness_loss: 0.6896 - val_loss: 0.9983 - val_regression_loss: 0.3193 - val_handedness_loss: 0.6785\n",
      "Epoch 2/150\n",
      "3012/3012 [==============================] - 0s 111us/step - loss: 0.9580 - regression_loss: 0.2893 - handedness_loss: 0.6682 - val_loss: 0.9584 - val_regression_loss: 0.2936 - val_handedness_loss: 0.6646\n",
      "Epoch 3/150\n",
      "3012/3012 [==============================] - 0s 146us/step - loss: 0.9099 - regression_loss: 0.2614 - handedness_loss: 0.6487 - val_loss: 0.9143 - val_regression_loss: 0.2656 - val_handedness_loss: 0.6483\n",
      "Epoch 4/150\n",
      "3012/3012 [==============================] - 0s 149us/step - loss: 0.8723 - regression_loss: 0.2378 - handedness_loss: 0.6347 - val_loss: 0.8765 - val_regression_loss: 0.2451 - val_handedness_loss: 0.6308\n",
      "Epoch 5/150\n",
      "3012/3012 [==============================] - 0s 139us/step - loss: 0.8138 - regression_loss: 0.2128 - handedness_loss: 0.6017 - val_loss: 0.8065 - val_regression_loss: 0.2216 - val_handedness_loss: 0.5850\n",
      "Epoch 6/150\n",
      "3012/3012 [==============================] - 0s 148us/step - loss: 0.7350 - regression_loss: 0.1890 - handedness_loss: 0.5464 - val_loss: 0.7307 - val_regression_loss: 0.1980 - val_handedness_loss: 0.5325\n",
      "Epoch 7/150\n",
      "3012/3012 [==============================] - 0s 148us/step - loss: 0.6888 - regression_loss: 0.1715 - handedness_loss: 0.5161 - val_loss: 0.7052 - val_regression_loss: 0.1903 - val_handedness_loss: 0.5139\n",
      "Epoch 8/150\n",
      "3012/3012 [==============================] - 0s 150us/step - loss: 0.6494 - regression_loss: 0.1597 - handedness_loss: 0.4880 - val_loss: 0.6379 - val_regression_loss: 0.1781 - val_handedness_loss: 0.4588\n",
      "Epoch 9/150\n",
      "3012/3012 [==============================] - 0s 147us/step - loss: 0.6161 - regression_loss: 0.1534 - handedness_loss: 0.4616 - val_loss: 0.6501 - val_regression_loss: 0.1683 - val_handedness_loss: 0.4801\n",
      "Epoch 10/150\n",
      "3012/3012 [==============================] - 0s 149us/step - loss: 0.5820 - regression_loss: 0.1434 - handedness_loss: 0.4387 - val_loss: 0.5697 - val_regression_loss: 0.1519 - val_handedness_loss: 0.4173\n",
      "Epoch 11/150\n",
      "3012/3012 [==============================] - 0s 151us/step - loss: 0.5424 - regression_loss: 0.1367 - handedness_loss: 0.4060 - val_loss: 0.5695 - val_regression_loss: 0.1471 - val_handedness_loss: 0.4214\n",
      "Epoch 12/150\n",
      "3012/3012 [==============================] - 0s 151us/step - loss: 0.5474 - regression_loss: 0.1342 - handedness_loss: 0.4131 - val_loss: 0.5474 - val_regression_loss: 0.1405 - val_handedness_loss: 0.4063\n",
      "Epoch 13/150\n",
      "3012/3012 [==============================] - 0s 147us/step - loss: 0.5172 - regression_loss: 0.1267 - handedness_loss: 0.3917 - val_loss: 0.5394 - val_regression_loss: 0.1362 - val_handedness_loss: 0.4023\n",
      "Epoch 14/150\n",
      "3012/3012 [==============================] - 0s 129us/step - loss: 0.5040 - regression_loss: 0.1232 - handedness_loss: 0.3815 - val_loss: 0.5212 - val_regression_loss: 0.1318 - val_handedness_loss: 0.3886\n",
      "Epoch 15/150\n",
      "3012/3012 [==============================] - 0s 139us/step - loss: 0.4931 - regression_loss: 0.1191 - handedness_loss: 0.3729 - val_loss: 0.5109 - val_regression_loss: 0.1283 - val_handedness_loss: 0.3821\n",
      "Epoch 16/150\n",
      "3012/3012 [==============================] - 0s 139us/step - loss: 0.4784 - regression_loss: 0.1136 - handedness_loss: 0.3644 - val_loss: 0.5056 - val_regression_loss: 0.1231 - val_handedness_loss: 0.3823\n",
      "Epoch 17/150\n",
      "3012/3012 [==============================] - 0s 144us/step - loss: 0.4668 - regression_loss: 0.1113 - handedness_loss: 0.3548 - val_loss: 0.4708 - val_regression_loss: 0.1171 - val_handedness_loss: 0.3533\n",
      "Epoch 18/150\n",
      "3012/3012 [==============================] - 0s 139us/step - loss: 0.4585 - regression_loss: 0.1070 - handedness_loss: 0.3543 - val_loss: 0.4714 - val_regression_loss: 0.1123 - val_handedness_loss: 0.3584\n",
      "Epoch 19/150\n",
      "3012/3012 [==============================] - 0s 108us/step - loss: 0.4524 - regression_loss: 0.1035 - handedness_loss: 0.3491 - val_loss: 0.4813 - val_regression_loss: 0.1101 - val_handedness_loss: 0.3711\n",
      "Epoch 20/150\n",
      "3012/3012 [==============================] - 0s 108us/step - loss: 0.4607 - regression_loss: 0.1016 - handedness_loss: 0.3590 - val_loss: 0.4687 - val_regression_loss: 0.1048 - val_handedness_loss: 0.3640\n",
      "Epoch 21/150\n",
      "3012/3012 [==============================] - 0s 150us/step - loss: 0.4389 - regression_loss: 0.0968 - handedness_loss: 0.3424 - val_loss: 0.4482 - val_regression_loss: 0.1024 - val_handedness_loss: 0.3447\n",
      "Epoch 22/150\n",
      "3012/3012 [==============================] - 0s 147us/step - loss: 0.4376 - regression_loss: 0.0944 - handedness_loss: 0.3449 - val_loss: 0.4400 - val_regression_loss: 0.0997 - val_handedness_loss: 0.3394\n",
      "Epoch 23/150\n",
      "3012/3012 [==============================] - 0s 124us/step - loss: 0.4179 - regression_loss: 0.0923 - handedness_loss: 0.3260 - val_loss: 0.4505 - val_regression_loss: 0.0978 - val_handedness_loss: 0.3524\n",
      "Epoch 24/150\n",
      "3012/3012 [==============================] - 0s 126us/step - loss: 0.4197 - regression_loss: 0.0903 - handedness_loss: 0.3289 - val_loss: 0.4270 - val_regression_loss: 0.0934 - val_handedness_loss: 0.3331\n",
      "Epoch 25/150\n",
      "3012/3012 [==============================] - 0s 149us/step - loss: 0.4162 - regression_loss: 0.0885 - handedness_loss: 0.3281 - val_loss: 0.4699 - val_regression_loss: 0.0934 - val_handedness_loss: 0.3765\n",
      "Epoch 26/150\n",
      "3012/3012 [==============================] - 0s 149us/step - loss: 0.4072 - regression_loss: 0.0855 - handedness_loss: 0.3208 - val_loss: 0.4073 - val_regression_loss: 0.0896 - val_handedness_loss: 0.3169\n",
      "Epoch 27/150\n",
      "3012/3012 [==============================] - 0s 136us/step - loss: 0.4111 - regression_loss: 0.0851 - handedness_loss: 0.3262 - val_loss: 0.4298 - val_regression_loss: 0.0870 - val_handedness_loss: 0.3424\n",
      "Epoch 28/150\n",
      "3012/3012 [==============================] - 0s 118us/step - loss: 0.3947 - regression_loss: 0.0837 - handedness_loss: 0.3113 - val_loss: 0.4142 - val_regression_loss: 0.0874 - val_handedness_loss: 0.3267\n",
      "Epoch 29/150\n",
      "3012/3012 [==============================] - 0s 149us/step - loss: 0.3898 - regression_loss: 0.0824 - handedness_loss: 0.3067 - val_loss: 0.3988 - val_regression_loss: 0.0837 - val_handedness_loss: 0.3159\n",
      "Epoch 30/150\n",
      "3012/3012 [==============================] - 0s 148us/step - loss: 0.3957 - regression_loss: 0.0808 - handedness_loss: 0.3142 - val_loss: 0.4428 - val_regression_loss: 0.0843 - val_handedness_loss: 0.3581\n",
      "Epoch 31/150\n",
      "3012/3012 [==============================] - 0s 150us/step - loss: 0.3945 - regression_loss: 0.0807 - handedness_loss: 0.3131 - val_loss: 0.4054 - val_regression_loss: 0.0829 - val_handedness_loss: 0.3220\n",
      "Epoch 32/150\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3012/3012 [==============================] - 0s 147us/step - loss: 0.3910 - regression_loss: 0.0792 - handedness_loss: 0.3114 - val_loss: 0.4129 - val_regression_loss: 0.0820 - val_handedness_loss: 0.3307\n",
      "Epoch 33/150\n",
      "3012/3012 [==============================] - 0s 151us/step - loss: 0.3859 - regression_loss: 0.0783 - handedness_loss: 0.3074 - val_loss: 0.3940 - val_regression_loss: 0.0812 - val_handedness_loss: 0.3130\n",
      "Epoch 34/150\n",
      "3012/3012 [==============================] - 0s 151us/step - loss: 0.3749 - regression_loss: 0.0775 - handedness_loss: 0.2969 - val_loss: 0.3677 - val_regression_loss: 0.0797 - val_handedness_loss: 0.2883\n",
      "Epoch 35/150\n",
      "3012/3012 [==============================] - 0s 137us/step - loss: 0.3728 - regression_loss: 0.0769 - handedness_loss: 0.2956 - val_loss: 0.3975 - val_regression_loss: 0.0802 - val_handedness_loss: 0.3160\n",
      "Epoch 36/150\n",
      "3012/3012 [==============================] - 0s 150us/step - loss: 0.3754 - regression_loss: 0.0771 - handedness_loss: 0.2997 - val_loss: 0.3909 - val_regression_loss: 0.0778 - val_handedness_loss: 0.3126\n",
      "Epoch 37/150\n",
      "3012/3012 [==============================] - 0s 150us/step - loss: 0.3767 - regression_loss: 0.0762 - handedness_loss: 0.3006 - val_loss: 0.4238 - val_regression_loss: 0.0794 - val_handedness_loss: 0.3431\n",
      "Epoch 38/150\n",
      "3012/3012 [==============================] - 0s 125us/step - loss: 0.3841 - regression_loss: 0.0760 - handedness_loss: 0.3090 - val_loss: 0.3747 - val_regression_loss: 0.0766 - val_handedness_loss: 0.2978\n",
      "Evaluating model with testing data...\n",
      "624/624 [==============================] - 0s 26us/step\n",
      "Getting distribution of predictions and covariance matrix...\n",
      "      1 of 20\n",
      "      2 of 20\n",
      "      3 of 20\n",
      "      4 of 20\n",
      "      5 of 20\n",
      "      6 of 20\n",
      "      7 of 20\n",
      "      8 of 20\n",
      "      9 of 20\n",
      "      10 of 20\n",
      "      11 of 20\n",
      "      12 of 20\n",
      "      13 of 20\n",
      "      14 of 20\n",
      "      15 of 20\n",
      "      16 of 20\n",
      "      17 of 20\n",
      "      18 of 20\n",
      "      19 of 20\n",
      "      20 of 20\n",
      "Computing ensemble means...\n",
      "Computing mean squared error...\n",
      "Iteration 19\n",
      "Train on 3152 samples, validate on 654 samples\n",
      "Epoch 1/150\n",
      "3152/3152 [==============================] - 0s 142us/step - loss: 1.2936 - regression_loss: 0.5874 - handedness_loss: 0.7018 - val_loss: 1.0128 - val_regression_loss: 0.3198 - val_handedness_loss: 0.6934\n",
      "Epoch 2/150\n",
      "3152/3152 [==============================] - 0s 101us/step - loss: 0.9782 - regression_loss: 0.2845 - handedness_loss: 0.6929 - val_loss: 0.9746 - val_regression_loss: 0.2809 - val_handedness_loss: 0.6933\n",
      "Epoch 3/150\n",
      "3152/3152 [==============================] - 0s 123us/step - loss: 0.9346 - regression_loss: 0.2438 - handedness_loss: 0.6905 - val_loss: 0.9334 - val_regression_loss: 0.2461 - val_handedness_loss: 0.6883\n",
      "Epoch 4/150\n",
      "3152/3152 [==============================] - 0s 149us/step - loss: 0.8993 - regression_loss: 0.2165 - handedness_loss: 0.6823 - val_loss: 0.8917 - val_regression_loss: 0.2109 - val_handedness_loss: 0.6780\n",
      "Epoch 5/150\n",
      "3152/3152 [==============================] - 0s 146us/step - loss: 0.8605 - regression_loss: 0.1893 - handedness_loss: 0.6709 - val_loss: 0.8652 - val_regression_loss: 0.1957 - val_handedness_loss: 0.6775\n",
      "Epoch 6/150\n",
      "3152/3152 [==============================] - 0s 116us/step - loss: 0.8295 - regression_loss: 0.1701 - handedness_loss: 0.6595 - val_loss: 0.8403 - val_regression_loss: 0.1772 - val_handedness_loss: 0.6694\n",
      "Epoch 7/150\n",
      "3152/3152 [==============================] - 0s 116us/step - loss: 0.8100 - regression_loss: 0.1610 - handedness_loss: 0.6486 - val_loss: 0.8148 - val_regression_loss: 0.1704 - val_handedness_loss: 0.6565\n",
      "Epoch 8/150\n",
      "3152/3152 [==============================] - 0s 131us/step - loss: 0.7889 - regression_loss: 0.1494 - handedness_loss: 0.6401 - val_loss: 0.7894 - val_regression_loss: 0.1486 - val_handedness_loss: 0.6495\n",
      "Epoch 9/150\n",
      "3152/3152 [==============================] - 0s 146us/step - loss: 0.7672 - regression_loss: 0.1408 - handedness_loss: 0.6271 - val_loss: 0.7769 - val_regression_loss: 0.1426 - val_handedness_loss: 0.6338\n",
      "Epoch 10/150\n",
      "3152/3152 [==============================] - 0s 144us/step - loss: 0.7532 - regression_loss: 0.1303 - handedness_loss: 0.6226 - val_loss: 0.7599 - val_regression_loss: 0.1343 - val_handedness_loss: 0.6357\n",
      "Epoch 11/150\n",
      "3152/3152 [==============================] - 0s 123us/step - loss: 0.7364 - regression_loss: 0.1243 - handedness_loss: 0.6120 - val_loss: 0.7521 - val_regression_loss: 0.1352 - val_handedness_loss: 0.6169\n",
      "Epoch 12/150\n",
      "3152/3152 [==============================] - 0s 148us/step - loss: 0.7232 - regression_loss: 0.1200 - handedness_loss: 0.6032 - val_loss: 0.7410 - val_regression_loss: 0.1258 - val_handedness_loss: 0.6204\n",
      "Epoch 13/150\n",
      "3152/3152 [==============================] - 0s 120us/step - loss: 0.7201 - regression_loss: 0.1143 - handedness_loss: 0.6050 - val_loss: 0.7450 - val_regression_loss: 0.1237 - val_handedness_loss: 0.6291\n",
      "Epoch 14/150\n",
      "3152/3152 [==============================] - 0s 130us/step - loss: 0.7117 - regression_loss: 0.1112 - handedness_loss: 0.6006 - val_loss: 0.7046 - val_regression_loss: 0.1163 - val_handedness_loss: 0.6038\n",
      "Epoch 15/150\n",
      "3152/3152 [==============================] - 0s 146us/step - loss: 0.7147 - regression_loss: 0.1096 - handedness_loss: 0.6051 - val_loss: 0.6969 - val_regression_loss: 0.1080 - val_handedness_loss: 0.5911\n",
      "Epoch 16/150\n",
      "3152/3152 [==============================] - 0s 150us/step - loss: 0.6982 - regression_loss: 0.1067 - handedness_loss: 0.5903 - val_loss: 0.6999 - val_regression_loss: 0.1060 - val_handedness_loss: 0.6095\n",
      "Epoch 17/150\n",
      "3152/3152 [==============================] - 0s 144us/step - loss: 0.6983 - regression_loss: 0.1023 - handedness_loss: 0.5954 - val_loss: 0.7160 - val_regression_loss: 0.1091 - val_handedness_loss: 0.6131\n",
      "Epoch 18/150\n",
      "3152/3152 [==============================] - 0s 135us/step - loss: 0.6954 - regression_loss: 0.1012 - handedness_loss: 0.5957 - val_loss: 0.6947 - val_regression_loss: 0.1008 - val_handedness_loss: 0.6099\n",
      "Epoch 19/150\n",
      "3152/3152 [==============================] - 0s 139us/step - loss: 0.6862 - regression_loss: 0.0992 - handedness_loss: 0.5872 - val_loss: 0.6976 - val_regression_loss: 0.1044 - val_handedness_loss: 0.6052\n",
      "Evaluating model with testing data...\n",
      "654/654 [==============================] - 0s 30us/step\n",
      "Getting distribution of predictions and covariance matrix...\n",
      "      1 of 20\n",
      "      2 of 20\n",
      "      3 of 20\n",
      "      4 of 20\n",
      "      5 of 20\n",
      "      6 of 20\n",
      "      7 of 20\n",
      "      8 of 20\n",
      "      9 of 20\n",
      "      10 of 20\n",
      "      11 of 20\n",
      "      12 of 20\n",
      "      13 of 20\n",
      "      14 of 20\n",
      "      15 of 20\n",
      "      16 of 20\n",
      "      17 of 20\n",
      "      18 of 20\n",
      "      19 of 20\n",
      "      20 of 20\n",
      "Computing ensemble means...\n",
      "Computing mean squared error...\n",
      "Iteration 20\n",
      "Train on 3292 samples, validate on 684 samples\n",
      "Epoch 1/150\n",
      "3292/3292 [==============================] - 1s 167us/step - loss: 1.2636 - regression_loss: 0.5628 - handedness_loss: 0.6975 - val_loss: 0.9613 - val_regression_loss: 0.2866 - val_handedness_loss: 0.6727\n",
      "Epoch 2/150\n",
      "3292/3292 [==============================] - 0s 115us/step - loss: 0.9001 - regression_loss: 0.2413 - handedness_loss: 0.6584 - val_loss: 0.8560 - val_regression_loss: 0.2095 - val_handedness_loss: 0.6468\n",
      "Epoch 3/150\n",
      "3292/3292 [==============================] - 0s 117us/step - loss: 0.8035 - regression_loss: 0.1812 - handedness_loss: 0.6217 - val_loss: 0.7731 - val_regression_loss: 0.1632 - val_handedness_loss: 0.6087\n",
      "Epoch 4/150\n",
      "3292/3292 [==============================] - 0s 145us/step - loss: 0.7474 - regression_loss: 0.1529 - handedness_loss: 0.5938 - val_loss: 0.7118 - val_regression_loss: 0.1493 - val_handedness_loss: 0.5621\n",
      "Epoch 5/150\n",
      "3292/3292 [==============================] - 0s 119us/step - loss: 0.6942 - regression_loss: 0.1428 - handedness_loss: 0.5513 - val_loss: 0.6735 - val_regression_loss: 0.1434 - val_handedness_loss: 0.5328\n",
      "Epoch 6/150\n",
      "3292/3292 [==============================] - 0s 120us/step - loss: 0.6633 - regression_loss: 0.1377 - handedness_loss: 0.5250 - val_loss: 0.6439 - val_regression_loss: 0.1386 - val_handedness_loss: 0.5066\n",
      "Epoch 7/150\n",
      "3292/3292 [==============================] - 0s 118us/step - loss: 0.6331 - regression_loss: 0.1348 - handedness_loss: 0.4979 - val_loss: 0.6025 - val_regression_loss: 0.1327 - val_handedness_loss: 0.4689\n",
      "Epoch 8/150\n",
      "3292/3292 [==============================] - 0s 118us/step - loss: 0.5879 - regression_loss: 0.1272 - handedness_loss: 0.4608 - val_loss: 0.5795 - val_regression_loss: 0.1289 - val_handedness_loss: 0.4497\n",
      "Epoch 9/150\n",
      "3292/3292 [==============================] - 0s 128us/step - loss: 0.5616 - regression_loss: 0.1285 - handedness_loss: 0.4328 - val_loss: 0.5419 - val_regression_loss: 0.1342 - val_handedness_loss: 0.4059\n",
      "Epoch 10/150\n",
      "3292/3292 [==============================] - 0s 128us/step - loss: 0.5290 - regression_loss: 0.1220 - handedness_loss: 0.4072 - val_loss: 0.5314 - val_regression_loss: 0.1272 - val_handedness_loss: 0.4014\n",
      "Epoch 11/150\n",
      "3292/3292 [==============================] - 0s 140us/step - loss: 0.4917 - regression_loss: 0.1177 - handedness_loss: 0.3742 - val_loss: 0.5056 - val_regression_loss: 0.1172 - val_handedness_loss: 0.3833\n",
      "Epoch 12/150\n",
      "3292/3292 [==============================] - 0s 122us/step - loss: 0.4897 - regression_loss: 0.1181 - handedness_loss: 0.3716 - val_loss: 0.4854 - val_regression_loss: 0.1145 - val_handedness_loss: 0.3566\n",
      "Epoch 13/150\n",
      "3292/3292 [==============================] - 0s 150us/step - loss: 0.4587 - regression_loss: 0.1141 - handedness_loss: 0.3450 - val_loss: 0.4602 - val_regression_loss: 0.1161 - val_handedness_loss: 0.3566\n",
      "Epoch 14/150\n",
      "3292/3292 [==============================] - 0s 137us/step - loss: 0.4491 - regression_loss: 0.1131 - handedness_loss: 0.3365 - val_loss: 0.4387 - val_regression_loss: 0.1154 - val_handedness_loss: 0.3279\n",
      "Epoch 15/150\n",
      "3292/3292 [==============================] - 0s 119us/step - loss: 0.4383 - regression_loss: 0.1097 - handedness_loss: 0.3285 - val_loss: 0.4339 - val_regression_loss: 0.1124 - val_handedness_loss: 0.3222\n",
      "Epoch 16/150\n",
      "3292/3292 [==============================] - 0s 126us/step - loss: 0.4385 - regression_loss: 0.1104 - handedness_loss: 0.3281 - val_loss: 0.4200 - val_regression_loss: 0.1067 - val_handedness_loss: 0.3085\n",
      "Epoch 17/150\n",
      "3292/3292 [==============================] - 0s 150us/step - loss: 0.4077 - regression_loss: 0.1052 - handedness_loss: 0.3029 - val_loss: 0.4169 - val_regression_loss: 0.1056 - val_handedness_loss: 0.2986\n",
      "Epoch 18/150\n",
      "3292/3292 [==============================] - 0s 96us/step - loss: 0.4002 - regression_loss: 0.1009 - handedness_loss: 0.2986 - val_loss: 0.3858 - val_regression_loss: 0.1007 - val_handedness_loss: 0.2805\n",
      "Epoch 19/150\n",
      "3292/3292 [==============================] - 0s 83us/step - loss: 0.4001 - regression_loss: 0.0973 - handedness_loss: 0.3022 - val_loss: 0.3741 - val_regression_loss: 0.0967 - val_handedness_loss: 0.2746\n",
      "Epoch 20/150\n",
      "3292/3292 [==============================] - 0s 84us/step - loss: 0.3787 - regression_loss: 0.0946 - handedness_loss: 0.2835 - val_loss: 0.4006 - val_regression_loss: 0.0987 - val_handedness_loss: 0.2930\n",
      "Epoch 21/150\n",
      "3292/3292 [==============================] - 0s 101us/step - loss: 0.3591 - regression_loss: 0.0924 - handedness_loss: 0.2672 - val_loss: 0.3610 - val_regression_loss: 0.0901 - val_handedness_loss: 0.2763\n",
      "Epoch 22/150\n",
      "3292/3292 [==============================] - 0s 139us/step - loss: 0.3409 - regression_loss: 0.0896 - handedness_loss: 0.2510 - val_loss: 0.3515 - val_regression_loss: 0.0901 - val_handedness_loss: 0.2624\n",
      "Epoch 23/150\n",
      "3292/3292 [==============================] - 0s 139us/step - loss: 0.3448 - regression_loss: 0.0866 - handedness_loss: 0.2586 - val_loss: 0.3419 - val_regression_loss: 0.0872 - val_handedness_loss: 0.2544\n",
      "Epoch 24/150\n",
      "3292/3292 [==============================] - 0s 139us/step - loss: 0.3562 - regression_loss: 0.0860 - handedness_loss: 0.2709 - val_loss: 0.3697 - val_regression_loss: 0.0864 - val_handedness_loss: 0.2844\n",
      "Epoch 25/150\n",
      "3292/3292 [==============================] - 0s 132us/step - loss: 0.3480 - regression_loss: 0.0845 - handedness_loss: 0.2644 - val_loss: 0.3419 - val_regression_loss: 0.0848 - val_handedness_loss: 0.2509\n",
      "Epoch 26/150\n",
      "3292/3292 [==============================] - 0s 129us/step - loss: 0.3299 - regression_loss: 0.0816 - handedness_loss: 0.2483 - val_loss: 0.3322 - val_regression_loss: 0.0825 - val_handedness_loss: 0.2542\n",
      "Epoch 27/150\n",
      "3292/3292 [==============================] - 0s 108us/step - loss: 0.3351 - regression_loss: 0.0811 - handedness_loss: 0.2534 - val_loss: 0.3284 - val_regression_loss: 0.0806 - val_handedness_loss: 0.2404\n",
      "Epoch 28/150\n",
      "3292/3292 [==============================] - 0s 109us/step - loss: 0.3149 - regression_loss: 0.0790 - handedness_loss: 0.2353 - val_loss: 0.3315 - val_regression_loss: 0.0789 - val_handedness_loss: 0.2479\n",
      "Epoch 29/150\n",
      "3292/3292 [==============================] - 0s 110us/step - loss: 0.3209 - regression_loss: 0.0776 - handedness_loss: 0.2431 - val_loss: 0.3300 - val_regression_loss: 0.0780 - val_handedness_loss: 0.2645\n",
      "Epoch 30/150\n",
      "3292/3292 [==============================] - 0s 108us/step - loss: 0.3154 - regression_loss: 0.0774 - handedness_loss: 0.2375 - val_loss: 0.3145 - val_regression_loss: 0.0776 - val_handedness_loss: 0.2351\n",
      "Epoch 31/150\n",
      "3292/3292 [==============================] - 0s 110us/step - loss: 0.3228 - regression_loss: 0.0770 - handedness_loss: 0.2461 - val_loss: 0.3090 - val_regression_loss: 0.0743 - val_handedness_loss: 0.2306\n",
      "Epoch 32/150\n",
      "3292/3292 [==============================] - 0s 114us/step - loss: 0.3210 - regression_loss: 0.0761 - handedness_loss: 0.2451 - val_loss: 0.3192 - val_regression_loss: 0.0751 - val_handedness_loss: 0.2409\n",
      "Epoch 33/150\n",
      "3292/3292 [==============================] - 0s 132us/step - loss: 0.3130 - regression_loss: 0.0744 - handedness_loss: 0.2385 - val_loss: 0.3137 - val_regression_loss: 0.0746 - val_handedness_loss: 0.2389\n",
      "Epoch 34/150\n",
      "3292/3292 [==============================] - 0s 112us/step - loss: 0.3100 - regression_loss: 0.0745 - handedness_loss: 0.2352 - val_loss: 0.3171 - val_regression_loss: 0.0731 - val_handedness_loss: 0.2388\n",
      "Epoch 35/150\n",
      "3292/3292 [==============================] - 0s 124us/step - loss: 0.3061 - regression_loss: 0.0751 - handedness_loss: 0.2308 - val_loss: 0.3279 - val_regression_loss: 0.0732 - val_handedness_loss: 0.2430\n",
      "Evaluating model with testing data...\n",
      "684/684 [==============================] - 0s 22us/step\n",
      "Getting distribution of predictions and covariance matrix...\n",
      "      1 of 20\n",
      "      2 of 20\n",
      "      3 of 20\n",
      "      4 of 20\n",
      "      5 of 20\n",
      "      6 of 20\n",
      "      7 of 20\n",
      "      8 of 20\n",
      "      9 of 20\n",
      "      10 of 20\n",
      "      11 of 20\n",
      "      12 of 20\n",
      "      13 of 20\n",
      "      14 of 20\n",
      "      15 of 20\n",
      "      16 of 20\n",
      "      17 of 20\n",
      "      18 of 20\n",
      "      19 of 20\n",
      "      20 of 20\n",
      "Computing ensemble means...\n",
      "Computing mean squared error...\n",
      "Iteration 21\n",
      "Train on 3432 samples, validate on 714 samples\n",
      "Epoch 1/150\n",
      "3432/3432 [==============================] - 0s 139us/step - loss: 1.3927 - regression_loss: 0.7231 - handedness_loss: 0.6665 - val_loss: 0.9591 - val_regression_loss: 0.3300 - val_handedness_loss: 0.6327\n",
      "Epoch 2/150\n",
      "3432/3432 [==============================] - 0s 94us/step - loss: 0.8733 - regression_loss: 0.2808 - handedness_loss: 0.5924 - val_loss: 0.8408 - val_regression_loss: 0.2640 - val_handedness_loss: 0.5782\n",
      "Epoch 3/150\n",
      "3432/3432 [==============================] - 0s 99us/step - loss: 0.7634 - regression_loss: 0.2218 - handedness_loss: 0.5412 - val_loss: 0.7793 - val_regression_loss: 0.2241 - val_handedness_loss: 0.5569\n",
      "Epoch 4/150\n",
      "3432/3432 [==============================] - 0s 101us/step - loss: 0.6894 - regression_loss: 0.1897 - handedness_loss: 0.4992 - val_loss: 0.7152 - val_regression_loss: 0.1948 - val_handedness_loss: 0.5213\n",
      "Epoch 5/150\n",
      "3432/3432 [==============================] - 0s 119us/step - loss: 0.6340 - regression_loss: 0.1760 - handedness_loss: 0.4580 - val_loss: 0.6297 - val_regression_loss: 0.1840 - val_handedness_loss: 0.4483\n",
      "Epoch 6/150\n",
      "3432/3432 [==============================] - 0s 105us/step - loss: 0.5777 - regression_loss: 0.1618 - handedness_loss: 0.4163 - val_loss: 0.6104 - val_regression_loss: 0.1783 - val_handedness_loss: 0.4330\n",
      "Epoch 7/150\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3432/3432 [==============================] - 0s 104us/step - loss: 0.5279 - regression_loss: 0.1507 - handedness_loss: 0.3773 - val_loss: 0.5695 - val_regression_loss: 0.1711 - val_handedness_loss: 0.3976\n",
      "Epoch 8/150\n",
      "3432/3432 [==============================] - 0s 109us/step - loss: 0.4953 - regression_loss: 0.1441 - handedness_loss: 0.3514 - val_loss: 0.5122 - val_regression_loss: 0.1596 - val_handedness_loss: 0.3523\n",
      "Epoch 9/150\n",
      "3432/3432 [==============================] - 0s 121us/step - loss: 0.4655 - regression_loss: 0.1361 - handedness_loss: 0.3291 - val_loss: 0.5016 - val_regression_loss: 0.1510 - val_handedness_loss: 0.3522\n",
      "Epoch 10/150\n",
      "3432/3432 [==============================] - 0s 118us/step - loss: 0.4279 - regression_loss: 0.1257 - handedness_loss: 0.3024 - val_loss: 0.4638 - val_regression_loss: 0.1369 - val_handedness_loss: 0.3302\n",
      "Epoch 11/150\n",
      "3432/3432 [==============================] - 0s 121us/step - loss: 0.4050 - regression_loss: 0.1169 - handedness_loss: 0.2878 - val_loss: 0.4301 - val_regression_loss: 0.1353 - val_handedness_loss: 0.2910\n",
      "Epoch 12/150\n",
      "3432/3432 [==============================] - 0s 118us/step - loss: 0.3817 - regression_loss: 0.1145 - handedness_loss: 0.2671 - val_loss: 0.4222 - val_regression_loss: 0.1274 - val_handedness_loss: 0.2983\n",
      "Epoch 13/150\n",
      "3432/3432 [==============================] - 0s 121us/step - loss: 0.3737 - regression_loss: 0.1110 - handedness_loss: 0.2629 - val_loss: 0.3863 - val_regression_loss: 0.1280 - val_handedness_loss: 0.2635\n",
      "Epoch 14/150\n",
      "3432/3432 [==============================] - 0s 119us/step - loss: 0.3646 - regression_loss: 0.1098 - handedness_loss: 0.2544 - val_loss: 0.3869 - val_regression_loss: 0.1256 - val_handedness_loss: 0.2636\n",
      "Epoch 15/150\n",
      "3432/3432 [==============================] - 0s 123us/step - loss: 0.3475 - regression_loss: 0.1085 - handedness_loss: 0.2390 - val_loss: 0.3776 - val_regression_loss: 0.1205 - val_handedness_loss: 0.2687\n",
      "Epoch 16/150\n",
      "3432/3432 [==============================] - 0s 118us/step - loss: 0.3414 - regression_loss: 0.1025 - handedness_loss: 0.2389 - val_loss: 0.3576 - val_regression_loss: 0.1146 - val_handedness_loss: 0.2427\n",
      "Epoch 17/150\n",
      "3432/3432 [==============================] - 0s 117us/step - loss: 0.3312 - regression_loss: 0.0994 - handedness_loss: 0.2314 - val_loss: 0.3465 - val_regression_loss: 0.1119 - val_handedness_loss: 0.2365\n",
      "Epoch 18/150\n",
      "3432/3432 [==============================] - 0s 124us/step - loss: 0.3059 - regression_loss: 0.0943 - handedness_loss: 0.2115 - val_loss: 0.3439 - val_regression_loss: 0.1065 - val_handedness_loss: 0.2421\n",
      "Epoch 19/150\n",
      "3432/3432 [==============================] - 0s 133us/step - loss: 0.3020 - regression_loss: 0.0916 - handedness_loss: 0.2108 - val_loss: 0.3372 - val_regression_loss: 0.1045 - val_handedness_loss: 0.2378\n",
      "Epoch 20/150\n",
      "3432/3432 [==============================] - 0s 136us/step - loss: 0.3043 - regression_loss: 0.0895 - handedness_loss: 0.2147 - val_loss: 0.3057 - val_regression_loss: 0.0980 - val_handedness_loss: 0.2073\n",
      "Epoch 21/150\n",
      "3432/3432 [==============================] - 0s 141us/step - loss: 0.2930 - regression_loss: 0.0871 - handedness_loss: 0.2067 - val_loss: 0.3478 - val_regression_loss: 0.0987 - val_handedness_loss: 0.2507\n",
      "Epoch 22/150\n",
      "3432/3432 [==============================] - 0s 145us/step - loss: 0.2969 - regression_loss: 0.0862 - handedness_loss: 0.2107 - val_loss: 0.3079 - val_regression_loss: 0.0958 - val_handedness_loss: 0.2138\n",
      "Epoch 23/150\n",
      "3432/3432 [==============================] - 0s 131us/step - loss: 0.2920 - regression_loss: 0.0847 - handedness_loss: 0.2075 - val_loss: 0.3153 - val_regression_loss: 0.0943 - val_handedness_loss: 0.2256\n",
      "Epoch 24/150\n",
      "3432/3432 [==============================] - 0s 130us/step - loss: 0.2798 - regression_loss: 0.0829 - handedness_loss: 0.1969 - val_loss: 0.2796 - val_regression_loss: 0.0932 - val_handedness_loss: 0.1878\n",
      "Epoch 25/150\n",
      "3432/3432 [==============================] - 0s 131us/step - loss: 0.2818 - regression_loss: 0.0816 - handedness_loss: 0.2002 - val_loss: 0.3066 - val_regression_loss: 0.0934 - val_handedness_loss: 0.2178\n",
      "Epoch 26/150\n",
      "3432/3432 [==============================] - 0s 130us/step - loss: 0.2692 - regression_loss: 0.0780 - handedness_loss: 0.1911 - val_loss: 0.3211 - val_regression_loss: 0.0906 - val_handedness_loss: 0.2305\n",
      "Epoch 27/150\n",
      "3432/3432 [==============================] - 0s 132us/step - loss: 0.2732 - regression_loss: 0.0788 - handedness_loss: 0.1943 - val_loss: 0.2900 - val_regression_loss: 0.0903 - val_handedness_loss: 0.2045\n",
      "Epoch 28/150\n",
      "3432/3432 [==============================] - 0s 109us/step - loss: 0.2632 - regression_loss: 0.0784 - handedness_loss: 0.1845 - val_loss: 0.2684 - val_regression_loss: 0.0856 - val_handedness_loss: 0.1876\n",
      "Epoch 29/150\n",
      "3432/3432 [==============================] - 0s 103us/step - loss: 0.2651 - regression_loss: 0.0764 - handedness_loss: 0.1891 - val_loss: 0.2658 - val_regression_loss: 0.0858 - val_handedness_loss: 0.1830\n",
      "Epoch 30/150\n",
      "3432/3432 [==============================] - 0s 137us/step - loss: 0.2608 - regression_loss: 0.0759 - handedness_loss: 0.1848 - val_loss: 0.2715 - val_regression_loss: 0.0830 - val_handedness_loss: 0.1866\n",
      "Epoch 31/150\n",
      "3432/3432 [==============================] - 0s 138us/step - loss: 0.2642 - regression_loss: 0.0760 - handedness_loss: 0.1886 - val_loss: 0.2842 - val_regression_loss: 0.0832 - val_handedness_loss: 0.2028\n",
      "Epoch 32/150\n",
      "3432/3432 [==============================] - 0s 116us/step - loss: 0.2584 - regression_loss: 0.0742 - handedness_loss: 0.1845 - val_loss: 0.2775 - val_regression_loss: 0.0820 - val_handedness_loss: 0.1979\n",
      "Epoch 33/150\n",
      "3432/3432 [==============================] - 0s 105us/step - loss: 0.2379 - regression_loss: 0.0722 - handedness_loss: 0.1658 - val_loss: 0.2963 - val_regression_loss: 0.0851 - val_handedness_loss: 0.2126\n",
      "Evaluating model with testing data...\n",
      "714/714 [==============================] - 0s 24us/step\n",
      "Getting distribution of predictions and covariance matrix...\n",
      "      1 of 20\n",
      "      2 of 20\n",
      "      3 of 20\n",
      "      4 of 20\n",
      "      5 of 20\n",
      "      6 of 20\n",
      "      7 of 20\n",
      "      8 of 20\n",
      "      9 of 20\n",
      "      10 of 20\n",
      "      11 of 20\n",
      "      12 of 20\n",
      "      13 of 20\n",
      "      14 of 20\n",
      "      15 of 20\n",
      "      16 of 20\n",
      "      17 of 20\n",
      "      18 of 20\n",
      "      19 of 20\n",
      "      20 of 20\n",
      "Computing ensemble means...\n",
      "Computing mean squared error...\n",
      "Iteration 22\n",
      "Train on 3572 samples, validate on 744 samples\n",
      "Epoch 1/150\n",
      "3572/3572 [==============================] - 1s 151us/step - loss: 1.0961 - regression_loss: 0.3955 - handedness_loss: 0.6996 - val_loss: 0.8959 - val_regression_loss: 0.1976 - val_handedness_loss: 0.6981\n",
      "Epoch 2/150\n",
      "3572/3572 [==============================] - 0s 86us/step - loss: 0.8455 - regression_loss: 0.1748 - handedness_loss: 0.6705 - val_loss: 0.8534 - val_regression_loss: 0.1759 - val_handedness_loss: 0.6779\n",
      "Epoch 3/150\n",
      "3572/3572 [==============================] - 0s 101us/step - loss: 0.8141 - regression_loss: 0.1626 - handedness_loss: 0.6515 - val_loss: 0.8256 - val_regression_loss: 0.1655 - val_handedness_loss: 0.6606\n",
      "Epoch 4/150\n",
      "3572/3572 [==============================] - 0s 111us/step - loss: 0.7760 - regression_loss: 0.1496 - handedness_loss: 0.6262 - val_loss: 0.7884 - val_regression_loss: 0.1573 - val_handedness_loss: 0.6305\n",
      "Epoch 5/150\n",
      "3572/3572 [==============================] - 0s 99us/step - loss: 0.7495 - regression_loss: 0.1434 - handedness_loss: 0.6060 - val_loss: 0.7557 - val_regression_loss: 0.1517 - val_handedness_loss: 0.6030\n",
      "Epoch 6/150\n",
      "3572/3572 [==============================] - 0s 133us/step - loss: 0.7153 - regression_loss: 0.1403 - handedness_loss: 0.5751 - val_loss: 0.7149 - val_regression_loss: 0.1386 - val_handedness_loss: 0.5752\n",
      "Epoch 7/150\n",
      "3572/3572 [==============================] - 0s 134us/step - loss: 0.6740 - regression_loss: 0.1310 - handedness_loss: 0.5431 - val_loss: 0.6767 - val_regression_loss: 0.1289 - val_handedness_loss: 0.5465\n",
      "Epoch 8/150\n",
      "3572/3572 [==============================] - 0s 124us/step - loss: 0.6474 - regression_loss: 0.1270 - handedness_loss: 0.5202 - val_loss: 0.6576 - val_regression_loss: 0.1297 - val_handedness_loss: 0.5257\n",
      "Epoch 9/150\n",
      "3572/3572 [==============================] - 0s 117us/step - loss: 0.6191 - regression_loss: 0.1205 - handedness_loss: 0.4985 - val_loss: 0.6370 - val_regression_loss: 0.1230 - val_handedness_loss: 0.5122\n",
      "Epoch 10/150\n",
      "3572/3572 [==============================] - 0s 122us/step - loss: 0.5939 - regression_loss: 0.1201 - handedness_loss: 0.4739 - val_loss: 0.6209 - val_regression_loss: 0.1251 - val_handedness_loss: 0.4934\n",
      "Epoch 11/150\n",
      "3572/3572 [==============================] - 1s 147us/step - loss: 0.5728 - regression_loss: 0.1132 - handedness_loss: 0.4595 - val_loss: 0.5965 - val_regression_loss: 0.1149 - val_handedness_loss: 0.4797\n",
      "Epoch 12/150\n",
      "3572/3572 [==============================] - 1s 147us/step - loss: 0.5579 - regression_loss: 0.1135 - handedness_loss: 0.4442 - val_loss: 0.5751 - val_regression_loss: 0.1115 - val_handedness_loss: 0.4611\n",
      "Epoch 13/150\n",
      "3572/3572 [==============================] - 1s 147us/step - loss: 0.5364 - regression_loss: 0.1074 - handedness_loss: 0.4290 - val_loss: 0.5548 - val_regression_loss: 0.1104 - val_handedness_loss: 0.4423\n",
      "Epoch 14/150\n",
      "3572/3572 [==============================] - 0s 129us/step - loss: 0.5192 - regression_loss: 0.1056 - handedness_loss: 0.4135 - val_loss: 0.5124 - val_regression_loss: 0.1103 - val_handedness_loss: 0.3994\n",
      "Epoch 15/150\n",
      "3572/3572 [==============================] - 1s 147us/step - loss: 0.4920 - regression_loss: 0.1029 - handedness_loss: 0.3890 - val_loss: 0.5328 - val_regression_loss: 0.1094 - val_handedness_loss: 0.4210\n",
      "Epoch 16/150\n",
      "3572/3572 [==============================] - 1s 144us/step - loss: 0.4955 - regression_loss: 0.1018 - handedness_loss: 0.3939 - val_loss: 0.5095 - val_regression_loss: 0.1035 - val_handedness_loss: 0.4061\n",
      "Epoch 17/150\n",
      "3572/3572 [==============================] - 0s 125us/step - loss: 0.4838 - regression_loss: 0.0980 - handedness_loss: 0.3859 - val_loss: 0.4993 - val_regression_loss: 0.1009 - val_handedness_loss: 0.3960\n",
      "Epoch 18/150\n",
      "3572/3572 [==============================] - 1s 147us/step - loss: 0.4712 - regression_loss: 0.0954 - handedness_loss: 0.3759 - val_loss: 0.4700 - val_regression_loss: 0.0980 - val_handedness_loss: 0.3697\n",
      "Epoch 19/150\n",
      "3572/3572 [==============================] - 1s 147us/step - loss: 0.4458 - regression_loss: 0.0911 - handedness_loss: 0.3547 - val_loss: 0.4705 - val_regression_loss: 0.0953 - val_handedness_loss: 0.3730\n",
      "Epoch 20/150\n",
      "3572/3572 [==============================] - 1s 146us/step - loss: 0.4485 - regression_loss: 0.0901 - handedness_loss: 0.3586 - val_loss: 0.4647 - val_regression_loss: 0.0898 - val_handedness_loss: 0.3712\n",
      "Epoch 21/150\n",
      "3572/3572 [==============================] - 1s 147us/step - loss: 0.4315 - regression_loss: 0.0873 - handedness_loss: 0.3443 - val_loss: 0.4454 - val_regression_loss: 0.0879 - val_handedness_loss: 0.3552\n",
      "Epoch 22/150\n",
      "3572/3572 [==============================] - 1s 144us/step - loss: 0.4372 - regression_loss: 0.0861 - handedness_loss: 0.3511 - val_loss: 0.4664 - val_regression_loss: 0.0884 - val_handedness_loss: 0.3747\n",
      "Epoch 23/150\n",
      "3572/3572 [==============================] - 0s 128us/step - loss: 0.4377 - regression_loss: 0.0849 - handedness_loss: 0.3529 - val_loss: 0.4620 - val_regression_loss: 0.0856 - val_handedness_loss: 0.3748\n",
      "Epoch 24/150\n",
      "3572/3572 [==============================] - 0s 139us/step - loss: 0.4250 - regression_loss: 0.0833 - handedness_loss: 0.3417 - val_loss: 0.4361 - val_regression_loss: 0.0837 - val_handedness_loss: 0.3532\n",
      "Epoch 25/150\n",
      "3572/3572 [==============================] - 1s 147us/step - loss: 0.4147 - regression_loss: 0.0814 - handedness_loss: 0.3334 - val_loss: 0.4354 - val_regression_loss: 0.0825 - val_handedness_loss: 0.3533\n",
      "Epoch 26/150\n",
      "3572/3572 [==============================] - 1s 148us/step - loss: 0.4165 - regression_loss: 0.0805 - handedness_loss: 0.3359 - val_loss: 0.4122 - val_regression_loss: 0.0814 - val_handedness_loss: 0.3292\n",
      "Epoch 27/150\n",
      "3572/3572 [==============================] - 1s 149us/step - loss: 0.4127 - regression_loss: 0.0802 - handedness_loss: 0.3325 - val_loss: 0.4493 - val_regression_loss: 0.0821 - val_handedness_loss: 0.3665\n",
      "Epoch 28/150\n",
      "3572/3572 [==============================] - 0s 102us/step - loss: 0.4068 - regression_loss: 0.0792 - handedness_loss: 0.3279 - val_loss: 0.4141 - val_regression_loss: 0.0793 - val_handedness_loss: 0.3336\n",
      "Epoch 29/150\n",
      "3572/3572 [==============================] - 0s 118us/step - loss: 0.4115 - regression_loss: 0.0797 - handedness_loss: 0.3319 - val_loss: 0.4238 - val_regression_loss: 0.0787 - val_handedness_loss: 0.3433\n",
      "Epoch 30/150\n",
      "3572/3572 [==============================] - 1s 148us/step - loss: 0.4196 - regression_loss: 0.0789 - handedness_loss: 0.3406 - val_loss: 0.4142 - val_regression_loss: 0.0797 - val_handedness_loss: 0.3328\n",
      "Evaluating model with testing data...\n",
      "744/744 [==============================] - 0s 22us/step\n",
      "Getting distribution of predictions and covariance matrix...\n",
      "      1 of 20\n",
      "      2 of 20\n",
      "      3 of 20\n",
      "      4 of 20\n",
      "      5 of 20\n",
      "      6 of 20\n",
      "      7 of 20\n",
      "      8 of 20\n",
      "      9 of 20\n",
      "      10 of 20\n",
      "      11 of 20\n",
      "      12 of 20\n",
      "      13 of 20\n",
      "      14 of 20\n",
      "      15 of 20\n",
      "      16 of 20\n",
      "      17 of 20\n",
      "      18 of 20\n",
      "      19 of 20\n",
      "      20 of 20\n",
      "Computing ensemble means...\n",
      "Computing mean squared error...\n",
      "Iteration 23\n",
      "Train on 3712 samples, validate on 774 samples\n",
      "Epoch 1/150\n",
      "3712/3712 [==============================] - 1s 166us/step - loss: 1.3754 - regression_loss: 0.6825 - handedness_loss: 0.6929 - val_loss: 0.9711 - val_regression_loss: 0.3088 - val_handedness_loss: 0.6760\n",
      "Epoch 2/150\n",
      "3712/3712 [==============================] - 0s 100us/step - loss: 0.9009 - regression_loss: 0.2532 - handedness_loss: 0.6478 - val_loss: 0.8809 - val_regression_loss: 0.2504 - val_handedness_loss: 0.6377\n",
      "Epoch 3/150\n",
      "3712/3712 [==============================] - 1s 146us/step - loss: 0.8202 - regression_loss: 0.2126 - handedness_loss: 0.6077 - val_loss: 0.8225 - val_regression_loss: 0.2199 - val_handedness_loss: 0.6296\n",
      "Epoch 4/150\n",
      "3712/3712 [==============================] - 1s 136us/step - loss: 0.7646 - regression_loss: 0.1883 - handedness_loss: 0.5763 - val_loss: 0.7616 - val_regression_loss: 0.2037 - val_handedness_loss: 0.5704\n",
      "Epoch 5/150\n",
      "3712/3712 [==============================] - 1s 144us/step - loss: 0.7254 - regression_loss: 0.1799 - handedness_loss: 0.5455 - val_loss: 0.7036 - val_regression_loss: 0.1806 - val_handedness_loss: 0.5285\n",
      "Epoch 6/150\n",
      "3712/3712 [==============================] - 0s 134us/step - loss: 0.6690 - regression_loss: 0.1622 - handedness_loss: 0.5068 - val_loss: 0.6689 - val_regression_loss: 0.1822 - val_handedness_loss: 0.4885\n",
      "Epoch 7/150\n",
      "3712/3712 [==============================] - 0s 117us/step - loss: 0.6304 - regression_loss: 0.1572 - handedness_loss: 0.4732 - val_loss: 0.6315 - val_regression_loss: 0.1684 - val_handedness_loss: 0.4748\n",
      "Epoch 8/150\n",
      "3712/3712 [==============================] - 1s 135us/step - loss: 0.5975 - regression_loss: 0.1500 - handedness_loss: 0.4475 - val_loss: 0.6044 - val_regression_loss: 0.1681 - val_handedness_loss: 0.4651\n",
      "Epoch 9/150\n",
      "3712/3712 [==============================] - 1s 147us/step - loss: 0.5502 - regression_loss: 0.1420 - handedness_loss: 0.4083 - val_loss: 0.5499 - val_regression_loss: 0.1662 - val_handedness_loss: 0.4348\n",
      "Epoch 10/150\n",
      "3712/3712 [==============================] - 0s 125us/step - loss: 0.5312 - regression_loss: 0.1342 - handedness_loss: 0.3971 - val_loss: 0.5394 - val_regression_loss: 0.1428 - val_handedness_loss: 0.3877\n",
      "Epoch 11/150\n",
      "3712/3712 [==============================] - 1s 135us/step - loss: 0.4957 - regression_loss: 0.1261 - handedness_loss: 0.3696 - val_loss: 0.5035 - val_regression_loss: 0.1283 - val_handedness_loss: 0.3531\n",
      "Epoch 12/150\n",
      "3712/3712 [==============================] - 1s 135us/step - loss: 0.4766 - regression_loss: 0.1187 - handedness_loss: 0.3580 - val_loss: 0.4943 - val_regression_loss: 0.1404 - val_handedness_loss: 0.3931\n",
      "Epoch 13/150\n",
      "3712/3712 [==============================] - 0s 125us/step - loss: 0.4558 - regression_loss: 0.1144 - handedness_loss: 0.3414 - val_loss: 0.4725 - val_regression_loss: 0.1304 - val_handedness_loss: 0.3504\n",
      "Epoch 14/150\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3712/3712 [==============================] - 1s 137us/step - loss: 0.4448 - regression_loss: 0.1091 - handedness_loss: 0.3356 - val_loss: 0.4358 - val_regression_loss: 0.1189 - val_handedness_loss: 0.3269\n",
      "Epoch 15/150\n",
      "3712/3712 [==============================] - 1s 145us/step - loss: 0.4225 - regression_loss: 0.1066 - handedness_loss: 0.3159 - val_loss: 0.4283 - val_regression_loss: 0.1124 - val_handedness_loss: 0.3107\n",
      "Epoch 16/150\n",
      "3712/3712 [==============================] - 1s 146us/step - loss: 0.4143 - regression_loss: 0.1011 - handedness_loss: 0.3133 - val_loss: 0.4070 - val_regression_loss: 0.1126 - val_handedness_loss: 0.3089\n",
      "Epoch 17/150\n",
      "3712/3712 [==============================] - 1s 147us/step - loss: 0.3833 - regression_loss: 0.0974 - handedness_loss: 0.2858 - val_loss: 0.3908 - val_regression_loss: 0.0946 - val_handedness_loss: 0.2646\n",
      "Epoch 18/150\n",
      "3712/3712 [==============================] - 1s 146us/step - loss: 0.3829 - regression_loss: 0.0951 - handedness_loss: 0.2879 - val_loss: 0.3747 - val_regression_loss: 0.1030 - val_handedness_loss: 0.2538\n",
      "Epoch 19/150\n",
      "3712/3712 [==============================] - 1s 149us/step - loss: 0.3621 - regression_loss: 0.0916 - handedness_loss: 0.2705 - val_loss: 0.4016 - val_regression_loss: 0.0924 - val_handedness_loss: 0.2926\n",
      "Epoch 20/150\n",
      "3712/3712 [==============================] - 1s 148us/step - loss: 0.3761 - regression_loss: 0.0911 - handedness_loss: 0.2850 - val_loss: 0.3493 - val_regression_loss: 0.0934 - val_handedness_loss: 0.2411\n",
      "Epoch 21/150\n",
      "3712/3712 [==============================] - 1s 149us/step - loss: 0.3622 - regression_loss: 0.0888 - handedness_loss: 0.2734 - val_loss: 0.3362 - val_regression_loss: 0.0871 - val_handedness_loss: 0.2331\n",
      "Epoch 22/150\n",
      "3712/3712 [==============================] - 1s 150us/step - loss: 0.3594 - regression_loss: 0.0868 - handedness_loss: 0.2727 - val_loss: 0.3540 - val_regression_loss: 0.0858 - val_handedness_loss: 0.2313\n",
      "Epoch 23/150\n",
      "3712/3712 [==============================] - 1s 137us/step - loss: 0.3496 - regression_loss: 0.0844 - handedness_loss: 0.2652 - val_loss: 0.3584 - val_regression_loss: 0.0873 - val_handedness_loss: 0.2329\n",
      "Epoch 24/150\n",
      "3712/3712 [==============================] - 1s 149us/step - loss: 0.3475 - regression_loss: 0.0837 - handedness_loss: 0.2638 - val_loss: 0.3567 - val_regression_loss: 0.0843 - val_handedness_loss: 0.2333\n",
      "Epoch 25/150\n",
      "3712/3712 [==============================] - 1s 150us/step - loss: 0.3483 - regression_loss: 0.0823 - handedness_loss: 0.2660 - val_loss: 0.3524 - val_regression_loss: 0.0878 - val_handedness_loss: 0.2466\n",
      "Epoch 26/150\n",
      "3712/3712 [==============================] - 1s 149us/step - loss: 0.3285 - regression_loss: 0.0797 - handedness_loss: 0.2487 - val_loss: 0.3368 - val_regression_loss: 0.0865 - val_handedness_loss: 0.2472\n",
      "Evaluating model with testing data...\n",
      "774/774 [==============================] - 0s 26us/step\n",
      "Getting distribution of predictions and covariance matrix...\n",
      "      1 of 20\n",
      "      2 of 20\n",
      "      3 of 20\n",
      "      4 of 20\n",
      "      5 of 20\n",
      "      6 of 20\n",
      "      7 of 20\n",
      "      8 of 20\n",
      "      9 of 20\n",
      "      10 of 20\n",
      "      11 of 20\n",
      "      12 of 20\n",
      "      13 of 20\n",
      "      14 of 20\n",
      "      15 of 20\n",
      "      16 of 20\n",
      "      17 of 20\n",
      "      18 of 20\n",
      "      19 of 20\n",
      "      20 of 20\n",
      "Computing ensemble means...\n",
      "Computing mean squared error...\n",
      "Iteration 24\n",
      "Train on 3852 samples, validate on 804 samples\n",
      "Epoch 1/150\n",
      "3852/3852 [==============================] - 1s 174us/step - loss: 1.4400 - regression_loss: 0.7354 - handedness_loss: 0.6889 - val_loss: 0.9633 - val_regression_loss: 0.2902 - val_handedness_loss: 0.6756\n",
      "Epoch 2/150\n",
      "3852/3852 [==============================] - 0s 108us/step - loss: 0.9005 - regression_loss: 0.2425 - handedness_loss: 0.6581 - val_loss: 0.8676 - val_regression_loss: 0.2226 - val_handedness_loss: 0.6464\n",
      "Epoch 3/150\n",
      "3852/3852 [==============================] - 1s 144us/step - loss: 0.8350 - regression_loss: 0.1927 - handedness_loss: 0.6390 - val_loss: 0.8335 - val_regression_loss: 0.1880 - val_handedness_loss: 0.6407\n",
      "Epoch 4/150\n",
      "3852/3852 [==============================] - 1s 152us/step - loss: 0.8025 - regression_loss: 0.1737 - handedness_loss: 0.6315 - val_loss: 0.7905 - val_regression_loss: 0.1739 - val_handedness_loss: 0.6221\n",
      "Epoch 5/150\n",
      "3852/3852 [==============================] - 1s 136us/step - loss: 0.7705 - regression_loss: 0.1604 - handedness_loss: 0.6146 - val_loss: 0.7644 - val_regression_loss: 0.1639 - val_handedness_loss: 0.5952\n",
      "Epoch 6/150\n",
      "3852/3852 [==============================] - 1s 151us/step - loss: 0.7419 - regression_loss: 0.1529 - handedness_loss: 0.5865 - val_loss: 0.7270 - val_regression_loss: 0.1592 - val_handedness_loss: 0.5663\n",
      "Epoch 7/150\n",
      "3852/3852 [==============================] - 0s 124us/step - loss: 0.7074 - regression_loss: 0.1429 - handedness_loss: 0.5651 - val_loss: 0.7153 - val_regression_loss: 0.1509 - val_handedness_loss: 0.5660\n",
      "Epoch 8/150\n",
      "3852/3852 [==============================] - 0s 129us/step - loss: 0.6767 - regression_loss: 0.1336 - handedness_loss: 0.5414 - val_loss: 0.6573 - val_regression_loss: 0.1313 - val_handedness_loss: 0.5317\n",
      "Epoch 9/150\n",
      "3852/3852 [==============================] - 1s 151us/step - loss: 0.6718 - regression_loss: 0.1288 - handedness_loss: 0.5459 - val_loss: 0.6520 - val_regression_loss: 0.1336 - val_handedness_loss: 0.5137\n",
      "Epoch 10/150\n",
      "3852/3852 [==============================] - 1s 133us/step - loss: 0.6716 - regression_loss: 0.1270 - handedness_loss: 0.5462 - val_loss: 0.6777 - val_regression_loss: 0.1275 - val_handedness_loss: 0.5508\n",
      "Epoch 11/150\n",
      "3852/3852 [==============================] - 1s 147us/step - loss: 0.6558 - regression_loss: 0.1210 - handedness_loss: 0.5370 - val_loss: 0.6665 - val_regression_loss: 0.1273 - val_handedness_loss: 0.5373\n",
      "Epoch 12/150\n",
      "3852/3852 [==============================] - 1s 140us/step - loss: 0.6477 - regression_loss: 0.1175 - handedness_loss: 0.5256 - val_loss: 0.6612 - val_regression_loss: 0.1208 - val_handedness_loss: 0.5445\n",
      "Epoch 13/150\n",
      "3852/3852 [==============================] - 1s 151us/step - loss: 0.6309 - regression_loss: 0.1122 - handedness_loss: 0.5254 - val_loss: 0.6486 - val_regression_loss: 0.1186 - val_handedness_loss: 0.5388\n",
      "Evaluating model with testing data...\n",
      "804/804 [==============================] - 0s 25us/step\n",
      "Getting distribution of predictions and covariance matrix...\n",
      "      1 of 20\n",
      "      2 of 20\n",
      "      3 of 20\n",
      "      4 of 20\n",
      "      5 of 20\n",
      "      6 of 20\n",
      "      7 of 20\n",
      "      8 of 20\n",
      "      9 of 20\n",
      "      10 of 20\n",
      "      11 of 20\n",
      "      12 of 20\n",
      "      13 of 20\n",
      "      14 of 20\n",
      "      15 of 20\n",
      "      16 of 20\n",
      "      17 of 20\n",
      "      18 of 20\n",
      "      19 of 20\n",
      "      20 of 20\n",
      "Computing ensemble means...\n",
      "Computing mean squared error...\n",
      "Iteration 25\n",
      "Train on 3992 samples, validate on 834 samples\n",
      "Epoch 1/150\n",
      "3992/3992 [==============================] - 1s 169us/step - loss: 1.3677 - regression_loss: 0.6799 - handedness_loss: 0.6764 - val_loss: 0.9940 - val_regression_loss: 0.3300 - val_handedness_loss: 0.6614\n",
      "Epoch 2/150\n",
      "3992/3992 [==============================] - 0s 122us/step - loss: 0.9402 - regression_loss: 0.2986 - handedness_loss: 0.6385 - val_loss: 0.9272 - val_regression_loss: 0.2987 - val_handedness_loss: 0.6266\n",
      "Epoch 3/150\n",
      "3992/3992 [==============================] - 0s 67us/step - loss: 0.8667 - regression_loss: 0.2644 - handedness_loss: 0.5985 - val_loss: 0.8604 - val_regression_loss: 0.2611 - val_handedness_loss: 0.5966\n",
      "Epoch 4/150\n",
      "3992/3992 [==============================] - 0s 65us/step - loss: 0.7878 - regression_loss: 0.2313 - handedness_loss: 0.5565 - val_loss: 0.7860 - val_regression_loss: 0.2236 - val_handedness_loss: 0.5616\n",
      "Epoch 5/150\n",
      "3992/3992 [==============================] - 0s 65us/step - loss: 0.7191 - regression_loss: 0.2026 - handedness_loss: 0.5164 - val_loss: 0.7025 - val_regression_loss: 0.1957 - val_handedness_loss: 0.5049\n",
      "Epoch 6/150\n",
      "3992/3992 [==============================] - 1s 135us/step - loss: 0.6555 - regression_loss: 0.1761 - handedness_loss: 0.4775 - val_loss: 0.6604 - val_regression_loss: 0.1824 - val_handedness_loss: 0.4755\n",
      "Epoch 7/150\n",
      "3992/3992 [==============================] - 0s 112us/step - loss: 0.6154 - regression_loss: 0.1600 - handedness_loss: 0.4536 - val_loss: 0.6068 - val_regression_loss: 0.1618 - val_handedness_loss: 0.4455\n",
      "Epoch 8/150\n",
      "3992/3992 [==============================] - 1s 148us/step - loss: 0.5788 - regression_loss: 0.1477 - handedness_loss: 0.4283 - val_loss: 0.5665 - val_regression_loss: 0.1538 - val_handedness_loss: 0.4067\n",
      "Epoch 9/150\n",
      "3992/3992 [==============================] - 1s 149us/step - loss: 0.5489 - regression_loss: 0.1412 - handedness_loss: 0.4053 - val_loss: 0.5466 - val_regression_loss: 0.1466 - val_handedness_loss: 0.3991\n",
      "Epoch 10/150\n",
      "3992/3992 [==============================] - 1s 141us/step - loss: 0.5285 - regression_loss: 0.1345 - handedness_loss: 0.3919 - val_loss: 0.5352 - val_regression_loss: 0.1436 - val_handedness_loss: 0.3897\n",
      "Epoch 11/150\n",
      "3992/3992 [==============================] - 1s 128us/step - loss: 0.5082 - regression_loss: 0.1294 - handedness_loss: 0.3810 - val_loss: 0.5213 - val_regression_loss: 0.1336 - val_handedness_loss: 0.3810\n",
      "Epoch 12/150\n",
      "3992/3992 [==============================] - 1s 146us/step - loss: 0.4926 - regression_loss: 0.1213 - handedness_loss: 0.3694 - val_loss: 0.4646 - val_regression_loss: 0.1227 - val_handedness_loss: 0.3406\n",
      "Epoch 13/150\n",
      "3992/3992 [==============================] - 1s 146us/step - loss: 0.4780 - regression_loss: 0.1191 - handedness_loss: 0.3616 - val_loss: 0.4788 - val_regression_loss: 0.1181 - val_handedness_loss: 0.3526\n",
      "Epoch 14/150\n",
      "3992/3992 [==============================] - 1s 147us/step - loss: 0.4600 - regression_loss: 0.1122 - handedness_loss: 0.3459 - val_loss: 0.4378 - val_regression_loss: 0.1166 - val_handedness_loss: 0.3209\n",
      "Epoch 15/150\n",
      "3992/3992 [==============================] - 1s 130us/step - loss: 0.4558 - regression_loss: 0.1085 - handedness_loss: 0.3504 - val_loss: 0.4352 - val_regression_loss: 0.1097 - val_handedness_loss: 0.3222\n",
      "Epoch 16/150\n",
      "3992/3992 [==============================] - 1s 147us/step - loss: 0.4380 - regression_loss: 0.1045 - handedness_loss: 0.3344 - val_loss: 0.4615 - val_regression_loss: 0.1072 - val_handedness_loss: 0.3524\n",
      "Epoch 17/150\n",
      "3992/3992 [==============================] - 1s 146us/step - loss: 0.4330 - regression_loss: 0.1015 - handedness_loss: 0.3323 - val_loss: 0.4579 - val_regression_loss: 0.1027 - val_handedness_loss: 0.3537\n",
      "Epoch 18/150\n",
      "3992/3992 [==============================] - 1s 148us/step - loss: 0.4247 - regression_loss: 0.0963 - handedness_loss: 0.3264 - val_loss: 0.4206 - val_regression_loss: 0.1006 - val_handedness_loss: 0.3208\n",
      "Epoch 19/150\n",
      "3992/3992 [==============================] - 1s 149us/step - loss: 0.4173 - regression_loss: 0.0942 - handedness_loss: 0.3251 - val_loss: 0.4167 - val_regression_loss: 0.0979 - val_handedness_loss: 0.3157\n",
      "Epoch 20/150\n",
      "3992/3992 [==============================] - 1s 149us/step - loss: 0.4045 - regression_loss: 0.0913 - handedness_loss: 0.3153 - val_loss: 0.4071 - val_regression_loss: 0.0924 - val_handedness_loss: 0.3099\n",
      "Epoch 21/150\n",
      "3992/3992 [==============================] - 1s 149us/step - loss: 0.4082 - regression_loss: 0.0891 - handedness_loss: 0.3224 - val_loss: 0.4007 - val_regression_loss: 0.0943 - val_handedness_loss: 0.3032\n",
      "Epoch 22/150\n",
      "3992/3992 [==============================] - 1s 146us/step - loss: 0.4090 - regression_loss: 0.0886 - handedness_loss: 0.3204 - val_loss: 0.3890 - val_regression_loss: 0.0884 - val_handedness_loss: 0.2970\n",
      "Epoch 23/150\n",
      "3992/3992 [==============================] - 0s 120us/step - loss: 0.4048 - regression_loss: 0.0866 - handedness_loss: 0.3201 - val_loss: 0.3794 - val_regression_loss: 0.0853 - val_handedness_loss: 0.2920\n",
      "Epoch 24/150\n",
      "3992/3992 [==============================] - 1s 148us/step - loss: 0.3901 - regression_loss: 0.0843 - handedness_loss: 0.3079 - val_loss: 0.4173 - val_regression_loss: 0.0887 - val_handedness_loss: 0.3249\n",
      "Epoch 25/150\n",
      "3992/3992 [==============================] - 1s 148us/step - loss: 0.3849 - regression_loss: 0.0842 - handedness_loss: 0.3040 - val_loss: 0.3811 - val_regression_loss: 0.0850 - val_handedness_loss: 0.2876\n",
      "Epoch 26/150\n",
      "3992/3992 [==============================] - 1s 148us/step - loss: 0.3814 - regression_loss: 0.0816 - handedness_loss: 0.2985 - val_loss: 0.3773 - val_regression_loss: 0.0832 - val_handedness_loss: 0.2891\n",
      "Epoch 27/150\n",
      "3992/3992 [==============================] - 1s 149us/step - loss: 0.3736 - regression_loss: 0.0799 - handedness_loss: 0.2936 - val_loss: 0.3856 - val_regression_loss: 0.0821 - val_handedness_loss: 0.3033\n",
      "Epoch 28/150\n",
      "3992/3992 [==============================] - 1s 149us/step - loss: 0.3806 - regression_loss: 0.0795 - handedness_loss: 0.2974 - val_loss: 0.3688 - val_regression_loss: 0.0806 - val_handedness_loss: 0.2904\n",
      "Epoch 29/150\n",
      "3992/3992 [==============================] - 1s 136us/step - loss: 0.3674 - regression_loss: 0.0783 - handedness_loss: 0.2856 - val_loss: 0.3766 - val_regression_loss: 0.0793 - val_handedness_loss: 0.2961\n",
      "Evaluating model with testing data...\n",
      "834/834 [==============================] - 0s 23us/step\n",
      "Getting distribution of predictions and covariance matrix...\n",
      "      1 of 20\n",
      "      2 of 20\n",
      "      3 of 20\n",
      "      4 of 20\n",
      "      5 of 20\n",
      "      6 of 20\n",
      "      7 of 20\n",
      "      8 of 20\n",
      "      9 of 20\n",
      "      10 of 20\n",
      "      11 of 20\n",
      "      12 of 20\n",
      "      13 of 20\n",
      "      14 of 20\n",
      "      15 of 20\n",
      "      16 of 20\n",
      "      17 of 20\n",
      "      18 of 20\n",
      "      19 of 20\n",
      "      20 of 20\n",
      "Computing ensemble means...\n",
      "Computing mean squared error...\n",
      "Iteration 26\n",
      "Train on 4132 samples, validate on 864 samples\n",
      "Epoch 1/150\n",
      "4132/4132 [==============================] - 1s 158us/step - loss: 1.0926 - regression_loss: 0.4078 - handedness_loss: 0.6831 - val_loss: 0.9752 - val_regression_loss: 0.3054 - val_handedness_loss: 0.6695\n",
      "Epoch 2/150\n",
      "4132/4132 [==============================] - 1s 130us/step - loss: 0.8993 - regression_loss: 0.2519 - handedness_loss: 0.6477 - val_loss: 0.8409 - val_regression_loss: 0.2176 - val_handedness_loss: 0.6242\n",
      "Epoch 3/150\n",
      "4132/4132 [==============================] - 0s 110us/step - loss: 0.7679 - regression_loss: 0.1632 - handedness_loss: 0.6057 - val_loss: 0.7445 - val_regression_loss: 0.1578 - val_handedness_loss: 0.5892\n",
      "Epoch 4/150\n",
      "4132/4132 [==============================] - 1s 129us/step - loss: 0.6912 - regression_loss: 0.1389 - handedness_loss: 0.5500 - val_loss: 0.6864 - val_regression_loss: 0.1421 - val_handedness_loss: 0.5490\n",
      "Epoch 5/150\n",
      "4132/4132 [==============================] - 1s 138us/step - loss: 0.6304 - regression_loss: 0.1313 - handedness_loss: 0.4975 - val_loss: 0.6507 - val_regression_loss: 0.1427 - val_handedness_loss: 0.5149\n",
      "Epoch 6/150\n",
      "4132/4132 [==============================] - 1s 138us/step - loss: 0.5870 - regression_loss: 0.1249 - handedness_loss: 0.4602 - val_loss: 0.5974 - val_regression_loss: 0.1322 - val_handedness_loss: 0.4697\n",
      "Epoch 7/150\n",
      "4132/4132 [==============================] - 1s 138us/step - loss: 0.5506 - regression_loss: 0.1215 - handedness_loss: 0.4305 - val_loss: 0.5677 - val_regression_loss: 0.1323 - val_handedness_loss: 0.4384\n",
      "Epoch 8/150\n",
      "4132/4132 [==============================] - 1s 150us/step - loss: 0.5235 - regression_loss: 0.1181 - handedness_loss: 0.4055 - val_loss: 0.5152 - val_regression_loss: 0.1216 - val_handedness_loss: 0.3960\n",
      "Epoch 9/150\n",
      "4132/4132 [==============================] - 1s 152us/step - loss: 0.5058 - regression_loss: 0.1176 - handedness_loss: 0.3885 - val_loss: 0.4956 - val_regression_loss: 0.1195 - val_handedness_loss: 0.3789\n",
      "Epoch 10/150\n",
      "4132/4132 [==============================] - 1s 151us/step - loss: 0.4810 - regression_loss: 0.1144 - handedness_loss: 0.3670 - val_loss: 0.4885 - val_regression_loss: 0.1178 - val_handedness_loss: 0.3705\n",
      "Epoch 11/150\n",
      "4132/4132 [==============================] - 1s 151us/step - loss: 0.4619 - regression_loss: 0.1117 - handedness_loss: 0.3493 - val_loss: 0.4572 - val_regression_loss: 0.1200 - val_handedness_loss: 0.3383\n",
      "Epoch 12/150\n",
      "4132/4132 [==============================] - 1s 152us/step - loss: 0.4385 - regression_loss: 0.1101 - handedness_loss: 0.3303 - val_loss: 0.4341 - val_regression_loss: 0.1130 - val_handedness_loss: 0.3217\n",
      "Epoch 13/150\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4132/4132 [==============================] - 1s 138us/step - loss: 0.4147 - regression_loss: 0.1064 - handedness_loss: 0.3101 - val_loss: 0.4053 - val_regression_loss: 0.1071 - val_handedness_loss: 0.3011\n",
      "Epoch 14/150\n",
      "4132/4132 [==============================] - 1s 148us/step - loss: 0.3848 - regression_loss: 0.0995 - handedness_loss: 0.2865 - val_loss: 0.4215 - val_regression_loss: 0.1096 - val_handedness_loss: 0.3175\n",
      "Epoch 15/150\n",
      "4132/4132 [==============================] - 1s 139us/step - loss: 0.3726 - regression_loss: 0.0961 - handedness_loss: 0.2774 - val_loss: 0.4015 - val_regression_loss: 0.1060 - val_handedness_loss: 0.2966\n",
      "Epoch 16/150\n",
      "4132/4132 [==============================] - 1s 150us/step - loss: 0.3797 - regression_loss: 0.0946 - handedness_loss: 0.2846 - val_loss: 0.3656 - val_regression_loss: 0.1014 - val_handedness_loss: 0.2684\n",
      "Epoch 17/150\n",
      "4132/4132 [==============================] - 1s 151us/step - loss: 0.3657 - regression_loss: 0.0914 - handedness_loss: 0.2735 - val_loss: 0.3606 - val_regression_loss: 0.0973 - val_handedness_loss: 0.2656\n",
      "Epoch 18/150\n",
      "4132/4132 [==============================] - 1s 149us/step - loss: 0.3648 - regression_loss: 0.0881 - handedness_loss: 0.2754 - val_loss: 0.3516 - val_regression_loss: 0.0949 - val_handedness_loss: 0.2580\n",
      "Epoch 19/150\n",
      "4132/4132 [==============================] - 1s 151us/step - loss: 0.3441 - regression_loss: 0.0859 - handedness_loss: 0.2606 - val_loss: 0.3690 - val_regression_loss: 0.0927 - val_handedness_loss: 0.2771\n",
      "Epoch 20/150\n",
      "4132/4132 [==============================] - 1s 152us/step - loss: 0.3445 - regression_loss: 0.0846 - handedness_loss: 0.2607 - val_loss: 0.3313 - val_regression_loss: 0.0905 - val_handedness_loss: 0.2429\n",
      "Epoch 21/150\n",
      "4132/4132 [==============================] - 1s 153us/step - loss: 0.3249 - regression_loss: 0.0818 - handedness_loss: 0.2395 - val_loss: 0.3458 - val_regression_loss: 0.0887 - val_handedness_loss: 0.2601\n",
      "Epoch 22/150\n",
      "4132/4132 [==============================] - 1s 152us/step - loss: 0.3357 - regression_loss: 0.0804 - handedness_loss: 0.2570 - val_loss: 0.3565 - val_regression_loss: 0.0875 - val_handedness_loss: 0.2721\n",
      "Epoch 23/150\n",
      "4132/4132 [==============================] - 1s 153us/step - loss: 0.3313 - regression_loss: 0.0792 - handedness_loss: 0.2525 - val_loss: 0.3645 - val_regression_loss: 0.0848 - val_handedness_loss: 0.2831\n",
      "Epoch 24/150\n",
      "4132/4132 [==============================] - 1s 136us/step - loss: 0.3419 - regression_loss: 0.0786 - handedness_loss: 0.2624 - val_loss: 0.3672 - val_regression_loss: 0.0846 - val_handedness_loss: 0.2866\n",
      "Evaluating model with testing data...\n",
      "864/864 [==============================] - 0s 25us/step\n",
      "Getting distribution of predictions and covariance matrix...\n",
      "      1 of 20\n",
      "      2 of 20\n",
      "      3 of 20\n",
      "      4 of 20\n",
      "      5 of 20\n",
      "      6 of 20\n",
      "      7 of 20\n",
      "      8 of 20\n",
      "      9 of 20\n",
      "      10 of 20\n",
      "      11 of 20\n",
      "      12 of 20\n",
      "      13 of 20\n",
      "      14 of 20\n",
      "      15 of 20\n",
      "      16 of 20\n",
      "      17 of 20\n",
      "      18 of 20\n",
      "      19 of 20\n",
      "      20 of 20\n",
      "Computing ensemble means...\n",
      "Computing mean squared error...\n",
      "Iteration 27\n",
      "Train on 4272 samples, validate on 894 samples\n",
      "Epoch 1/150\n",
      "4272/4272 [==============================] - 1s 165us/step - loss: 1.3139 - regression_loss: 0.6207 - handedness_loss: 0.6863 - val_loss: 1.0017 - val_regression_loss: 0.3296 - val_handedness_loss: 0.6721\n",
      "Epoch 2/150\n",
      "4272/4272 [==============================] - 1s 120us/step - loss: 0.9390 - regression_loss: 0.2809 - handedness_loss: 0.6581 - val_loss: 0.9329 - val_regression_loss: 0.2677 - val_handedness_loss: 0.6652\n",
      "Epoch 3/150\n",
      "4272/4272 [==============================] - 1s 146us/step - loss: 0.8691 - regression_loss: 0.2318 - handedness_loss: 0.6359 - val_loss: 0.8616 - val_regression_loss: 0.2272 - val_handedness_loss: 0.6344\n",
      "Epoch 4/150\n",
      "4272/4272 [==============================] - 1s 148us/step - loss: 0.8187 - regression_loss: 0.2057 - handedness_loss: 0.6134 - val_loss: 0.8313 - val_regression_loss: 0.2114 - val_handedness_loss: 0.6198\n",
      "Epoch 5/150\n",
      "4272/4272 [==============================] - 1s 147us/step - loss: 0.7725 - regression_loss: 0.1875 - handedness_loss: 0.5849 - val_loss: 0.7760 - val_regression_loss: 0.1911 - val_handedness_loss: 0.5849\n",
      "Epoch 6/150\n",
      "4272/4272 [==============================] - 1s 149us/step - loss: 0.7289 - regression_loss: 0.1764 - handedness_loss: 0.5526 - val_loss: 0.7354 - val_regression_loss: 0.1800 - val_handedness_loss: 0.5554\n",
      "Epoch 7/150\n",
      "4272/4272 [==============================] - 1s 149us/step - loss: 0.6947 - regression_loss: 0.1647 - handedness_loss: 0.5292 - val_loss: 0.7062 - val_regression_loss: 0.1671 - val_handedness_loss: 0.5391\n",
      "Epoch 8/150\n",
      "4272/4272 [==============================] - 1s 150us/step - loss: 0.6700 - regression_loss: 0.1549 - handedness_loss: 0.5142 - val_loss: 0.6681 - val_regression_loss: 0.1585 - val_handedness_loss: 0.5096\n",
      "Epoch 9/150\n",
      "4272/4272 [==============================] - 1s 150us/step - loss: 0.6384 - regression_loss: 0.1465 - handedness_loss: 0.4911 - val_loss: 0.6527 - val_regression_loss: 0.1533 - val_handedness_loss: 0.4995\n",
      "Epoch 10/150\n",
      "4272/4272 [==============================] - 1s 124us/step - loss: 0.6234 - regression_loss: 0.1402 - handedness_loss: 0.4830 - val_loss: 0.6267 - val_regression_loss: 0.1478 - val_handedness_loss: 0.4788\n",
      "Epoch 11/150\n",
      "4272/4272 [==============================] - 1s 129us/step - loss: 0.6009 - regression_loss: 0.1320 - handedness_loss: 0.4696 - val_loss: 0.6131 - val_regression_loss: 0.1401 - val_handedness_loss: 0.4729\n",
      "Epoch 12/150\n",
      "4272/4272 [==============================] - 1s 139us/step - loss: 0.5916 - regression_loss: 0.1258 - handedness_loss: 0.4645 - val_loss: 0.6168 - val_regression_loss: 0.1341 - val_handedness_loss: 0.4827\n",
      "Epoch 13/150\n",
      "4272/4272 [==============================] - 1s 122us/step - loss: 0.5732 - regression_loss: 0.1174 - handedness_loss: 0.4547 - val_loss: 0.5855 - val_regression_loss: 0.1236 - val_handedness_loss: 0.4620\n",
      "Epoch 14/150\n",
      "4272/4272 [==============================] - 0s 117us/step - loss: 0.5579 - regression_loss: 0.1120 - handedness_loss: 0.4468 - val_loss: 0.5689 - val_regression_loss: 0.1167 - val_handedness_loss: 0.4521\n",
      "Epoch 15/150\n",
      "4272/4272 [==============================] - 1s 146us/step - loss: 0.5442 - regression_loss: 0.1057 - handedness_loss: 0.4398 - val_loss: 0.5594 - val_regression_loss: 0.1128 - val_handedness_loss: 0.4466\n",
      "Epoch 16/150\n",
      "4272/4272 [==============================] - 1s 139us/step - loss: 0.5217 - regression_loss: 0.1005 - handedness_loss: 0.4198 - val_loss: 0.5506 - val_regression_loss: 0.1064 - val_handedness_loss: 0.4442\n",
      "Epoch 17/150\n",
      "4272/4272 [==============================] - 1s 118us/step - loss: 0.5191 - regression_loss: 0.0969 - handedness_loss: 0.4222 - val_loss: 0.5201 - val_regression_loss: 0.1021 - val_handedness_loss: 0.4180\n",
      "Epoch 18/150\n",
      "4272/4272 [==============================] - 1s 119us/step - loss: 0.5116 - regression_loss: 0.0937 - handedness_loss: 0.4183 - val_loss: 0.5523 - val_regression_loss: 0.0967 - val_handedness_loss: 0.4557\n",
      "Epoch 19/150\n",
      "4272/4272 [==============================] - 1s 131us/step - loss: 0.5133 - regression_loss: 0.0912 - handedness_loss: 0.4212 - val_loss: 0.5344 - val_regression_loss: 0.0956 - val_handedness_loss: 0.4388\n",
      "Epoch 20/150\n",
      "4272/4272 [==============================] - 0s 114us/step - loss: 0.4989 - regression_loss: 0.0883 - handedness_loss: 0.4123 - val_loss: 0.5075 - val_regression_loss: 0.0934 - val_handedness_loss: 0.4140\n",
      "Epoch 21/150\n",
      "4272/4272 [==============================] - 1s 136us/step - loss: 0.4829 - regression_loss: 0.0861 - handedness_loss: 0.3958 - val_loss: 0.4921 - val_regression_loss: 0.0901 - val_handedness_loss: 0.4019\n",
      "Epoch 22/150\n",
      "4272/4272 [==============================] - 1s 137us/step - loss: 0.4899 - regression_loss: 0.0848 - handedness_loss: 0.4057 - val_loss: 0.4733 - val_regression_loss: 0.0880 - val_handedness_loss: 0.3852\n",
      "Epoch 23/150\n",
      "4272/4272 [==============================] - 1s 136us/step - loss: 0.4826 - regression_loss: 0.0832 - handedness_loss: 0.4005 - val_loss: 0.4890 - val_regression_loss: 0.0864 - val_handedness_loss: 0.4026\n",
      "Epoch 24/150\n",
      "4272/4272 [==============================] - 1s 137us/step - loss: 0.4856 - regression_loss: 0.0824 - handedness_loss: 0.4035 - val_loss: 0.5025 - val_regression_loss: 0.0863 - val_handedness_loss: 0.4161\n",
      "Epoch 25/150\n",
      "4272/4272 [==============================] - 1s 137us/step - loss: 0.4636 - regression_loss: 0.0811 - handedness_loss: 0.3825 - val_loss: 0.4723 - val_regression_loss: 0.0841 - val_handedness_loss: 0.3882\n",
      "Epoch 26/150\n",
      "4272/4272 [==============================] - 1s 141us/step - loss: 0.4640 - regression_loss: 0.0807 - handedness_loss: 0.3832 - val_loss: 0.4663 - val_regression_loss: 0.0832 - val_handedness_loss: 0.3830\n",
      "Epoch 27/150\n",
      "4272/4272 [==============================] - 1s 148us/step - loss: 0.4543 - regression_loss: 0.0798 - handedness_loss: 0.3755 - val_loss: 0.4573 - val_regression_loss: 0.0833 - val_handedness_loss: 0.3740\n",
      "Epoch 28/150\n",
      "4272/4272 [==============================] - 1s 148us/step - loss: 0.4617 - regression_loss: 0.0793 - handedness_loss: 0.3829 - val_loss: 0.4807 - val_regression_loss: 0.0825 - val_handedness_loss: 0.3983\n",
      "Epoch 29/150\n",
      "4272/4272 [==============================] - 1s 135us/step - loss: 0.4605 - regression_loss: 0.0793 - handedness_loss: 0.3814 - val_loss: 0.4570 - val_regression_loss: 0.0830 - val_handedness_loss: 0.3741\n",
      "Epoch 30/150\n",
      "4272/4272 [==============================] - 1s 138us/step - loss: 0.4622 - regression_loss: 0.0787 - handedness_loss: 0.3831 - val_loss: 0.4784 - val_regression_loss: 0.0809 - val_handedness_loss: 0.3976\n",
      "Epoch 31/150\n",
      "4272/4272 [==============================] - 1s 139us/step - loss: 0.4534 - regression_loss: 0.0783 - handedness_loss: 0.3755 - val_loss: 0.4914 - val_regression_loss: 0.0817 - val_handedness_loss: 0.4099\n",
      "Evaluating model with testing data...\n",
      "894/894 [==============================] - 0s 28us/step\n",
      "Getting distribution of predictions and covariance matrix...\n",
      "      1 of 20\n",
      "      2 of 20\n",
      "      3 of 20\n",
      "      4 of 20\n",
      "      5 of 20\n",
      "      6 of 20\n",
      "      7 of 20\n",
      "      8 of 20\n",
      "      9 of 20\n",
      "      10 of 20\n",
      "      11 of 20\n",
      "      12 of 20\n",
      "      13 of 20\n",
      "      14 of 20\n",
      "      15 of 20\n",
      "      16 of 20\n",
      "      17 of 20\n",
      "      18 of 20\n",
      "      19 of 20\n",
      "      20 of 20\n",
      "Computing ensemble means...\n",
      "Computing mean squared error...\n",
      "Iteration 28\n",
      "Train on 4412 samples, validate on 924 samples\n",
      "Epoch 1/150\n",
      "4412/4412 [==============================] - 1s 142us/step - loss: 1.1725 - regression_loss: 0.4788 - handedness_loss: 0.6902 - val_loss: 0.9675 - val_regression_loss: 0.2814 - val_handedness_loss: 0.6948\n",
      "Epoch 2/150\n",
      "4412/4412 [==============================] - 0s 113us/step - loss: 0.8801 - regression_loss: 0.1975 - handedness_loss: 0.6818 - val_loss: 0.8509 - val_regression_loss: 0.1843 - val_handedness_loss: 0.6687\n",
      "Epoch 3/150\n",
      "4412/4412 [==============================] - 1s 147us/step - loss: 0.7806 - regression_loss: 0.1485 - handedness_loss: 0.6322 - val_loss: 0.7743 - val_regression_loss: 0.1614 - val_handedness_loss: 0.6149\n",
      "Epoch 4/150\n",
      "4412/4412 [==============================] - 1s 148us/step - loss: 0.7284 - regression_loss: 0.1397 - handedness_loss: 0.5883 - val_loss: 0.7232 - val_regression_loss: 0.1430 - val_handedness_loss: 0.5801\n",
      "Epoch 5/150\n",
      "4412/4412 [==============================] - 1s 135us/step - loss: 0.6731 - regression_loss: 0.1307 - handedness_loss: 0.5421 - val_loss: 0.6648 - val_regression_loss: 0.1275 - val_handedness_loss: 0.5269\n",
      "Epoch 6/150\n",
      "4412/4412 [==============================] - 1s 123us/step - loss: 0.6290 - regression_loss: 0.1241 - handedness_loss: 0.5047 - val_loss: 0.6472 - val_regression_loss: 0.1323 - val_handedness_loss: 0.5199\n",
      "Epoch 7/150\n",
      "4412/4412 [==============================] - 1s 145us/step - loss: 0.6105 - regression_loss: 0.1229 - handedness_loss: 0.4861 - val_loss: 0.6303 - val_regression_loss: 0.1332 - val_handedness_loss: 0.5042\n",
      "Epoch 8/150\n",
      "4412/4412 [==============================] - 1s 116us/step - loss: 0.5797 - regression_loss: 0.1204 - handedness_loss: 0.4593 - val_loss: 0.6211 - val_regression_loss: 0.1376 - val_handedness_loss: 0.4921\n",
      "Epoch 9/150\n",
      "4412/4412 [==============================] - 0s 103us/step - loss: 0.5641 - regression_loss: 0.1170 - handedness_loss: 0.4468 - val_loss: 0.5536 - val_regression_loss: 0.1233 - val_handedness_loss: 0.4268\n",
      "Epoch 10/150\n",
      "4412/4412 [==============================] - 1s 120us/step - loss: 0.5394 - regression_loss: 0.1137 - handedness_loss: 0.4254 - val_loss: 0.5567 - val_regression_loss: 0.1247 - val_handedness_loss: 0.4321\n",
      "Epoch 11/150\n",
      "4412/4412 [==============================] - 1s 117us/step - loss: 0.5340 - regression_loss: 0.1102 - handedness_loss: 0.4235 - val_loss: 0.5474 - val_regression_loss: 0.1169 - val_handedness_loss: 0.4292\n",
      "Epoch 12/150\n",
      "4412/4412 [==============================] - 1s 127us/step - loss: 0.5173 - regression_loss: 0.1056 - handedness_loss: 0.4099 - val_loss: 0.5358 - val_regression_loss: 0.1172 - val_handedness_loss: 0.4107\n",
      "Epoch 13/150\n",
      "4412/4412 [==============================] - 1s 127us/step - loss: 0.5105 - regression_loss: 0.1039 - handedness_loss: 0.4072 - val_loss: 0.5413 - val_regression_loss: 0.1182 - val_handedness_loss: 0.4181\n",
      "Epoch 14/150\n",
      "4412/4412 [==============================] - 1s 129us/step - loss: 0.4908 - regression_loss: 0.1005 - handedness_loss: 0.3886 - val_loss: 0.4949 - val_regression_loss: 0.1108 - val_handedness_loss: 0.3782\n",
      "Epoch 15/150\n",
      "4412/4412 [==============================] - 1s 128us/step - loss: 0.4774 - regression_loss: 0.0996 - handedness_loss: 0.3780 - val_loss: 0.5052 - val_regression_loss: 0.1076 - val_handedness_loss: 0.3947\n",
      "Epoch 16/150\n",
      "4412/4412 [==============================] - 0s 101us/step - loss: 0.4635 - regression_loss: 0.0944 - handedness_loss: 0.3695 - val_loss: 0.4737 - val_regression_loss: 0.1034 - val_handedness_loss: 0.3646\n",
      "Epoch 17/150\n",
      "4412/4412 [==============================] - 0s 104us/step - loss: 0.4533 - regression_loss: 0.0919 - handedness_loss: 0.3608 - val_loss: 0.4758 - val_regression_loss: 0.0986 - val_handedness_loss: 0.3678\n",
      "Epoch 18/150\n",
      "4412/4412 [==============================] - 0s 89us/step - loss: 0.4500 - regression_loss: 0.0896 - handedness_loss: 0.3608 - val_loss: 0.4706 - val_regression_loss: 0.0964 - val_handedness_loss: 0.3735\n",
      "Epoch 19/150\n",
      "4412/4412 [==============================] - 0s 92us/step - loss: 0.4372 - regression_loss: 0.0857 - handedness_loss: 0.3497 - val_loss: 0.4928 - val_regression_loss: 0.0953 - val_handedness_loss: 0.3957\n",
      "Epoch 20/150\n",
      "4412/4412 [==============================] - 1s 122us/step - loss: 0.4308 - regression_loss: 0.0829 - handedness_loss: 0.3476 - val_loss: 0.4595 - val_regression_loss: 0.0909 - val_handedness_loss: 0.3698\n",
      "Evaluating model with testing data...\n",
      "924/924 [==============================] - 0s 23us/step\n",
      "Getting distribution of predictions and covariance matrix...\n",
      "      1 of 20\n",
      "      2 of 20\n",
      "      3 of 20\n",
      "      4 of 20\n",
      "      5 of 20\n",
      "      6 of 20\n",
      "      7 of 20\n",
      "      8 of 20\n",
      "      9 of 20\n",
      "      10 of 20\n",
      "      11 of 20\n",
      "      12 of 20\n",
      "      13 of 20\n",
      "      14 of 20\n",
      "      15 of 20\n",
      "      16 of 20\n",
      "      17 of 20\n",
      "      18 of 20\n",
      "      19 of 20\n",
      "      20 of 20\n",
      "Computing ensemble means...\n",
      "Computing mean squared error...\n",
      "Iteration 29\n",
      "Train on 4552 samples, validate on 954 samples\n",
      "Epoch 1/150\n",
      "4552/4552 [==============================] - 1s 144us/step - loss: 1.2380 - regression_loss: 0.5548 - handedness_loss: 0.6794 - val_loss: 1.0052 - val_regression_loss: 0.3339 - val_handedness_loss: 0.6711\n",
      "Epoch 2/150\n",
      "4552/4552 [==============================] - 0s 89us/step - loss: 0.9399 - regression_loss: 0.2884 - handedness_loss: 0.6507 - val_loss: 0.9339 - val_regression_loss: 0.2880 - val_handedness_loss: 0.6476\n",
      "Epoch 3/150\n",
      "4552/4552 [==============================] - 0s 95us/step - loss: 0.8740 - regression_loss: 0.2514 - handedness_loss: 0.6223 - val_loss: 0.8774 - val_regression_loss: 0.2560 - val_handedness_loss: 0.6210\n",
      "Epoch 4/150\n",
      "4552/4552 [==============================] - 1s 124us/step - loss: 0.8125 - regression_loss: 0.2227 - handedness_loss: 0.5889 - val_loss: 0.8108 - val_regression_loss: 0.2249 - val_handedness_loss: 0.5837\n",
      "Epoch 5/150\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4552/4552 [==============================] - 0s 103us/step - loss: 0.7479 - regression_loss: 0.1947 - handedness_loss: 0.5538 - val_loss: 0.7544 - val_regression_loss: 0.1983 - val_handedness_loss: 0.5552\n",
      "Epoch 6/150\n",
      "4552/4552 [==============================] - 1s 132us/step - loss: 0.7056 - regression_loss: 0.1764 - handedness_loss: 0.5285 - val_loss: 0.7060 - val_regression_loss: 0.1826 - val_handedness_loss: 0.5232\n",
      "Epoch 7/150\n",
      "4552/4552 [==============================] - 1s 133us/step - loss: 0.6723 - regression_loss: 0.1641 - handedness_loss: 0.5079 - val_loss: 0.6827 - val_regression_loss: 0.1728 - val_handedness_loss: 0.5108\n",
      "Epoch 8/150\n",
      "4552/4552 [==============================] - 1s 123us/step - loss: 0.6533 - regression_loss: 0.1557 - handedness_loss: 0.4974 - val_loss: 0.6615 - val_regression_loss: 0.1597 - val_handedness_loss: 0.5004\n",
      "Epoch 9/150\n",
      "4552/4552 [==============================] - 1s 148us/step - loss: 0.6327 - regression_loss: 0.1441 - handedness_loss: 0.4878 - val_loss: 0.6447 - val_regression_loss: 0.1541 - val_handedness_loss: 0.4897\n",
      "Epoch 10/150\n",
      "4552/4552 [==============================] - 1s 146us/step - loss: 0.6030 - regression_loss: 0.1345 - handedness_loss: 0.4683 - val_loss: 0.5939 - val_regression_loss: 0.1387 - val_handedness_loss: 0.4525\n",
      "Epoch 11/150\n",
      "4552/4552 [==============================] - 1s 144us/step - loss: 0.5899 - regression_loss: 0.1263 - handedness_loss: 0.4641 - val_loss: 0.6203 - val_regression_loss: 0.1348 - val_handedness_loss: 0.4835\n",
      "Epoch 12/150\n",
      "4552/4552 [==============================] - 1s 119us/step - loss: 0.5721 - regression_loss: 0.1192 - handedness_loss: 0.4534 - val_loss: 0.5843 - val_regression_loss: 0.1318 - val_handedness_loss: 0.4521\n",
      "Epoch 13/150\n",
      "4552/4552 [==============================] - 1s 117us/step - loss: 0.5695 - regression_loss: 0.1134 - handedness_loss: 0.4559 - val_loss: 0.5833 - val_regression_loss: 0.1173 - val_handedness_loss: 0.4682\n",
      "Epoch 14/150\n",
      "4552/4552 [==============================] - 1s 117us/step - loss: 0.5548 - regression_loss: 0.1080 - handedness_loss: 0.4469 - val_loss: 0.5687 - val_regression_loss: 0.1130 - val_handedness_loss: 0.4567\n",
      "Epoch 15/150\n",
      "4552/4552 [==============================] - 1s 117us/step - loss: 0.5525 - regression_loss: 0.1033 - handedness_loss: 0.4479 - val_loss: 0.5597 - val_regression_loss: 0.1075 - val_handedness_loss: 0.4562\n",
      "Epoch 16/150\n",
      "4552/4552 [==============================] - 1s 120us/step - loss: 0.5380 - regression_loss: 0.0992 - handedness_loss: 0.4392 - val_loss: 0.5627 - val_regression_loss: 0.1030 - val_handedness_loss: 0.4641\n",
      "Evaluating model with testing data...\n",
      "954/954 [==============================] - 0s 22us/step\n",
      "Getting distribution of predictions and covariance matrix...\n",
      "      1 of 20\n",
      "      2 of 20\n",
      "      3 of 20\n",
      "      4 of 20\n",
      "      5 of 20\n",
      "      6 of 20\n",
      "      7 of 20\n",
      "      8 of 20\n",
      "      9 of 20\n",
      "      10 of 20\n",
      "      11 of 20\n",
      "      12 of 20\n",
      "      13 of 20\n",
      "      14 of 20\n",
      "      15 of 20\n",
      "      16 of 20\n",
      "      17 of 20\n",
      "      18 of 20\n",
      "      19 of 20\n",
      "      20 of 20\n",
      "Computing ensemble means...\n",
      "Computing mean squared error...\n",
      "Iteration 30\n",
      "Train on 4692 samples, validate on 984 samples\n",
      "Epoch 1/150\n",
      "4692/4692 [==============================] - 1s 121us/step - loss: 1.1940 - regression_loss: 0.4951 - handedness_loss: 0.6969 - val_loss: 0.9899 - val_regression_loss: 0.3032 - val_handedness_loss: 0.6870\n",
      "Epoch 2/150\n",
      "4692/4692 [==============================] - 0s 83us/step - loss: 0.9271 - regression_loss: 0.2479 - handedness_loss: 0.6792 - val_loss: 0.8960 - val_regression_loss: 0.2304 - val_handedness_loss: 0.6658\n",
      "Epoch 3/150\n",
      "4692/4692 [==============================] - 1s 121us/step - loss: 0.8526 - regression_loss: 0.1928 - handedness_loss: 0.6598 - val_loss: 0.8203 - val_regression_loss: 0.1836 - val_handedness_loss: 0.6344\n",
      "Epoch 4/150\n",
      "4692/4692 [==============================] - 1s 130us/step - loss: 0.8093 - regression_loss: 0.1695 - handedness_loss: 0.6401 - val_loss: 0.7831 - val_regression_loss: 0.1751 - val_handedness_loss: 0.6078\n",
      "Epoch 5/150\n",
      "4692/4692 [==============================] - 0s 101us/step - loss: 0.7765 - regression_loss: 0.1617 - handedness_loss: 0.6152 - val_loss: 0.7567 - val_regression_loss: 0.1670 - val_handedness_loss: 0.5894\n",
      "Epoch 6/150\n",
      "4692/4692 [==============================] - 0s 97us/step - loss: 0.7394 - regression_loss: 0.1562 - handedness_loss: 0.5825 - val_loss: 0.7360 - val_regression_loss: 0.1650 - val_handedness_loss: 0.5680\n",
      "Epoch 7/150\n",
      "4692/4692 [==============================] - 1s 108us/step - loss: 0.7043 - regression_loss: 0.1502 - handedness_loss: 0.5543 - val_loss: 0.6855 - val_regression_loss: 0.1557 - val_handedness_loss: 0.5279\n",
      "Epoch 8/150\n",
      "4692/4692 [==============================] - 1s 109us/step - loss: 0.6571 - regression_loss: 0.1404 - handedness_loss: 0.5167 - val_loss: 0.6640 - val_regression_loss: 0.1495 - val_handedness_loss: 0.5167\n",
      "Epoch 9/150\n",
      "4692/4692 [==============================] - 1s 107us/step - loss: 0.6359 - regression_loss: 0.1328 - handedness_loss: 0.5022 - val_loss: 0.6132 - val_regression_loss: 0.1443 - val_handedness_loss: 0.4697\n",
      "Epoch 10/150\n",
      "4692/4692 [==============================] - 1s 127us/step - loss: 0.6053 - regression_loss: 0.1272 - handedness_loss: 0.4775 - val_loss: 0.5945 - val_regression_loss: 0.1321 - val_handedness_loss: 0.4611\n",
      "Epoch 11/150\n",
      "4692/4692 [==============================] - 0s 97us/step - loss: 0.5674 - regression_loss: 0.1186 - handedness_loss: 0.4484 - val_loss: 0.5567 - val_regression_loss: 0.1234 - val_handedness_loss: 0.4314\n",
      "Epoch 12/150\n",
      "4692/4692 [==============================] - 0s 98us/step - loss: 0.5377 - regression_loss: 0.1114 - handedness_loss: 0.4265 - val_loss: 0.5343 - val_regression_loss: 0.1169 - val_handedness_loss: 0.4160\n",
      "Epoch 13/150\n",
      "4692/4692 [==============================] - 0s 97us/step - loss: 0.5355 - regression_loss: 0.1071 - handedness_loss: 0.4286 - val_loss: 0.5265 - val_regression_loss: 0.1143 - val_handedness_loss: 0.4082\n",
      "Epoch 14/150\n",
      "4692/4692 [==============================] - 1s 112us/step - loss: 0.5099 - regression_loss: 0.1025 - handedness_loss: 0.4076 - val_loss: 0.5144 - val_regression_loss: 0.1056 - val_handedness_loss: 0.4096\n",
      "Epoch 15/150\n",
      "4692/4692 [==============================] - 1s 109us/step - loss: 0.5088 - regression_loss: 0.0982 - handedness_loss: 0.4098 - val_loss: 0.5059 - val_regression_loss: 0.1029 - val_handedness_loss: 0.4034\n",
      "Epoch 16/150\n",
      "4692/4692 [==============================] - 0s 93us/step - loss: 0.4986 - regression_loss: 0.0939 - handedness_loss: 0.4046 - val_loss: 0.4820 - val_regression_loss: 0.0976 - val_handedness_loss: 0.3844\n",
      "Epoch 17/150\n",
      "4692/4692 [==============================] - 0s 101us/step - loss: 0.4870 - regression_loss: 0.0908 - handedness_loss: 0.3962 - val_loss: 0.4659 - val_regression_loss: 0.0920 - val_handedness_loss: 0.3714\n",
      "Epoch 18/150\n",
      "4692/4692 [==============================] - 0s 88us/step - loss: 0.4847 - regression_loss: 0.0879 - handedness_loss: 0.3966 - val_loss: 0.4933 - val_regression_loss: 0.0939 - val_handedness_loss: 0.3989\n",
      "Epoch 19/150\n",
      "4692/4692 [==============================] - 0s 94us/step - loss: 0.4711 - regression_loss: 0.0860 - handedness_loss: 0.3855 - val_loss: 0.4801 - val_regression_loss: 0.0911 - val_handedness_loss: 0.3887\n",
      "Epoch 20/150\n",
      "4692/4692 [==============================] - 0s 102us/step - loss: 0.4660 - regression_loss: 0.0843 - handedness_loss: 0.3818 - val_loss: 0.4912 - val_regression_loss: 0.0883 - val_handedness_loss: 0.4016\n",
      "Epoch 21/150\n",
      "4692/4692 [==============================] - 1s 131us/step - loss: 0.4675 - regression_loss: 0.0824 - handedness_loss: 0.3851 - val_loss: 0.4690 - val_regression_loss: 0.0871 - val_handedness_loss: 0.3813\n",
      "Evaluating model with testing data...\n",
      "984/984 [==============================] - 0s 26us/step\n",
      "Getting distribution of predictions and covariance matrix...\n",
      "      1 of 20\n",
      "      2 of 20\n",
      "      3 of 20\n",
      "      4 of 20\n",
      "      5 of 20\n",
      "      6 of 20\n",
      "      7 of 20\n",
      "      8 of 20\n",
      "      9 of 20\n",
      "      10 of 20\n",
      "      11 of 20\n",
      "      12 of 20\n",
      "      13 of 20\n",
      "      14 of 20\n",
      "      15 of 20\n",
      "      16 of 20\n",
      "      17 of 20\n",
      "      18 of 20\n",
      "      19 of 20\n",
      "      20 of 20\n",
      "Computing ensemble means...\n",
      "Computing mean squared error...\n",
      "Iteration 31\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 4832 samples, validate on 1014 samples\n",
      "Epoch 1/150\n",
      "4832/4832 [==============================] - 1s 152us/step - loss: 1.0910 - regression_loss: 0.4040 - handedness_loss: 0.6858 - val_loss: 0.9141 - val_regression_loss: 0.2649 - val_handedness_loss: 0.6489\n",
      "Epoch 2/150\n",
      "4832/4832 [==============================] - 1s 122us/step - loss: 0.8351 - regression_loss: 0.2212 - handedness_loss: 0.6136 - val_loss: 0.7693 - val_regression_loss: 0.1888 - val_handedness_loss: 0.5803\n",
      "Epoch 3/150\n",
      "4832/4832 [==============================] - 1s 144us/step - loss: 0.7068 - regression_loss: 0.1731 - handedness_loss: 0.5333 - val_loss: 0.6678 - val_regression_loss: 0.1600 - val_handedness_loss: 0.5077\n",
      "Epoch 4/150\n",
      "4832/4832 [==============================] - 1s 145us/step - loss: 0.5982 - regression_loss: 0.1471 - handedness_loss: 0.4512 - val_loss: 0.5513 - val_regression_loss: 0.1396 - val_handedness_loss: 0.4113\n",
      "Epoch 5/150\n",
      "4832/4832 [==============================] - 1s 145us/step - loss: 0.5179 - regression_loss: 0.1311 - handedness_loss: 0.3867 - val_loss: 0.4953 - val_regression_loss: 0.1290 - val_handedness_loss: 0.3665\n",
      "Epoch 6/150\n",
      "4832/4832 [==============================] - 1s 146us/step - loss: 0.4602 - regression_loss: 0.1193 - handedness_loss: 0.3409 - val_loss: 0.4495 - val_regression_loss: 0.1219 - val_handedness_loss: 0.3275\n",
      "Epoch 7/150\n",
      "4832/4832 [==============================] - 1s 146us/step - loss: 0.4270 - regression_loss: 0.1136 - handedness_loss: 0.3128 - val_loss: 0.3979 - val_regression_loss: 0.1158 - val_handedness_loss: 0.2820\n",
      "Epoch 8/150\n",
      "4832/4832 [==============================] - 1s 136us/step - loss: 0.3937 - regression_loss: 0.1051 - handedness_loss: 0.2881 - val_loss: 0.3961 - val_regression_loss: 0.1083 - val_handedness_loss: 0.2875\n",
      "Epoch 9/150\n",
      "4832/4832 [==============================] - 1s 146us/step - loss: 0.3638 - regression_loss: 0.0997 - handedness_loss: 0.2644 - val_loss: 0.3768 - val_regression_loss: 0.0999 - val_handedness_loss: 0.2777\n",
      "Epoch 10/150\n",
      "4832/4832 [==============================] - 1s 146us/step - loss: 0.3464 - regression_loss: 0.0963 - handedness_loss: 0.2496 - val_loss: 0.3663 - val_regression_loss: 0.0971 - val_handedness_loss: 0.2690\n",
      "Epoch 11/150\n",
      "4832/4832 [==============================] - 1s 121us/step - loss: 0.3300 - regression_loss: 0.0915 - handedness_loss: 0.2383 - val_loss: 0.3242 - val_regression_loss: 0.0952 - val_handedness_loss: 0.2290\n",
      "Epoch 12/150\n",
      "4832/4832 [==============================] - 1s 117us/step - loss: 0.3262 - regression_loss: 0.0890 - handedness_loss: 0.2374 - val_loss: 0.3112 - val_regression_loss: 0.0903 - val_handedness_loss: 0.2209\n",
      "Epoch 13/150\n",
      "4832/4832 [==============================] - 1s 136us/step - loss: 0.3059 - regression_loss: 0.0848 - handedness_loss: 0.2210 - val_loss: 0.2952 - val_regression_loss: 0.0867 - val_handedness_loss: 0.2088\n",
      "Epoch 14/150\n",
      "4832/4832 [==============================] - 1s 135us/step - loss: 0.3021 - regression_loss: 0.0829 - handedness_loss: 0.2191 - val_loss: 0.3310 - val_regression_loss: 0.0872 - val_handedness_loss: 0.2440\n",
      "Epoch 15/150\n",
      "4832/4832 [==============================] - 1s 135us/step - loss: 0.3031 - regression_loss: 0.0797 - handedness_loss: 0.2238 - val_loss: 0.3029 - val_regression_loss: 0.0836 - val_handedness_loss: 0.2203\n",
      "Epoch 16/150\n",
      "4832/4832 [==============================] - 1s 145us/step - loss: 0.2912 - regression_loss: 0.0787 - handedness_loss: 0.2121 - val_loss: 0.3023 - val_regression_loss: 0.0825 - val_handedness_loss: 0.2203\n",
      "Epoch 17/150\n",
      "4832/4832 [==============================] - 1s 129us/step - loss: 0.2829 - regression_loss: 0.0776 - handedness_loss: 0.2053 - val_loss: 0.2892 - val_regression_loss: 0.0798 - val_handedness_loss: 0.2099\n",
      "Evaluating model with testing data...\n",
      "1014/1014 [==============================] - 0s 21us/step\n",
      "Getting distribution of predictions and covariance matrix...\n",
      "      1 of 20\n",
      "      2 of 20\n",
      "      3 of 20\n",
      "      4 of 20\n",
      "      5 of 20\n",
      "      6 of 20\n",
      "      7 of 20\n",
      "      8 of 20\n",
      "      9 of 20\n",
      "      10 of 20\n",
      "      11 of 20\n",
      "      12 of 20\n",
      "      13 of 20\n",
      "      14 of 20\n",
      "      15 of 20\n",
      "      16 of 20\n",
      "      17 of 20\n",
      "      18 of 20\n",
      "      19 of 20\n",
      "      20 of 20\n",
      "Computing ensemble means...\n",
      "Computing mean squared error...\n",
      "Iteration 32\n",
      "Train on 4972 samples, validate on 1044 samples\n",
      "Epoch 1/150\n",
      "4972/4972 [==============================] - 1s 160us/step - loss: 1.2953 - regression_loss: 0.6057 - handedness_loss: 0.6884 - val_loss: 1.0151 - val_regression_loss: 0.3331 - val_handedness_loss: 0.6809\n",
      "Epoch 2/150\n",
      "4972/4972 [==============================] - 1s 123us/step - loss: 0.9669 - regression_loss: 0.2949 - handedness_loss: 0.6720 - val_loss: 0.9618 - val_regression_loss: 0.2980 - val_handedness_loss: 0.6635\n",
      "Epoch 3/150\n",
      "4972/4972 [==============================] - 1s 146us/step - loss: 0.9140 - regression_loss: 0.2582 - handedness_loss: 0.6556 - val_loss: 0.9247 - val_regression_loss: 0.2620 - val_handedness_loss: 0.6662\n",
      "Epoch 4/150\n",
      "4972/4972 [==============================] - 1s 145us/step - loss: 0.8746 - regression_loss: 0.2308 - handedness_loss: 0.6440 - val_loss: 0.8843 - val_regression_loss: 0.2397 - val_handedness_loss: 0.6442\n",
      "Epoch 5/150\n",
      "4972/4972 [==============================] - 1s 135us/step - loss: 0.8422 - regression_loss: 0.2092 - handedness_loss: 0.6330 - val_loss: 0.8650 - val_regression_loss: 0.2200 - val_handedness_loss: 0.6449\n",
      "Epoch 6/150\n",
      "4972/4972 [==============================] - 1s 136us/step - loss: 0.8129 - regression_loss: 0.1920 - handedness_loss: 0.6209 - val_loss: 0.8305 - val_regression_loss: 0.2020 - val_handedness_loss: 0.6265\n",
      "Epoch 7/150\n",
      "4972/4972 [==============================] - 1s 146us/step - loss: 0.7912 - regression_loss: 0.1749 - handedness_loss: 0.6162 - val_loss: 0.8130 - val_regression_loss: 0.1856 - val_handedness_loss: 0.6270\n",
      "Epoch 8/150\n",
      "4972/4972 [==============================] - 1s 113us/step - loss: 0.7710 - regression_loss: 0.1624 - handedness_loss: 0.6086 - val_loss: 0.7726 - val_regression_loss: 0.1698 - val_handedness_loss: 0.6043\n",
      "Epoch 9/150\n",
      "4972/4972 [==============================] - 1s 129us/step - loss: 0.7271 - regression_loss: 0.1459 - handedness_loss: 0.5811 - val_loss: 0.7124 - val_regression_loss: 0.1470 - val_handedness_loss: 0.5597\n",
      "Epoch 10/150\n",
      "4972/4972 [==============================] - 1s 146us/step - loss: 0.6713 - regression_loss: 0.1271 - handedness_loss: 0.5444 - val_loss: 0.6919 - val_regression_loss: 0.1369 - val_handedness_loss: 0.5583\n",
      "Epoch 11/150\n",
      "4972/4972 [==============================] - 1s 146us/step - loss: 0.6579 - regression_loss: 0.1196 - handedness_loss: 0.5382 - val_loss: 0.6635 - val_regression_loss: 0.1302 - val_handedness_loss: 0.5429\n",
      "Epoch 12/150\n",
      "4972/4972 [==============================] - 1s 147us/step - loss: 0.6455 - regression_loss: 0.1134 - handedness_loss: 0.5322 - val_loss: 0.6742 - val_regression_loss: 0.1226 - val_handedness_loss: 0.5486\n",
      "Epoch 13/150\n",
      "4972/4972 [==============================] - 1s 121us/step - loss: 0.6409 - regression_loss: 0.1080 - handedness_loss: 0.5330 - val_loss: 0.6600 - val_regression_loss: 0.1213 - val_handedness_loss: 0.5363\n",
      "Epoch 14/150\n",
      "4972/4972 [==============================] - 1s 125us/step - loss: 0.6093 - regression_loss: 0.1021 - handedness_loss: 0.5070 - val_loss: 0.6077 - val_regression_loss: 0.1041 - val_handedness_loss: 0.5067\n",
      "Epoch 15/150\n",
      "4972/4972 [==============================] - 1s 113us/step - loss: 0.5710 - regression_loss: 0.0932 - handedness_loss: 0.4775 - val_loss: 0.5997 - val_regression_loss: 0.0972 - val_handedness_loss: 0.4968\n",
      "Epoch 16/150\n",
      "4972/4972 [==============================] - 1s 114us/step - loss: 0.5702 - regression_loss: 0.0911 - handedness_loss: 0.4793 - val_loss: 0.5727 - val_regression_loss: 0.0948 - val_handedness_loss: 0.4872\n",
      "Epoch 17/150\n",
      "4972/4972 [==============================] - 1s 145us/step - loss: 0.5554 - regression_loss: 0.0880 - handedness_loss: 0.4672 - val_loss: 0.5479 - val_regression_loss: 0.0901 - val_handedness_loss: 0.4456\n",
      "Epoch 18/150\n",
      "4972/4972 [==============================] - 1s 145us/step - loss: 0.5455 - regression_loss: 0.0855 - handedness_loss: 0.4598 - val_loss: 0.5649 - val_regression_loss: 0.0884 - val_handedness_loss: 0.4770\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 19/150\n",
      "4972/4972 [==============================] - 1s 147us/step - loss: 0.5498 - regression_loss: 0.0849 - handedness_loss: 0.4651 - val_loss: 0.5666 - val_regression_loss: 0.0889 - val_handedness_loss: 0.4808\n",
      "Epoch 20/150\n",
      "4972/4972 [==============================] - 1s 145us/step - loss: 0.5358 - regression_loss: 0.0827 - handedness_loss: 0.4531 - val_loss: 0.5532 - val_regression_loss: 0.0877 - val_handedness_loss: 0.4719\n",
      "Epoch 21/150\n",
      "4972/4972 [==============================] - 1s 147us/step - loss: 0.5366 - regression_loss: 0.0823 - handedness_loss: 0.4544 - val_loss: 0.5377 - val_regression_loss: 0.0837 - val_handedness_loss: 0.4414\n",
      "Epoch 22/150\n",
      "4972/4972 [==============================] - 1s 147us/step - loss: 0.5305 - regression_loss: 0.0806 - handedness_loss: 0.4500 - val_loss: 0.5527 - val_regression_loss: 0.0836 - val_handedness_loss: 0.4621\n",
      "Epoch 23/150\n",
      "4972/4972 [==============================] - 1s 135us/step - loss: 0.5351 - regression_loss: 0.0803 - handedness_loss: 0.4546 - val_loss: 0.5474 - val_regression_loss: 0.0816 - val_handedness_loss: 0.4670\n",
      "Epoch 24/150\n",
      "4972/4972 [==============================] - 1s 139us/step - loss: 0.5220 - regression_loss: 0.0795 - handedness_loss: 0.4425 - val_loss: 0.5228 - val_regression_loss: 0.0814 - val_handedness_loss: 0.4523\n",
      "Epoch 25/150\n",
      "4972/4972 [==============================] - 1s 146us/step - loss: 0.5243 - regression_loss: 0.0793 - handedness_loss: 0.4447 - val_loss: 0.5668 - val_regression_loss: 0.0817 - val_handedness_loss: 0.4760\n",
      "Evaluating model with testing data...\n",
      "1044/1044 [==============================] - 0s 22us/step\n",
      "Getting distribution of predictions and covariance matrix...\n",
      "      1 of 20\n",
      "      2 of 20\n",
      "      3 of 20\n",
      "      4 of 20\n",
      "      5 of 20\n",
      "      6 of 20\n",
      "      7 of 20\n",
      "      8 of 20\n",
      "      9 of 20\n",
      "      10 of 20\n",
      "      11 of 20\n",
      "      12 of 20\n",
      "      13 of 20\n",
      "      14 of 20\n",
      "      15 of 20\n",
      "      16 of 20\n",
      "      17 of 20\n",
      "      18 of 20\n",
      "      19 of 20\n",
      "      20 of 20\n",
      "Computing ensemble means...\n",
      "Computing mean squared error...\n",
      "Iteration 33\n",
      "Train on 5112 samples, validate on 1074 samples\n",
      "Epoch 1/150\n",
      "5112/5112 [==============================] - 1s 149us/step - loss: 1.1688 - regression_loss: 0.4735 - handedness_loss: 0.6948 - val_loss: 0.9281 - val_regression_loss: 0.2469 - val_handedness_loss: 0.6826\n",
      "Epoch 2/150\n",
      "5112/5112 [==============================] - 1s 135us/step - loss: 0.8818 - regression_loss: 0.2056 - handedness_loss: 0.6761 - val_loss: 0.8678 - val_regression_loss: 0.1982 - val_handedness_loss: 0.6697\n",
      "Epoch 3/150\n",
      "5112/5112 [==============================] - 1s 148us/step - loss: 0.8454 - regression_loss: 0.1804 - handedness_loss: 0.6650 - val_loss: 0.8516 - val_regression_loss: 0.1852 - val_handedness_loss: 0.6652\n",
      "Epoch 4/150\n",
      "5112/5112 [==============================] - 1s 109us/step - loss: 0.8128 - regression_loss: 0.1640 - handedness_loss: 0.6487 - val_loss: 0.8143 - val_regression_loss: 0.1651 - val_handedness_loss: 0.6490\n",
      "Epoch 5/150\n",
      "5112/5112 [==============================] - 0s 64us/step - loss: 0.7721 - regression_loss: 0.1455 - handedness_loss: 0.6266 - val_loss: 0.7708 - val_regression_loss: 0.1511 - val_handedness_loss: 0.6148\n",
      "Epoch 6/150\n",
      "5112/5112 [==============================] - 0s 65us/step - loss: 0.7412 - regression_loss: 0.1416 - handedness_loss: 0.5995 - val_loss: 0.7320 - val_regression_loss: 0.1359 - val_handedness_loss: 0.5903\n",
      "Epoch 7/150\n",
      "5112/5112 [==============================] - 1s 114us/step - loss: 0.7118 - regression_loss: 0.1334 - handedness_loss: 0.5783 - val_loss: 0.7118 - val_regression_loss: 0.1344 - val_handedness_loss: 0.5742\n",
      "Epoch 8/150\n",
      "5112/5112 [==============================] - 1s 130us/step - loss: 0.6867 - regression_loss: 0.1243 - handedness_loss: 0.5625 - val_loss: 0.6935 - val_regression_loss: 0.1291 - val_handedness_loss: 0.5625\n",
      "Epoch 9/150\n",
      "5112/5112 [==============================] - 1s 127us/step - loss: 0.6626 - regression_loss: 0.1189 - handedness_loss: 0.5436 - val_loss: 0.6851 - val_regression_loss: 0.1189 - val_handedness_loss: 0.5621\n",
      "Epoch 10/150\n",
      "5112/5112 [==============================] - 1s 132us/step - loss: 0.6514 - regression_loss: 0.1112 - handedness_loss: 0.5402 - val_loss: 0.6688 - val_regression_loss: 0.1139 - val_handedness_loss: 0.5484\n",
      "Epoch 11/150\n",
      "5112/5112 [==============================] - 1s 135us/step - loss: 0.6438 - regression_loss: 0.1098 - handedness_loss: 0.5340 - val_loss: 0.6552 - val_regression_loss: 0.1132 - val_handedness_loss: 0.5385\n",
      "Epoch 12/150\n",
      "5112/5112 [==============================] - 1s 146us/step - loss: 0.6344 - regression_loss: 0.1025 - handedness_loss: 0.5319 - val_loss: 0.6560 - val_regression_loss: 0.1068 - val_handedness_loss: 0.5526\n",
      "Epoch 13/150\n",
      "5112/5112 [==============================] - 1s 147us/step - loss: 0.6227 - regression_loss: 0.0987 - handedness_loss: 0.5241 - val_loss: 0.6267 - val_regression_loss: 0.1008 - val_handedness_loss: 0.5272\n",
      "Epoch 14/150\n",
      "5112/5112 [==============================] - 1s 148us/step - loss: 0.6067 - regression_loss: 0.0959 - handedness_loss: 0.5108 - val_loss: 0.6331 - val_regression_loss: 0.1022 - val_handedness_loss: 0.5283\n",
      "Epoch 15/150\n",
      "5112/5112 [==============================] - 1s 144us/step - loss: 0.6051 - regression_loss: 0.0974 - handedness_loss: 0.5077 - val_loss: 0.6159 - val_regression_loss: 0.1037 - val_handedness_loss: 0.5120\n",
      "Epoch 16/150\n",
      "5112/5112 [==============================] - 1s 139us/step - loss: 0.5786 - regression_loss: 0.0963 - handedness_loss: 0.4822 - val_loss: 0.5921 - val_regression_loss: 0.1011 - val_handedness_loss: 0.4940\n",
      "Epoch 17/150\n",
      "5112/5112 [==============================] - 1s 130us/step - loss: 0.5748 - regression_loss: 0.0936 - handedness_loss: 0.4810 - val_loss: 0.5540 - val_regression_loss: 0.0936 - val_handedness_loss: 0.4583\n",
      "Epoch 18/150\n",
      "5112/5112 [==============================] - 1s 124us/step - loss: 0.5611 - regression_loss: 0.0901 - handedness_loss: 0.4711 - val_loss: 0.5632 - val_regression_loss: 0.0929 - val_handedness_loss: 0.4707\n",
      "Epoch 19/150\n",
      "5112/5112 [==============================] - 1s 148us/step - loss: 0.5538 - regression_loss: 0.0864 - handedness_loss: 0.4674 - val_loss: 0.5593 - val_regression_loss: 0.0892 - val_handedness_loss: 0.4680\n",
      "Epoch 20/150\n",
      "5112/5112 [==============================] - 1s 138us/step - loss: 0.5371 - regression_loss: 0.0845 - handedness_loss: 0.4525 - val_loss: 0.5525 - val_regression_loss: 0.0858 - val_handedness_loss: 0.4685\n",
      "Epoch 21/150\n",
      "5112/5112 [==============================] - 1s 130us/step - loss: 0.5204 - regression_loss: 0.0854 - handedness_loss: 0.4351 - val_loss: 0.4950 - val_regression_loss: 0.0857 - val_handedness_loss: 0.4069\n",
      "Epoch 22/150\n",
      "5112/5112 [==============================] - 1s 147us/step - loss: 0.5020 - regression_loss: 0.0813 - handedness_loss: 0.4208 - val_loss: 0.4956 - val_regression_loss: 0.0834 - val_handedness_loss: 0.4123\n",
      "Epoch 23/150\n",
      "5112/5112 [==============================] - 1s 148us/step - loss: 0.4938 - regression_loss: 0.0798 - handedness_loss: 0.4139 - val_loss: 0.4883 - val_regression_loss: 0.0814 - val_handedness_loss: 0.4077\n",
      "Epoch 24/150\n",
      "5112/5112 [==============================] - 1s 149us/step - loss: 0.4865 - regression_loss: 0.0799 - handedness_loss: 0.4065 - val_loss: 0.4821 - val_regression_loss: 0.0815 - val_handedness_loss: 0.3998\n",
      "Epoch 25/150\n",
      "5112/5112 [==============================] - 1s 123us/step - loss: 0.4621 - regression_loss: 0.0789 - handedness_loss: 0.3831 - val_loss: 0.4466 - val_regression_loss: 0.0783 - val_handedness_loss: 0.3738\n",
      "Epoch 26/150\n",
      "5112/5112 [==============================] - 1s 110us/step - loss: 0.4646 - regression_loss: 0.0774 - handedness_loss: 0.3871 - val_loss: 0.4483 - val_regression_loss: 0.0793 - val_handedness_loss: 0.3698\n",
      "Epoch 27/150\n",
      "5112/5112 [==============================] - 1s 146us/step - loss: 0.4614 - regression_loss: 0.0774 - handedness_loss: 0.3840 - val_loss: 0.4540 - val_regression_loss: 0.0789 - val_handedness_loss: 0.3713\n",
      "Epoch 28/150\n",
      "5112/5112 [==============================] - 1s 126us/step - loss: 0.4408 - regression_loss: 0.0769 - handedness_loss: 0.3638 - val_loss: 0.4418 - val_regression_loss: 0.0780 - val_handedness_loss: 0.3636\n",
      "Epoch 29/150\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5112/5112 [==============================] - 1s 148us/step - loss: 0.4437 - regression_loss: 0.0776 - handedness_loss: 0.3660 - val_loss: 0.4240 - val_regression_loss: 0.0787 - val_handedness_loss: 0.3485\n",
      "Epoch 30/150\n",
      "5112/5112 [==============================] - 1s 130us/step - loss: 0.4301 - regression_loss: 0.0774 - handedness_loss: 0.3528 - val_loss: 0.4477 - val_regression_loss: 0.0793 - val_handedness_loss: 0.3704\n",
      "Epoch 31/150\n",
      "5112/5112 [==============================] - 1s 139us/step - loss: 0.4325 - regression_loss: 0.0773 - handedness_loss: 0.3551 - val_loss: 0.4143 - val_regression_loss: 0.0765 - val_handedness_loss: 0.3382\n",
      "Epoch 32/150\n",
      "5112/5112 [==============================] - 1s 147us/step - loss: 0.4314 - regression_loss: 0.0774 - handedness_loss: 0.3541 - val_loss: 0.4282 - val_regression_loss: 0.0777 - val_handedness_loss: 0.3551\n",
      "Epoch 33/150\n",
      "5112/5112 [==============================] - 1s 149us/step - loss: 0.4310 - regression_loss: 0.0778 - handedness_loss: 0.3531 - val_loss: 0.4149 - val_regression_loss: 0.0768 - val_handedness_loss: 0.3376\n",
      "Epoch 34/150\n",
      "5112/5112 [==============================] - 1s 126us/step - loss: 0.4224 - regression_loss: 0.0774 - handedness_loss: 0.3449 - val_loss: 0.4261 - val_regression_loss: 0.0789 - val_handedness_loss: 0.3438\n",
      "Epoch 35/150\n",
      "5112/5112 [==============================] - 1s 122us/step - loss: 0.4167 - regression_loss: 0.0770 - handedness_loss: 0.3396 - val_loss: 0.3965 - val_regression_loss: 0.0777 - val_handedness_loss: 0.3177\n",
      "Evaluating model with testing data...\n",
      "1074/1074 [==============================] - 0s 23us/step\n",
      "Getting distribution of predictions and covariance matrix...\n",
      "      1 of 20\n",
      "      2 of 20\n",
      "      3 of 20\n",
      "      4 of 20\n",
      "      5 of 20\n",
      "      6 of 20\n",
      "      7 of 20\n",
      "      8 of 20\n",
      "      9 of 20\n",
      "      10 of 20\n",
      "      11 of 20\n",
      "      12 of 20\n",
      "      13 of 20\n",
      "      14 of 20\n",
      "      15 of 20\n",
      "      16 of 20\n",
      "      17 of 20\n",
      "      18 of 20\n",
      "      19 of 20\n",
      "      20 of 20\n",
      "Computing ensemble means...\n",
      "Computing mean squared error...\n",
      "Iteration 34\n",
      "Train on 5252 samples, validate on 1104 samples\n",
      "Epoch 1/150\n",
      "5252/5252 [==============================] - 1s 137us/step - loss: 1.0665 - regression_loss: 0.3821 - handedness_loss: 0.6788 - val_loss: 0.8609 - val_regression_loss: 0.2102 - val_handedness_loss: 0.6509\n",
      "Epoch 2/150\n",
      "5252/5252 [==============================] - 1s 118us/step - loss: 0.7715 - regression_loss: 0.1713 - handedness_loss: 0.6024 - val_loss: 0.7599 - val_regression_loss: 0.1685 - val_handedness_loss: 0.5916\n",
      "Epoch 3/150\n",
      "5252/5252 [==============================] - 1s 149us/step - loss: 0.6940 - regression_loss: 0.1502 - handedness_loss: 0.5523 - val_loss: 0.6799 - val_regression_loss: 0.1484 - val_handedness_loss: 0.5314\n",
      "Epoch 4/150\n",
      "5252/5252 [==============================] - 1s 150us/step - loss: 0.6199 - regression_loss: 0.1353 - handedness_loss: 0.4857 - val_loss: 0.6490 - val_regression_loss: 0.1481 - val_handedness_loss: 0.5022\n",
      "Epoch 5/150\n",
      "5252/5252 [==============================] - 1s 152us/step - loss: 0.5673 - regression_loss: 0.1271 - handedness_loss: 0.4362 - val_loss: 0.5655 - val_regression_loss: 0.1283 - val_handedness_loss: 0.4340\n",
      "Epoch 6/150\n",
      "5252/5252 [==============================] - 1s 151us/step - loss: 0.5142 - regression_loss: 0.1190 - handedness_loss: 0.3950 - val_loss: 0.5233 - val_regression_loss: 0.1194 - val_handedness_loss: 0.4024\n",
      "Epoch 7/150\n",
      "5252/5252 [==============================] - 1s 151us/step - loss: 0.4755 - regression_loss: 0.1128 - handedness_loss: 0.3662 - val_loss: 0.5025 - val_regression_loss: 0.1157 - val_handedness_loss: 0.3863\n",
      "Epoch 8/150\n",
      "5252/5252 [==============================] - 1s 153us/step - loss: 0.4545 - regression_loss: 0.1086 - handedness_loss: 0.3536 - val_loss: 0.4614 - val_regression_loss: 0.1147 - val_handedness_loss: 0.3493\n",
      "Epoch 9/150\n",
      "5252/5252 [==============================] - 1s 143us/step - loss: 0.4655 - regression_loss: 0.1059 - handedness_loss: 0.3634 - val_loss: 0.4379 - val_regression_loss: 0.1109 - val_handedness_loss: 0.3274\n",
      "Epoch 10/150\n",
      "5252/5252 [==============================] - 1s 145us/step - loss: 0.4391 - regression_loss: 0.1026 - handedness_loss: 0.3336 - val_loss: 0.4312 - val_regression_loss: 0.1030 - val_handedness_loss: 0.3267\n",
      "Epoch 11/150\n",
      "5252/5252 [==============================] - 1s 136us/step - loss: 0.4140 - regression_loss: 0.0938 - handedness_loss: 0.3176 - val_loss: 0.4385 - val_regression_loss: 0.1024 - val_handedness_loss: 0.3351\n",
      "Epoch 12/150\n",
      "5252/5252 [==============================] - 1s 140us/step - loss: 0.4054 - regression_loss: 0.0926 - handedness_loss: 0.3086 - val_loss: 0.4244 - val_regression_loss: 0.0966 - val_handedness_loss: 0.3280\n",
      "Epoch 13/150\n",
      "5252/5252 [==============================] - 1s 143us/step - loss: 0.3811 - regression_loss: 0.0874 - handedness_loss: 0.2920 - val_loss: 0.4281 - val_regression_loss: 0.0964 - val_handedness_loss: 0.3286\n",
      "Epoch 14/150\n",
      "5252/5252 [==============================] - 1s 152us/step - loss: 0.3700 - regression_loss: 0.0887 - handedness_loss: 0.2754 - val_loss: 0.3853 - val_regression_loss: 0.0901 - val_handedness_loss: 0.2957\n",
      "Epoch 15/150\n",
      "5252/5252 [==============================] - 1s 152us/step - loss: 0.3757 - regression_loss: 0.0846 - handedness_loss: 0.2899 - val_loss: 0.3611 - val_regression_loss: 0.0908 - val_handedness_loss: 0.2706\n",
      "Epoch 16/150\n",
      "5252/5252 [==============================] - 1s 143us/step - loss: 0.3625 - regression_loss: 0.0843 - handedness_loss: 0.2734 - val_loss: 0.3816 - val_regression_loss: 0.0876 - val_handedness_loss: 0.2917\n",
      "Epoch 17/150\n",
      "5252/5252 [==============================] - 1s 121us/step - loss: 0.3470 - regression_loss: 0.0817 - handedness_loss: 0.2661 - val_loss: 0.3673 - val_regression_loss: 0.0830 - val_handedness_loss: 0.2804\n",
      "Epoch 18/150\n",
      "5252/5252 [==============================] - 1s 149us/step - loss: 0.3468 - regression_loss: 0.0822 - handedness_loss: 0.2600 - val_loss: 0.3698 - val_regression_loss: 0.0845 - val_handedness_loss: 0.2826\n",
      "Epoch 19/150\n",
      "5252/5252 [==============================] - 1s 144us/step - loss: 0.3262 - regression_loss: 0.0782 - handedness_loss: 0.2434 - val_loss: 0.3457 - val_regression_loss: 0.0828 - val_handedness_loss: 0.2632\n",
      "Epoch 20/150\n",
      "5252/5252 [==============================] - 1s 134us/step - loss: 0.3199 - regression_loss: 0.0767 - handedness_loss: 0.2423 - val_loss: 0.3511 - val_regression_loss: 0.0817 - val_handedness_loss: 0.2693\n",
      "Epoch 21/150\n",
      "5252/5252 [==============================] - 1s 139us/step - loss: 0.3155 - regression_loss: 0.0749 - handedness_loss: 0.2421 - val_loss: 0.3225 - val_regression_loss: 0.0787 - val_handedness_loss: 0.2443\n",
      "Epoch 22/150\n",
      "5252/5252 [==============================] - 1s 145us/step - loss: 0.3035 - regression_loss: 0.0740 - handedness_loss: 0.2248 - val_loss: 0.3056 - val_regression_loss: 0.0773 - val_handedness_loss: 0.2257\n",
      "Epoch 23/150\n",
      "5252/5252 [==============================] - 1s 150us/step - loss: 0.3073 - regression_loss: 0.0731 - handedness_loss: 0.2281 - val_loss: 0.3206 - val_regression_loss: 0.0761 - val_handedness_loss: 0.2419\n",
      "Epoch 24/150\n",
      "5252/5252 [==============================] - 1s 133us/step - loss: 0.2978 - regression_loss: 0.0731 - handedness_loss: 0.2239 - val_loss: 0.3144 - val_regression_loss: 0.0751 - val_handedness_loss: 0.2373\n",
      "Epoch 25/150\n",
      "5252/5252 [==============================] - 1s 139us/step - loss: 0.2969 - regression_loss: 0.0731 - handedness_loss: 0.2192 - val_loss: 0.2870 - val_regression_loss: 0.0736 - val_handedness_loss: 0.2154\n",
      "Epoch 26/150\n",
      "5252/5252 [==============================] - 1s 133us/step - loss: 0.3003 - regression_loss: 0.0720 - handedness_loss: 0.2227 - val_loss: 0.3107 - val_regression_loss: 0.0747 - val_handedness_loss: 0.2384\n",
      "Epoch 27/150\n",
      "5252/5252 [==============================] - 1s 134us/step - loss: 0.3118 - regression_loss: 0.0732 - handedness_loss: 0.2375 - val_loss: 0.3256 - val_regression_loss: 0.0757 - val_handedness_loss: 0.2489\n",
      "Epoch 28/150\n",
      "5252/5252 [==============================] - 1s 134us/step - loss: 0.2993 - regression_loss: 0.0711 - handedness_loss: 0.2262 - val_loss: 0.2843 - val_regression_loss: 0.0720 - val_handedness_loss: 0.2127\n",
      "Epoch 29/150\n",
      "5252/5252 [==============================] - 1s 150us/step - loss: 0.2842 - regression_loss: 0.0713 - handedness_loss: 0.2091 - val_loss: 0.2988 - val_regression_loss: 0.0735 - val_handedness_loss: 0.2284\n",
      "Epoch 30/150\n",
      "5252/5252 [==============================] - 1s 150us/step - loss: 0.2869 - regression_loss: 0.0715 - handedness_loss: 0.2110 - val_loss: 0.2985 - val_regression_loss: 0.0732 - val_handedness_loss: 0.2273\n",
      "Epoch 31/150\n",
      "5252/5252 [==============================] - 1s 130us/step - loss: 0.2938 - regression_loss: 0.0723 - handedness_loss: 0.2231 - val_loss: 0.2860 - val_regression_loss: 0.0725 - val_handedness_loss: 0.2125\n",
      "Epoch 32/150\n",
      "5252/5252 [==============================] - 1s 138us/step - loss: 0.3005 - regression_loss: 0.0714 - handedness_loss: 0.2279 - val_loss: 0.3001 - val_regression_loss: 0.0730 - val_handedness_loss: 0.2297\n",
      "Evaluating model with testing data...\n",
      "1104/1104 [==============================] - 0s 23us/step\n",
      "Getting distribution of predictions and covariance matrix...\n",
      "      1 of 20\n",
      "      2 of 20\n",
      "      3 of 20\n",
      "      4 of 20\n",
      "      5 of 20\n",
      "      6 of 20\n",
      "      7 of 20\n",
      "      8 of 20\n",
      "      9 of 20\n",
      "      10 of 20\n",
      "      11 of 20\n",
      "      12 of 20\n",
      "      13 of 20\n",
      "      14 of 20\n",
      "      15 of 20\n",
      "      16 of 20\n",
      "      17 of 20\n",
      "      18 of 20\n",
      "      19 of 20\n",
      "      20 of 20\n",
      "Computing ensemble means...\n",
      "Computing mean squared error...\n",
      "Iteration 35\n",
      "Train on 5392 samples, validate on 1134 samples\n",
      "Epoch 1/150\n",
      "5392/5392 [==============================] - 1s 137us/step - loss: 1.0357 - regression_loss: 0.3710 - handedness_loss: 0.6606 - val_loss: 0.8993 - val_regression_loss: 0.2676 - val_handedness_loss: 0.6317\n",
      "Epoch 2/150\n",
      "5392/5392 [==============================] - 1s 122us/step - loss: 0.7896 - regression_loss: 0.1907 - handedness_loss: 0.5967 - val_loss: 0.7115 - val_regression_loss: 0.1585 - val_handedness_loss: 0.5527\n",
      "Epoch 3/150\n",
      "5392/5392 [==============================] - 1s 142us/step - loss: 0.6542 - regression_loss: 0.1420 - handedness_loss: 0.5124 - val_loss: 0.6151 - val_regression_loss: 0.1399 - val_handedness_loss: 0.4747\n",
      "Epoch 4/150\n",
      "5392/5392 [==============================] - 1s 120us/step - loss: 0.5501 - regression_loss: 0.1308 - handedness_loss: 0.4187 - val_loss: 0.5192 - val_regression_loss: 0.1244 - val_handedness_loss: 0.3939\n",
      "Epoch 5/150\n",
      "5392/5392 [==============================] - 1s 138us/step - loss: 0.4667 - regression_loss: 0.1185 - handedness_loss: 0.3491 - val_loss: 0.4509 - val_regression_loss: 0.1202 - val_handedness_loss: 0.3306\n",
      "Epoch 6/150\n",
      "5392/5392 [==============================] - 1s 137us/step - loss: 0.4096 - regression_loss: 0.1078 - handedness_loss: 0.2981 - val_loss: 0.3882 - val_regression_loss: 0.1105 - val_handedness_loss: 0.2770\n",
      "Epoch 7/150\n",
      "5392/5392 [==============================] - 1s 128us/step - loss: 0.3731 - regression_loss: 0.1039 - handedness_loss: 0.2740 - val_loss: 0.3559 - val_regression_loss: 0.1075 - val_handedness_loss: 0.2477\n",
      "Epoch 8/150\n",
      "5392/5392 [==============================] - 1s 146us/step - loss: 0.3590 - regression_loss: 0.1018 - handedness_loss: 0.2576 - val_loss: 0.3703 - val_regression_loss: 0.1113 - val_handedness_loss: 0.2585\n",
      "Epoch 9/150\n",
      "5392/5392 [==============================] - 1s 146us/step - loss: 0.3414 - regression_loss: 0.0974 - handedness_loss: 0.2433 - val_loss: 0.3308 - val_regression_loss: 0.0993 - val_handedness_loss: 0.2316\n",
      "Epoch 10/150\n",
      "5392/5392 [==============================] - 1s 146us/step - loss: 0.3263 - regression_loss: 0.0928 - handedness_loss: 0.2359 - val_loss: 0.3360 - val_regression_loss: 0.1013 - val_handedness_loss: 0.2340\n",
      "Epoch 11/150\n",
      "5392/5392 [==============================] - 1s 149us/step - loss: 0.3204 - regression_loss: 0.0918 - handedness_loss: 0.2267 - val_loss: 0.3269 - val_regression_loss: 0.1010 - val_handedness_loss: 0.2259\n",
      "Epoch 12/150\n",
      "5392/5392 [==============================] - 1s 149us/step - loss: 0.2974 - regression_loss: 0.0894 - handedness_loss: 0.2065 - val_loss: 0.3009 - val_regression_loss: 0.0957 - val_handedness_loss: 0.2045\n",
      "Epoch 13/150\n",
      "5392/5392 [==============================] - 1s 138us/step - loss: 0.2861 - regression_loss: 0.0882 - handedness_loss: 0.1957 - val_loss: 0.3070 - val_regression_loss: 0.0938 - val_handedness_loss: 0.2123\n",
      "Epoch 14/150\n",
      "5392/5392 [==============================] - 1s 139us/step - loss: 0.2818 - regression_loss: 0.0857 - handedness_loss: 0.1980 - val_loss: 0.2785 - val_regression_loss: 0.0907 - val_handedness_loss: 0.1874\n",
      "Epoch 15/150\n",
      "5392/5392 [==============================] - 1s 139us/step - loss: 0.2897 - regression_loss: 0.0843 - handedness_loss: 0.2052 - val_loss: 0.2825 - val_regression_loss: 0.0871 - val_handedness_loss: 0.1950\n",
      "Epoch 16/150\n",
      "5392/5392 [==============================] - 1s 138us/step - loss: 0.2736 - regression_loss: 0.0802 - handedness_loss: 0.1938 - val_loss: 0.2814 - val_regression_loss: 0.0861 - val_handedness_loss: 0.1950\n",
      "Epoch 17/150\n",
      "5392/5392 [==============================] - 1s 130us/step - loss: 0.2572 - regression_loss: 0.0778 - handedness_loss: 0.1770 - val_loss: 0.2822 - val_regression_loss: 0.0831 - val_handedness_loss: 0.1990\n",
      "Epoch 18/150\n",
      "5392/5392 [==============================] - 1s 142us/step - loss: 0.2533 - regression_loss: 0.0763 - handedness_loss: 0.1759 - val_loss: 0.2710 - val_regression_loss: 0.0828 - val_handedness_loss: 0.1889\n",
      "Evaluating model with testing data...\n",
      "1134/1134 [==============================] - 0s 26us/step\n",
      "Getting distribution of predictions and covariance matrix...\n",
      "      1 of 20\n",
      "      2 of 20\n",
      "      3 of 20\n",
      "      4 of 20\n",
      "      5 of 20\n",
      "      6 of 20\n",
      "      7 of 20\n",
      "      8 of 20\n",
      "      9 of 20\n",
      "      10 of 20\n",
      "      11 of 20\n",
      "      12 of 20\n",
      "      13 of 20\n",
      "      14 of 20\n",
      "      15 of 20\n",
      "      16 of 20\n",
      "      17 of 20\n",
      "      18 of 20\n",
      "      19 of 20\n",
      "      20 of 20\n",
      "Computing ensemble means...\n",
      "Computing mean squared error...\n",
      "Iteration 36\n",
      "Train on 5532 samples, validate on 1164 samples\n",
      "Epoch 1/150\n",
      "5532/5532 [==============================] - 1s 161us/step - loss: 1.2980 - regression_loss: 0.6070 - handedness_loss: 0.6852 - val_loss: 0.9697 - val_regression_loss: 0.2952 - val_handedness_loss: 0.6770\n",
      "Epoch 2/150\n",
      "5532/5532 [==============================] - 1s 124us/step - loss: 0.9159 - regression_loss: 0.2529 - handedness_loss: 0.6621 - val_loss: 0.8985 - val_regression_loss: 0.2447 - val_handedness_loss: 0.6545\n",
      "Epoch 3/150\n",
      "5532/5532 [==============================] - 1s 148us/step - loss: 0.8394 - regression_loss: 0.2078 - handedness_loss: 0.6309 - val_loss: 0.8268 - val_regression_loss: 0.2033 - val_handedness_loss: 0.6205\n",
      "Epoch 4/150\n",
      "5532/5532 [==============================] - 1s 148us/step - loss: 0.7709 - regression_loss: 0.1805 - handedness_loss: 0.5900 - val_loss: 0.7621 - val_regression_loss: 0.1856 - val_handedness_loss: 0.5840\n",
      "Epoch 5/150\n",
      "5532/5532 [==============================] - 1s 128us/step - loss: 0.7146 - regression_loss: 0.1710 - handedness_loss: 0.5436 - val_loss: 0.6943 - val_regression_loss: 0.1786 - val_handedness_loss: 0.5204\n",
      "Epoch 6/150\n",
      "5532/5532 [==============================] - 1s 138us/step - loss: 0.6225 - regression_loss: 0.1513 - handedness_loss: 0.4694 - val_loss: 0.5966 - val_regression_loss: 0.1388 - val_handedness_loss: 0.4390\n",
      "Epoch 7/150\n",
      "5532/5532 [==============================] - 1s 137us/step - loss: 0.5536 - regression_loss: 0.1316 - handedness_loss: 0.4202 - val_loss: 0.5735 - val_regression_loss: 0.1381 - val_handedness_loss: 0.4175\n",
      "Epoch 8/150\n",
      "5532/5532 [==============================] - 1s 140us/step - loss: 0.5077 - regression_loss: 0.1250 - handedness_loss: 0.3837 - val_loss: 0.5052 - val_regression_loss: 0.1319 - val_handedness_loss: 0.3755\n",
      "Epoch 9/150\n",
      "5532/5532 [==============================] - 1s 139us/step - loss: 0.4834 - regression_loss: 0.1197 - handedness_loss: 0.3634 - val_loss: 0.4735 - val_regression_loss: 0.1192 - val_handedness_loss: 0.3381\n",
      "Epoch 10/150\n",
      "5532/5532 [==============================] - 1s 127us/step - loss: 0.4625 - regression_loss: 0.1150 - handedness_loss: 0.3464 - val_loss: 0.4830 - val_regression_loss: 0.1222 - val_handedness_loss: 0.3522\n",
      "Epoch 11/150\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5532/5532 [==============================] - 1s 136us/step - loss: 0.4486 - regression_loss: 0.1074 - handedness_loss: 0.3415 - val_loss: 0.4547 - val_regression_loss: 0.1112 - val_handedness_loss: 0.3398\n",
      "Epoch 12/150\n",
      "5532/5532 [==============================] - 1s 146us/step - loss: 0.4327 - regression_loss: 0.1027 - handedness_loss: 0.3323 - val_loss: 0.4624 - val_regression_loss: 0.1063 - val_handedness_loss: 0.3666\n",
      "Epoch 13/150\n",
      "5532/5532 [==============================] - 1s 148us/step - loss: 0.4235 - regression_loss: 0.0985 - handedness_loss: 0.3278 - val_loss: 0.4501 - val_regression_loss: 0.1001 - val_handedness_loss: 0.3602\n",
      "Evaluating model with testing data...\n",
      "1164/1164 [==============================] - 0s 16us/step\n",
      "Getting distribution of predictions and covariance matrix...\n",
      "      1 of 20\n",
      "      2 of 20\n",
      "      3 of 20\n",
      "      4 of 20\n",
      "      5 of 20\n",
      "      6 of 20\n",
      "      7 of 20\n",
      "      8 of 20\n",
      "      9 of 20\n",
      "      10 of 20\n",
      "      11 of 20\n",
      "      12 of 20\n",
      "      13 of 20\n",
      "      14 of 20\n",
      "      15 of 20\n",
      "      16 of 20\n",
      "      17 of 20\n",
      "      18 of 20\n",
      "      19 of 20\n",
      "      20 of 20\n",
      "Computing ensemble means...\n",
      "Computing mean squared error...\n",
      "Iteration 37\n",
      "Train on 5672 samples, validate on 1194 samples\n",
      "Epoch 1/150\n",
      "5672/5672 [==============================] - 1s 136us/step - loss: 1.1708 - regression_loss: 0.4738 - handedness_loss: 0.6946 - val_loss: 1.0068 - val_regression_loss: 0.3121 - val_handedness_loss: 0.6896\n",
      "Epoch 2/150\n",
      "5672/5672 [==============================] - 1s 127us/step - loss: 0.9614 - regression_loss: 0.2769 - handedness_loss: 0.6841 - val_loss: 0.9469 - val_regression_loss: 0.2650 - val_handedness_loss: 0.6780\n",
      "Epoch 3/150\n",
      "5672/5672 [==============================] - 1s 148us/step - loss: 0.8904 - regression_loss: 0.2220 - handedness_loss: 0.6679 - val_loss: 0.8687 - val_regression_loss: 0.1980 - val_handedness_loss: 0.6667\n",
      "Epoch 4/150\n",
      "5672/5672 [==============================] - 1s 138us/step - loss: 0.8071 - regression_loss: 0.1708 - handedness_loss: 0.6357 - val_loss: 0.8023 - val_regression_loss: 0.1654 - val_handedness_loss: 0.6330\n",
      "Epoch 5/150\n",
      "5672/5672 [==============================] - 1s 147us/step - loss: 0.7433 - regression_loss: 0.1480 - handedness_loss: 0.5952 - val_loss: 0.7435 - val_regression_loss: 0.1513 - val_handedness_loss: 0.5908\n",
      "Epoch 6/150\n",
      "5672/5672 [==============================] - 1s 146us/step - loss: 0.6932 - regression_loss: 0.1394 - handedness_loss: 0.5540 - val_loss: 0.6911 - val_regression_loss: 0.1346 - val_handedness_loss: 0.5491\n",
      "Epoch 7/150\n",
      "5672/5672 [==============================] - 1s 148us/step - loss: 0.6441 - regression_loss: 0.1300 - handedness_loss: 0.5141 - val_loss: 0.6609 - val_regression_loss: 0.1364 - val_handedness_loss: 0.5158\n",
      "Epoch 8/150\n",
      "5672/5672 [==============================] - 1s 149us/step - loss: 0.6000 - regression_loss: 0.1296 - handedness_loss: 0.4688 - val_loss: 0.6217 - val_regression_loss: 0.1361 - val_handedness_loss: 0.4812\n",
      "Epoch 9/150\n",
      "5672/5672 [==============================] - 1s 149us/step - loss: 0.5586 - regression_loss: 0.1268 - handedness_loss: 0.4304 - val_loss: 0.5447 - val_regression_loss: 0.1244 - val_handedness_loss: 0.4163\n",
      "Epoch 10/150\n",
      "5672/5672 [==============================] - 1s 146us/step - loss: 0.5175 - regression_loss: 0.1163 - handedness_loss: 0.4024 - val_loss: 0.5408 - val_regression_loss: 0.1221 - val_handedness_loss: 0.4160\n",
      "Epoch 11/150\n",
      "5672/5672 [==============================] - 1s 150us/step - loss: 0.4835 - regression_loss: 0.1090 - handedness_loss: 0.3736 - val_loss: 0.4630 - val_regression_loss: 0.1046 - val_handedness_loss: 0.3555\n",
      "Epoch 12/150\n",
      "5672/5672 [==============================] - 1s 151us/step - loss: 0.4610 - regression_loss: 0.1024 - handedness_loss: 0.3584 - val_loss: 0.4869 - val_regression_loss: 0.1077 - val_handedness_loss: 0.3819\n",
      "Epoch 13/150\n",
      "5672/5672 [==============================] - 1s 136us/step - loss: 0.4474 - regression_loss: 0.0980 - handedness_loss: 0.3488 - val_loss: 0.4423 - val_regression_loss: 0.0983 - val_handedness_loss: 0.3334\n",
      "Epoch 14/150\n",
      "5672/5672 [==============================] - 1s 144us/step - loss: 0.4329 - regression_loss: 0.0917 - handedness_loss: 0.3406 - val_loss: 0.4308 - val_regression_loss: 0.0954 - val_handedness_loss: 0.3356\n",
      "Epoch 15/150\n",
      "5672/5672 [==============================] - 1s 120us/step - loss: 0.4198 - regression_loss: 0.0891 - handedness_loss: 0.3301 - val_loss: 0.4413 - val_regression_loss: 0.0923 - val_handedness_loss: 0.3471\n",
      "Epoch 16/150\n",
      "5672/5672 [==============================] - 1s 145us/step - loss: 0.4118 - regression_loss: 0.0865 - handedness_loss: 0.3248 - val_loss: 0.4461 - val_regression_loss: 0.0888 - val_handedness_loss: 0.3523\n",
      "Epoch 17/150\n",
      "5672/5672 [==============================] - 1s 132us/step - loss: 0.4027 - regression_loss: 0.0837 - handedness_loss: 0.3183 - val_loss: 0.4164 - val_regression_loss: 0.0854 - val_handedness_loss: 0.3289\n",
      "Epoch 18/150\n",
      "5672/5672 [==============================] - 1s 145us/step - loss: 0.3943 - regression_loss: 0.0812 - handedness_loss: 0.3126 - val_loss: 0.4282 - val_regression_loss: 0.0844 - val_handedness_loss: 0.3419\n",
      "Epoch 19/150\n",
      "5672/5672 [==============================] - 1s 145us/step - loss: 0.4009 - regression_loss: 0.0798 - handedness_loss: 0.3201 - val_loss: 0.4281 - val_regression_loss: 0.0836 - val_handedness_loss: 0.3407\n",
      "Epoch 20/150\n",
      "5672/5672 [==============================] - 1s 147us/step - loss: 0.4020 - regression_loss: 0.0786 - handedness_loss: 0.3236 - val_loss: 0.4152 - val_regression_loss: 0.0803 - val_handedness_loss: 0.3295\n",
      "Epoch 21/150\n",
      "5672/5672 [==============================] - 1s 148us/step - loss: 0.3910 - regression_loss: 0.0783 - handedness_loss: 0.3133 - val_loss: 0.4183 - val_regression_loss: 0.0801 - val_handedness_loss: 0.3352\n",
      "Evaluating model with testing data...\n",
      "1194/1194 [==============================] - 0s 19us/step\n",
      "Getting distribution of predictions and covariance matrix...\n",
      "      1 of 20\n",
      "      2 of 20\n",
      "      3 of 20\n",
      "      4 of 20\n",
      "      5 of 20\n",
      "      6 of 20\n",
      "      7 of 20\n",
      "      8 of 20\n",
      "      9 of 20\n",
      "      10 of 20\n",
      "      11 of 20\n",
      "      12 of 20\n",
      "      13 of 20\n",
      "      14 of 20\n",
      "      15 of 20\n",
      "      16 of 20\n",
      "      17 of 20\n",
      "      18 of 20\n",
      "      19 of 20\n",
      "      20 of 20\n",
      "Computing ensemble means...\n",
      "Computing mean squared error...\n",
      "Iteration 38\n",
      "Train on 5812 samples, validate on 1224 samples\n",
      "Epoch 1/150\n",
      "5812/5812 [==============================] - 1s 161us/step - loss: 1.1525 - regression_loss: 0.4760 - handedness_loss: 0.6738 - val_loss: 0.9289 - val_regression_loss: 0.2861 - val_handedness_loss: 0.6433\n",
      "Epoch 2/150\n",
      "5812/5812 [==============================] - 1s 121us/step - loss: 0.8276 - regression_loss: 0.2095 - handedness_loss: 0.6165 - val_loss: 0.7665 - val_regression_loss: 0.1820 - val_handedness_loss: 0.5838\n",
      "Epoch 3/150\n",
      "5812/5812 [==============================] - 1s 117us/step - loss: 0.7252 - regression_loss: 0.1620 - handedness_loss: 0.5630 - val_loss: 0.7063 - val_regression_loss: 0.1596 - val_handedness_loss: 0.5464\n",
      "Epoch 4/150\n",
      "5812/5812 [==============================] - 1s 130us/step - loss: 0.6582 - regression_loss: 0.1431 - handedness_loss: 0.5161 - val_loss: 0.6442 - val_regression_loss: 0.1435 - val_handedness_loss: 0.4999\n",
      "Epoch 5/150\n",
      "5812/5812 [==============================] - 1s 117us/step - loss: 0.6054 - regression_loss: 0.1330 - handedness_loss: 0.4740 - val_loss: 0.6028 - val_regression_loss: 0.1331 - val_handedness_loss: 0.4711\n",
      "Epoch 6/150\n",
      "5812/5812 [==============================] - 1s 132us/step - loss: 0.5669 - regression_loss: 0.1268 - handedness_loss: 0.4395 - val_loss: 0.5610 - val_regression_loss: 0.1323 - val_handedness_loss: 0.4271\n",
      "Epoch 7/150\n",
      "5812/5812 [==============================] - 1s 129us/step - loss: 0.5218 - regression_loss: 0.1235 - handedness_loss: 0.3977 - val_loss: 0.5064 - val_regression_loss: 0.1234 - val_handedness_loss: 0.3798\n",
      "Epoch 8/150\n",
      "5812/5812 [==============================] - 1s 136us/step - loss: 0.4624 - regression_loss: 0.1135 - handedness_loss: 0.3491 - val_loss: 0.4888 - val_regression_loss: 0.1182 - val_handedness_loss: 0.3680\n",
      "Epoch 9/150\n",
      "5812/5812 [==============================] - 1s 138us/step - loss: 0.4422 - regression_loss: 0.1090 - handedness_loss: 0.3316 - val_loss: 0.4562 - val_regression_loss: 0.1153 - val_handedness_loss: 0.3407\n",
      "Epoch 10/150\n",
      "5812/5812 [==============================] - 1s 147us/step - loss: 0.4291 - regression_loss: 0.1068 - handedness_loss: 0.3221 - val_loss: 0.4336 - val_regression_loss: 0.1110 - val_handedness_loss: 0.3232\n",
      "Epoch 11/150\n",
      "5812/5812 [==============================] - 1s 137us/step - loss: 0.4134 - regression_loss: 0.1018 - handedness_loss: 0.3135 - val_loss: 0.4263 - val_regression_loss: 0.1031 - val_handedness_loss: 0.3232\n",
      "Epoch 12/150\n",
      "5812/5812 [==============================] - 1s 138us/step - loss: 0.4084 - regression_loss: 0.0972 - handedness_loss: 0.3110 - val_loss: 0.4177 - val_regression_loss: 0.0986 - val_handedness_loss: 0.3156\n",
      "Epoch 13/150\n",
      "5812/5812 [==============================] - 1s 146us/step - loss: 0.3930 - regression_loss: 0.0924 - handedness_loss: 0.3016 - val_loss: 0.3957 - val_regression_loss: 0.0951 - val_handedness_loss: 0.3048\n",
      "Epoch 14/150\n",
      "5812/5812 [==============================] - 1s 147us/step - loss: 0.3895 - regression_loss: 0.0888 - handedness_loss: 0.3007 - val_loss: 0.3837 - val_regression_loss: 0.0887 - val_handedness_loss: 0.2942\n",
      "Epoch 15/150\n",
      "5812/5812 [==============================] - 1s 149us/step - loss: 0.3842 - regression_loss: 0.0861 - handedness_loss: 0.2974 - val_loss: 0.3866 - val_regression_loss: 0.0876 - val_handedness_loss: 0.2993\n",
      "Epoch 16/150\n",
      "5812/5812 [==============================] - 1s 151us/step - loss: 0.3755 - regression_loss: 0.0824 - handedness_loss: 0.2933 - val_loss: 0.3752 - val_regression_loss: 0.0843 - val_handedness_loss: 0.2920\n",
      "Epoch 17/150\n",
      "5812/5812 [==============================] - 1s 150us/step - loss: 0.3592 - regression_loss: 0.0807 - handedness_loss: 0.2794 - val_loss: 0.3746 - val_regression_loss: 0.0826 - val_handedness_loss: 0.2882\n",
      "Epoch 18/150\n",
      "5812/5812 [==============================] - 1s 142us/step - loss: 0.3509 - regression_loss: 0.0796 - handedness_loss: 0.2709 - val_loss: 0.4101 - val_regression_loss: 0.0822 - val_handedness_loss: 0.3292\n",
      "Epoch 19/150\n",
      "5812/5812 [==============================] - 1s 142us/step - loss: 0.3627 - regression_loss: 0.0783 - handedness_loss: 0.2841 - val_loss: 0.3657 - val_regression_loss: 0.0788 - val_handedness_loss: 0.2859\n",
      "Epoch 20/150\n",
      "5812/5812 [==============================] - 1s 115us/step - loss: 0.3451 - regression_loss: 0.0763 - handedness_loss: 0.2685 - val_loss: 0.3551 - val_regression_loss: 0.0770 - val_handedness_loss: 0.2746\n",
      "Epoch 21/150\n",
      "5812/5812 [==============================] - 1s 147us/step - loss: 0.3472 - regression_loss: 0.0758 - handedness_loss: 0.2707 - val_loss: 0.3606 - val_regression_loss: 0.0764 - val_handedness_loss: 0.2845\n",
      "Epoch 22/150\n",
      "5812/5812 [==============================] - 1s 146us/step - loss: 0.3428 - regression_loss: 0.0750 - handedness_loss: 0.2676 - val_loss: 0.3499 - val_regression_loss: 0.0760 - val_handedness_loss: 0.2725\n",
      "Epoch 23/150\n",
      "5812/5812 [==============================] - 1s 146us/step - loss: 0.3438 - regression_loss: 0.0745 - handedness_loss: 0.2690 - val_loss: 0.3736 - val_regression_loss: 0.0763 - val_handedness_loss: 0.2974\n",
      "Epoch 24/150\n",
      "5812/5812 [==============================] - 1s 147us/step - loss: 0.3370 - regression_loss: 0.0743 - handedness_loss: 0.2638 - val_loss: 0.3673 - val_regression_loss: 0.0749 - val_handedness_loss: 0.2925\n",
      "Epoch 25/150\n",
      "5812/5812 [==============================] - 1s 131us/step - loss: 0.3386 - regression_loss: 0.0738 - handedness_loss: 0.2647 - val_loss: 0.3682 - val_regression_loss: 0.0765 - val_handedness_loss: 0.2900\n",
      "Epoch 26/150\n",
      "5812/5812 [==============================] - 1s 148us/step - loss: 0.3352 - regression_loss: 0.0737 - handedness_loss: 0.2624 - val_loss: 0.3306 - val_regression_loss: 0.0740 - val_handedness_loss: 0.2557\n",
      "Epoch 27/150\n",
      "5812/5812 [==============================] - 1s 149us/step - loss: 0.3431 - regression_loss: 0.0740 - handedness_loss: 0.2689 - val_loss: 0.3546 - val_regression_loss: 0.0741 - val_handedness_loss: 0.2829\n",
      "Epoch 28/150\n",
      "5812/5812 [==============================] - 1s 149us/step - loss: 0.3348 - regression_loss: 0.0731 - handedness_loss: 0.2621 - val_loss: 0.3467 - val_regression_loss: 0.0751 - val_handedness_loss: 0.2713\n",
      "Epoch 29/150\n",
      "5812/5812 [==============================] - 1s 134us/step - loss: 0.3372 - regression_loss: 0.0739 - handedness_loss: 0.2639 - val_loss: 0.4138 - val_regression_loss: 0.0752 - val_handedness_loss: 0.3382\n",
      "Epoch 30/150\n",
      "5812/5812 [==============================] - 1s 148us/step - loss: 0.3435 - regression_loss: 0.0740 - handedness_loss: 0.2688 - val_loss: 0.3462 - val_regression_loss: 0.0734 - val_handedness_loss: 0.2721\n",
      "Evaluating model with testing data...\n",
      "1224/1224 [==============================] - 0s 20us/step\n",
      "Getting distribution of predictions and covariance matrix...\n",
      "      1 of 20\n",
      "      2 of 20\n",
      "      3 of 20\n",
      "      4 of 20\n",
      "      5 of 20\n",
      "      6 of 20\n",
      "      7 of 20\n",
      "      8 of 20\n",
      "      9 of 20\n",
      "      10 of 20\n",
      "      11 of 20\n",
      "      12 of 20\n",
      "      13 of 20\n",
      "      14 of 20\n",
      "      15 of 20\n",
      "      16 of 20\n",
      "      17 of 20\n",
      "      18 of 20\n",
      "      19 of 20\n",
      "      20 of 20\n",
      "Computing ensemble means...\n",
      "Computing mean squared error...\n",
      "Iteration 39\n",
      "Train on 5952 samples, validate on 1254 samples\n",
      "Epoch 1/150\n",
      "5952/5952 [==============================] - 1s 133us/step - loss: 1.0520 - regression_loss: 0.3606 - handedness_loss: 0.6893 - val_loss: 0.8912 - val_regression_loss: 0.2332 - val_handedness_loss: 0.6593\n",
      "Epoch 2/150\n",
      "5952/5952 [==============================] - 0s 65us/step - loss: 0.8315 - regression_loss: 0.1977 - handedness_loss: 0.6329 - val_loss: 0.7724 - val_regression_loss: 0.1821 - val_handedness_loss: 0.5911\n",
      "Epoch 3/150\n",
      "5952/5952 [==============================] - 0s 65us/step - loss: 0.7099 - regression_loss: 0.1626 - handedness_loss: 0.5463 - val_loss: 0.6526 - val_regression_loss: 0.1540 - val_handedness_loss: 0.4997\n",
      "Epoch 4/150\n",
      "5952/5952 [==============================] - 1s 118us/step - loss: 0.6103 - regression_loss: 0.1403 - handedness_loss: 0.4689 - val_loss: 0.5653 - val_regression_loss: 0.1306 - val_handedness_loss: 0.4362\n",
      "Epoch 5/150\n",
      "5952/5952 [==============================] - 1s 129us/step - loss: 0.5367 - regression_loss: 0.1249 - handedness_loss: 0.4121 - val_loss: 0.5432 - val_regression_loss: 0.1275 - val_handedness_loss: 0.4159\n",
      "Epoch 6/150\n",
      "5952/5952 [==============================] - 1s 113us/step - loss: 0.5003 - regression_loss: 0.1184 - handedness_loss: 0.3816 - val_loss: 0.5145 - val_regression_loss: 0.1208 - val_handedness_loss: 0.3946\n",
      "Epoch 7/150\n",
      "5952/5952 [==============================] - 1s 124us/step - loss: 0.4814 - regression_loss: 0.1097 - handedness_loss: 0.3711 - val_loss: 0.4825 - val_regression_loss: 0.1141 - val_handedness_loss: 0.3689\n",
      "Epoch 8/150\n",
      "5952/5952 [==============================] - 1s 134us/step - loss: 0.4432 - regression_loss: 0.1013 - handedness_loss: 0.3418 - val_loss: 0.4722 - val_regression_loss: 0.1098 - val_handedness_loss: 0.3642\n",
      "Epoch 9/150\n",
      "5952/5952 [==============================] - 1s 129us/step - loss: 0.4364 - regression_loss: 0.0973 - handedness_loss: 0.3390 - val_loss: 0.4557 - val_regression_loss: 0.1016 - val_handedness_loss: 0.3554\n",
      "Epoch 10/150\n",
      "5952/5952 [==============================] - 1s 129us/step - loss: 0.4280 - regression_loss: 0.0931 - handedness_loss: 0.3352 - val_loss: 0.4353 - val_regression_loss: 0.0959 - val_handedness_loss: 0.3399\n",
      "Epoch 11/150\n",
      "5952/5952 [==============================] - 1s 130us/step - loss: 0.4157 - regression_loss: 0.0885 - handedness_loss: 0.3268 - val_loss: 0.4528 - val_regression_loss: 0.0936 - val_handedness_loss: 0.3597\n",
      "Epoch 12/150\n",
      "5952/5952 [==============================] - 1s 126us/step - loss: 0.4073 - regression_loss: 0.0857 - handedness_loss: 0.3211 - val_loss: 0.4107 - val_regression_loss: 0.0922 - val_handedness_loss: 0.3191\n",
      "Epoch 13/150\n",
      "5952/5952 [==============================] - 1s 121us/step - loss: 0.3922 - regression_loss: 0.0837 - handedness_loss: 0.3093 - val_loss: 0.3956 - val_regression_loss: 0.0865 - val_handedness_loss: 0.3102\n",
      "Epoch 14/150\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5952/5952 [==============================] - 1s 132us/step - loss: 0.3780 - regression_loss: 0.0826 - handedness_loss: 0.2957 - val_loss: 0.4056 - val_regression_loss: 0.0878 - val_handedness_loss: 0.3187\n",
      "Epoch 15/150\n",
      "5952/5952 [==============================] - 1s 147us/step - loss: 0.3758 - regression_loss: 0.0827 - handedness_loss: 0.2925 - val_loss: 0.3835 - val_regression_loss: 0.0878 - val_handedness_loss: 0.2949\n",
      "Epoch 16/150\n",
      "5952/5952 [==============================] - 1s 145us/step - loss: 0.3693 - regression_loss: 0.0807 - handedness_loss: 0.2887 - val_loss: 0.3944 - val_regression_loss: 0.0845 - val_handedness_loss: 0.3094\n",
      "Epoch 17/150\n",
      "5952/5952 [==============================] - 1s 147us/step - loss: 0.3678 - regression_loss: 0.0790 - handedness_loss: 0.2894 - val_loss: 0.3988 - val_regression_loss: 0.0830 - val_handedness_loss: 0.3150\n",
      "Epoch 18/150\n",
      "5952/5952 [==============================] - 1s 148us/step - loss: 0.3661 - regression_loss: 0.0777 - handedness_loss: 0.2879 - val_loss: 0.3811 - val_regression_loss: 0.0803 - val_handedness_loss: 0.3012\n",
      "Epoch 19/150\n",
      "5952/5952 [==============================] - 1s 148us/step - loss: 0.3574 - regression_loss: 0.0761 - handedness_loss: 0.2820 - val_loss: 0.3886 - val_regression_loss: 0.0818 - val_handedness_loss: 0.3072\n",
      "Evaluating model with testing data...\n",
      "1254/1254 [==============================] - 0s 16us/step\n",
      "Getting distribution of predictions and covariance matrix...\n",
      "      1 of 20\n",
      "      2 of 20\n",
      "      3 of 20\n",
      "      4 of 20\n",
      "      5 of 20\n",
      "      6 of 20\n",
      "      7 of 20\n",
      "      8 of 20\n",
      "      9 of 20\n",
      "      10 of 20\n",
      "      11 of 20\n",
      "      12 of 20\n",
      "      13 of 20\n",
      "      14 of 20\n",
      "      15 of 20\n",
      "      16 of 20\n",
      "      17 of 20\n",
      "      18 of 20\n",
      "      19 of 20\n",
      "      20 of 20\n",
      "Computing ensemble means...\n",
      "Computing mean squared error...\n",
      "Iteration 40\n",
      "Train on 6092 samples, validate on 1284 samples\n",
      "Epoch 1/150\n",
      "6092/6092 [==============================] - 1s 161us/step - loss: 1.1665 - regression_loss: 0.4802 - handedness_loss: 0.6845 - val_loss: 0.9716 - val_regression_loss: 0.3056 - val_handedness_loss: 0.6636\n",
      "Epoch 2/150\n",
      "6092/6092 [==============================] - 1s 134us/step - loss: 0.8823 - regression_loss: 0.2393 - handedness_loss: 0.6420 - val_loss: 0.8358 - val_regression_loss: 0.2024 - val_handedness_loss: 0.6417\n",
      "Epoch 3/150\n",
      "6092/6092 [==============================] - 1s 136us/step - loss: 0.7795 - regression_loss: 0.1712 - handedness_loss: 0.6082 - val_loss: 0.7504 - val_regression_loss: 0.1583 - val_handedness_loss: 0.5683\n",
      "Epoch 4/150\n",
      "6092/6092 [==============================] - 1s 140us/step - loss: 0.7180 - regression_loss: 0.1508 - handedness_loss: 0.5667 - val_loss: 0.6934 - val_regression_loss: 0.1475 - val_handedness_loss: 0.5662\n",
      "Epoch 5/150\n",
      "6092/6092 [==============================] - 1s 150us/step - loss: 0.6696 - regression_loss: 0.1391 - handedness_loss: 0.5302 - val_loss: 0.6496 - val_regression_loss: 0.1473 - val_handedness_loss: 0.5128\n",
      "Epoch 6/150\n",
      "6092/6092 [==============================] - 1s 150us/step - loss: 0.6182 - regression_loss: 0.1287 - handedness_loss: 0.4891 - val_loss: 0.6199 - val_regression_loss: 0.1353 - val_handedness_loss: 0.4669\n",
      "Epoch 7/150\n",
      "6092/6092 [==============================] - 1s 151us/step - loss: 0.5966 - regression_loss: 0.1260 - handedness_loss: 0.4707 - val_loss: 0.6071 - val_regression_loss: 0.1375 - val_handedness_loss: 0.4624\n",
      "Epoch 8/150\n",
      "6092/6092 [==============================] - 1s 151us/step - loss: 0.5841 - regression_loss: 0.1244 - handedness_loss: 0.4596 - val_loss: 0.5525 - val_regression_loss: 0.1261 - val_handedness_loss: 0.4567\n",
      "Epoch 9/150\n",
      "6092/6092 [==============================] - 1s 151us/step - loss: 0.5561 - regression_loss: 0.1179 - handedness_loss: 0.4380 - val_loss: 0.5538 - val_regression_loss: 0.1139 - val_handedness_loss: 0.4519\n",
      "Epoch 10/150\n",
      "6092/6092 [==============================] - 1s 152us/step - loss: 0.5477 - regression_loss: 0.1101 - handedness_loss: 0.4373 - val_loss: 0.5146 - val_regression_loss: 0.1087 - val_handedness_loss: 0.4161\n",
      "Epoch 11/150\n",
      "6092/6092 [==============================] - 1s 143us/step - loss: 0.5161 - regression_loss: 0.1022 - handedness_loss: 0.4132 - val_loss: 0.5188 - val_regression_loss: 0.1041 - val_handedness_loss: 0.4076\n",
      "Epoch 12/150\n",
      "6092/6092 [==============================] - 1s 133us/step - loss: 0.5137 - regression_loss: 0.0978 - handedness_loss: 0.4153 - val_loss: 0.5329 - val_regression_loss: 0.1011 - val_handedness_loss: 0.4154\n",
      "Epoch 13/150\n",
      "6092/6092 [==============================] - 1s 123us/step - loss: 0.5045 - regression_loss: 0.0940 - handedness_loss: 0.4107 - val_loss: 0.5148 - val_regression_loss: 0.0917 - val_handedness_loss: 0.4143\n",
      "Epoch 14/150\n",
      "6092/6092 [==============================] - 1s 146us/step - loss: 0.4818 - regression_loss: 0.0889 - handedness_loss: 0.3929 - val_loss: 0.4883 - val_regression_loss: 0.0902 - val_handedness_loss: 0.3934\n",
      "Epoch 15/150\n",
      "6092/6092 [==============================] - 1s 113us/step - loss: 0.4870 - regression_loss: 0.0866 - handedness_loss: 0.4000 - val_loss: 0.4606 - val_regression_loss: 0.0858 - val_handedness_loss: 0.3729\n",
      "Epoch 16/150\n",
      "6092/6092 [==============================] - 1s 129us/step - loss: 0.4820 - regression_loss: 0.0840 - handedness_loss: 0.3981 - val_loss: 0.4786 - val_regression_loss: 0.0824 - val_handedness_loss: 0.4093\n",
      "Epoch 17/150\n",
      "6092/6092 [==============================] - 1s 148us/step - loss: 0.4802 - regression_loss: 0.0823 - handedness_loss: 0.3976 - val_loss: 0.4861 - val_regression_loss: 0.0822 - val_handedness_loss: 0.3829\n",
      "Epoch 18/150\n",
      "6092/6092 [==============================] - 1s 137us/step - loss: 0.4683 - regression_loss: 0.0805 - handedness_loss: 0.3875 - val_loss: 0.4790 - val_regression_loss: 0.0802 - val_handedness_loss: 0.3936\n",
      "Epoch 19/150\n",
      "6092/6092 [==============================] - 1s 147us/step - loss: 0.4728 - regression_loss: 0.0798 - handedness_loss: 0.3933 - val_loss: 0.4632 - val_regression_loss: 0.0805 - val_handedness_loss: 0.3600\n",
      "Epoch 20/150\n",
      "6092/6092 [==============================] - 1s 121us/step - loss: 0.4666 - regression_loss: 0.0788 - handedness_loss: 0.3878 - val_loss: 0.4806 - val_regression_loss: 0.0779 - val_handedness_loss: 0.3701\n",
      "Epoch 21/150\n",
      "6092/6092 [==============================] - 1s 132us/step - loss: 0.4722 - regression_loss: 0.0780 - handedness_loss: 0.3938 - val_loss: 0.4620 - val_regression_loss: 0.0768 - val_handedness_loss: 0.3974\n",
      "Epoch 22/150\n",
      "6092/6092 [==============================] - 1s 131us/step - loss: 0.4576 - regression_loss: 0.0777 - handedness_loss: 0.3795 - val_loss: 0.4715 - val_regression_loss: 0.0768 - val_handedness_loss: 0.3738\n",
      "Epoch 23/150\n",
      "6092/6092 [==============================] - 1s 134us/step - loss: 0.4651 - regression_loss: 0.0778 - handedness_loss: 0.3875 - val_loss: 0.4612 - val_regression_loss: 0.0782 - val_handedness_loss: 0.3654\n",
      "Evaluating model with testing data...\n",
      "1284/1284 [==============================] - 0s 20us/step\n",
      "Getting distribution of predictions and covariance matrix...\n",
      "      1 of 20\n",
      "      2 of 20\n",
      "      3 of 20\n",
      "      4 of 20\n",
      "      5 of 20\n",
      "      6 of 20\n",
      "      7 of 20\n",
      "      8 of 20\n",
      "      9 of 20\n",
      "      10 of 20\n",
      "      11 of 20\n",
      "      12 of 20\n",
      "      13 of 20\n",
      "      14 of 20\n",
      "      15 of 20\n",
      "      16 of 20\n",
      "      17 of 20\n",
      "      18 of 20\n",
      "      19 of 20\n",
      "      20 of 20\n",
      "Computing ensemble means...\n",
      "Computing mean squared error...\n",
      "Iteration 41\n",
      "Train on 6232 samples, validate on 1314 samples\n",
      "Epoch 1/150\n",
      "6232/6232 [==============================] - 1s 133us/step - loss: 1.1566 - regression_loss: 0.4529 - handedness_loss: 0.7023 - val_loss: 0.9854 - val_regression_loss: 0.2925 - val_handedness_loss: 0.6942\n",
      "Epoch 2/150\n",
      "6232/6232 [==============================] - 1s 135us/step - loss: 0.9146 - regression_loss: 0.2328 - handedness_loss: 0.6817 - val_loss: 0.8915 - val_regression_loss: 0.2196 - val_handedness_loss: 0.6681\n",
      "Epoch 3/150\n",
      "6232/6232 [==============================] - 1s 117us/step - loss: 0.8500 - regression_loss: 0.1862 - handedness_loss: 0.6635 - val_loss: 0.8353 - val_regression_loss: 0.1793 - val_handedness_loss: 0.6557\n",
      "Epoch 4/150\n",
      "6232/6232 [==============================] - 1s 129us/step - loss: 0.8108 - regression_loss: 0.1615 - handedness_loss: 0.6495 - val_loss: 0.8158 - val_regression_loss: 0.1605 - val_handedness_loss: 0.6506\n",
      "Epoch 5/150\n",
      "6232/6232 [==============================] - 1s 145us/step - loss: 0.7770 - regression_loss: 0.1442 - handedness_loss: 0.6329 - val_loss: 0.7740 - val_regression_loss: 0.1457 - val_handedness_loss: 0.6265\n",
      "Epoch 6/150\n",
      "6232/6232 [==============================] - 1s 144us/step - loss: 0.7463 - regression_loss: 0.1357 - handedness_loss: 0.6105 - val_loss: 0.7407 - val_regression_loss: 0.1374 - val_handedness_loss: 0.6044\n",
      "Epoch 7/150\n",
      "6232/6232 [==============================] - 1s 146us/step - loss: 0.6950 - regression_loss: 0.1227 - handedness_loss: 0.5720 - val_loss: 0.6957 - val_regression_loss: 0.1209 - val_handedness_loss: 0.5711\n",
      "Epoch 8/150\n",
      "6232/6232 [==============================] - 1s 147us/step - loss: 0.6705 - regression_loss: 0.1142 - handedness_loss: 0.5561 - val_loss: 0.6683 - val_regression_loss: 0.1163 - val_handedness_loss: 0.5513\n",
      "Epoch 9/150\n",
      "6232/6232 [==============================] - 1s 148us/step - loss: 0.6414 - regression_loss: 0.1079 - handedness_loss: 0.5334 - val_loss: 0.6689 - val_regression_loss: 0.1109 - val_handedness_loss: 0.5538\n",
      "Epoch 10/150\n",
      "6232/6232 [==============================] - 1s 149us/step - loss: 0.6362 - regression_loss: 0.1052 - handedness_loss: 0.5309 - val_loss: 0.6588 - val_regression_loss: 0.1140 - val_handedness_loss: 0.5450\n",
      "Epoch 11/150\n",
      "6232/6232 [==============================] - 1s 149us/step - loss: 0.6272 - regression_loss: 0.1047 - handedness_loss: 0.5226 - val_loss: 0.6658 - val_regression_loss: 0.1128 - val_handedness_loss: 0.5516\n",
      "Epoch 12/150\n",
      "6232/6232 [==============================] - 1s 145us/step - loss: 0.6172 - regression_loss: 0.1041 - handedness_loss: 0.5133 - val_loss: 0.6276 - val_regression_loss: 0.1138 - val_handedness_loss: 0.5128\n",
      "Epoch 13/150\n",
      "6232/6232 [==============================] - 1s 136us/step - loss: 0.5873 - regression_loss: 0.1009 - handedness_loss: 0.4862 - val_loss: 0.5922 - val_regression_loss: 0.1034 - val_handedness_loss: 0.4917\n",
      "Epoch 14/150\n",
      "6232/6232 [==============================] - 1s 147us/step - loss: 0.5682 - regression_loss: 0.0952 - handedness_loss: 0.4740 - val_loss: 0.5749 - val_regression_loss: 0.0971 - val_handedness_loss: 0.4720\n",
      "Epoch 15/150\n",
      "6232/6232 [==============================] - 1s 146us/step - loss: 0.5542 - regression_loss: 0.0910 - handedness_loss: 0.4627 - val_loss: 0.5806 - val_regression_loss: 0.0923 - val_handedness_loss: 0.4902\n",
      "Epoch 16/150\n",
      "6232/6232 [==============================] - 1s 137us/step - loss: 0.5530 - regression_loss: 0.0871 - handedness_loss: 0.4655 - val_loss: 0.5514 - val_regression_loss: 0.0901 - val_handedness_loss: 0.4650\n",
      "Epoch 17/150\n",
      "6232/6232 [==============================] - 1s 135us/step - loss: 0.5373 - regression_loss: 0.0851 - handedness_loss: 0.4522 - val_loss: 0.5529 - val_regression_loss: 0.0870 - val_handedness_loss: 0.4594\n",
      "Epoch 18/150\n",
      "6232/6232 [==============================] - 1s 146us/step - loss: 0.5283 - regression_loss: 0.0836 - handedness_loss: 0.4447 - val_loss: 0.5555 - val_regression_loss: 0.0856 - val_handedness_loss: 0.4649\n",
      "Epoch 19/150\n",
      "6232/6232 [==============================] - 1s 146us/step - loss: 0.5263 - regression_loss: 0.0826 - handedness_loss: 0.4438 - val_loss: 0.5340 - val_regression_loss: 0.0842 - val_handedness_loss: 0.4475\n",
      "Epoch 20/150\n",
      "6232/6232 [==============================] - 1s 132us/step - loss: 0.5126 - regression_loss: 0.0814 - handedness_loss: 0.4310 - val_loss: 0.5309 - val_regression_loss: 0.0830 - val_handedness_loss: 0.4444\n",
      "Epoch 21/150\n",
      "6232/6232 [==============================] - 1s 145us/step - loss: 0.5222 - regression_loss: 0.0812 - handedness_loss: 0.4412 - val_loss: 0.5372 - val_regression_loss: 0.0812 - val_handedness_loss: 0.4517\n",
      "Epoch 22/150\n",
      "6232/6232 [==============================] - 1s 146us/step - loss: 0.5227 - regression_loss: 0.0807 - handedness_loss: 0.4428 - val_loss: 0.5385 - val_regression_loss: 0.0815 - val_handedness_loss: 0.4569\n",
      "Epoch 23/150\n",
      "6232/6232 [==============================] - 1s 147us/step - loss: 0.5118 - regression_loss: 0.0806 - handedness_loss: 0.4311 - val_loss: 0.5306 - val_regression_loss: 0.0816 - val_handedness_loss: 0.4540\n",
      "Epoch 24/150\n",
      "6232/6232 [==============================] - 1s 147us/step - loss: 0.5195 - regression_loss: 0.0801 - handedness_loss: 0.4390 - val_loss: 0.5173 - val_regression_loss: 0.0809 - val_handedness_loss: 0.4339\n",
      "Epoch 25/150\n",
      "6232/6232 [==============================] - 1s 148us/step - loss: 0.5107 - regression_loss: 0.0803 - handedness_loss: 0.4301 - val_loss: 0.5071 - val_regression_loss: 0.0808 - val_handedness_loss: 0.4274\n",
      "Epoch 26/150\n",
      "6232/6232 [==============================] - 1s 146us/step - loss: 0.5146 - regression_loss: 0.0800 - handedness_loss: 0.4343 - val_loss: 0.5062 - val_regression_loss: 0.0800 - val_handedness_loss: 0.4258\n",
      "Epoch 27/150\n",
      "6232/6232 [==============================] - 1s 136us/step - loss: 0.5198 - regression_loss: 0.0801 - handedness_loss: 0.4396 - val_loss: 0.5281 - val_regression_loss: 0.0803 - val_handedness_loss: 0.4531\n",
      "Epoch 28/150\n",
      "6232/6232 [==============================] - 1s 121us/step - loss: 0.5105 - regression_loss: 0.0801 - handedness_loss: 0.4301 - val_loss: 0.5013 - val_regression_loss: 0.0801 - val_handedness_loss: 0.4244\n",
      "Epoch 29/150\n",
      "6232/6232 [==============================] - 1s 138us/step - loss: 0.5106 - regression_loss: 0.0804 - handedness_loss: 0.4298 - val_loss: 0.4963 - val_regression_loss: 0.0801 - val_handedness_loss: 0.4222\n",
      "Epoch 30/150\n",
      "6232/6232 [==============================] - 1s 135us/step - loss: 0.5010 - regression_loss: 0.0797 - handedness_loss: 0.4214 - val_loss: 0.5151 - val_regression_loss: 0.0799 - val_handedness_loss: 0.4374\n",
      "Epoch 31/150\n",
      "6232/6232 [==============================] - 1s 148us/step - loss: 0.5149 - regression_loss: 0.0805 - handedness_loss: 0.4345 - val_loss: 0.5031 - val_regression_loss: 0.0802 - val_handedness_loss: 0.4249\n",
      "Epoch 32/150\n",
      "6232/6232 [==============================] - 1s 118us/step - loss: 0.5038 - regression_loss: 0.0793 - handedness_loss: 0.4245 - val_loss: 0.5231 - val_regression_loss: 0.0804 - val_handedness_loss: 0.4454\n",
      "Epoch 33/150\n",
      "6232/6232 [==============================] - 1s 104us/step - loss: 0.5119 - regression_loss: 0.0803 - handedness_loss: 0.4317 - val_loss: 0.4943 - val_regression_loss: 0.0809 - val_handedness_loss: 0.4122\n",
      "Epoch 34/150\n",
      "6232/6232 [==============================] - 1s 123us/step - loss: 0.5078 - regression_loss: 0.0802 - handedness_loss: 0.4275 - val_loss: 0.5071 - val_regression_loss: 0.0803 - val_handedness_loss: 0.4231\n",
      "Evaluating model with testing data...\n",
      "1314/1314 [==============================] - 0s 16us/step\n",
      "Getting distribution of predictions and covariance matrix...\n",
      "      1 of 20\n",
      "      2 of 20\n",
      "      3 of 20\n",
      "      4 of 20\n",
      "      5 of 20\n",
      "      6 of 20\n",
      "      7 of 20\n",
      "      8 of 20\n",
      "      9 of 20\n",
      "      10 of 20\n",
      "      11 of 20\n",
      "      12 of 20\n",
      "      13 of 20\n",
      "      14 of 20\n",
      "      15 of 20\n",
      "      16 of 20\n",
      "      17 of 20\n",
      "      18 of 20\n",
      "      19 of 20\n",
      "      20 of 20\n",
      "Computing ensemble means...\n",
      "Computing mean squared error...\n",
      "Iteration 42\n",
      "Train on 6372 samples, validate on 1344 samples\n",
      "Epoch 1/150\n",
      "6372/6372 [==============================] - 1s 149us/step - loss: 1.1954 - regression_loss: 0.5275 - handedness_loss: 0.6668 - val_loss: 0.9121 - val_regression_loss: 0.2819 - val_handedness_loss: 0.6289\n",
      "Epoch 2/150\n",
      "6372/6372 [==============================] - 1s 127us/step - loss: 0.8166 - regression_loss: 0.2210 - handedness_loss: 0.5954 - val_loss: 0.7564 - val_regression_loss: 0.1986 - val_handedness_loss: 0.5586\n",
      "Epoch 3/150\n",
      "6372/6372 [==============================] - 1s 134us/step - loss: 0.6987 - regression_loss: 0.1710 - handedness_loss: 0.5274 - val_loss: 0.6658 - val_regression_loss: 0.1651 - val_handedness_loss: 0.4992\n",
      "Epoch 4/150\n",
      "6372/6372 [==============================] - 1s 119us/step - loss: 0.6193 - regression_loss: 0.1551 - handedness_loss: 0.4643 - val_loss: 0.5943 - val_regression_loss: 0.1575 - val_handedness_loss: 0.4377\n",
      "Epoch 5/150\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6372/6372 [==============================] - 1s 147us/step - loss: 0.5659 - regression_loss: 0.1443 - handedness_loss: 0.4216 - val_loss: 0.5587 - val_regression_loss: 0.1502 - val_handedness_loss: 0.4071\n",
      "Epoch 6/150\n",
      "6372/6372 [==============================] - 1s 146us/step - loss: 0.5182 - regression_loss: 0.1368 - handedness_loss: 0.3815 - val_loss: 0.4927 - val_regression_loss: 0.1380 - val_handedness_loss: 0.3496\n",
      "Epoch 7/150\n",
      "6372/6372 [==============================] - 1s 148us/step - loss: 0.4802 - regression_loss: 0.1280 - handedness_loss: 0.3519 - val_loss: 0.4682 - val_regression_loss: 0.1300 - val_handedness_loss: 0.3385\n",
      "Epoch 8/150\n",
      "6372/6372 [==============================] - 1s 135us/step - loss: 0.4504 - regression_loss: 0.1188 - handedness_loss: 0.3316 - val_loss: 0.4497 - val_regression_loss: 0.1224 - val_handedness_loss: 0.3289\n",
      "Epoch 9/150\n",
      "6372/6372 [==============================] - 1s 148us/step - loss: 0.4306 - regression_loss: 0.1117 - handedness_loss: 0.3188 - val_loss: 0.4480 - val_regression_loss: 0.1146 - val_handedness_loss: 0.3331\n",
      "Epoch 10/150\n",
      "6372/6372 [==============================] - 1s 147us/step - loss: 0.3978 - regression_loss: 0.1046 - handedness_loss: 0.2931 - val_loss: 0.4158 - val_regression_loss: 0.1071 - val_handedness_loss: 0.3089\n",
      "Epoch 11/150\n",
      "6372/6372 [==============================] - 1s 149us/step - loss: 0.3807 - regression_loss: 0.0972 - handedness_loss: 0.2834 - val_loss: 0.3949 - val_regression_loss: 0.1027 - val_handedness_loss: 0.2911\n",
      "Epoch 12/150\n",
      "6372/6372 [==============================] - 1s 150us/step - loss: 0.3688 - regression_loss: 0.0936 - handedness_loss: 0.2751 - val_loss: 0.3978 - val_regression_loss: 0.0956 - val_handedness_loss: 0.3014\n",
      "Epoch 13/150\n",
      "6372/6372 [==============================] - 1s 151us/step - loss: 0.3563 - regression_loss: 0.0888 - handedness_loss: 0.2673 - val_loss: 0.3572 - val_regression_loss: 0.0906 - val_handedness_loss: 0.2637\n",
      "Epoch 14/150\n",
      "6372/6372 [==============================] - 1s 150us/step - loss: 0.3496 - regression_loss: 0.0855 - handedness_loss: 0.2639 - val_loss: 0.3544 - val_regression_loss: 0.0884 - val_handedness_loss: 0.2675\n",
      "Epoch 15/150\n",
      "6372/6372 [==============================] - 1s 152us/step - loss: 0.3457 - regression_loss: 0.0831 - handedness_loss: 0.2625 - val_loss: 0.3416 - val_regression_loss: 0.0858 - val_handedness_loss: 0.2583\n",
      "Epoch 16/150\n",
      "6372/6372 [==============================] - 1s 144us/step - loss: 0.3350 - regression_loss: 0.0804 - handedness_loss: 0.2545 - val_loss: 0.3420 - val_regression_loss: 0.0847 - val_handedness_loss: 0.2618\n",
      "Epoch 17/150\n",
      "6372/6372 [==============================] - 1s 133us/step - loss: 0.3329 - regression_loss: 0.0789 - handedness_loss: 0.2539 - val_loss: 0.3562 - val_regression_loss: 0.0812 - val_handedness_loss: 0.2778\n",
      "Epoch 18/150\n",
      "6372/6372 [==============================] - 1s 141us/step - loss: 0.3300 - regression_loss: 0.0772 - handedness_loss: 0.2532 - val_loss: 0.3482 - val_regression_loss: 0.0804 - val_handedness_loss: 0.2718\n",
      "Epoch 19/150\n",
      "6372/6372 [==============================] - 1s 130us/step - loss: 0.3244 - regression_loss: 0.0768 - handedness_loss: 0.2477 - val_loss: 0.3516 - val_regression_loss: 0.0788 - val_handedness_loss: 0.2737\n",
      "Evaluating model with testing data...\n",
      "1344/1344 [==============================] - 0s 16us/step\n",
      "Getting distribution of predictions and covariance matrix...\n",
      "      1 of 20\n",
      "      2 of 20\n",
      "      3 of 20\n",
      "      4 of 20\n",
      "      5 of 20\n",
      "      6 of 20\n",
      "      7 of 20\n",
      "      8 of 20\n",
      "      9 of 20\n",
      "      10 of 20\n",
      "      11 of 20\n",
      "      12 of 20\n",
      "      13 of 20\n",
      "      14 of 20\n",
      "      15 of 20\n",
      "      16 of 20\n",
      "      17 of 20\n",
      "      18 of 20\n",
      "      19 of 20\n",
      "      20 of 20\n",
      "Computing ensemble means...\n",
      "Computing mean squared error...\n",
      "Iteration 43\n",
      "Train on 6512 samples, validate on 1374 samples\n",
      "Epoch 1/150\n",
      "6512/6512 [==============================] - 1s 130us/step - loss: 1.0588 - regression_loss: 0.3596 - handedness_loss: 0.6988 - val_loss: 0.8947 - val_regression_loss: 0.2225 - val_handedness_loss: 0.6722\n",
      "Epoch 2/150\n",
      "6512/6512 [==============================] - 1s 125us/step - loss: 0.8436 - regression_loss: 0.1813 - handedness_loss: 0.6621 - val_loss: 0.8271 - val_regression_loss: 0.1767 - val_handedness_loss: 0.6497\n",
      "Epoch 3/150\n",
      "6512/6512 [==============================] - 1s 129us/step - loss: 0.7759 - regression_loss: 0.1596 - handedness_loss: 0.6163 - val_loss: 0.7316 - val_regression_loss: 0.1511 - val_handedness_loss: 0.5800\n",
      "Epoch 4/150\n",
      "6512/6512 [==============================] - 1s 135us/step - loss: 0.6866 - regression_loss: 0.1484 - handedness_loss: 0.5380 - val_loss: 0.6399 - val_regression_loss: 0.1500 - val_handedness_loss: 0.4884\n",
      "Epoch 5/150\n",
      "6512/6512 [==============================] - 1s 144us/step - loss: 0.5866 - regression_loss: 0.1373 - handedness_loss: 0.4491 - val_loss: 0.5803 - val_regression_loss: 0.1379 - val_handedness_loss: 0.4400\n",
      "Epoch 6/150\n",
      "6512/6512 [==============================] - 1s 124us/step - loss: 0.5137 - regression_loss: 0.1240 - handedness_loss: 0.3897 - val_loss: 0.5081 - val_regression_loss: 0.1319 - val_handedness_loss: 0.3758\n",
      "Epoch 7/150\n",
      "6512/6512 [==============================] - 1s 122us/step - loss: 0.4769 - regression_loss: 0.1162 - handedness_loss: 0.3607 - val_loss: 0.4986 - val_regression_loss: 0.1277 - val_handedness_loss: 0.3697\n",
      "Epoch 8/150\n",
      "6512/6512 [==============================] - 1s 146us/step - loss: 0.4318 - regression_loss: 0.1088 - handedness_loss: 0.3231 - val_loss: 0.4318 - val_regression_loss: 0.1114 - val_handedness_loss: 0.3172\n",
      "Epoch 9/150\n",
      "6512/6512 [==============================] - 1s 144us/step - loss: 0.4104 - regression_loss: 0.1043 - handedness_loss: 0.3062 - val_loss: 0.4067 - val_regression_loss: 0.1064 - val_handedness_loss: 0.2986\n",
      "Epoch 10/150\n",
      "6512/6512 [==============================] - 1s 147us/step - loss: 0.3702 - regression_loss: 0.0955 - handedness_loss: 0.2746 - val_loss: 0.3786 - val_regression_loss: 0.0983 - val_handedness_loss: 0.2788\n",
      "Epoch 11/150\n",
      "6512/6512 [==============================] - 1s 128us/step - loss: 0.3450 - regression_loss: 0.0907 - handedness_loss: 0.2544 - val_loss: 0.3595 - val_regression_loss: 0.0939 - val_handedness_loss: 0.2636\n",
      "Epoch 12/150\n",
      "6512/6512 [==============================] - 1s 135us/step - loss: 0.3443 - regression_loss: 0.0859 - handedness_loss: 0.2583 - val_loss: 0.3489 - val_regression_loss: 0.0902 - val_handedness_loss: 0.2571\n",
      "Epoch 13/150\n",
      "6512/6512 [==============================] - 1s 145us/step - loss: 0.3277 - regression_loss: 0.0826 - handedness_loss: 0.2451 - val_loss: 0.3351 - val_regression_loss: 0.0864 - val_handedness_loss: 0.2469\n",
      "Epoch 14/150\n",
      "6512/6512 [==============================] - 1s 135us/step - loss: 0.3116 - regression_loss: 0.0804 - handedness_loss: 0.2311 - val_loss: 0.3331 - val_regression_loss: 0.0852 - val_handedness_loss: 0.2470\n",
      "Epoch 15/150\n",
      "6512/6512 [==============================] - 1s 145us/step - loss: 0.3082 - regression_loss: 0.0782 - handedness_loss: 0.2300 - val_loss: 0.3219 - val_regression_loss: 0.0828 - val_handedness_loss: 0.2381\n",
      "Epoch 16/150\n",
      "6512/6512 [==============================] - 1s 127us/step - loss: 0.3046 - regression_loss: 0.0763 - handedness_loss: 0.2286 - val_loss: 0.3215 - val_regression_loss: 0.0813 - val_handedness_loss: 0.2398\n",
      "Epoch 17/150\n",
      "6512/6512 [==============================] - 1s 135us/step - loss: 0.3026 - regression_loss: 0.0750 - handedness_loss: 0.2276 - val_loss: 0.3228 - val_regression_loss: 0.0787 - val_handedness_loss: 0.2427\n",
      "Epoch 18/150\n",
      "6512/6512 [==============================] - 1s 130us/step - loss: 0.2950 - regression_loss: 0.0743 - handedness_loss: 0.2206 - val_loss: 0.2967 - val_regression_loss: 0.0771 - val_handedness_loss: 0.2181\n",
      "Epoch 19/150\n",
      "6512/6512 [==============================] - 1s 118us/step - loss: 0.2872 - regression_loss: 0.0731 - handedness_loss: 0.2142 - val_loss: 0.3062 - val_regression_loss: 0.0759 - val_handedness_loss: 0.2294\n",
      "Epoch 20/150\n",
      "6512/6512 [==============================] - 1s 136us/step - loss: 0.2917 - regression_loss: 0.0736 - handedness_loss: 0.2182 - val_loss: 0.2846 - val_regression_loss: 0.0760 - val_handedness_loss: 0.2062\n",
      "Epoch 21/150\n",
      "6512/6512 [==============================] - 1s 117us/step - loss: 0.2847 - regression_loss: 0.0721 - handedness_loss: 0.2128 - val_loss: 0.3037 - val_regression_loss: 0.0751 - val_handedness_loss: 0.2282\n",
      "Epoch 22/150\n",
      "6512/6512 [==============================] - 1s 121us/step - loss: 0.2820 - regression_loss: 0.0720 - handedness_loss: 0.2102 - val_loss: 0.2968 - val_regression_loss: 0.0754 - val_handedness_loss: 0.2206\n",
      "Epoch 23/150\n",
      "6512/6512 [==============================] - 1s 138us/step - loss: 0.2771 - regression_loss: 0.0719 - handedness_loss: 0.2053 - val_loss: 0.2939 - val_regression_loss: 0.0761 - val_handedness_loss: 0.2178\n",
      "Epoch 24/150\n",
      "6512/6512 [==============================] - 1s 145us/step - loss: 0.2795 - regression_loss: 0.0719 - handedness_loss: 0.2074 - val_loss: 0.2997 - val_regression_loss: 0.0758 - val_handedness_loss: 0.2227\n",
      "Evaluating model with testing data...\n",
      "1374/1374 [==============================] - 0s 20us/step\n",
      "Getting distribution of predictions and covariance matrix...\n",
      "      1 of 20\n",
      "      2 of 20\n",
      "      3 of 20\n",
      "      4 of 20\n",
      "      5 of 20\n",
      "      6 of 20\n",
      "      7 of 20\n",
      "      8 of 20\n",
      "      9 of 20\n",
      "      10 of 20\n",
      "      11 of 20\n",
      "      12 of 20\n",
      "      13 of 20\n",
      "      14 of 20\n",
      "      15 of 20\n",
      "      16 of 20\n",
      "      17 of 20\n",
      "      18 of 20\n",
      "      19 of 20\n",
      "      20 of 20\n",
      "Computing ensemble means...\n",
      "Computing mean squared error...\n",
      "Iteration 44\n",
      "Train on 6652 samples, validate on 1404 samples\n",
      "Epoch 1/150\n",
      "6652/6652 [==============================] - 1s 138us/step - loss: 1.0470 - regression_loss: 0.3721 - handedness_loss: 0.6748 - val_loss: 0.9400 - val_regression_loss: 0.2608 - val_handedness_loss: 0.6794\n",
      "Epoch 2/150\n",
      "6652/6652 [==============================] - 1s 116us/step - loss: 0.8420 - regression_loss: 0.2201 - handedness_loss: 0.6219 - val_loss: 0.8031 - val_regression_loss: 0.2066 - val_handedness_loss: 0.5964\n",
      "Epoch 3/150\n",
      "6652/6652 [==============================] - 1s 147us/step - loss: 0.7622 - regression_loss: 0.1880 - handedness_loss: 0.5742 - val_loss: 0.7472 - val_regression_loss: 0.1920 - val_handedness_loss: 0.5552\n",
      "Epoch 4/150\n",
      "6652/6652 [==============================] - 1s 145us/step - loss: 0.7247 - regression_loss: 0.1749 - handedness_loss: 0.5498 - val_loss: 0.7105 - val_regression_loss: 0.1765 - val_handedness_loss: 0.5341\n",
      "Epoch 5/150\n",
      "6652/6652 [==============================] - 1s 149us/step - loss: 0.6709 - regression_loss: 0.1584 - handedness_loss: 0.5126 - val_loss: 0.6823 - val_regression_loss: 0.1615 - val_handedness_loss: 0.5209\n",
      "Epoch 6/150\n",
      "6652/6652 [==============================] - 1s 132us/step - loss: 0.6519 - regression_loss: 0.1447 - handedness_loss: 0.5072 - val_loss: 0.6374 - val_regression_loss: 0.1440 - val_handedness_loss: 0.4935\n",
      "Epoch 7/150\n",
      "6652/6652 [==============================] - 1s 136us/step - loss: 0.6237 - regression_loss: 0.1300 - handedness_loss: 0.4937 - val_loss: 0.6252 - val_regression_loss: 0.1318 - val_handedness_loss: 0.4934\n",
      "Epoch 8/150\n",
      "6652/6652 [==============================] - 1s 147us/step - loss: 0.5984 - regression_loss: 0.1185 - handedness_loss: 0.4798 - val_loss: 0.6189 - val_regression_loss: 0.1211 - val_handedness_loss: 0.4977\n",
      "Epoch 9/150\n",
      "6652/6652 [==============================] - 1s 148us/step - loss: 0.5874 - regression_loss: 0.1090 - handedness_loss: 0.4784 - val_loss: 0.5846 - val_regression_loss: 0.1108 - val_handedness_loss: 0.4738\n",
      "Epoch 10/150\n",
      "6652/6652 [==============================] - 1s 148us/step - loss: 0.5707 - regression_loss: 0.1008 - handedness_loss: 0.4699 - val_loss: 0.5789 - val_regression_loss: 0.1031 - val_handedness_loss: 0.4758\n",
      "Epoch 11/150\n",
      "6652/6652 [==============================] - 1s 150us/step - loss: 0.5640 - regression_loss: 0.0951 - handedness_loss: 0.4689 - val_loss: 0.5617 - val_regression_loss: 0.0978 - val_handedness_loss: 0.4638\n",
      "Epoch 12/150\n",
      "6652/6652 [==============================] - 1s 126us/step - loss: 0.5608 - regression_loss: 0.0909 - handedness_loss: 0.4699 - val_loss: 0.5536 - val_regression_loss: 0.0936 - val_handedness_loss: 0.4599\n",
      "Epoch 13/150\n",
      "6652/6652 [==============================] - 0s 67us/step - loss: 0.5483 - regression_loss: 0.0876 - handedness_loss: 0.4608 - val_loss: 0.5523 - val_regression_loss: 0.0900 - val_handedness_loss: 0.4623\n",
      "Epoch 14/150\n",
      "6652/6652 [==============================] - 0s 65us/step - loss: 0.5456 - regression_loss: 0.0849 - handedness_loss: 0.4607 - val_loss: 0.5465 - val_regression_loss: 0.0881 - val_handedness_loss: 0.4584\n",
      "Epoch 15/150\n",
      "6652/6652 [==============================] - 1s 118us/step - loss: 0.5436 - regression_loss: 0.0828 - handedness_loss: 0.4608 - val_loss: 0.5452 - val_regression_loss: 0.0865 - val_handedness_loss: 0.4587\n",
      "Epoch 16/150\n",
      "6652/6652 [==============================] - 1s 146us/step - loss: 0.5359 - regression_loss: 0.0814 - handedness_loss: 0.4545 - val_loss: 0.5418 - val_regression_loss: 0.0846 - val_handedness_loss: 0.4573\n",
      "Epoch 17/150\n",
      "6652/6652 [==============================] - 1s 125us/step - loss: 0.5331 - regression_loss: 0.0807 - handedness_loss: 0.4525 - val_loss: 0.5305 - val_regression_loss: 0.0832 - val_handedness_loss: 0.4474\n",
      "Epoch 18/150\n",
      "6652/6652 [==============================] - 1s 136us/step - loss: 0.5299 - regression_loss: 0.0798 - handedness_loss: 0.4501 - val_loss: 0.5389 - val_regression_loss: 0.0833 - val_handedness_loss: 0.4556\n",
      "Epoch 19/150\n",
      "6652/6652 [==============================] - 1s 118us/step - loss: 0.5350 - regression_loss: 0.0798 - handedness_loss: 0.4552 - val_loss: 0.5425 - val_regression_loss: 0.0828 - val_handedness_loss: 0.4595\n",
      "Epoch 20/150\n",
      "6652/6652 [==============================] - 1s 134us/step - loss: 0.5324 - regression_loss: 0.0795 - handedness_loss: 0.4529 - val_loss: 0.5449 - val_regression_loss: 0.0829 - val_handedness_loss: 0.4620\n",
      "Epoch 21/150\n",
      "6652/6652 [==============================] - 1s 135us/step - loss: 0.5333 - regression_loss: 0.0794 - handedness_loss: 0.4539 - val_loss: 0.5333 - val_regression_loss: 0.0825 - val_handedness_loss: 0.4507\n",
      "Evaluating model with testing data...\n",
      "1404/1404 [==============================] - 0s 23us/step\n",
      "Getting distribution of predictions and covariance matrix...\n",
      "      1 of 20\n",
      "      2 of 20\n",
      "      3 of 20\n",
      "      4 of 20\n",
      "      5 of 20\n",
      "      6 of 20\n",
      "      7 of 20\n",
      "      8 of 20\n",
      "      9 of 20\n",
      "      10 of 20\n",
      "      11 of 20\n",
      "      12 of 20\n",
      "      13 of 20\n",
      "      14 of 20\n",
      "      15 of 20\n",
      "      16 of 20\n",
      "      17 of 20\n",
      "      18 of 20\n",
      "      19 of 20\n",
      "      20 of 20\n",
      "Computing ensemble means...\n",
      "Computing mean squared error...\n",
      "Iteration 45\n",
      "Train on 6792 samples, validate on 1434 samples\n",
      "Epoch 1/150\n",
      "6792/6792 [==============================] - 1s 156us/step - loss: 0.8784 - regression_loss: 0.2346 - handedness_loss: 0.6418 - val_loss: 0.7077 - val_regression_loss: 0.1410 - val_handedness_loss: 0.5686\n",
      "Epoch 2/150\n",
      "6792/6792 [==============================] - 1s 135us/step - loss: 0.6433 - regression_loss: 0.1320 - handedness_loss: 0.5106 - val_loss: 0.5539 - val_regression_loss: 0.1304 - val_handedness_loss: 0.4301\n",
      "Epoch 3/150\n",
      "6792/6792 [==============================] - 1s 123us/step - loss: 0.4901 - regression_loss: 0.1189 - handedness_loss: 0.3725 - val_loss: 0.4447 - val_regression_loss: 0.1136 - val_handedness_loss: 0.3322\n",
      "Epoch 4/150\n",
      "6792/6792 [==============================] - 1s 138us/step - loss: 0.3939 - regression_loss: 0.1055 - handedness_loss: 0.2870 - val_loss: 0.3683 - val_regression_loss: 0.1117 - val_handedness_loss: 0.2567\n",
      "Epoch 5/150\n",
      "6792/6792 [==============================] - 1s 127us/step - loss: 0.3394 - regression_loss: 0.0980 - handedness_loss: 0.2443 - val_loss: 0.3110 - val_regression_loss: 0.0968 - val_handedness_loss: 0.2140\n",
      "Epoch 6/150\n",
      "6792/6792 [==============================] - 1s 137us/step - loss: 0.2991 - regression_loss: 0.0925 - handedness_loss: 0.2150 - val_loss: 0.3044 - val_regression_loss: 0.0975 - val_handedness_loss: 0.2121\n",
      "Epoch 7/150\n",
      "6792/6792 [==============================] - 1s 122us/step - loss: 0.3017 - regression_loss: 0.0901 - handedness_loss: 0.2112 - val_loss: 0.2978 - val_regression_loss: 0.0893 - val_handedness_loss: 0.2128\n",
      "Epoch 8/150\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6792/6792 [==============================] - 1s 145us/step - loss: 0.2730 - regression_loss: 0.0849 - handedness_loss: 0.1885 - val_loss: 0.2500 - val_regression_loss: 0.0871 - val_handedness_loss: 0.1707\n",
      "Epoch 9/150\n",
      "6792/6792 [==============================] - 1s 146us/step - loss: 0.2541 - regression_loss: 0.0798 - handedness_loss: 0.1738 - val_loss: 0.2531 - val_regression_loss: 0.0821 - val_handedness_loss: 0.1749\n",
      "Epoch 10/150\n",
      "6792/6792 [==============================] - 1s 148us/step - loss: 0.2503 - regression_loss: 0.0787 - handedness_loss: 0.1757 - val_loss: 0.2539 - val_regression_loss: 0.0773 - val_handedness_loss: 0.1822\n",
      "Epoch 11/150\n",
      "6792/6792 [==============================] - 1s 124us/step - loss: 0.2445 - regression_loss: 0.0744 - handedness_loss: 0.1672 - val_loss: 0.2617 - val_regression_loss: 0.0770 - val_handedness_loss: 0.1877\n",
      "Epoch 12/150\n",
      "6792/6792 [==============================] - 1s 139us/step - loss: 0.2410 - regression_loss: 0.0734 - handedness_loss: 0.1657 - val_loss: 0.2336 - val_regression_loss: 0.0760 - val_handedness_loss: 0.1592\n",
      "Epoch 13/150\n",
      "6792/6792 [==============================] - 1s 146us/step - loss: 0.2186 - regression_loss: 0.0702 - handedness_loss: 0.1460 - val_loss: 0.2181 - val_regression_loss: 0.0726 - val_handedness_loss: 0.1686\n",
      "Epoch 14/150\n",
      "6792/6792 [==============================] - 1s 125us/step - loss: 0.2197 - regression_loss: 0.0693 - handedness_loss: 0.1486 - val_loss: 0.2264 - val_regression_loss: 0.0705 - val_handedness_loss: 0.1559\n",
      "Epoch 15/150\n",
      "6792/6792 [==============================] - 1s 142us/step - loss: 0.2074 - regression_loss: 0.0678 - handedness_loss: 0.1453 - val_loss: 0.2278 - val_regression_loss: 0.0697 - val_handedness_loss: 0.1685\n",
      "Epoch 16/150\n",
      "6792/6792 [==============================] - 1s 147us/step - loss: 0.2200 - regression_loss: 0.0696 - handedness_loss: 0.1528 - val_loss: 0.2330 - val_regression_loss: 0.0715 - val_handedness_loss: 0.1679\n",
      "Epoch 17/150\n",
      "6792/6792 [==============================] - 1s 145us/step - loss: 0.2194 - regression_loss: 0.0674 - handedness_loss: 0.1519 - val_loss: 0.2204 - val_regression_loss: 0.0679 - val_handedness_loss: 0.1513\n",
      "Epoch 18/150\n",
      "6792/6792 [==============================] - 1s 139us/step - loss: 0.2074 - regression_loss: 0.0664 - handedness_loss: 0.1411 - val_loss: 0.2111 - val_regression_loss: 0.0702 - val_handedness_loss: 0.1461\n",
      "Epoch 19/150\n",
      "6792/6792 [==============================] - 1s 139us/step - loss: 0.2010 - regression_loss: 0.0654 - handedness_loss: 0.1335 - val_loss: 0.1979 - val_regression_loss: 0.0692 - val_handedness_loss: 0.1290\n",
      "Epoch 20/150\n",
      "6792/6792 [==============================] - 1s 124us/step - loss: 0.1888 - regression_loss: 0.0657 - handedness_loss: 0.1248 - val_loss: 0.2207 - val_regression_loss: 0.0678 - val_handedness_loss: 0.1491\n",
      "Epoch 21/150\n",
      "6792/6792 [==============================] - 1s 137us/step - loss: 0.1969 - regression_loss: 0.0656 - handedness_loss: 0.1302 - val_loss: 0.1842 - val_regression_loss: 0.0700 - val_handedness_loss: 0.1200\n",
      "Epoch 22/150\n",
      "6792/6792 [==============================] - 1s 145us/step - loss: 0.1991 - regression_loss: 0.0657 - handedness_loss: 0.1311 - val_loss: 0.2023 - val_regression_loss: 0.0691 - val_handedness_loss: 0.1329\n",
      "Epoch 23/150\n",
      "6792/6792 [==============================] - 1s 93us/step - loss: 0.1892 - regression_loss: 0.0657 - handedness_loss: 0.1246 - val_loss: 0.2043 - val_regression_loss: 0.0685 - val_handedness_loss: 0.1307\n",
      "Epoch 24/150\n",
      "6792/6792 [==============================] - 1s 115us/step - loss: 0.1937 - regression_loss: 0.0655 - handedness_loss: 0.1257 - val_loss: 0.2013 - val_regression_loss: 0.0684 - val_handedness_loss: 0.1354\n",
      "Evaluating model with testing data...\n",
      "1434/1434 [==============================] - 0s 16us/step\n",
      "Getting distribution of predictions and covariance matrix...\n",
      "      1 of 20\n",
      "      2 of 20\n",
      "      3 of 20\n",
      "      4 of 20\n",
      "      5 of 20\n",
      "      6 of 20\n",
      "      7 of 20\n",
      "      8 of 20\n",
      "      9 of 20\n",
      "      10 of 20\n",
      "      11 of 20\n",
      "      12 of 20\n",
      "      13 of 20\n",
      "      14 of 20\n",
      "      15 of 20\n",
      "      16 of 20\n",
      "      17 of 20\n",
      "      18 of 20\n",
      "      19 of 20\n",
      "      20 of 20\n",
      "Computing ensemble means...\n",
      "Computing mean squared error...\n",
      "Iteration 46\n",
      "Train on 6932 samples, validate on 1464 samples\n",
      "Epoch 1/150\n",
      "6932/6932 [==============================] - 1s 131us/step - loss: 1.1802 - regression_loss: 0.4888 - handedness_loss: 0.6873 - val_loss: 0.9720 - val_regression_loss: 0.2965 - val_handedness_loss: 0.6774\n",
      "Epoch 2/150\n",
      "6932/6932 [==============================] - 1s 121us/step - loss: 0.8996 - regression_loss: 0.2356 - handedness_loss: 0.6640 - val_loss: 0.8695 - val_regression_loss: 0.2191 - val_handedness_loss: 0.6503\n",
      "Epoch 3/150\n",
      "6932/6932 [==============================] - 1s 120us/step - loss: 0.8085 - regression_loss: 0.1829 - handedness_loss: 0.6243 - val_loss: 0.7931 - val_regression_loss: 0.1813 - val_handedness_loss: 0.6135\n",
      "Epoch 4/150\n",
      "6932/6932 [==============================] - 1s 143us/step - loss: 0.7305 - regression_loss: 0.1505 - handedness_loss: 0.5789 - val_loss: 0.7285 - val_regression_loss: 0.1492 - val_handedness_loss: 0.5797\n",
      "Epoch 5/150\n",
      "6932/6932 [==============================] - 1s 145us/step - loss: 0.6824 - regression_loss: 0.1346 - handedness_loss: 0.5469 - val_loss: 0.6815 - val_regression_loss: 0.1561 - val_handedness_loss: 0.5300\n",
      "Epoch 6/150\n",
      "6932/6932 [==============================] - 1s 147us/step - loss: 0.6175 - regression_loss: 0.1257 - handedness_loss: 0.4924 - val_loss: 0.6232 - val_regression_loss: 0.1321 - val_handedness_loss: 0.4959\n",
      "Epoch 7/150\n",
      "6932/6932 [==============================] - 1s 139us/step - loss: 0.5837 - regression_loss: 0.1162 - handedness_loss: 0.4654 - val_loss: 0.5888 - val_regression_loss: 0.1227 - val_handedness_loss: 0.4685\n",
      "Epoch 8/150\n",
      "6932/6932 [==============================] - 1s 147us/step - loss: 0.5539 - regression_loss: 0.1134 - handedness_loss: 0.4402 - val_loss: 0.5583 - val_regression_loss: 0.1229 - val_handedness_loss: 0.4392\n",
      "Epoch 9/150\n",
      "6932/6932 [==============================] - 1s 144us/step - loss: 0.5140 - regression_loss: 0.1098 - handedness_loss: 0.4025 - val_loss: 0.5433 - val_regression_loss: 0.1171 - val_handedness_loss: 0.4238\n",
      "Epoch 10/150\n",
      "6932/6932 [==============================] - 1s 128us/step - loss: 0.4960 - regression_loss: 0.1055 - handedness_loss: 0.3906 - val_loss: 0.5042 - val_regression_loss: 0.1102 - val_handedness_loss: 0.3937\n",
      "Epoch 11/150\n",
      "6932/6932 [==============================] - 1s 132us/step - loss: 0.4773 - regression_loss: 0.0985 - handedness_loss: 0.3791 - val_loss: 0.5024 - val_regression_loss: 0.1075 - val_handedness_loss: 0.4018\n",
      "Epoch 12/150\n",
      "6932/6932 [==============================] - 1s 118us/step - loss: 0.4668 - regression_loss: 0.0943 - handedness_loss: 0.3718 - val_loss: 0.4685 - val_regression_loss: 0.0961 - val_handedness_loss: 0.3723\n",
      "Epoch 13/150\n",
      "6932/6932 [==============================] - 1s 134us/step - loss: 0.4521 - regression_loss: 0.0898 - handedness_loss: 0.3641 - val_loss: 0.4558 - val_regression_loss: 0.0926 - val_handedness_loss: 0.3607\n",
      "Epoch 14/150\n",
      "6932/6932 [==============================] - 1s 142us/step - loss: 0.4478 - regression_loss: 0.0862 - handedness_loss: 0.3619 - val_loss: 0.4397 - val_regression_loss: 0.0911 - val_handedness_loss: 0.3501\n",
      "Epoch 15/150\n",
      "6932/6932 [==============================] - 1s 144us/step - loss: 0.4551 - regression_loss: 0.0840 - handedness_loss: 0.3708 - val_loss: 0.4537 - val_regression_loss: 0.0862 - val_handedness_loss: 0.3659\n",
      "Epoch 16/150\n",
      "6932/6932 [==============================] - 1s 147us/step - loss: 0.4370 - regression_loss: 0.0813 - handedness_loss: 0.3530 - val_loss: 0.4337 - val_regression_loss: 0.0852 - val_handedness_loss: 0.3501\n",
      "Epoch 17/150\n",
      "6932/6932 [==============================] - 1s 119us/step - loss: 0.4269 - regression_loss: 0.0799 - handedness_loss: 0.3460 - val_loss: 0.4485 - val_regression_loss: 0.0862 - val_handedness_loss: 0.3616\n",
      "Epoch 18/150\n",
      "6932/6932 [==============================] - 1s 118us/step - loss: 0.4266 - regression_loss: 0.0791 - handedness_loss: 0.3514 - val_loss: 0.4459 - val_regression_loss: 0.0824 - val_handedness_loss: 0.3642\n",
      "Evaluating model with testing data...\n",
      "1464/1464 [==============================] - 0s 16us/step\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Getting distribution of predictions and covariance matrix...\n",
      "      1 of 20\n",
      "      2 of 20\n",
      "      3 of 20\n",
      "      4 of 20\n",
      "      5 of 20\n",
      "      6 of 20\n",
      "      7 of 20\n",
      "      8 of 20\n",
      "      9 of 20\n",
      "      10 of 20\n",
      "      11 of 20\n",
      "      12 of 20\n",
      "      13 of 20\n",
      "      14 of 20\n",
      "      15 of 20\n",
      "      16 of 20\n",
      "      17 of 20\n",
      "      18 of 20\n",
      "      19 of 20\n",
      "      20 of 20\n",
      "Computing ensemble means...\n",
      "Computing mean squared error...\n",
      "Iteration 47\n",
      "Train on 7072 samples, validate on 1494 samples\n",
      "Epoch 1/150\n",
      "7072/7072 [==============================] - 1s 148us/step - loss: 1.2187 - regression_loss: 0.5251 - handedness_loss: 0.6899 - val_loss: 0.9874 - val_regression_loss: 0.3155 - val_handedness_loss: 0.6729\n",
      "Epoch 2/150\n",
      "7072/7072 [==============================] - 1s 132us/step - loss: 0.9248 - regression_loss: 0.2616 - handedness_loss: 0.6630 - val_loss: 0.9118 - val_regression_loss: 0.2590 - val_handedness_loss: 0.6540\n",
      "Epoch 3/150\n",
      "7072/7072 [==============================] - 1s 141us/step - loss: 0.8618 - regression_loss: 0.2230 - handedness_loss: 0.6386 - val_loss: 0.8704 - val_regression_loss: 0.2271 - val_handedness_loss: 0.6437\n",
      "Epoch 4/150\n",
      "7072/7072 [==============================] - 1s 144us/step - loss: 0.8103 - regression_loss: 0.1949 - handedness_loss: 0.6150 - val_loss: 0.8119 - val_regression_loss: 0.2029 - val_handedness_loss: 0.6093\n",
      "Epoch 5/150\n",
      "7072/7072 [==============================] - 1s 141us/step - loss: 0.7504 - regression_loss: 0.1717 - handedness_loss: 0.5783 - val_loss: 0.7580 - val_regression_loss: 0.1786 - val_handedness_loss: 0.5790\n",
      "Epoch 6/150\n",
      "7072/7072 [==============================] - 1s 145us/step - loss: 0.7192 - regression_loss: 0.1553 - handedness_loss: 0.5648 - val_loss: 0.7261 - val_regression_loss: 0.1607 - val_handedness_loss: 0.5641\n",
      "Epoch 7/150\n",
      "7072/7072 [==============================] - 1s 147us/step - loss: 0.6912 - regression_loss: 0.1394 - handedness_loss: 0.5526 - val_loss: 0.7080 - val_regression_loss: 0.1479 - val_handedness_loss: 0.5588\n",
      "Epoch 8/150\n",
      "7072/7072 [==============================] - 1s 148us/step - loss: 0.6507 - regression_loss: 0.1205 - handedness_loss: 0.5303 - val_loss: 0.6642 - val_regression_loss: 0.1264 - val_handedness_loss: 0.5363\n",
      "Epoch 9/150\n",
      "7072/7072 [==============================] - 1s 147us/step - loss: 0.5995 - regression_loss: 0.1089 - handedness_loss: 0.4898 - val_loss: 0.6295 - val_regression_loss: 0.1174 - val_handedness_loss: 0.5108\n",
      "Epoch 10/150\n",
      "7072/7072 [==============================] - 1s 148us/step - loss: 0.5797 - regression_loss: 0.1026 - handedness_loss: 0.4784 - val_loss: 0.6014 - val_regression_loss: 0.1108 - val_handedness_loss: 0.4914\n",
      "Epoch 11/150\n",
      "7072/7072 [==============================] - 1s 131us/step - loss: 0.5749 - regression_loss: 0.0974 - handedness_loss: 0.4776 - val_loss: 0.5852 - val_regression_loss: 0.1032 - val_handedness_loss: 0.4820\n",
      "Epoch 12/150\n",
      "7072/7072 [==============================] - 1s 143us/step - loss: 0.5576 - regression_loss: 0.0925 - handedness_loss: 0.4648 - val_loss: 0.5667 - val_regression_loss: 0.0997 - val_handedness_loss: 0.4641\n",
      "Epoch 13/150\n",
      "7072/7072 [==============================] - 1s 122us/step - loss: 0.5520 - regression_loss: 0.0895 - handedness_loss: 0.4626 - val_loss: 0.5552 - val_regression_loss: 0.0963 - val_handedness_loss: 0.4596\n",
      "Epoch 14/150\n",
      "7072/7072 [==============================] - 1s 142us/step - loss: 0.5393 - regression_loss: 0.0863 - handedness_loss: 0.4533 - val_loss: 0.5578 - val_regression_loss: 0.0924 - val_handedness_loss: 0.4645\n",
      "Epoch 15/150\n",
      "7072/7072 [==============================] - 1s 143us/step - loss: 0.5377 - regression_loss: 0.0848 - handedness_loss: 0.4538 - val_loss: 0.5649 - val_regression_loss: 0.0920 - val_handedness_loss: 0.4714\n",
      "Epoch 16/150\n",
      "7072/7072 [==============================] - 1s 146us/step - loss: 0.5331 - regression_loss: 0.0831 - handedness_loss: 0.4498 - val_loss: 0.5633 - val_regression_loss: 0.0903 - val_handedness_loss: 0.4734\n",
      "Epoch 17/150\n",
      "7072/7072 [==============================] - 1s 120us/step - loss: 0.5360 - regression_loss: 0.0825 - handedness_loss: 0.4546 - val_loss: 0.5491 - val_regression_loss: 0.0876 - val_handedness_loss: 0.4599\n",
      "Evaluating model with testing data...\n",
      "1494/1494 [==============================] - 0s 19us/step\n",
      "Getting distribution of predictions and covariance matrix...\n",
      "      1 of 20\n",
      "      2 of 20\n",
      "      3 of 20\n",
      "      4 of 20\n",
      "      5 of 20\n",
      "      6 of 20\n",
      "      7 of 20\n",
      "      8 of 20\n",
      "      9 of 20\n",
      "      10 of 20\n",
      "      11 of 20\n",
      "      12 of 20\n",
      "      13 of 20\n",
      "      14 of 20\n",
      "      15 of 20\n",
      "      16 of 20\n",
      "      17 of 20\n",
      "      18 of 20\n",
      "      19 of 20\n",
      "      20 of 20\n",
      "Computing ensemble means...\n",
      "Computing mean squared error...\n",
      "Iteration 48\n",
      "Train on 7212 samples, validate on 1524 samples\n",
      "Epoch 1/150\n",
      "7212/7212 [==============================] - 1s 155us/step - loss: 1.0706 - regression_loss: 0.3948 - handedness_loss: 0.6741 - val_loss: 0.8925 - val_regression_loss: 0.2411 - val_handedness_loss: 0.6514\n",
      "Epoch 2/150\n",
      "7212/7212 [==============================] - 1s 112us/step - loss: 0.7983 - regression_loss: 0.1768 - handedness_loss: 0.6215 - val_loss: 0.7629 - val_regression_loss: 0.1696 - val_handedness_loss: 0.5930\n",
      "Epoch 3/150\n",
      "7212/7212 [==============================] - 1s 145us/step - loss: 0.6963 - regression_loss: 0.1483 - handedness_loss: 0.5476 - val_loss: 0.6835 - val_regression_loss: 0.1536 - val_handedness_loss: 0.5297\n",
      "Epoch 4/150\n",
      "7212/7212 [==============================] - 1s 136us/step - loss: 0.6388 - regression_loss: 0.1377 - handedness_loss: 0.5016 - val_loss: 0.6435 - val_regression_loss: 0.1497 - val_handedness_loss: 0.4941\n",
      "Epoch 5/150\n",
      "7212/7212 [==============================] - 1s 148us/step - loss: 0.5951 - regression_loss: 0.1345 - handedness_loss: 0.4607 - val_loss: 0.5775 - val_regression_loss: 0.1417 - val_handedness_loss: 0.4357\n",
      "Epoch 6/150\n",
      "7212/7212 [==============================] - 1s 129us/step - loss: 0.5418 - regression_loss: 0.1245 - handedness_loss: 0.4170 - val_loss: 0.5355 - val_regression_loss: 0.1286 - val_handedness_loss: 0.4068\n",
      "Epoch 7/150\n",
      "7212/7212 [==============================] - 1s 135us/step - loss: 0.5224 - regression_loss: 0.1181 - handedness_loss: 0.4046 - val_loss: 0.5269 - val_regression_loss: 0.1209 - val_handedness_loss: 0.4059\n",
      "Epoch 8/150\n",
      "7212/7212 [==============================] - 1s 137us/step - loss: 0.4987 - regression_loss: 0.1114 - handedness_loss: 0.3873 - val_loss: 0.4931 - val_regression_loss: 0.1150 - val_handedness_loss: 0.3777\n",
      "Epoch 9/150\n",
      "7212/7212 [==============================] - 1s 148us/step - loss: 0.4772 - regression_loss: 0.1018 - handedness_loss: 0.3754 - val_loss: 0.4803 - val_regression_loss: 0.1043 - val_handedness_loss: 0.3756\n",
      "Epoch 10/150\n",
      "7212/7212 [==============================] - 1s 149us/step - loss: 0.4630 - regression_loss: 0.0946 - handedness_loss: 0.3695 - val_loss: 0.4823 - val_regression_loss: 0.1014 - val_handedness_loss: 0.3806\n",
      "Epoch 11/150\n",
      "7212/7212 [==============================] - 1s 141us/step - loss: 0.4484 - regression_loss: 0.0910 - handedness_loss: 0.3576 - val_loss: 0.4502 - val_regression_loss: 0.0947 - val_handedness_loss: 0.3548\n",
      "Epoch 12/150\n",
      "7212/7212 [==============================] - 1s 140us/step - loss: 0.4375 - regression_loss: 0.0863 - handedness_loss: 0.3512 - val_loss: 0.4737 - val_regression_loss: 0.0921 - val_handedness_loss: 0.3815\n",
      "Epoch 13/150\n",
      "7212/7212 [==============================] - 1s 136us/step - loss: 0.4282 - regression_loss: 0.0829 - handedness_loss: 0.3439 - val_loss: 0.4268 - val_regression_loss: 0.0881 - val_handedness_loss: 0.3381\n",
      "Epoch 14/150\n",
      "7212/7212 [==============================] - 1s 125us/step - loss: 0.4223 - regression_loss: 0.0806 - handedness_loss: 0.3415 - val_loss: 0.4246 - val_regression_loss: 0.0858 - val_handedness_loss: 0.3383\n",
      "Epoch 15/150\n",
      "7212/7212 [==============================] - 1s 129us/step - loss: 0.4178 - regression_loss: 0.0802 - handedness_loss: 0.3376 - val_loss: 0.4317 - val_regression_loss: 0.0847 - val_handedness_loss: 0.3466\n",
      "Epoch 16/150\n",
      "7212/7212 [==============================] - 1s 123us/step - loss: 0.4268 - regression_loss: 0.0790 - handedness_loss: 0.3472 - val_loss: 0.4300 - val_regression_loss: 0.0835 - val_handedness_loss: 0.3466\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 17/150\n",
      "7212/7212 [==============================] - 1s 143us/step - loss: 0.4173 - regression_loss: 0.0784 - handedness_loss: 0.3383 - val_loss: 0.4316 - val_regression_loss: 0.0819 - val_handedness_loss: 0.3495\n",
      "Evaluating model with testing data...\n",
      "1524/1524 [==============================] - 0s 16us/step\n",
      "Getting distribution of predictions and covariance matrix...\n",
      "      1 of 20\n",
      "      2 of 20\n",
      "      3 of 20\n",
      "      4 of 20\n",
      "      5 of 20\n",
      "      6 of 20\n",
      "      7 of 20\n",
      "      8 of 20\n",
      "      9 of 20\n",
      "      10 of 20\n",
      "      11 of 20\n",
      "      12 of 20\n",
      "      13 of 20\n",
      "      14 of 20\n",
      "      15 of 20\n",
      "      16 of 20\n",
      "      17 of 20\n",
      "      18 of 20\n",
      "      19 of 20\n",
      "      20 of 20\n",
      "Computing ensemble means...\n",
      "Computing mean squared error...\n",
      "Iteration 49\n",
      "Train on 7352 samples, validate on 1554 samples\n",
      "Epoch 1/150\n",
      "7352/7352 [==============================] - 1s 151us/step - loss: 0.9381 - regression_loss: 0.2680 - handedness_loss: 0.6684 - val_loss: 0.7662 - val_regression_loss: 0.1467 - val_handedness_loss: 0.6194\n",
      "Epoch 2/150\n",
      "7352/7352 [==============================] - 1s 131us/step - loss: 0.6928 - regression_loss: 0.1293 - handedness_loss: 0.5627 - val_loss: 0.6494 - val_regression_loss: 0.1305 - val_handedness_loss: 0.5154\n",
      "Epoch 3/150\n",
      "7352/7352 [==============================] - 1s 126us/step - loss: 0.5927 - regression_loss: 0.1231 - handedness_loss: 0.4691 - val_loss: 0.5830 - val_regression_loss: 0.1298 - val_handedness_loss: 0.4534\n",
      "Epoch 4/150\n",
      "7352/7352 [==============================] - 1s 142us/step - loss: 0.5307 - regression_loss: 0.1198 - handedness_loss: 0.4103 - val_loss: 0.5140 - val_regression_loss: 0.1278 - val_handedness_loss: 0.3827\n",
      "Epoch 5/150\n",
      "7352/7352 [==============================] - 1s 126us/step - loss: 0.4682 - regression_loss: 0.1152 - handedness_loss: 0.3521 - val_loss: 0.4639 - val_regression_loss: 0.1229 - val_handedness_loss: 0.3418\n",
      "Epoch 6/150\n",
      "7352/7352 [==============================] - 1s 143us/step - loss: 0.4347 - regression_loss: 0.1099 - handedness_loss: 0.3247 - val_loss: 0.4298 - val_regression_loss: 0.1097 - val_handedness_loss: 0.3008\n",
      "Epoch 7/150\n",
      "7352/7352 [==============================] - 1s 146us/step - loss: 0.4065 - regression_loss: 0.1016 - handedness_loss: 0.3046 - val_loss: 0.4222 - val_regression_loss: 0.1037 - val_handedness_loss: 0.3036\n",
      "Epoch 8/150\n",
      "7352/7352 [==============================] - 1s 142us/step - loss: 0.3844 - regression_loss: 0.0944 - handedness_loss: 0.2899 - val_loss: 0.4081 - val_regression_loss: 0.1031 - val_handedness_loss: 0.3036\n",
      "Epoch 9/150\n",
      "7352/7352 [==============================] - 1s 146us/step - loss: 0.3651 - regression_loss: 0.0903 - handedness_loss: 0.2742 - val_loss: 0.3709 - val_regression_loss: 0.0933 - val_handedness_loss: 0.2764\n",
      "Epoch 10/150\n",
      "7352/7352 [==============================] - 1s 148us/step - loss: 0.3485 - regression_loss: 0.0849 - handedness_loss: 0.2638 - val_loss: 0.3524 - val_regression_loss: 0.0888 - val_handedness_loss: 0.2633\n",
      "Epoch 11/150\n",
      "7352/7352 [==============================] - 1s 125us/step - loss: 0.3562 - regression_loss: 0.0838 - handedness_loss: 0.2722 - val_loss: 0.3552 - val_regression_loss: 0.0905 - val_handedness_loss: 0.2618\n",
      "Epoch 12/150\n",
      "7352/7352 [==============================] - 1s 143us/step - loss: 0.3319 - regression_loss: 0.0802 - handedness_loss: 0.2520 - val_loss: 0.3326 - val_regression_loss: 0.0834 - val_handedness_loss: 0.2433\n",
      "Epoch 13/150\n",
      "7352/7352 [==============================] - 1s 145us/step - loss: 0.3216 - regression_loss: 0.0783 - handedness_loss: 0.2430 - val_loss: 0.3287 - val_regression_loss: 0.0808 - val_handedness_loss: 0.2376\n",
      "Epoch 14/150\n",
      "7352/7352 [==============================] - 1s 147us/step - loss: 0.3141 - regression_loss: 0.0763 - handedness_loss: 0.2372 - val_loss: 0.3021 - val_regression_loss: 0.0785 - val_handedness_loss: 0.2103\n",
      "Epoch 15/150\n",
      "7352/7352 [==============================] - 1s 148us/step - loss: 0.3151 - regression_loss: 0.0754 - handedness_loss: 0.2391 - val_loss: 0.3127 - val_regression_loss: 0.0787 - val_handedness_loss: 0.2368\n",
      "Epoch 16/150\n",
      "7352/7352 [==============================] - 1s 149us/step - loss: 0.3107 - regression_loss: 0.0743 - handedness_loss: 0.2371 - val_loss: 0.3321 - val_regression_loss: 0.0779 - val_handedness_loss: 0.2520\n",
      "Epoch 17/150\n",
      "7352/7352 [==============================] - 1s 148us/step - loss: 0.3038 - regression_loss: 0.0738 - handedness_loss: 0.2294 - val_loss: 0.2928 - val_regression_loss: 0.0761 - val_handedness_loss: 0.2108\n",
      "Epoch 18/150\n",
      "7352/7352 [==============================] - 1s 149us/step - loss: 0.3019 - regression_loss: 0.0736 - handedness_loss: 0.2295 - val_loss: 0.3060 - val_regression_loss: 0.0758 - val_handedness_loss: 0.2232\n",
      "Evaluating model with testing data...\n",
      "1554/1554 [==============================] - 0s 17us/step\n",
      "Getting distribution of predictions and covariance matrix...\n",
      "      1 of 20\n",
      "      2 of 20\n",
      "      3 of 20\n",
      "      4 of 20\n",
      "      5 of 20\n",
      "      6 of 20\n",
      "      7 of 20\n",
      "      8 of 20\n",
      "      9 of 20\n",
      "      10 of 20\n",
      "      11 of 20\n",
      "      12 of 20\n",
      "      13 of 20\n",
      "      14 of 20\n",
      "      15 of 20\n",
      "      16 of 20\n",
      "      17 of 20\n",
      "      18 of 20\n",
      "      19 of 20\n",
      "      20 of 20\n",
      "Computing ensemble means...\n",
      "Computing mean squared error...\n",
      "Iteration 50\n",
      "Train on 7492 samples, validate on 1584 samples\n",
      "Epoch 1/150\n",
      "7492/7492 [==============================] - 1s 141us/step - loss: 1.0997 - regression_loss: 0.4236 - handedness_loss: 0.6747 - val_loss: 0.9650 - val_regression_loss: 0.3063 - val_handedness_loss: 0.6580\n",
      "Epoch 2/150\n",
      "7492/7492 [==============================] - 1s 130us/step - loss: 0.8832 - regression_loss: 0.2568 - handedness_loss: 0.6259 - val_loss: 0.8661 - val_regression_loss: 0.2499 - val_handedness_loss: 0.6137\n",
      "Epoch 3/150\n",
      "7492/7492 [==============================] - 1s 146us/step - loss: 0.7970 - regression_loss: 0.2133 - handedness_loss: 0.5833 - val_loss: 0.7948 - val_regression_loss: 0.2135 - val_handedness_loss: 0.5774\n",
      "Epoch 4/150\n",
      "7492/7492 [==============================] - 1s 146us/step - loss: 0.7251 - regression_loss: 0.1821 - handedness_loss: 0.5434 - val_loss: 0.7348 - val_regression_loss: 0.1824 - val_handedness_loss: 0.5486\n",
      "Epoch 5/150\n",
      "7492/7492 [==============================] - 1s 144us/step - loss: 0.6789 - regression_loss: 0.1583 - handedness_loss: 0.5204 - val_loss: 0.6920 - val_regression_loss: 0.1634 - val_handedness_loss: 0.5300\n",
      "Epoch 6/150\n",
      "7492/7492 [==============================] - 1s 128us/step - loss: 0.6239 - regression_loss: 0.1348 - handedness_loss: 0.4891 - val_loss: 0.6056 - val_regression_loss: 0.1356 - val_handedness_loss: 0.4707\n",
      "Epoch 7/150\n",
      "7492/7492 [==============================] - 1s 73us/step - loss: 0.5749 - regression_loss: 0.1196 - handedness_loss: 0.4545 - val_loss: 0.5826 - val_regression_loss: 0.1261 - val_handedness_loss: 0.4613\n",
      "Epoch 8/150\n",
      "7492/7492 [==============================] - 1s 95us/step - loss: 0.5434 - regression_loss: 0.1103 - handedness_loss: 0.4332 - val_loss: 0.5560 - val_regression_loss: 0.1159 - val_handedness_loss: 0.4440\n",
      "Epoch 9/150\n",
      "7492/7492 [==============================] - 1s 138us/step - loss: 0.5318 - regression_loss: 0.1033 - handedness_loss: 0.4286 - val_loss: 0.5471 - val_regression_loss: 0.1085 - val_handedness_loss: 0.4416\n",
      "Epoch 10/150\n",
      "7492/7492 [==============================] - 1s 145us/step - loss: 0.5220 - regression_loss: 0.0969 - handedness_loss: 0.4250 - val_loss: 0.5289 - val_regression_loss: 0.1016 - val_handedness_loss: 0.4326\n",
      "Epoch 11/150\n",
      "7492/7492 [==============================] - 1s 143us/step - loss: 0.5033 - regression_loss: 0.0919 - handedness_loss: 0.4111 - val_loss: 0.5318 - val_regression_loss: 0.0971 - val_handedness_loss: 0.4325\n",
      "Epoch 12/150\n",
      "7492/7492 [==============================] - 1s 125us/step - loss: 0.5000 - regression_loss: 0.0888 - handedness_loss: 0.4111 - val_loss: 0.5204 - val_regression_loss: 0.0952 - val_handedness_loss: 0.4261\n",
      "Epoch 13/150\n",
      "7492/7492 [==============================] - 1s 72us/step - loss: 0.4945 - regression_loss: 0.0854 - handedness_loss: 0.4096 - val_loss: 0.4917 - val_regression_loss: 0.0909 - val_handedness_loss: 0.4023\n",
      "Epoch 14/150\n",
      "7492/7492 [==============================] - 1s 70us/step - loss: 0.4844 - regression_loss: 0.0836 - handedness_loss: 0.4009 - val_loss: 0.4993 - val_regression_loss: 0.0882 - val_handedness_loss: 0.4097\n",
      "Epoch 15/150\n",
      "7492/7492 [==============================] - 1s 134us/step - loss: 0.4836 - regression_loss: 0.0819 - handedness_loss: 0.4015 - val_loss: 0.4776 - val_regression_loss: 0.0872 - val_handedness_loss: 0.3904\n",
      "Epoch 16/150\n",
      "7492/7492 [==============================] - 1s 145us/step - loss: 0.4781 - regression_loss: 0.0806 - handedness_loss: 0.3984 - val_loss: 0.4778 - val_regression_loss: 0.0852 - val_handedness_loss: 0.3918\n",
      "Epoch 17/150\n",
      "7492/7492 [==============================] - 1s 144us/step - loss: 0.4719 - regression_loss: 0.0800 - handedness_loss: 0.3918 - val_loss: 0.5005 - val_regression_loss: 0.0850 - val_handedness_loss: 0.4235\n",
      "Epoch 18/150\n",
      "7492/7492 [==============================] - 1s 148us/step - loss: 0.4715 - regression_loss: 0.0791 - handedness_loss: 0.3929 - val_loss: 0.4938 - val_regression_loss: 0.0837 - val_handedness_loss: 0.4097\n",
      "Epoch 19/150\n",
      "7492/7492 [==============================] - 1s 148us/step - loss: 0.4803 - regression_loss: 0.0788 - handedness_loss: 0.4015 - val_loss: 0.4830 - val_regression_loss: 0.0831 - val_handedness_loss: 0.3984\n",
      "Evaluating model with testing data...\n",
      "1584/1584 [==============================] - 0s 18us/step\n",
      "Getting distribution of predictions and covariance matrix...\n",
      "      1 of 20\n",
      "      2 of 20\n",
      "      3 of 20\n",
      "      4 of 20\n",
      "      5 of 20\n",
      "      6 of 20\n",
      "      7 of 20\n",
      "      8 of 20\n",
      "      9 of 20\n",
      "      10 of 20\n",
      "      11 of 20\n",
      "      12 of 20\n",
      "      13 of 20\n",
      "      14 of 20\n",
      "      15 of 20\n",
      "      16 of 20\n",
      "      17 of 20\n",
      "      18 of 20\n",
      "      19 of 20\n",
      "      20 of 20\n",
      "Computing ensemble means...\n",
      "Computing mean squared error...\n",
      "Iteration 51\n",
      "Train on 7632 samples, validate on 1614 samples\n",
      "Epoch 1/150\n",
      "7632/7632 [==============================] - 1s 146us/step - loss: 0.8124 - regression_loss: 0.1828 - handedness_loss: 0.6290 - val_loss: 0.6839 - val_regression_loss: 0.1279 - val_handedness_loss: 0.5553\n",
      "Epoch 2/150\n",
      "7632/7632 [==============================] - 1s 134us/step - loss: 0.5734 - regression_loss: 0.1301 - handedness_loss: 0.4428 - val_loss: 0.5021 - val_regression_loss: 0.1304 - val_handedness_loss: 0.3702\n",
      "Epoch 3/150\n",
      "7632/7632 [==============================] - 1s 141us/step - loss: 0.4052 - regression_loss: 0.1139 - handedness_loss: 0.2911 - val_loss: 0.3742 - val_regression_loss: 0.1035 - val_handedness_loss: 0.2688\n",
      "Epoch 4/150\n",
      "7632/7632 [==============================] - 1s 143us/step - loss: 0.3235 - regression_loss: 0.0964 - handedness_loss: 0.2268 - val_loss: 0.3232 - val_regression_loss: 0.0993 - val_handedness_loss: 0.2213\n",
      "Epoch 5/150\n",
      "7632/7632 [==============================] - 1s 142us/step - loss: 0.2899 - regression_loss: 0.0929 - handedness_loss: 0.1965 - val_loss: 0.2998 - val_regression_loss: 0.0872 - val_handedness_loss: 0.2113\n",
      "Epoch 6/150\n",
      "7632/7632 [==============================] - 1s 147us/step - loss: 0.2649 - regression_loss: 0.0865 - handedness_loss: 0.1784 - val_loss: 0.2768 - val_regression_loss: 0.0883 - val_handedness_loss: 0.1860\n",
      "Epoch 7/150\n",
      "7632/7632 [==============================] - 1s 148us/step - loss: 0.2475 - regression_loss: 0.0819 - handedness_loss: 0.1656 - val_loss: 0.2493 - val_regression_loss: 0.0847 - val_handedness_loss: 0.1648\n",
      "Epoch 8/150\n",
      "7632/7632 [==============================] - 1s 148us/step - loss: 0.2323 - regression_loss: 0.0773 - handedness_loss: 0.1548 - val_loss: 0.2087 - val_regression_loss: 0.0770 - val_handedness_loss: 0.1297\n",
      "Epoch 9/150\n",
      "7632/7632 [==============================] - 1s 147us/step - loss: 0.2185 - regression_loss: 0.0749 - handedness_loss: 0.1439 - val_loss: 0.2147 - val_regression_loss: 0.0741 - val_handedness_loss: 0.1388\n",
      "Epoch 10/150\n",
      "7632/7632 [==============================] - 1s 147us/step - loss: 0.2082 - regression_loss: 0.0692 - handedness_loss: 0.1388 - val_loss: 0.2179 - val_regression_loss: 0.0695 - val_handedness_loss: 0.1467\n",
      "Epoch 11/150\n",
      "7632/7632 [==============================] - 1s 147us/step - loss: 0.1976 - regression_loss: 0.0662 - handedness_loss: 0.1317 - val_loss: 0.2000 - val_regression_loss: 0.0680 - val_handedness_loss: 0.1300\n",
      "Epoch 12/150\n",
      "7632/7632 [==============================] - 1s 148us/step - loss: 0.1989 - regression_loss: 0.0649 - handedness_loss: 0.1341 - val_loss: 0.2077 - val_regression_loss: 0.0677 - val_handedness_loss: 0.1399\n",
      "Evaluating model with testing data...\n",
      "1614/1614 [==============================] - 0s 17us/step\n",
      "Getting distribution of predictions and covariance matrix...\n",
      "      1 of 20\n",
      "      2 of 20\n",
      "      3 of 20\n",
      "      4 of 20\n",
      "      5 of 20\n",
      "      6 of 20\n",
      "      7 of 20\n",
      "      8 of 20\n",
      "      9 of 20\n",
      "      10 of 20\n",
      "      11 of 20\n",
      "      12 of 20\n",
      "      13 of 20\n",
      "      14 of 20\n",
      "      15 of 20\n",
      "      16 of 20\n",
      "      17 of 20\n",
      "      18 of 20\n",
      "      19 of 20\n",
      "      20 of 20\n",
      "Computing ensemble means...\n",
      "Computing mean squared error...\n",
      "Iteration 52\n",
      "Train on 7772 samples, validate on 1644 samples\n",
      "Epoch 1/150\n",
      "7772/7772 [==============================] - 1s 146us/step - loss: 1.1007 - regression_loss: 0.4271 - handedness_loss: 0.6724 - val_loss: 0.8981 - val_regression_loss: 0.2660 - val_handedness_loss: 0.6318\n",
      "Epoch 2/150\n",
      "7772/7772 [==============================] - 1s 126us/step - loss: 0.7907 - regression_loss: 0.2090 - handedness_loss: 0.5817 - val_loss: 0.7298 - val_regression_loss: 0.1848 - val_handedness_loss: 0.5445\n",
      "Epoch 3/150\n",
      "7772/7772 [==============================] - 1s 139us/step - loss: 0.6671 - regression_loss: 0.1543 - handedness_loss: 0.5129 - val_loss: 0.6404 - val_regression_loss: 0.1513 - val_handedness_loss: 0.4891\n",
      "Epoch 4/150\n",
      "7772/7772 [==============================] - 1s 146us/step - loss: 0.5991 - regression_loss: 0.1331 - handedness_loss: 0.4661 - val_loss: 0.6088 - val_regression_loss: 0.1356 - val_handedness_loss: 0.4737\n",
      "Epoch 5/150\n",
      "7772/7772 [==============================] - 1s 147us/step - loss: 0.5691 - regression_loss: 0.1234 - handedness_loss: 0.4458 - val_loss: 0.5707 - val_regression_loss: 0.1305 - val_handedness_loss: 0.4406\n",
      "Epoch 6/150\n",
      "7772/7772 [==============================] - 1s 149us/step - loss: 0.5464 - regression_loss: 0.1168 - handedness_loss: 0.4296 - val_loss: 0.5542 - val_regression_loss: 0.1198 - val_handedness_loss: 0.4346\n",
      "Epoch 7/150\n",
      "7772/7772 [==============================] - 1s 138us/step - loss: 0.5218 - regression_loss: 0.1111 - handedness_loss: 0.4105 - val_loss: 0.5389 - val_regression_loss: 0.1196 - val_handedness_loss: 0.4192\n",
      "Epoch 8/150\n",
      "7772/7772 [==============================] - 1s 145us/step - loss: 0.5054 - regression_loss: 0.1087 - handedness_loss: 0.3967 - val_loss: 0.5024 - val_regression_loss: 0.1120 - val_handedness_loss: 0.3902\n",
      "Epoch 9/150\n",
      "7772/7772 [==============================] - 1s 129us/step - loss: 0.4826 - regression_loss: 0.1022 - handedness_loss: 0.3802 - val_loss: 0.4945 - val_regression_loss: 0.1101 - val_handedness_loss: 0.3848\n",
      "Epoch 10/150\n",
      "7772/7772 [==============================] - 1s 139us/step - loss: 0.4615 - regression_loss: 0.0963 - handedness_loss: 0.3653 - val_loss: 0.4625 - val_regression_loss: 0.1008 - val_handedness_loss: 0.3621\n",
      "Epoch 11/150\n",
      "7772/7772 [==============================] - 1s 143us/step - loss: 0.4494 - regression_loss: 0.0910 - handedness_loss: 0.3581 - val_loss: 0.4484 - val_regression_loss: 0.0951 - val_handedness_loss: 0.3535\n",
      "Epoch 12/150\n",
      "7772/7772 [==============================] - 1s 138us/step - loss: 0.4388 - regression_loss: 0.0871 - handedness_loss: 0.3519 - val_loss: 0.4553 - val_regression_loss: 0.0915 - val_handedness_loss: 0.3642\n",
      "Epoch 13/150\n",
      "7772/7772 [==============================] - 1s 143us/step - loss: 0.4422 - regression_loss: 0.0840 - handedness_loss: 0.3582 - val_loss: 0.4451 - val_regression_loss: 0.0886 - val_handedness_loss: 0.3566\n",
      "Epoch 14/150\n",
      "7772/7772 [==============================] - 1s 130us/step - loss: 0.4192 - regression_loss: 0.0811 - handedness_loss: 0.3379 - val_loss: 0.4314 - val_regression_loss: 0.0851 - val_handedness_loss: 0.3468\n",
      "Epoch 15/150\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7772/7772 [==============================] - 1s 138us/step - loss: 0.4179 - regression_loss: 0.0801 - handedness_loss: 0.3379 - val_loss: 0.4369 - val_regression_loss: 0.0836 - val_handedness_loss: 0.3540\n",
      "Epoch 16/150\n",
      "7772/7772 [==============================] - 1s 147us/step - loss: 0.4211 - regression_loss: 0.0789 - handedness_loss: 0.3422 - val_loss: 0.4127 - val_regression_loss: 0.0814 - val_handedness_loss: 0.3309\n",
      "Epoch 17/150\n",
      "7772/7772 [==============================] - 1s 147us/step - loss: 0.4115 - regression_loss: 0.0779 - handedness_loss: 0.3336 - val_loss: 0.4198 - val_regression_loss: 0.0809 - val_handedness_loss: 0.3393\n",
      "Epoch 18/150\n",
      "7772/7772 [==============================] - 1s 148us/step - loss: 0.4110 - regression_loss: 0.0778 - handedness_loss: 0.3329 - val_loss: 0.4387 - val_regression_loss: 0.0810 - val_handedness_loss: 0.3578\n",
      "Epoch 19/150\n",
      "7772/7772 [==============================] - 1s 148us/step - loss: 0.4165 - regression_loss: 0.0776 - handedness_loss: 0.3388 - val_loss: 0.4254 - val_regression_loss: 0.0798 - val_handedness_loss: 0.3459\n",
      "Epoch 20/150\n",
      "7772/7772 [==============================] - 1s 148us/step - loss: 0.4026 - regression_loss: 0.0766 - handedness_loss: 0.3259 - val_loss: 0.4118 - val_regression_loss: 0.0785 - val_handedness_loss: 0.3333\n",
      "Evaluating model with testing data...\n",
      "1644/1644 [==============================] - 0s 17us/step\n",
      "Getting distribution of predictions and covariance matrix...\n",
      "      1 of 20\n",
      "      2 of 20\n",
      "      3 of 20\n",
      "      4 of 20\n",
      "      5 of 20\n",
      "      6 of 20\n",
      "      7 of 20\n",
      "      8 of 20\n",
      "      9 of 20\n",
      "      10 of 20\n",
      "      11 of 20\n",
      "      12 of 20\n",
      "      13 of 20\n",
      "      14 of 20\n",
      "      15 of 20\n",
      "      16 of 20\n",
      "      17 of 20\n",
      "      18 of 20\n",
      "      19 of 20\n",
      "      20 of 20\n",
      "Computing ensemble means...\n",
      "Computing mean squared error...\n",
      "Iteration 53\n",
      "Train on 7912 samples, validate on 1674 samples\n",
      "Epoch 1/150\n",
      "7912/7912 [==============================] - 1s 150us/step - loss: 1.1690 - regression_loss: 0.4764 - handedness_loss: 0.6920 - val_loss: 0.9644 - val_regression_loss: 0.2952 - val_handedness_loss: 0.6576\n",
      "Epoch 2/150\n",
      "7912/7912 [==============================] - 1s 110us/step - loss: 0.9061 - regression_loss: 0.2557 - handedness_loss: 0.6502 - val_loss: 0.8639 - val_regression_loss: 0.2346 - val_handedness_loss: 0.6280\n",
      "Epoch 3/150\n",
      "7912/7912 [==============================] - 1s 108us/step - loss: 0.8377 - regression_loss: 0.2089 - handedness_loss: 0.6288 - val_loss: 0.8173 - val_regression_loss: 0.1997 - val_handedness_loss: 0.6168\n",
      "Epoch 4/150\n",
      "7912/7912 [==============================] - 1s 85us/step - loss: 0.7806 - regression_loss: 0.1780 - handedness_loss: 0.6025 - val_loss: 0.7533 - val_regression_loss: 0.1707 - val_handedness_loss: 0.5819\n",
      "Epoch 5/150\n",
      "7912/7912 [==============================] - 1s 114us/step - loss: 0.7430 - regression_loss: 0.1562 - handedness_loss: 0.5868 - val_loss: 0.7139 - val_regression_loss: 0.1494 - val_handedness_loss: 0.5713\n",
      "Epoch 6/150\n",
      "7912/7912 [==============================] - 1s 144us/step - loss: 0.7068 - regression_loss: 0.1373 - handedness_loss: 0.5695 - val_loss: 0.6817 - val_regression_loss: 0.1330 - val_handedness_loss: 0.5513\n",
      "Epoch 7/150\n",
      "7912/7912 [==============================] - 1s 145us/step - loss: 0.6848 - regression_loss: 0.1230 - handedness_loss: 0.5618 - val_loss: 0.6653 - val_regression_loss: 0.1194 - val_handedness_loss: 0.5495\n",
      "Epoch 8/150\n",
      "7912/7912 [==============================] - 1s 148us/step - loss: 0.6725 - regression_loss: 0.1121 - handedness_loss: 0.5603 - val_loss: 0.6544 - val_regression_loss: 0.1120 - val_handedness_loss: 0.5532\n",
      "Epoch 9/150\n",
      "7912/7912 [==============================] - 1s 148us/step - loss: 0.6539 - regression_loss: 0.1037 - handedness_loss: 0.5504 - val_loss: 0.6481 - val_regression_loss: 0.1024 - val_handedness_loss: 0.5500\n",
      "Epoch 10/150\n",
      "7912/7912 [==============================] - 1s 148us/step - loss: 0.6396 - regression_loss: 0.0968 - handedness_loss: 0.5428 - val_loss: 0.6521 - val_regression_loss: 0.0966 - val_handedness_loss: 0.5598\n",
      "Epoch 11/150\n",
      "7912/7912 [==============================] - 1s 149us/step - loss: 0.6362 - regression_loss: 0.0923 - handedness_loss: 0.5438 - val_loss: 0.6289 - val_regression_loss: 0.0930 - val_handedness_loss: 0.5429\n",
      "Epoch 12/150\n",
      "7912/7912 [==============================] - 1s 131us/step - loss: 0.6106 - regression_loss: 0.0886 - handedness_loss: 0.5219 - val_loss: 0.6086 - val_regression_loss: 0.0890 - val_handedness_loss: 0.5223\n",
      "Epoch 13/150\n",
      "7912/7912 [==============================] - 1s 70us/step - loss: 0.5834 - regression_loss: 0.0875 - handedness_loss: 0.4958 - val_loss: 0.5670 - val_regression_loss: 0.0878 - val_handedness_loss: 0.4893\n",
      "Epoch 14/150\n",
      "7912/7912 [==============================] - 1s 130us/step - loss: 0.5307 - regression_loss: 0.0838 - handedness_loss: 0.4468 - val_loss: 0.4935 - val_regression_loss: 0.0823 - val_handedness_loss: 0.4146\n",
      "Epoch 15/150\n",
      "7912/7912 [==============================] - 1s 145us/step - loss: 0.4925 - regression_loss: 0.0786 - handedness_loss: 0.4140 - val_loss: 0.5003 - val_regression_loss: 0.0812 - val_handedness_loss: 0.4234\n",
      "Epoch 16/150\n",
      "7912/7912 [==============================] - 1s 89us/step - loss: 0.4709 - regression_loss: 0.0789 - handedness_loss: 0.3918 - val_loss: 0.4575 - val_regression_loss: 0.0801 - val_handedness_loss: 0.3874\n",
      "Epoch 17/150\n",
      "7912/7912 [==============================] - 1s 95us/step - loss: 0.4690 - regression_loss: 0.0784 - handedness_loss: 0.3905 - val_loss: 0.4538 - val_regression_loss: 0.0801 - val_handedness_loss: 0.3786\n",
      "Epoch 18/150\n",
      "7912/7912 [==============================] - 1s 124us/step - loss: 0.4596 - regression_loss: 0.0773 - handedness_loss: 0.3825 - val_loss: 0.4424 - val_regression_loss: 0.0792 - val_handedness_loss: 0.3805\n",
      "Epoch 19/150\n",
      "7912/7912 [==============================] - 1s 107us/step - loss: 0.4436 - regression_loss: 0.0781 - handedness_loss: 0.3653 - val_loss: 0.4920 - val_regression_loss: 0.0800 - val_handedness_loss: 0.4072\n",
      "Epoch 20/150\n",
      "7912/7912 [==============================] - 1s 104us/step - loss: 0.4496 - regression_loss: 0.0780 - handedness_loss: 0.3715 - val_loss: 0.4438 - val_regression_loss: 0.0794 - val_handedness_loss: 0.3777\n",
      "Epoch 21/150\n",
      "7912/7912 [==============================] - 1s 92us/step - loss: 0.4437 - regression_loss: 0.0784 - handedness_loss: 0.3651 - val_loss: 0.4416 - val_regression_loss: 0.0797 - val_handedness_loss: 0.3584\n",
      "Epoch 22/150\n",
      "7912/7912 [==============================] - 1s 101us/step - loss: 0.4243 - regression_loss: 0.0778 - handedness_loss: 0.3465 - val_loss: 0.4641 - val_regression_loss: 0.0787 - val_handedness_loss: 0.3814\n",
      "Epoch 23/150\n",
      "7912/7912 [==============================] - 1s 104us/step - loss: 0.4374 - regression_loss: 0.0781 - handedness_loss: 0.3596 - val_loss: 0.4200 - val_regression_loss: 0.0797 - val_handedness_loss: 0.3386\n",
      "Epoch 24/150\n",
      "7912/7912 [==============================] - 1s 108us/step - loss: 0.4238 - regression_loss: 0.0781 - handedness_loss: 0.3456 - val_loss: 0.4470 - val_regression_loss: 0.0794 - val_handedness_loss: 0.3766\n",
      "Epoch 25/150\n",
      "7912/7912 [==============================] - 1s 93us/step - loss: 0.4319 - regression_loss: 0.0779 - handedness_loss: 0.3539 - val_loss: 0.4379 - val_regression_loss: 0.0783 - val_handedness_loss: 0.3552\n",
      "Epoch 26/150\n",
      "7912/7912 [==============================] - 1s 98us/step - loss: 0.4280 - regression_loss: 0.0778 - handedness_loss: 0.3501 - val_loss: 0.4230 - val_regression_loss: 0.0784 - val_handedness_loss: 0.3582\n",
      "Epoch 27/150\n",
      "7912/7912 [==============================] - 1s 102us/step - loss: 0.3926 - regression_loss: 0.0771 - handedness_loss: 0.3155 - val_loss: 0.3957 - val_regression_loss: 0.0782 - val_handedness_loss: 0.3280\n",
      "Epoch 28/150\n",
      "7912/7912 [==============================] - 1s 115us/step - loss: 0.3832 - regression_loss: 0.0767 - handedness_loss: 0.3063 - val_loss: 0.3577 - val_regression_loss: 0.0764 - val_handedness_loss: 0.2862\n",
      "Epoch 29/150\n",
      "7912/7912 [==============================] - 1s 117us/step - loss: 0.3758 - regression_loss: 0.0762 - handedness_loss: 0.2997 - val_loss: 0.3853 - val_regression_loss: 0.0778 - val_handedness_loss: 0.3146\n",
      "Epoch 30/150\n",
      "7912/7912 [==============================] - 1s 130us/step - loss: 0.3756 - regression_loss: 0.0763 - handedness_loss: 0.2994 - val_loss: 0.3763 - val_regression_loss: 0.0780 - val_handedness_loss: 0.3052\n",
      "Epoch 31/150\n",
      "7912/7912 [==============================] - 1s 144us/step - loss: 0.3749 - regression_loss: 0.0767 - handedness_loss: 0.2981 - val_loss: 0.3788 - val_regression_loss: 0.0764 - val_handedness_loss: 0.3069\n",
      "Epoch 32/150\n",
      "7912/7912 [==============================] - 1s 146us/step - loss: 0.3689 - regression_loss: 0.0764 - handedness_loss: 0.2923 - val_loss: 0.3802 - val_regression_loss: 0.0777 - val_handedness_loss: 0.3073\n",
      "Evaluating model with testing data...\n",
      "1674/1674 [==============================] - 0s 19us/step\n",
      "Getting distribution of predictions and covariance matrix...\n",
      "      1 of 20\n",
      "      2 of 20\n",
      "      3 of 20\n",
      "      4 of 20\n",
      "      5 of 20\n",
      "      6 of 20\n",
      "      7 of 20\n",
      "      8 of 20\n",
      "      9 of 20\n",
      "      10 of 20\n",
      "      11 of 20\n",
      "      12 of 20\n",
      "      13 of 20\n",
      "      14 of 20\n",
      "      15 of 20\n",
      "      16 of 20\n",
      "      17 of 20\n",
      "      18 of 20\n",
      "      19 of 20\n",
      "      20 of 20\n",
      "Computing ensemble means...\n",
      "Computing mean squared error...\n",
      "Iteration 54\n",
      "Train on 8052 samples, validate on 1704 samples\n",
      "Epoch 1/150\n",
      "8052/8052 [==============================] - 1s 124us/step - loss: 0.9824 - regression_loss: 0.3483 - handedness_loss: 0.6339 - val_loss: 0.8079 - val_regression_loss: 0.2212 - val_handedness_loss: 0.5859\n",
      "Epoch 2/150\n",
      "8052/8052 [==============================] - 1s 120us/step - loss: 0.6976 - regression_loss: 0.1786 - handedness_loss: 0.5189 - val_loss: 0.6455 - val_regression_loss: 0.1624 - val_handedness_loss: 0.4848\n",
      "Epoch 3/150\n",
      "8052/8052 [==============================] - 1s 116us/step - loss: 0.5688 - regression_loss: 0.1450 - handedness_loss: 0.4238 - val_loss: 0.5199 - val_regression_loss: 0.1384 - val_handedness_loss: 0.3805\n",
      "Epoch 4/150\n",
      "8052/8052 [==============================] - 1s 101us/step - loss: 0.4816 - regression_loss: 0.1234 - handedness_loss: 0.3581 - val_loss: 0.4604 - val_regression_loss: 0.1230 - val_handedness_loss: 0.3381\n",
      "Epoch 5/150\n",
      "8052/8052 [==============================] - 1s 117us/step - loss: 0.4389 - regression_loss: 0.1128 - handedness_loss: 0.3261 - val_loss: 0.4493 - val_regression_loss: 0.1157 - val_handedness_loss: 0.3360\n",
      "Epoch 6/150\n",
      "8052/8052 [==============================] - 1s 132us/step - loss: 0.4144 - regression_loss: 0.1066 - handedness_loss: 0.3078 - val_loss: 0.4086 - val_regression_loss: 0.1105 - val_handedness_loss: 0.2954\n",
      "Epoch 7/150\n",
      "8052/8052 [==============================] - 1s 145us/step - loss: 0.3942 - regression_loss: 0.1008 - handedness_loss: 0.2934 - val_loss: 0.3836 - val_regression_loss: 0.1038 - val_handedness_loss: 0.2796\n",
      "Epoch 8/150\n",
      "8052/8052 [==============================] - 1s 147us/step - loss: 0.3692 - regression_loss: 0.0960 - handedness_loss: 0.2732 - val_loss: 0.3686 - val_regression_loss: 0.0969 - val_handedness_loss: 0.2726\n",
      "Epoch 9/150\n",
      "8052/8052 [==============================] - 1s 130us/step - loss: 0.3611 - regression_loss: 0.0921 - handedness_loss: 0.2691 - val_loss: 0.3425 - val_regression_loss: 0.0920 - val_handedness_loss: 0.2551\n",
      "Epoch 10/150\n",
      "8052/8052 [==============================] - 1s 121us/step - loss: 0.3489 - regression_loss: 0.0866 - handedness_loss: 0.2623 - val_loss: 0.3523 - val_regression_loss: 0.0881 - val_handedness_loss: 0.2642\n",
      "Epoch 11/150\n",
      "8052/8052 [==============================] - 1s 128us/step - loss: 0.3315 - regression_loss: 0.0831 - handedness_loss: 0.2484 - val_loss: 0.3257 - val_regression_loss: 0.0853 - val_handedness_loss: 0.2404\n",
      "Epoch 12/150\n",
      "8052/8052 [==============================] - 1s 145us/step - loss: 0.3273 - regression_loss: 0.0790 - handedness_loss: 0.2483 - val_loss: 0.3218 - val_regression_loss: 0.0807 - val_handedness_loss: 0.2435\n",
      "Epoch 13/150\n",
      "8052/8052 [==============================] - 1s 146us/step - loss: 0.3177 - regression_loss: 0.0765 - handedness_loss: 0.2412 - val_loss: 0.3400 - val_regression_loss: 0.0789 - val_handedness_loss: 0.2638\n",
      "Epoch 14/150\n",
      "8052/8052 [==============================] - 1s 133us/step - loss: 0.3129 - regression_loss: 0.0751 - handedness_loss: 0.2378 - val_loss: 0.3075 - val_regression_loss: 0.0774 - val_handedness_loss: 0.2334\n",
      "Epoch 15/150\n",
      "8052/8052 [==============================] - 1s 135us/step - loss: 0.3175 - regression_loss: 0.0736 - handedness_loss: 0.2439 - val_loss: 0.3031 - val_regression_loss: 0.0749 - val_handedness_loss: 0.2285\n",
      "Epoch 16/150\n",
      "8052/8052 [==============================] - 1s 110us/step - loss: 0.3072 - regression_loss: 0.0727 - handedness_loss: 0.2345 - val_loss: 0.2943 - val_regression_loss: 0.0740 - val_handedness_loss: 0.2246\n",
      "Epoch 17/150\n",
      "8052/8052 [==============================] - 1s 134us/step - loss: 0.2987 - regression_loss: 0.0719 - handedness_loss: 0.2267 - val_loss: 0.3112 - val_regression_loss: 0.0745 - val_handedness_loss: 0.2378\n",
      "Epoch 18/150\n",
      "8052/8052 [==============================] - 1s 128us/step - loss: 0.2996 - regression_loss: 0.0714 - handedness_loss: 0.2282 - val_loss: 0.3055 - val_regression_loss: 0.0739 - val_handedness_loss: 0.2308\n",
      "Epoch 19/150\n",
      "8052/8052 [==============================] - 1s 117us/step - loss: 0.2989 - regression_loss: 0.0719 - handedness_loss: 0.2270 - val_loss: 0.3053 - val_regression_loss: 0.0734 - val_handedness_loss: 0.2317\n",
      "Epoch 20/150\n",
      "8052/8052 [==============================] - 1s 101us/step - loss: 0.2952 - regression_loss: 0.0717 - handedness_loss: 0.2234 - val_loss: 0.2857 - val_regression_loss: 0.0731 - val_handedness_loss: 0.2117\n",
      "Epoch 21/150\n",
      "8052/8052 [==============================] - 1s 121us/step - loss: 0.3003 - regression_loss: 0.0714 - handedness_loss: 0.2289 - val_loss: 0.2874 - val_regression_loss: 0.0729 - val_handedness_loss: 0.2162\n",
      "Epoch 22/150\n",
      "8052/8052 [==============================] - 1s 145us/step - loss: 0.2914 - regression_loss: 0.0714 - handedness_loss: 0.2201 - val_loss: 0.3057 - val_regression_loss: 0.0756 - val_handedness_loss: 0.2323\n",
      "Epoch 23/150\n",
      "8052/8052 [==============================] - 1s 135us/step - loss: 0.2869 - regression_loss: 0.0710 - handedness_loss: 0.2159 - val_loss: 0.2833 - val_regression_loss: 0.0727 - val_handedness_loss: 0.2132\n",
      "Epoch 24/150\n",
      "8052/8052 [==============================] - 1s 128us/step - loss: 0.2840 - regression_loss: 0.0708 - handedness_loss: 0.2131 - val_loss: 0.2725 - val_regression_loss: 0.0715 - val_handedness_loss: 0.1983\n",
      "Epoch 25/150\n",
      "8052/8052 [==============================] - 1s 145us/step - loss: 0.2783 - regression_loss: 0.0709 - handedness_loss: 0.2072 - val_loss: 0.2721 - val_regression_loss: 0.0734 - val_handedness_loss: 0.1990\n",
      "Epoch 26/150\n",
      "8052/8052 [==============================] - 1s 147us/step - loss: 0.2797 - regression_loss: 0.0705 - handedness_loss: 0.2092 - val_loss: 0.2664 - val_regression_loss: 0.0717 - val_handedness_loss: 0.1970\n",
      "Epoch 27/150\n",
      "8052/8052 [==============================] - 1s 150us/step - loss: 0.2641 - regression_loss: 0.0710 - handedness_loss: 0.1931 - val_loss: 0.2579 - val_regression_loss: 0.0727 - val_handedness_loss: 0.1868\n",
      "Epoch 28/150\n",
      "8052/8052 [==============================] - 1s 130us/step - loss: 0.2638 - regression_loss: 0.0709 - handedness_loss: 0.1929 - val_loss: 0.2508 - val_regression_loss: 0.0729 - val_handedness_loss: 0.1778\n",
      "Evaluating model with testing data...\n",
      "1704/1704 [==============================] - 0s 15us/step\n",
      "Getting distribution of predictions and covariance matrix...\n",
      "      1 of 20\n",
      "      2 of 20\n",
      "      3 of 20\n",
      "      4 of 20\n",
      "      5 of 20\n",
      "      6 of 20\n",
      "      7 of 20\n",
      "      8 of 20\n",
      "      9 of 20\n",
      "      10 of 20\n",
      "      11 of 20\n",
      "      12 of 20\n",
      "      13 of 20\n",
      "      14 of 20\n",
      "      15 of 20\n",
      "      16 of 20\n",
      "      17 of 20\n",
      "      18 of 20\n",
      "      19 of 20\n",
      "      20 of 20\n",
      "Computing ensemble means...\n",
      "Computing mean squared error...\n",
      "Iteration 55\n",
      "Train on 8192 samples, validate on 1734 samples\n",
      "Epoch 1/150\n",
      "8192/8192 [==============================] - 1s 124us/step - loss: 1.0530 - regression_loss: 0.3692 - handedness_loss: 0.6839 - val_loss: 0.9184 - val_regression_loss: 0.2471 - val_handedness_loss: 0.6707\n",
      "Epoch 2/150\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8192/8192 [==============================] - 1s 126us/step - loss: 0.8447 - regression_loss: 0.2016 - handedness_loss: 0.6431 - val_loss: 0.8129 - val_regression_loss: 0.1848 - val_handedness_loss: 0.6275\n",
      "Epoch 3/150\n",
      "8192/8192 [==============================] - 1s 143us/step - loss: 0.7398 - regression_loss: 0.1605 - handedness_loss: 0.5793 - val_loss: 0.7104 - val_regression_loss: 0.1626 - val_handedness_loss: 0.5463\n",
      "Epoch 4/150\n",
      "8192/8192 [==============================] - 1s 144us/step - loss: 0.6327 - regression_loss: 0.1484 - handedness_loss: 0.4843 - val_loss: 0.6086 - val_regression_loss: 0.1512 - val_handedness_loss: 0.4591\n",
      "Epoch 5/150\n",
      "8192/8192 [==============================] - 1s 145us/step - loss: 0.5429 - regression_loss: 0.1337 - handedness_loss: 0.4092 - val_loss: 0.5355 - val_regression_loss: 0.1315 - val_handedness_loss: 0.4065\n",
      "Epoch 6/150\n",
      "8192/8192 [==============================] - 1s 147us/step - loss: 0.5001 - regression_loss: 0.1225 - handedness_loss: 0.3776 - val_loss: 0.4993 - val_regression_loss: 0.1248 - val_handedness_loss: 0.3757\n",
      "Epoch 7/150\n",
      "8192/8192 [==============================] - 1s 147us/step - loss: 0.4602 - regression_loss: 0.1118 - handedness_loss: 0.3483 - val_loss: 0.4585 - val_regression_loss: 0.1152 - val_handedness_loss: 0.3432\n",
      "Epoch 8/150\n",
      "8192/8192 [==============================] - 1s 147us/step - loss: 0.4405 - regression_loss: 0.1030 - handedness_loss: 0.3374 - val_loss: 0.4457 - val_regression_loss: 0.1037 - val_handedness_loss: 0.3424\n",
      "Epoch 9/150\n",
      "8192/8192 [==============================] - 1s 131us/step - loss: 0.4246 - regression_loss: 0.0964 - handedness_loss: 0.3282 - val_loss: 0.4081 - val_regression_loss: 0.0978 - val_handedness_loss: 0.3137\n",
      "Epoch 10/150\n",
      "8192/8192 [==============================] - 1s 65us/step - loss: 0.4102 - regression_loss: 0.0902 - handedness_loss: 0.3200 - val_loss: 0.4141 - val_regression_loss: 0.0936 - val_handedness_loss: 0.3208\n",
      "Epoch 11/150\n",
      "8192/8192 [==============================] - 1s 91us/step - loss: 0.3980 - regression_loss: 0.0856 - handedness_loss: 0.3124 - val_loss: 0.4055 - val_regression_loss: 0.0882 - val_handedness_loss: 0.3195\n",
      "Epoch 12/150\n",
      "8192/8192 [==============================] - 1s 127us/step - loss: 0.4000 - regression_loss: 0.0825 - handedness_loss: 0.3175 - val_loss: 0.4069 - val_regression_loss: 0.0858 - val_handedness_loss: 0.3281\n",
      "Epoch 13/150\n",
      "8192/8192 [==============================] - 1s 129us/step - loss: 0.3925 - regression_loss: 0.0801 - handedness_loss: 0.3124 - val_loss: 0.4155 - val_regression_loss: 0.0841 - val_handedness_loss: 0.3327\n",
      "Evaluating model with testing data...\n",
      "1734/1734 [==============================] - 0s 16us/step\n",
      "Getting distribution of predictions and covariance matrix...\n",
      "      1 of 20\n",
      "      2 of 20\n",
      "      3 of 20\n",
      "      4 of 20\n",
      "      5 of 20\n",
      "      6 of 20\n",
      "      7 of 20\n",
      "      8 of 20\n",
      "      9 of 20\n",
      "      10 of 20\n",
      "      11 of 20\n",
      "      12 of 20\n",
      "      13 of 20\n",
      "      14 of 20\n",
      "      15 of 20\n",
      "      16 of 20\n",
      "      17 of 20\n",
      "      18 of 20\n",
      "      19 of 20\n",
      "      20 of 20\n",
      "Computing ensemble means...\n",
      "Computing mean squared error...\n",
      "Iteration 56\n",
      "Train on 8332 samples, validate on 1764 samples\n",
      "Epoch 1/150\n",
      "8332/8332 [==============================] - 1s 153us/step - loss: 1.0316 - regression_loss: 0.3776 - handedness_loss: 0.6504 - val_loss: 0.8774 - val_regression_loss: 0.2657 - val_handedness_loss: 0.6119\n",
      "Epoch 2/150\n",
      "8332/8332 [==============================] - 1s 135us/step - loss: 0.7636 - regression_loss: 0.2136 - handedness_loss: 0.5479 - val_loss: 0.7045 - val_regression_loss: 0.1918 - val_handedness_loss: 0.5126\n",
      "Epoch 3/150\n",
      "8332/8332 [==============================] - 1s 143us/step - loss: 0.6163 - regression_loss: 0.1652 - handedness_loss: 0.4525 - val_loss: 0.5754 - val_regression_loss: 0.1490 - val_handedness_loss: 0.4263\n",
      "Epoch 4/150\n",
      "8332/8332 [==============================] - 1s 136us/step - loss: 0.5118 - regression_loss: 0.1344 - handedness_loss: 0.3790 - val_loss: 0.4846 - val_regression_loss: 0.1351 - val_handedness_loss: 0.3499\n",
      "Epoch 5/150\n",
      "8332/8332 [==============================] - 1s 141us/step - loss: 0.4618 - regression_loss: 0.1219 - handedness_loss: 0.3409 - val_loss: 0.4615 - val_regression_loss: 0.1244 - val_handedness_loss: 0.3377\n",
      "Epoch 6/150\n",
      "8332/8332 [==============================] - 1s 146us/step - loss: 0.4327 - regression_loss: 0.1134 - handedness_loss: 0.3171 - val_loss: 0.4000 - val_regression_loss: 0.1129 - val_handedness_loss: 0.2877\n",
      "Epoch 7/150\n",
      "8332/8332 [==============================] - 1s 134us/step - loss: 0.3870 - regression_loss: 0.1026 - handedness_loss: 0.2857 - val_loss: 0.3834 - val_regression_loss: 0.1031 - val_handedness_loss: 0.2806\n",
      "Epoch 8/150\n",
      "8332/8332 [==============================] - 1s 145us/step - loss: 0.3779 - regression_loss: 0.0961 - handedness_loss: 0.2794 - val_loss: 0.3741 - val_regression_loss: 0.1001 - val_handedness_loss: 0.2748\n",
      "Epoch 9/150\n",
      "8332/8332 [==============================] - 1s 145us/step - loss: 0.3598 - regression_loss: 0.0900 - handedness_loss: 0.2663 - val_loss: 0.3687 - val_regression_loss: 0.0946 - val_handedness_loss: 0.2750\n",
      "Epoch 10/150\n",
      "8332/8332 [==============================] - 1s 122us/step - loss: 0.3453 - regression_loss: 0.0865 - handedness_loss: 0.2579 - val_loss: 0.3387 - val_regression_loss: 0.0858 - val_handedness_loss: 0.2533\n",
      "Epoch 11/150\n",
      "8332/8332 [==============================] - 1s 130us/step - loss: 0.3414 - regression_loss: 0.0813 - handedness_loss: 0.2595 - val_loss: 0.3433 - val_regression_loss: 0.0836 - val_handedness_loss: 0.2602\n",
      "Epoch 12/150\n",
      "8332/8332 [==============================] - 1s 128us/step - loss: 0.3343 - regression_loss: 0.0791 - handedness_loss: 0.2562 - val_loss: 0.3320 - val_regression_loss: 0.0792 - val_handedness_loss: 0.2537\n",
      "Epoch 13/150\n",
      "8332/8332 [==============================] - 1s 135us/step - loss: 0.3373 - regression_loss: 0.0768 - handedness_loss: 0.2604 - val_loss: 0.3126 - val_regression_loss: 0.0801 - val_handedness_loss: 0.2322\n",
      "Epoch 14/150\n",
      "8332/8332 [==============================] - 1s 112us/step - loss: 0.3144 - regression_loss: 0.0753 - handedness_loss: 0.2369 - val_loss: 0.3289 - val_regression_loss: 0.0786 - val_handedness_loss: 0.2509\n",
      "Epoch 15/150\n",
      "8332/8332 [==============================] - 1s 144us/step - loss: 0.3153 - regression_loss: 0.0741 - handedness_loss: 0.2423 - val_loss: 0.3191 - val_regression_loss: 0.0776 - val_handedness_loss: 0.2423\n",
      "Epoch 16/150\n",
      "8332/8332 [==============================] - 1s 145us/step - loss: 0.3063 - regression_loss: 0.0738 - handedness_loss: 0.2355 - val_loss: 0.3075 - val_regression_loss: 0.0755 - val_handedness_loss: 0.2324\n",
      "Epoch 17/150\n",
      "8332/8332 [==============================] - 1s 146us/step - loss: 0.3124 - regression_loss: 0.0723 - handedness_loss: 0.2393 - val_loss: 0.3169 - val_regression_loss: 0.0742 - val_handedness_loss: 0.2440\n",
      "Evaluating model with testing data...\n",
      "1764/1764 [==============================] - 0s 18us/step\n",
      "Getting distribution of predictions and covariance matrix...\n",
      "      1 of 20\n",
      "      2 of 20\n",
      "      3 of 20\n",
      "      4 of 20\n",
      "      5 of 20\n",
      "      6 of 20\n",
      "      7 of 20\n",
      "      8 of 20\n",
      "      9 of 20\n",
      "      10 of 20\n",
      "      11 of 20\n",
      "      12 of 20\n",
      "      13 of 20\n",
      "      14 of 20\n",
      "      15 of 20\n",
      "      16 of 20\n",
      "      17 of 20\n",
      "      18 of 20\n",
      "      19 of 20\n",
      "      20 of 20\n",
      "Computing ensemble means...\n",
      "Computing mean squared error...\n",
      "Iteration 57\n",
      "Train on 8472 samples, validate on 1794 samples\n",
      "Epoch 1/150\n",
      "8472/8472 [==============================] - 1s 132us/step - loss: 1.0806 - regression_loss: 0.4008 - handedness_loss: 0.6777 - val_loss: 0.9063 - val_regression_loss: 0.2413 - val_handedness_loss: 0.6603\n",
      "Epoch 2/150\n",
      "8472/8472 [==============================] - 1s 138us/step - loss: 0.8291 - regression_loss: 0.1923 - handedness_loss: 0.6367 - val_loss: 0.7933 - val_regression_loss: 0.1637 - val_handedness_loss: 0.6328\n",
      "Epoch 3/150\n",
      "8472/8472 [==============================] - 1s 136us/step - loss: 0.7429 - regression_loss: 0.1516 - handedness_loss: 0.5913 - val_loss: 0.7123 - val_regression_loss: 0.1392 - val_handedness_loss: 0.5626\n",
      "Epoch 4/150\n",
      "8472/8472 [==============================] - 1s 126us/step - loss: 0.6694 - regression_loss: 0.1324 - handedness_loss: 0.5375 - val_loss: 0.6617 - val_regression_loss: 0.1291 - val_handedness_loss: 0.5414\n",
      "Epoch 5/150\n",
      "8472/8472 [==============================] - 1s 145us/step - loss: 0.6227 - regression_loss: 0.1243 - handedness_loss: 0.4978 - val_loss: 0.5977 - val_regression_loss: 0.1201 - val_handedness_loss: 0.4705\n",
      "Epoch 6/150\n",
      "8472/8472 [==============================] - 1s 132us/step - loss: 0.5716 - regression_loss: 0.1141 - handedness_loss: 0.4572 - val_loss: 0.5676 - val_regression_loss: 0.1148 - val_handedness_loss: 0.4367\n",
      "Epoch 7/150\n",
      "8472/8472 [==============================] - 1s 135us/step - loss: 0.5389 - regression_loss: 0.1076 - handedness_loss: 0.4300 - val_loss: 0.5289 - val_regression_loss: 0.1129 - val_handedness_loss: 0.4110\n",
      "Epoch 8/150\n",
      "8472/8472 [==============================] - 1s 136us/step - loss: 0.5013 - regression_loss: 0.1033 - handedness_loss: 0.3961 - val_loss: 0.5166 - val_regression_loss: 0.1074 - val_handedness_loss: 0.3910\n",
      "Epoch 9/150\n",
      "8472/8472 [==============================] - 1s 146us/step - loss: 0.4742 - regression_loss: 0.0977 - handedness_loss: 0.3746 - val_loss: 0.4807 - val_regression_loss: 0.0976 - val_handedness_loss: 0.3644\n",
      "Epoch 10/150\n",
      "8472/8472 [==============================] - 1s 146us/step - loss: 0.4668 - regression_loss: 0.0915 - handedness_loss: 0.3737 - val_loss: 0.4567 - val_regression_loss: 0.0918 - val_handedness_loss: 0.3449\n",
      "Epoch 11/150\n",
      "8472/8472 [==============================] - 1s 144us/step - loss: 0.4442 - regression_loss: 0.0859 - handedness_loss: 0.3580 - val_loss: 0.4644 - val_regression_loss: 0.0896 - val_handedness_loss: 0.3705\n",
      "Epoch 12/150\n",
      "8472/8472 [==============================] - 1s 136us/step - loss: 0.4441 - regression_loss: 0.0835 - handedness_loss: 0.3597 - val_loss: 0.4409 - val_regression_loss: 0.0861 - val_handedness_loss: 0.3520\n",
      "Epoch 13/150\n",
      "8472/8472 [==============================] - 1s 131us/step - loss: 0.4319 - regression_loss: 0.0810 - handedness_loss: 0.3498 - val_loss: 0.4321 - val_regression_loss: 0.0832 - val_handedness_loss: 0.3578\n",
      "Epoch 14/150\n",
      "8472/8472 [==============================] - 1s 135us/step - loss: 0.4295 - regression_loss: 0.0792 - handedness_loss: 0.3507 - val_loss: 0.4451 - val_regression_loss: 0.0837 - val_handedness_loss: 0.3855\n",
      "Evaluating model with testing data...\n",
      "1794/1794 [==============================] - 0s 16us/step\n",
      "Getting distribution of predictions and covariance matrix...\n",
      "      1 of 20\n",
      "      2 of 20\n",
      "      3 of 20\n",
      "      4 of 20\n",
      "      5 of 20\n",
      "      6 of 20\n",
      "      7 of 20\n",
      "      8 of 20\n",
      "      9 of 20\n",
      "      10 of 20\n",
      "      11 of 20\n",
      "      12 of 20\n",
      "      13 of 20\n",
      "      14 of 20\n",
      "      15 of 20\n",
      "      16 of 20\n",
      "      17 of 20\n",
      "      18 of 20\n",
      "      19 of 20\n",
      "      20 of 20\n",
      "Computing ensemble means...\n",
      "Computing mean squared error...\n",
      "Iteration 58\n",
      "Train on 8612 samples, validate on 1824 samples\n",
      "Epoch 1/150\n",
      "8612/8612 [==============================] - 1s 139us/step - loss: 1.1062 - regression_loss: 0.4384 - handedness_loss: 0.6656 - val_loss: 0.9336 - val_regression_loss: 0.2859 - val_handedness_loss: 0.6450\n",
      "Epoch 2/150\n",
      "8612/8612 [==============================] - 1s 123us/step - loss: 0.8683 - regression_loss: 0.2498 - handedness_loss: 0.6190 - val_loss: 0.8151 - val_regression_loss: 0.2255 - val_handedness_loss: 0.5886\n",
      "Epoch 3/150\n",
      "8612/8612 [==============================] - 1s 137us/step - loss: 0.7717 - regression_loss: 0.2003 - handedness_loss: 0.5704 - val_loss: 0.7545 - val_regression_loss: 0.1918 - val_handedness_loss: 0.5637\n",
      "Epoch 4/150\n",
      "8612/8612 [==============================] - 1s 145us/step - loss: 0.7006 - regression_loss: 0.1709 - handedness_loss: 0.5297 - val_loss: 0.6881 - val_regression_loss: 0.1665 - val_handedness_loss: 0.5167\n",
      "Epoch 5/150\n",
      "8612/8612 [==============================] - 1s 127us/step - loss: 0.6585 - regression_loss: 0.1497 - handedness_loss: 0.5080 - val_loss: 0.6588 - val_regression_loss: 0.1472 - val_handedness_loss: 0.5106\n",
      "Epoch 6/150\n",
      "8612/8612 [==============================] - 1s 140us/step - loss: 0.6190 - regression_loss: 0.1317 - handedness_loss: 0.4872 - val_loss: 0.6251 - val_regression_loss: 0.1283 - val_handedness_loss: 0.4994\n",
      "Epoch 7/150\n",
      "8612/8612 [==============================] - 1s 145us/step - loss: 0.6009 - regression_loss: 0.1172 - handedness_loss: 0.4825 - val_loss: 0.6014 - val_regression_loss: 0.1165 - val_handedness_loss: 0.4841\n",
      "Epoch 8/150\n",
      "8612/8612 [==============================] - 1s 127us/step - loss: 0.5866 - regression_loss: 0.1076 - handedness_loss: 0.4789 - val_loss: 0.5785 - val_regression_loss: 0.1058 - val_handedness_loss: 0.4688\n",
      "Epoch 9/150\n",
      "8612/8612 [==============================] - 1s 130us/step - loss: 0.5720 - regression_loss: 0.0999 - handedness_loss: 0.4724 - val_loss: 0.5822 - val_regression_loss: 0.0998 - val_handedness_loss: 0.4824\n",
      "Epoch 10/150\n",
      "8612/8612 [==============================] - 1s 124us/step - loss: 0.5635 - regression_loss: 0.0939 - handedness_loss: 0.4693 - val_loss: 0.5649 - val_regression_loss: 0.0948 - val_handedness_loss: 0.4685\n",
      "Epoch 11/150\n",
      "8612/8612 [==============================] - 1s 131us/step - loss: 0.5526 - regression_loss: 0.0893 - handedness_loss: 0.4633 - val_loss: 0.5557 - val_regression_loss: 0.0909 - val_handedness_loss: 0.4611\n",
      "Epoch 12/150\n",
      "8612/8612 [==============================] - 1s 146us/step - loss: 0.5439 - regression_loss: 0.0868 - handedness_loss: 0.4590 - val_loss: 0.5655 - val_regression_loss: 0.0888 - val_handedness_loss: 0.4728\n",
      "Epoch 13/150\n",
      "8612/8612 [==============================] - 1s 143us/step - loss: 0.5469 - regression_loss: 0.0847 - handedness_loss: 0.4621 - val_loss: 0.5398 - val_regression_loss: 0.0868 - val_handedness_loss: 0.4519\n",
      "Epoch 14/150\n",
      "8612/8612 [==============================] - 1s 126us/step - loss: 0.5360 - regression_loss: 0.0834 - handedness_loss: 0.4522 - val_loss: 0.5522 - val_regression_loss: 0.0859 - val_handedness_loss: 0.4710\n",
      "Epoch 15/150\n",
      "8612/8612 [==============================] - 1s 146us/step - loss: 0.5393 - regression_loss: 0.0826 - handedness_loss: 0.4557 - val_loss: 0.5417 - val_regression_loss: 0.0846 - val_handedness_loss: 0.4603\n",
      "Epoch 16/150\n",
      "8612/8612 [==============================] - 1s 138us/step - loss: 0.5363 - regression_loss: 0.0822 - handedness_loss: 0.4551 - val_loss: 0.5394 - val_regression_loss: 0.0843 - val_handedness_loss: 0.4587\n",
      "Epoch 17/150\n",
      "8612/8612 [==============================] - 1s 114us/step - loss: 0.5368 - regression_loss: 0.0825 - handedness_loss: 0.4552 - val_loss: 0.5511 - val_regression_loss: 0.0851 - val_handedness_loss: 0.4712\n",
      "Evaluating model with testing data...\n",
      "1824/1824 [==============================] - 0s 16us/step\n",
      "Getting distribution of predictions and covariance matrix...\n",
      "      1 of 20\n",
      "      2 of 20\n",
      "      3 of 20\n",
      "      4 of 20\n",
      "      5 of 20\n",
      "      6 of 20\n",
      "      7 of 20\n",
      "      8 of 20\n",
      "      9 of 20\n",
      "      10 of 20\n",
      "      11 of 20\n",
      "      12 of 20\n",
      "      13 of 20\n",
      "      14 of 20\n",
      "      15 of 20\n",
      "      16 of 20\n",
      "      17 of 20\n",
      "      18 of 20\n",
      "      19 of 20\n",
      "      20 of 20\n",
      "Computing ensemble means...\n",
      "Computing mean squared error...\n",
      "Iteration 59\n",
      "Train on 8752 samples, validate on 1854 samples\n",
      "Epoch 1/150\n",
      "8752/8752 [==============================] - 1s 139us/step - loss: 1.0222 - regression_loss: 0.3641 - handedness_loss: 0.6563 - val_loss: 0.8507 - val_regression_loss: 0.2471 - val_handedness_loss: 0.6024\n",
      "Epoch 2/150\n",
      "8752/8752 [==============================] - 1s 111us/step - loss: 0.7484 - regression_loss: 0.1956 - handedness_loss: 0.5518 - val_loss: 0.6778 - val_regression_loss: 0.1647 - val_handedness_loss: 0.5117\n",
      "Epoch 3/150\n",
      "8752/8752 [==============================] - 1s 122us/step - loss: 0.6109 - regression_loss: 0.1468 - handedness_loss: 0.4632 - val_loss: 0.5827 - val_regression_loss: 0.1410 - val_handedness_loss: 0.4412\n",
      "Epoch 4/150\n",
      "8752/8752 [==============================] - 1s 117us/step - loss: 0.5426 - regression_loss: 0.1303 - handedness_loss: 0.4125 - val_loss: 0.5305 - val_regression_loss: 0.1313 - val_handedness_loss: 0.3996\n",
      "Epoch 5/150\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8752/8752 [==============================] - 1s 139us/step - loss: 0.5059 - regression_loss: 0.1211 - handedness_loss: 0.3854 - val_loss: 0.4809 - val_regression_loss: 0.1160 - val_handedness_loss: 0.3653\n",
      "Epoch 6/150\n",
      "8752/8752 [==============================] - 1s 145us/step - loss: 0.4687 - regression_loss: 0.1110 - handedness_loss: 0.3575 - val_loss: 0.4608 - val_regression_loss: 0.1111 - val_handedness_loss: 0.3482\n",
      "Epoch 7/150\n",
      "8752/8752 [==============================] - 1s 146us/step - loss: 0.4391 - regression_loss: 0.1032 - handedness_loss: 0.3355 - val_loss: 0.4514 - val_regression_loss: 0.1047 - val_handedness_loss: 0.3462\n",
      "Epoch 8/150\n",
      "8752/8752 [==============================] - 1s 147us/step - loss: 0.4247 - regression_loss: 0.0978 - handedness_loss: 0.3271 - val_loss: 0.4222 - val_regression_loss: 0.0981 - val_handedness_loss: 0.3222\n",
      "Epoch 9/150\n",
      "8752/8752 [==============================] - 1s 131us/step - loss: 0.4218 - regression_loss: 0.0921 - handedness_loss: 0.3293 - val_loss: 0.4224 - val_regression_loss: 0.0918 - val_handedness_loss: 0.3293\n",
      "Epoch 10/150\n",
      "8752/8752 [==============================] - 1s 137us/step - loss: 0.4061 - regression_loss: 0.0862 - handedness_loss: 0.3196 - val_loss: 0.3837 - val_regression_loss: 0.0863 - val_handedness_loss: 0.2953\n",
      "Epoch 11/150\n",
      "8752/8752 [==============================] - 1s 145us/step - loss: 0.3949 - regression_loss: 0.0826 - handedness_loss: 0.3112 - val_loss: 0.4082 - val_regression_loss: 0.0842 - val_handedness_loss: 0.3247\n",
      "Epoch 12/150\n",
      "8752/8752 [==============================] - 1s 147us/step - loss: 0.3950 - regression_loss: 0.0804 - handedness_loss: 0.3136 - val_loss: 0.3849 - val_regression_loss: 0.0812 - val_handedness_loss: 0.3014\n",
      "Epoch 13/150\n",
      "8752/8752 [==============================] - 1s 148us/step - loss: 0.3843 - regression_loss: 0.0788 - handedness_loss: 0.3055 - val_loss: 0.3879 - val_regression_loss: 0.0795 - val_handedness_loss: 0.3091\n",
      "Epoch 14/150\n",
      "8752/8752 [==============================] - 1s 149us/step - loss: 0.3837 - regression_loss: 0.0777 - handedness_loss: 0.3057 - val_loss: 0.3641 - val_regression_loss: 0.0789 - val_handedness_loss: 0.2839\n",
      "Epoch 15/150\n",
      "8752/8752 [==============================] - 1s 149us/step - loss: 0.3822 - regression_loss: 0.0770 - handedness_loss: 0.3040 - val_loss: 0.3603 - val_regression_loss: 0.0783 - val_handedness_loss: 0.2804\n",
      "Epoch 16/150\n",
      "8752/8752 [==============================] - 1s 149us/step - loss: 0.3684 - regression_loss: 0.0761 - handedness_loss: 0.2921 - val_loss: 0.3730 - val_regression_loss: 0.0775 - val_handedness_loss: 0.2943\n",
      "Epoch 17/150\n",
      "8752/8752 [==============================] - 1s 149us/step - loss: 0.3701 - regression_loss: 0.0762 - handedness_loss: 0.2961 - val_loss: 0.3773 - val_regression_loss: 0.0777 - val_handedness_loss: 0.3003\n",
      "Epoch 18/150\n",
      "8752/8752 [==============================] - 1s 136us/step - loss: 0.3667 - regression_loss: 0.0762 - handedness_loss: 0.2911 - val_loss: 0.3810 - val_regression_loss: 0.0780 - val_handedness_loss: 0.2995\n",
      "Epoch 19/150\n",
      "8752/8752 [==============================] - 1s 138us/step - loss: 0.3781 - regression_loss: 0.0768 - handedness_loss: 0.3029 - val_loss: 0.3773 - val_regression_loss: 0.0792 - val_handedness_loss: 0.2976\n",
      "Evaluating model with testing data...\n",
      "1854/1854 [==============================] - 0s 18us/step\n",
      "Getting distribution of predictions and covariance matrix...\n",
      "      1 of 20\n",
      "      2 of 20\n",
      "      3 of 20\n",
      "      4 of 20\n",
      "      5 of 20\n",
      "      6 of 20\n",
      "      7 of 20\n",
      "      8 of 20\n",
      "      9 of 20\n",
      "      10 of 20\n",
      "      11 of 20\n",
      "      12 of 20\n",
      "      13 of 20\n",
      "      14 of 20\n",
      "      15 of 20\n",
      "      16 of 20\n",
      "      17 of 20\n",
      "      18 of 20\n",
      "      19 of 20\n",
      "      20 of 20\n",
      "Computing ensemble means...\n",
      "Computing mean squared error...\n",
      "Iteration 60\n",
      "Train on 8892 samples, validate on 1884 samples\n",
      "Epoch 1/150\n",
      "8892/8892 [==============================] - 1s 149us/step - loss: 1.1740 - regression_loss: 0.4988 - handedness_loss: 0.6726 - val_loss: 0.9194 - val_regression_loss: 0.2686 - val_handedness_loss: 0.6508\n",
      "Epoch 2/150\n",
      "8892/8892 [==============================] - 1s 135us/step - loss: 0.8484 - regression_loss: 0.2198 - handedness_loss: 0.6281 - val_loss: 0.8077 - val_regression_loss: 0.1985 - val_handedness_loss: 0.6092\n",
      "Epoch 3/150\n",
      "8892/8892 [==============================] - 1s 147us/step - loss: 0.7400 - regression_loss: 0.1726 - handedness_loss: 0.5667 - val_loss: 0.7078 - val_regression_loss: 0.1601 - val_handedness_loss: 0.5477\n",
      "Epoch 4/150\n",
      "8892/8892 [==============================] - 1s 148us/step - loss: 0.6525 - regression_loss: 0.1435 - handedness_loss: 0.5086 - val_loss: 0.6285 - val_regression_loss: 0.1341 - val_handedness_loss: 0.4949\n",
      "Epoch 5/150\n",
      "8892/8892 [==============================] - 1s 148us/step - loss: 0.5821 - regression_loss: 0.1211 - handedness_loss: 0.4613 - val_loss: 0.5637 - val_regression_loss: 0.1173 - val_handedness_loss: 0.4477\n",
      "Epoch 6/150\n",
      "8892/8892 [==============================] - 1s 149us/step - loss: 0.5525 - regression_loss: 0.1116 - handedness_loss: 0.4412 - val_loss: 0.5629 - val_regression_loss: 0.1120 - val_handedness_loss: 0.4517\n",
      "Epoch 7/150\n",
      "8892/8892 [==============================] - 1s 138us/step - loss: 0.5241 - regression_loss: 0.1049 - handedness_loss: 0.4183 - val_loss: 0.5102 - val_regression_loss: 0.1042 - val_handedness_loss: 0.4069\n",
      "Epoch 8/150\n",
      "8892/8892 [==============================] - 1s 130us/step - loss: 0.5125 - regression_loss: 0.1000 - handedness_loss: 0.4129 - val_loss: 0.5114 - val_regression_loss: 0.1028 - val_handedness_loss: 0.4087\n",
      "Epoch 9/150\n",
      "8892/8892 [==============================] - 1s 139us/step - loss: 0.4931 - regression_loss: 0.0984 - handedness_loss: 0.3939 - val_loss: 0.4996 - val_regression_loss: 0.1015 - val_handedness_loss: 0.3980\n",
      "Epoch 10/150\n",
      "8892/8892 [==============================] - 1s 144us/step - loss: 0.4697 - regression_loss: 0.0952 - handedness_loss: 0.3742 - val_loss: 0.4779 - val_regression_loss: 0.0969 - val_handedness_loss: 0.3805\n",
      "Epoch 11/150\n",
      "8892/8892 [==============================] - 1s 119us/step - loss: 0.4436 - regression_loss: 0.0897 - handedness_loss: 0.3538 - val_loss: 0.4269 - val_regression_loss: 0.0887 - val_handedness_loss: 0.3380\n",
      "Epoch 12/150\n",
      "8892/8892 [==============================] - 1s 137us/step - loss: 0.4253 - regression_loss: 0.0853 - handedness_loss: 0.3399 - val_loss: 0.4114 - val_regression_loss: 0.0847 - val_handedness_loss: 0.3266\n",
      "Epoch 13/150\n",
      "8892/8892 [==============================] - 1s 144us/step - loss: 0.4128 - regression_loss: 0.0816 - handedness_loss: 0.3311 - val_loss: 0.4210 - val_regression_loss: 0.0835 - val_handedness_loss: 0.3407\n",
      "Epoch 14/150\n",
      "8892/8892 [==============================] - 1s 136us/step - loss: 0.4031 - regression_loss: 0.0797 - handedness_loss: 0.3233 - val_loss: 0.4053 - val_regression_loss: 0.0808 - val_handedness_loss: 0.3234\n",
      "Epoch 15/150\n",
      "8892/8892 [==============================] - 1s 126us/step - loss: 0.3963 - regression_loss: 0.0778 - handedness_loss: 0.3185 - val_loss: 0.4132 - val_regression_loss: 0.0787 - val_handedness_loss: 0.3342\n",
      "Epoch 16/150\n",
      "8892/8892 [==============================] - 1s 146us/step - loss: 0.3926 - regression_loss: 0.0771 - handedness_loss: 0.3156 - val_loss: 0.3890 - val_regression_loss: 0.0786 - val_handedness_loss: 0.3101\n",
      "Epoch 17/150\n",
      "8892/8892 [==============================] - 1s 147us/step - loss: 0.3903 - regression_loss: 0.0765 - handedness_loss: 0.3138 - val_loss: 0.3988 - val_regression_loss: 0.0769 - val_handedness_loss: 0.3211\n",
      "Epoch 18/150\n",
      "8892/8892 [==============================] - 1s 125us/step - loss: 0.3823 - regression_loss: 0.0757 - handedness_loss: 0.3067 - val_loss: 0.3819 - val_regression_loss: 0.0773 - val_handedness_loss: 0.3041\n",
      "Epoch 19/150\n",
      "8892/8892 [==============================] - 1s 128us/step - loss: 0.3898 - regression_loss: 0.0759 - handedness_loss: 0.3144 - val_loss: 0.3872 - val_regression_loss: 0.0768 - val_handedness_loss: 0.3105\n",
      "Epoch 20/150\n",
      "8892/8892 [==============================] - 1s 122us/step - loss: 0.3893 - regression_loss: 0.0750 - handedness_loss: 0.3143 - val_loss: 0.3746 - val_regression_loss: 0.0765 - val_handedness_loss: 0.2968\n",
      "Epoch 21/150\n",
      "8892/8892 [==============================] - 1s 119us/step - loss: 0.3728 - regression_loss: 0.0751 - handedness_loss: 0.2978 - val_loss: 0.3969 - val_regression_loss: 0.0765 - val_handedness_loss: 0.3184\n",
      "Epoch 22/150\n",
      "8892/8892 [==============================] - 1s 137us/step - loss: 0.3810 - regression_loss: 0.0755 - handedness_loss: 0.3056 - val_loss: 0.3755 - val_regression_loss: 0.0766 - val_handedness_loss: 0.2988\n",
      "Epoch 23/150\n",
      "8892/8892 [==============================] - 1s 143us/step - loss: 0.3732 - regression_loss: 0.0752 - handedness_loss: 0.2979 - val_loss: 0.3676 - val_regression_loss: 0.0770 - val_handedness_loss: 0.2896\n",
      "Epoch 24/150\n",
      "8892/8892 [==============================] - 1s 108us/step - loss: 0.3820 - regression_loss: 0.0757 - handedness_loss: 0.3059 - val_loss: 0.3805 - val_regression_loss: 0.0768 - val_handedness_loss: 0.3032\n",
      "Evaluating model with testing data...\n",
      "1884/1884 [==============================] - 0s 16us/step\n",
      "Getting distribution of predictions and covariance matrix...\n",
      "      1 of 20\n",
      "      2 of 20\n",
      "      3 of 20\n",
      "      4 of 20\n",
      "      5 of 20\n",
      "      6 of 20\n",
      "      7 of 20\n",
      "      8 of 20\n",
      "      9 of 20\n",
      "      10 of 20\n",
      "      11 of 20\n",
      "      12 of 20\n",
      "      13 of 20\n",
      "      14 of 20\n",
      "      15 of 20\n",
      "      16 of 20\n",
      "      17 of 20\n",
      "      18 of 20\n",
      "      19 of 20\n",
      "      20 of 20\n",
      "Computing ensemble means...\n",
      "Computing mean squared error...\n",
      "Iteration 61\n",
      "Train on 9032 samples, validate on 1914 samples\n",
      "Epoch 1/150\n",
      "9032/9032 [==============================] - 1s 142us/step - loss: 1.1418 - regression_loss: 0.4641 - handedness_loss: 0.6763 - val_loss: 0.9416 - val_regression_loss: 0.2887 - val_handedness_loss: 0.6529\n",
      "Epoch 2/150\n",
      "9032/9032 [==============================] - 1s 109us/step - loss: 0.8709 - regression_loss: 0.2441 - handedness_loss: 0.6267 - val_loss: 0.8204 - val_regression_loss: 0.2168 - val_handedness_loss: 0.6036\n",
      "Epoch 3/150\n",
      "9032/9032 [==============================] - 1s 146us/step - loss: 0.7479 - regression_loss: 0.1776 - handedness_loss: 0.5704 - val_loss: 0.6821 - val_regression_loss: 0.1538 - val_handedness_loss: 0.5284\n",
      "Epoch 4/150\n",
      "9032/9032 [==============================] - 1s 147us/step - loss: 0.6396 - regression_loss: 0.1414 - handedness_loss: 0.4983 - val_loss: 0.6223 - val_regression_loss: 0.1430 - val_handedness_loss: 0.4791\n",
      "Epoch 5/150\n",
      "9032/9032 [==============================] - 1s 147us/step - loss: 0.6036 - regression_loss: 0.1380 - handedness_loss: 0.4655 - val_loss: 0.5770 - val_regression_loss: 0.1337 - val_handedness_loss: 0.4433\n",
      "Epoch 6/150\n",
      "9032/9032 [==============================] - 1s 150us/step - loss: 0.5583 - regression_loss: 0.1224 - handedness_loss: 0.4356 - val_loss: 0.5544 - val_regression_loss: 0.1205 - val_handedness_loss: 0.4338\n",
      "Epoch 7/150\n",
      "9032/9032 [==============================] - 1s 150us/step - loss: 0.5454 - regression_loss: 0.1128 - handedness_loss: 0.4324 - val_loss: 0.5522 - val_regression_loss: 0.1115 - val_handedness_loss: 0.4408\n",
      "Epoch 8/150\n",
      "9032/9032 [==============================] - 1s 130us/step - loss: 0.5184 - regression_loss: 0.1023 - handedness_loss: 0.4159 - val_loss: 0.5325 - val_regression_loss: 0.1035 - val_handedness_loss: 0.4286\n",
      "Epoch 9/150\n",
      "9032/9032 [==============================] - 1s 139us/step - loss: 0.5093 - regression_loss: 0.0951 - handedness_loss: 0.4141 - val_loss: 0.5297 - val_regression_loss: 0.0955 - val_handedness_loss: 0.4341\n",
      "Epoch 10/150\n",
      "9032/9032 [==============================] - 1s 147us/step - loss: 0.4951 - regression_loss: 0.0900 - handedness_loss: 0.4049 - val_loss: 0.5145 - val_regression_loss: 0.0921 - val_handedness_loss: 0.4225\n",
      "Epoch 11/150\n",
      "9032/9032 [==============================] - 1s 145us/step - loss: 0.4929 - regression_loss: 0.0863 - handedness_loss: 0.4069 - val_loss: 0.4867 - val_regression_loss: 0.0871 - val_handedness_loss: 0.3996\n",
      "Epoch 12/150\n",
      "9032/9032 [==============================] - 1s 148us/step - loss: 0.4864 - regression_loss: 0.0833 - handedness_loss: 0.4028 - val_loss: 0.4917 - val_regression_loss: 0.0851 - val_handedness_loss: 0.4064\n",
      "Epoch 13/150\n",
      "9032/9032 [==============================] - 1s 149us/step - loss: 0.4827 - regression_loss: 0.0818 - handedness_loss: 0.4009 - val_loss: 0.4885 - val_regression_loss: 0.0820 - val_handedness_loss: 0.4066\n",
      "Epoch 14/150\n",
      "9032/9032 [==============================] - 1s 150us/step - loss: 0.4735 - regression_loss: 0.0805 - handedness_loss: 0.3932 - val_loss: 0.4857 - val_regression_loss: 0.0813 - val_handedness_loss: 0.4043\n",
      "Epoch 15/150\n",
      "9032/9032 [==============================] - 1s 137us/step - loss: 0.4661 - regression_loss: 0.0795 - handedness_loss: 0.3865 - val_loss: 0.4704 - val_regression_loss: 0.0801 - val_handedness_loss: 0.3904\n",
      "Epoch 16/150\n",
      "9032/9032 [==============================] - 1s 147us/step - loss: 0.4716 - regression_loss: 0.0790 - handedness_loss: 0.3925 - val_loss: 0.5023 - val_regression_loss: 0.0806 - val_handedness_loss: 0.4216\n",
      "Epoch 17/150\n",
      "9032/9032 [==============================] - 1s 148us/step - loss: 0.4654 - regression_loss: 0.0784 - handedness_loss: 0.3871 - val_loss: 0.4993 - val_regression_loss: 0.0798 - val_handedness_loss: 0.4195\n",
      "Epoch 18/150\n",
      "9032/9032 [==============================] - 1s 140us/step - loss: 0.4612 - regression_loss: 0.0784 - handedness_loss: 0.3829 - val_loss: 0.4768 - val_regression_loss: 0.0785 - val_handedness_loss: 0.3982\n",
      "Epoch 19/150\n",
      "9032/9032 [==============================] - 1s 150us/step - loss: 0.4664 - regression_loss: 0.0788 - handedness_loss: 0.3873 - val_loss: 0.4654 - val_regression_loss: 0.0799 - val_handedness_loss: 0.3856\n",
      "Epoch 20/150\n",
      "9032/9032 [==============================] - 1s 135us/step - loss: 0.4637 - regression_loss: 0.0782 - handedness_loss: 0.3862 - val_loss: 0.4713 - val_regression_loss: 0.0785 - val_handedness_loss: 0.3928\n",
      "Epoch 21/150\n",
      "9032/9032 [==============================] - 1s 137us/step - loss: 0.4606 - regression_loss: 0.0785 - handedness_loss: 0.3822 - val_loss: 0.4642 - val_regression_loss: 0.0788 - val_handedness_loss: 0.3852\n",
      "Epoch 22/150\n",
      "9032/9032 [==============================] - 1s 147us/step - loss: 0.4601 - regression_loss: 0.0785 - handedness_loss: 0.3816 - val_loss: 0.4640 - val_regression_loss: 0.0788 - val_handedness_loss: 0.3853\n",
      "Epoch 23/150\n",
      "9032/9032 [==============================] - 1s 137us/step - loss: 0.4646 - regression_loss: 0.0784 - handedness_loss: 0.3856 - val_loss: 0.4732 - val_regression_loss: 0.0790 - val_handedness_loss: 0.3942\n",
      "Epoch 24/150\n",
      "9032/9032 [==============================] - 1s 147us/step - loss: 0.4550 - regression_loss: 0.0782 - handedness_loss: 0.3770 - val_loss: 0.4743 - val_regression_loss: 0.0795 - val_handedness_loss: 0.3948\n",
      "Evaluating model with testing data...\n",
      "1914/1914 [==============================] - 0s 16us/step\n",
      "Getting distribution of predictions and covariance matrix...\n",
      "      1 of 20\n",
      "      2 of 20\n",
      "      3 of 20\n",
      "      4 of 20\n",
      "      5 of 20\n",
      "      6 of 20\n",
      "      7 of 20\n",
      "      8 of 20\n",
      "      9 of 20\n",
      "      10 of 20\n",
      "      11 of 20\n",
      "      12 of 20\n",
      "      13 of 20\n",
      "      14 of 20\n",
      "      15 of 20\n",
      "      16 of 20\n",
      "      17 of 20\n",
      "      18 of 20\n",
      "      19 of 20\n",
      "      20 of 20\n",
      "Computing ensemble means...\n",
      "Computing mean squared error...\n",
      "Iteration 62\n",
      "Train on 9172 samples, validate on 1944 samples\n",
      "Epoch 1/150\n",
      "9172/9172 [==============================] - 1s 147us/step - loss: 0.9862 - regression_loss: 0.3552 - handedness_loss: 0.6300 - val_loss: 0.7969 - val_regression_loss: 0.2425 - val_handedness_loss: 0.5577\n",
      "Epoch 2/150\n",
      "9172/9172 [==============================] - 1s 132us/step - loss: 0.6779 - regression_loss: 0.1873 - handedness_loss: 0.4900 - val_loss: 0.5995 - val_regression_loss: 0.1636 - val_handedness_loss: 0.4363\n",
      "Epoch 3/150\n",
      "9172/9172 [==============================] - 1s 132us/step - loss: 0.5333 - regression_loss: 0.1468 - handedness_loss: 0.3864 - val_loss: 0.5118 - val_regression_loss: 0.1441 - val_handedness_loss: 0.3685\n",
      "Epoch 4/150\n",
      "9172/9172 [==============================] - 1s 145us/step - loss: 0.4379 - regression_loss: 0.1273 - handedness_loss: 0.3107 - val_loss: 0.4160 - val_regression_loss: 0.1284 - val_handedness_loss: 0.2953\n",
      "Epoch 5/150\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9172/9172 [==============================] - 1s 147us/step - loss: 0.3878 - regression_loss: 0.1158 - handedness_loss: 0.2721 - val_loss: 0.3679 - val_regression_loss: 0.1154 - val_handedness_loss: 0.2546\n",
      "Epoch 6/150\n",
      "9172/9172 [==============================] - 1s 149us/step - loss: 0.3530 - regression_loss: 0.1043 - handedness_loss: 0.2487 - val_loss: 0.3678 - val_regression_loss: 0.1043 - val_handedness_loss: 0.2655\n",
      "Epoch 7/150\n",
      "9172/9172 [==============================] - 1s 149us/step - loss: 0.3386 - regression_loss: 0.0968 - handedness_loss: 0.2422 - val_loss: 0.3359 - val_regression_loss: 0.0980 - val_handedness_loss: 0.2543\n",
      "Epoch 8/150\n",
      "9172/9172 [==============================] - 1s 150us/step - loss: 0.3221 - regression_loss: 0.0907 - handedness_loss: 0.2314 - val_loss: 0.3219 - val_regression_loss: 0.0907 - val_handedness_loss: 0.2528\n",
      "Epoch 9/150\n",
      "9172/9172 [==============================] - 1s 145us/step - loss: 0.3123 - regression_loss: 0.0857 - handedness_loss: 0.2268 - val_loss: 0.3142 - val_regression_loss: 0.0852 - val_handedness_loss: 0.2327\n",
      "Epoch 10/150\n",
      "9172/9172 [==============================] - 1s 149us/step - loss: 0.3082 - regression_loss: 0.0817 - handedness_loss: 0.2265 - val_loss: 0.2874 - val_regression_loss: 0.0808 - val_handedness_loss: 0.2092\n",
      "Epoch 11/150\n",
      "9172/9172 [==============================] - 1s 145us/step - loss: 0.3021 - regression_loss: 0.0783 - handedness_loss: 0.2236 - val_loss: 0.2933 - val_regression_loss: 0.0779 - val_handedness_loss: 0.2298\n",
      "Epoch 12/150\n",
      "9172/9172 [==============================] - 1s 146us/step - loss: 0.2983 - regression_loss: 0.0755 - handedness_loss: 0.2226 - val_loss: 0.3047 - val_regression_loss: 0.0764 - val_handedness_loss: 0.2342\n",
      "Epoch 13/150\n",
      "9172/9172 [==============================] - 1s 149us/step - loss: 0.2940 - regression_loss: 0.0742 - handedness_loss: 0.2202 - val_loss: 0.2948 - val_regression_loss: 0.0735 - val_handedness_loss: 0.2302\n",
      "Epoch 14/150\n",
      "9172/9172 [==============================] - 1s 139us/step - loss: 0.2813 - regression_loss: 0.0732 - handedness_loss: 0.2080 - val_loss: 0.2895 - val_regression_loss: 0.0734 - val_handedness_loss: 0.2220\n",
      "Evaluating model with testing data...\n",
      "1944/1944 [==============================] - 0s 18us/step\n",
      "Getting distribution of predictions and covariance matrix...\n",
      "      1 of 20\n",
      "      2 of 20\n",
      "      3 of 20\n",
      "      4 of 20\n",
      "      5 of 20\n",
      "      6 of 20\n",
      "      7 of 20\n",
      "      8 of 20\n",
      "      9 of 20\n",
      "      10 of 20\n",
      "      11 of 20\n",
      "      12 of 20\n",
      "      13 of 20\n",
      "      14 of 20\n",
      "      15 of 20\n",
      "      16 of 20\n",
      "      17 of 20\n",
      "      18 of 20\n",
      "      19 of 20\n",
      "      20 of 20\n",
      "Computing ensemble means...\n",
      "Computing mean squared error...\n",
      "Iteration 63\n",
      "Train on 9312 samples, validate on 1974 samples\n",
      "Epoch 1/150\n",
      "9312/9312 [==============================] - 1s 133us/step - loss: 1.1263 - regression_loss: 0.4559 - handedness_loss: 0.6696 - val_loss: 0.8779 - val_regression_loss: 0.2227 - val_handedness_loss: 0.6528\n",
      "Epoch 2/150\n",
      "9312/9312 [==============================] - 1s 122us/step - loss: 0.8204 - regression_loss: 0.1925 - handedness_loss: 0.6278 - val_loss: 0.7884 - val_regression_loss: 0.1790 - val_handedness_loss: 0.6074\n",
      "Epoch 3/150\n",
      "9312/9312 [==============================] - 1s 145us/step - loss: 0.7270 - regression_loss: 0.1631 - handedness_loss: 0.5639 - val_loss: 0.7033 - val_regression_loss: 0.1558 - val_handedness_loss: 0.5438\n",
      "Epoch 4/150\n",
      "9312/9312 [==============================] - 1s 146us/step - loss: 0.6657 - regression_loss: 0.1498 - handedness_loss: 0.5161 - val_loss: 0.6633 - val_regression_loss: 0.1484 - val_handedness_loss: 0.5134\n",
      "Epoch 5/150\n",
      "9312/9312 [==============================] - 1s 147us/step - loss: 0.6255 - regression_loss: 0.1398 - handedness_loss: 0.4857 - val_loss: 0.6212 - val_regression_loss: 0.1344 - val_handedness_loss: 0.4872\n",
      "Epoch 6/150\n",
      "9312/9312 [==============================] - 1s 148us/step - loss: 0.5776 - regression_loss: 0.1245 - handedness_loss: 0.4530 - val_loss: 0.5481 - val_regression_loss: 0.1183 - val_handedness_loss: 0.4299\n",
      "Epoch 7/150\n",
      "9312/9312 [==============================] - 1s 144us/step - loss: 0.5184 - regression_loss: 0.1127 - handedness_loss: 0.4058 - val_loss: 0.5012 - val_regression_loss: 0.1044 - val_handedness_loss: 0.3948\n",
      "Epoch 8/150\n",
      "9312/9312 [==============================] - 1s 128us/step - loss: 0.4798 - regression_loss: 0.1006 - handedness_loss: 0.3790 - val_loss: 0.4783 - val_regression_loss: 0.0969 - val_handedness_loss: 0.3811\n",
      "Epoch 9/150\n",
      "9312/9312 [==============================] - 1s 144us/step - loss: 0.4632 - regression_loss: 0.0939 - handedness_loss: 0.3694 - val_loss: 0.4660 - val_regression_loss: 0.0916 - val_handedness_loss: 0.3722\n",
      "Epoch 10/150\n",
      "9312/9312 [==============================] - 1s 147us/step - loss: 0.4444 - regression_loss: 0.0880 - handedness_loss: 0.3565 - val_loss: 0.4646 - val_regression_loss: 0.0862 - val_handedness_loss: 0.3774\n",
      "Epoch 11/150\n",
      "9312/9312 [==============================] - 1s 148us/step - loss: 0.4409 - regression_loss: 0.0850 - handedness_loss: 0.3557 - val_loss: 0.4403 - val_regression_loss: 0.0837 - val_handedness_loss: 0.3540\n",
      "Epoch 12/150\n",
      "9312/9312 [==============================] - 1s 147us/step - loss: 0.4375 - regression_loss: 0.0819 - handedness_loss: 0.3555 - val_loss: 0.4555 - val_regression_loss: 0.0812 - val_handedness_loss: 0.3724\n",
      "Epoch 13/150\n",
      "9312/9312 [==============================] - 1s 147us/step - loss: 0.4300 - regression_loss: 0.0800 - handedness_loss: 0.3499 - val_loss: 0.4182 - val_regression_loss: 0.0807 - val_handedness_loss: 0.3356\n",
      "Epoch 14/150\n",
      "9312/9312 [==============================] - 1s 143us/step - loss: 0.4310 - regression_loss: 0.0789 - handedness_loss: 0.3520 - val_loss: 0.4335 - val_regression_loss: 0.0800 - val_handedness_loss: 0.3539\n",
      "Epoch 15/150\n",
      "9312/9312 [==============================] - 1s 117us/step - loss: 0.4294 - regression_loss: 0.0787 - handedness_loss: 0.3506 - val_loss: 0.4265 - val_regression_loss: 0.0791 - val_handedness_loss: 0.3493\n",
      "Epoch 16/150\n",
      "9312/9312 [==============================] - 1s 136us/step - loss: 0.4152 - regression_loss: 0.0783 - handedness_loss: 0.3369 - val_loss: 0.4085 - val_regression_loss: 0.0780 - val_handedness_loss: 0.3277\n",
      "Epoch 17/150\n",
      "9312/9312 [==============================] - 1s 125us/step - loss: 0.4139 - regression_loss: 0.0775 - handedness_loss: 0.3365 - val_loss: 0.3968 - val_regression_loss: 0.0770 - val_handedness_loss: 0.3170\n",
      "Epoch 18/150\n",
      "9312/9312 [==============================] - 1s 140us/step - loss: 0.4139 - regression_loss: 0.0779 - handedness_loss: 0.3359 - val_loss: 0.4103 - val_regression_loss: 0.0770 - val_handedness_loss: 0.3322\n",
      "Epoch 19/150\n",
      "9312/9312 [==============================] - 1s 141us/step - loss: 0.4149 - regression_loss: 0.0772 - handedness_loss: 0.3376 - val_loss: 0.4224 - val_regression_loss: 0.0773 - val_handedness_loss: 0.3433\n",
      "Epoch 20/150\n",
      "9312/9312 [==============================] - 1s 146us/step - loss: 0.4156 - regression_loss: 0.0774 - handedness_loss: 0.3381 - val_loss: 0.4057 - val_regression_loss: 0.0779 - val_handedness_loss: 0.3258\n",
      "Epoch 21/150\n",
      "9312/9312 [==============================] - 1s 135us/step - loss: 0.4051 - regression_loss: 0.0772 - handedness_loss: 0.3278 - val_loss: 0.4106 - val_regression_loss: 0.0772 - val_handedness_loss: 0.3324\n",
      "Evaluating model with testing data...\n",
      "1974/1974 [==============================] - 0s 16us/step\n",
      "Getting distribution of predictions and covariance matrix...\n",
      "      1 of 20\n",
      "      2 of 20\n",
      "      3 of 20\n",
      "      4 of 20\n",
      "      5 of 20\n",
      "      6 of 20\n",
      "      7 of 20\n",
      "      8 of 20\n",
      "      9 of 20\n",
      "      10 of 20\n",
      "      11 of 20\n",
      "      12 of 20\n",
      "      13 of 20\n",
      "      14 of 20\n",
      "      15 of 20\n",
      "      16 of 20\n",
      "      17 of 20\n",
      "      18 of 20\n",
      "      19 of 20\n",
      "      20 of 20\n",
      "Computing ensemble means...\n",
      "Computing mean squared error...\n",
      "Iteration 64\n",
      "Train on 9452 samples, validate on 2004 samples\n",
      "Epoch 1/150\n",
      "9452/9452 [==============================] - 1s 132us/step - loss: 1.0735 - regression_loss: 0.3989 - handedness_loss: 0.6743 - val_loss: 0.8856 - val_regression_loss: 0.2397 - val_handedness_loss: 0.6454\n",
      "Epoch 2/150\n",
      "9452/9452 [==============================] - 1s 131us/step - loss: 0.8207 - regression_loss: 0.2094 - handedness_loss: 0.6112 - val_loss: 0.7748 - val_regression_loss: 0.1863 - val_handedness_loss: 0.5879\n",
      "Epoch 3/150\n",
      "9452/9452 [==============================] - 1s 145us/step - loss: 0.7419 - regression_loss: 0.1766 - handedness_loss: 0.5653 - val_loss: 0.7202 - val_regression_loss: 0.1650 - val_handedness_loss: 0.5551\n",
      "Epoch 4/150\n",
      "9452/9452 [==============================] - 1s 145us/step - loss: 0.6962 - regression_loss: 0.1574 - handedness_loss: 0.5386 - val_loss: 0.6726 - val_regression_loss: 0.1471 - val_handedness_loss: 0.5263\n",
      "Epoch 5/150\n",
      "9452/9452 [==============================] - 1s 147us/step - loss: 0.6465 - regression_loss: 0.1383 - handedness_loss: 0.5082 - val_loss: 0.6257 - val_regression_loss: 0.1287 - val_handedness_loss: 0.4967\n",
      "Epoch 6/150\n",
      "9452/9452 [==============================] - 1s 145us/step - loss: 0.6021 - regression_loss: 0.1207 - handedness_loss: 0.4812 - val_loss: 0.6082 - val_regression_loss: 0.1152 - val_handedness_loss: 0.4937\n",
      "Epoch 7/150\n",
      "9452/9452 [==============================] - 1s 127us/step - loss: 0.5800 - regression_loss: 0.1080 - handedness_loss: 0.4720 - val_loss: 0.5716 - val_regression_loss: 0.1019 - val_handedness_loss: 0.4702\n",
      "Epoch 8/150\n",
      "9452/9452 [==============================] - 1s 143us/step - loss: 0.5654 - regression_loss: 0.0980 - handedness_loss: 0.4675 - val_loss: 0.5609 - val_regression_loss: 0.0940 - val_handedness_loss: 0.4652\n",
      "Epoch 9/150\n",
      "9452/9452 [==============================] - 1s 145us/step - loss: 0.5542 - regression_loss: 0.0914 - handedness_loss: 0.4628 - val_loss: 0.5383 - val_regression_loss: 0.0883 - val_handedness_loss: 0.4491\n",
      "Epoch 10/150\n",
      "9452/9452 [==============================] - 1s 147us/step - loss: 0.5461 - regression_loss: 0.0865 - handedness_loss: 0.4596 - val_loss: 0.5303 - val_regression_loss: 0.0842 - val_handedness_loss: 0.4460\n",
      "Epoch 11/150\n",
      "9452/9452 [==============================] - 1s 148us/step - loss: 0.5454 - regression_loss: 0.0841 - handedness_loss: 0.4612 - val_loss: 0.5266 - val_regression_loss: 0.0818 - val_handedness_loss: 0.4455\n",
      "Epoch 12/150\n",
      "9452/9452 [==============================] - 1s 144us/step - loss: 0.5223 - regression_loss: 0.0818 - handedness_loss: 0.4405 - val_loss: 0.5271 - val_regression_loss: 0.0805 - val_handedness_loss: 0.4476\n",
      "Epoch 13/150\n",
      "9452/9452 [==============================] - 1s 148us/step - loss: 0.5203 - regression_loss: 0.0808 - handedness_loss: 0.4396 - val_loss: 0.5200 - val_regression_loss: 0.0795 - val_handedness_loss: 0.4400\n",
      "Epoch 14/150\n",
      "9452/9452 [==============================] - 1s 149us/step - loss: 0.5200 - regression_loss: 0.0804 - handedness_loss: 0.4395 - val_loss: 0.5101 - val_regression_loss: 0.0795 - val_handedness_loss: 0.4304\n",
      "Epoch 15/150\n",
      "9452/9452 [==============================] - 1s 149us/step - loss: 0.5210 - regression_loss: 0.0802 - handedness_loss: 0.4409 - val_loss: 0.5050 - val_regression_loss: 0.0795 - val_handedness_loss: 0.4241\n",
      "Epoch 16/150\n",
      "9452/9452 [==============================] - 1s 148us/step - loss: 0.5104 - regression_loss: 0.0799 - handedness_loss: 0.4303 - val_loss: 0.5189 - val_regression_loss: 0.0788 - val_handedness_loss: 0.4394\n",
      "Epoch 17/150\n",
      "9452/9452 [==============================] - 1s 133us/step - loss: 0.5092 - regression_loss: 0.0797 - handedness_loss: 0.4294 - val_loss: 0.5155 - val_regression_loss: 0.0789 - val_handedness_loss: 0.4366\n",
      "Epoch 18/150\n",
      "9452/9452 [==============================] - 1s 133us/step - loss: 0.5085 - regression_loss: 0.0798 - handedness_loss: 0.4286 - val_loss: 0.5034 - val_regression_loss: 0.0793 - val_handedness_loss: 0.4238\n",
      "Epoch 19/150\n",
      "9452/9452 [==============================] - 1s 110us/step - loss: 0.5036 - regression_loss: 0.0799 - handedness_loss: 0.4237 - val_loss: 0.5264 - val_regression_loss: 0.0795 - val_handedness_loss: 0.4481\n",
      "Epoch 20/150\n",
      "9452/9452 [==============================] - 1s 144us/step - loss: 0.5177 - regression_loss: 0.0802 - handedness_loss: 0.4376 - val_loss: 0.5177 - val_regression_loss: 0.0789 - val_handedness_loss: 0.4390\n",
      "Evaluating model with testing data...\n",
      "2004/2004 [==============================] - 0s 16us/step\n",
      "Getting distribution of predictions and covariance matrix...\n",
      "      1 of 20\n",
      "      2 of 20\n",
      "      3 of 20\n",
      "      4 of 20\n",
      "      5 of 20\n",
      "      6 of 20\n",
      "      7 of 20\n",
      "      8 of 20\n",
      "      9 of 20\n",
      "      10 of 20\n",
      "      11 of 20\n",
      "      12 of 20\n",
      "      13 of 20\n",
      "      14 of 20\n",
      "      15 of 20\n",
      "      16 of 20\n",
      "      17 of 20\n",
      "      18 of 20\n",
      "      19 of 20\n",
      "      20 of 20\n",
      "Computing ensemble means...\n",
      "Computing mean squared error...\n",
      "Iteration 65\n",
      "Train on 9592 samples, validate on 2034 samples\n",
      "Epoch 1/150\n",
      "9592/9592 [==============================] - 1s 145us/step - loss: 1.1005 - regression_loss: 0.4422 - handedness_loss: 0.6581 - val_loss: 0.8908 - val_regression_loss: 0.2695 - val_handedness_loss: 0.6212\n",
      "Epoch 2/150\n",
      "9592/9592 [==============================] - 1s 128us/step - loss: 0.8209 - regression_loss: 0.2340 - handedness_loss: 0.5868 - val_loss: 0.7567 - val_regression_loss: 0.2064 - val_handedness_loss: 0.5504\n",
      "Epoch 3/150\n",
      "9592/9592 [==============================] - 1s 144us/step - loss: 0.7023 - regression_loss: 0.1817 - handedness_loss: 0.5205 - val_loss: 0.6615 - val_regression_loss: 0.1635 - val_handedness_loss: 0.4976\n",
      "Epoch 4/150\n",
      "9592/9592 [==============================] - 1s 128us/step - loss: 0.6209 - regression_loss: 0.1552 - handedness_loss: 0.4657 - val_loss: 0.5975 - val_regression_loss: 0.1434 - val_handedness_loss: 0.4536\n",
      "Epoch 5/150\n",
      "9592/9592 [==============================] - 1s 134us/step - loss: 0.5617 - regression_loss: 0.1360 - handedness_loss: 0.4257 - val_loss: 0.5573 - val_regression_loss: 0.1276 - val_handedness_loss: 0.4291\n",
      "Epoch 6/150\n",
      "9592/9592 [==============================] - 1s 99us/step - loss: 0.5162 - regression_loss: 0.1191 - handedness_loss: 0.3972 - val_loss: 0.5062 - val_regression_loss: 0.1135 - val_handedness_loss: 0.3925\n",
      "Epoch 7/150\n",
      "9592/9592 [==============================] - 1s 64us/step - loss: 0.4957 - regression_loss: 0.1085 - handedness_loss: 0.3873 - val_loss: 0.5014 - val_regression_loss: 0.1046 - val_handedness_loss: 0.3964\n",
      "Epoch 8/150\n",
      "9592/9592 [==============================] - 1s 128us/step - loss: 0.4761 - regression_loss: 0.0996 - handedness_loss: 0.3764 - val_loss: 0.4646 - val_regression_loss: 0.0949 - val_handedness_loss: 0.3695\n",
      "Epoch 9/150\n",
      "9592/9592 [==============================] - 1s 132us/step - loss: 0.4639 - regression_loss: 0.0922 - handedness_loss: 0.3718 - val_loss: 0.4663 - val_regression_loss: 0.0897 - val_handedness_loss: 0.3761\n",
      "Epoch 10/150\n",
      "9592/9592 [==============================] - 1s 128us/step - loss: 0.4615 - regression_loss: 0.0876 - handedness_loss: 0.3739 - val_loss: 0.4524 - val_regression_loss: 0.0848 - val_handedness_loss: 0.3673\n",
      "Epoch 11/150\n",
      "9592/9592 [==============================] - 1s 123us/step - loss: 0.4496 - regression_loss: 0.0842 - handedness_loss: 0.3654 - val_loss: 0.4552 - val_regression_loss: 0.0812 - val_handedness_loss: 0.3740\n",
      "Epoch 12/150\n",
      "9592/9592 [==============================] - 1s 134us/step - loss: 0.4395 - regression_loss: 0.0815 - handedness_loss: 0.3580 - val_loss: 0.4547 - val_regression_loss: 0.0803 - val_handedness_loss: 0.3740\n",
      "Epoch 13/150\n",
      "9592/9592 [==============================] - 1s 134us/step - loss: 0.4408 - regression_loss: 0.0801 - handedness_loss: 0.3608 - val_loss: 0.4385 - val_regression_loss: 0.0781 - val_handedness_loss: 0.3600\n",
      "Epoch 14/150\n",
      "9592/9592 [==============================] - 1s 135us/step - loss: 0.4366 - regression_loss: 0.0791 - handedness_loss: 0.3575 - val_loss: 0.4499 - val_regression_loss: 0.0783 - val_handedness_loss: 0.3712\n",
      "Epoch 15/150\n",
      "9592/9592 [==============================] - 1s 143us/step - loss: 0.4311 - regression_loss: 0.0783 - handedness_loss: 0.3528 - val_loss: 0.4350 - val_regression_loss: 0.0772 - val_handedness_loss: 0.3575\n",
      "Epoch 16/150\n",
      "9592/9592 [==============================] - 1s 146us/step - loss: 0.4277 - regression_loss: 0.0777 - handedness_loss: 0.3499 - val_loss: 0.4297 - val_regression_loss: 0.0764 - val_handedness_loss: 0.3529\n",
      "Epoch 17/150\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9592/9592 [==============================] - 1s 139us/step - loss: 0.4303 - regression_loss: 0.0777 - handedness_loss: 0.3526 - val_loss: 0.4451 - val_regression_loss: 0.0769 - val_handedness_loss: 0.3679\n",
      "Epoch 18/150\n",
      "9592/9592 [==============================] - 1s 146us/step - loss: 0.4280 - regression_loss: 0.0779 - handedness_loss: 0.3502 - val_loss: 0.4214 - val_regression_loss: 0.0766 - val_handedness_loss: 0.3446\n",
      "Epoch 19/150\n",
      "9592/9592 [==============================] - 1s 147us/step - loss: 0.4239 - regression_loss: 0.0779 - handedness_loss: 0.3460 - val_loss: 0.4184 - val_regression_loss: 0.0760 - val_handedness_loss: 0.3421\n",
      "Epoch 20/150\n",
      "9592/9592 [==============================] - 1s 136us/step - loss: 0.4246 - regression_loss: 0.0777 - handedness_loss: 0.3468 - val_loss: 0.4244 - val_regression_loss: 0.0765 - val_handedness_loss: 0.3473\n",
      "Epoch 21/150\n",
      "9592/9592 [==============================] - 1s 146us/step - loss: 0.4174 - regression_loss: 0.0774 - handedness_loss: 0.3400 - val_loss: 0.4203 - val_regression_loss: 0.0762 - val_handedness_loss: 0.3437\n",
      "Epoch 22/150\n",
      "9592/9592 [==============================] - 1s 133us/step - loss: 0.4219 - regression_loss: 0.0775 - handedness_loss: 0.3444 - val_loss: 0.4278 - val_regression_loss: 0.0763 - val_handedness_loss: 0.3506\n",
      "Epoch 23/150\n",
      "9592/9592 [==============================] - 1s 143us/step - loss: 0.4201 - regression_loss: 0.0775 - handedness_loss: 0.3426 - val_loss: 0.4376 - val_regression_loss: 0.0766 - val_handedness_loss: 0.3609\n",
      "Evaluating model with testing data...\n",
      "2034/2034 [==============================] - 0s 17us/step\n",
      "Getting distribution of predictions and covariance matrix...\n",
      "      1 of 20\n",
      "      2 of 20\n",
      "      3 of 20\n",
      "      4 of 20\n",
      "      5 of 20\n",
      "      6 of 20\n",
      "      7 of 20\n",
      "      8 of 20\n",
      "      9 of 20\n",
      "      10 of 20\n",
      "      11 of 20\n",
      "      12 of 20\n",
      "      13 of 20\n",
      "      14 of 20\n",
      "      15 of 20\n",
      "      16 of 20\n",
      "      17 of 20\n",
      "      18 of 20\n",
      "      19 of 20\n",
      "      20 of 20\n",
      "Computing ensemble means...\n",
      "Computing mean squared error...\n",
      "Iteration 66\n",
      "Train on 9732 samples, validate on 2064 samples\n",
      "Epoch 1/150\n",
      "9732/9732 [==============================] - 1s 127us/step - loss: 1.0718 - regression_loss: 0.3775 - handedness_loss: 0.6902 - val_loss: 0.9469 - val_regression_loss: 0.2759 - val_handedness_loss: 0.6750\n",
      "Epoch 2/150\n",
      "9732/9732 [==============================] - 1s 132us/step - loss: 0.8852 - regression_loss: 0.2252 - handedness_loss: 0.6602 - val_loss: 0.8199 - val_regression_loss: 0.1683 - val_handedness_loss: 0.6525\n",
      "Epoch 3/150\n",
      "9732/9732 [==============================] - 1s 148us/step - loss: 0.7640 - regression_loss: 0.1463 - handedness_loss: 0.6159 - val_loss: 0.7126 - val_regression_loss: 0.1318 - val_handedness_loss: 0.5807\n",
      "Epoch 4/150\n",
      "9732/9732 [==============================] - 1s 144us/step - loss: 0.6940 - regression_loss: 0.1263 - handedness_loss: 0.5676 - val_loss: 0.6898 - val_regression_loss: 0.1245 - val_handedness_loss: 0.5721\n",
      "Epoch 5/150\n",
      "9732/9732 [==============================] - 1s 149us/step - loss: 0.6708 - regression_loss: 0.1179 - handedness_loss: 0.5497 - val_loss: 0.6694 - val_regression_loss: 0.1113 - val_handedness_loss: 0.5555\n",
      "Epoch 6/150\n",
      "9732/9732 [==============================] - 1s 114us/step - loss: 0.6403 - regression_loss: 0.1159 - handedness_loss: 0.5247 - val_loss: 0.6311 - val_regression_loss: 0.1189 - val_handedness_loss: 0.5172\n",
      "Epoch 7/150\n",
      "9732/9732 [==============================] - 1s 107us/step - loss: 0.5921 - regression_loss: 0.1098 - handedness_loss: 0.4807 - val_loss: 0.5796 - val_regression_loss: 0.1041 - val_handedness_loss: 0.4816\n",
      "Epoch 8/150\n",
      "9732/9732 [==============================] - 1s 144us/step - loss: 0.5700 - regression_loss: 0.1009 - handedness_loss: 0.4706 - val_loss: 0.5681 - val_regression_loss: 0.0951 - val_handedness_loss: 0.4718\n",
      "Epoch 9/150\n",
      "9732/9732 [==============================] - 1s 128us/step - loss: 0.5512 - regression_loss: 0.0916 - handedness_loss: 0.4625 - val_loss: 0.5470 - val_regression_loss: 0.0886 - val_handedness_loss: 0.4712\n",
      "Epoch 10/150\n",
      "9732/9732 [==============================] - 1s 144us/step - loss: 0.5464 - regression_loss: 0.0869 - handedness_loss: 0.4570 - val_loss: 0.5365 - val_regression_loss: 0.0839 - val_handedness_loss: 0.4477\n",
      "Epoch 11/150\n",
      "9732/9732 [==============================] - 1s 138us/step - loss: 0.5367 - regression_loss: 0.0837 - handedness_loss: 0.4524 - val_loss: 0.5395 - val_regression_loss: 0.0814 - val_handedness_loss: 0.4606\n",
      "Epoch 12/150\n",
      "9732/9732 [==============================] - 1s 128us/step - loss: 0.5403 - regression_loss: 0.0817 - handedness_loss: 0.4590 - val_loss: 0.5287 - val_regression_loss: 0.0795 - val_handedness_loss: 0.4504\n",
      "Epoch 13/150\n",
      "9732/9732 [==============================] - 1s 136us/step - loss: 0.5248 - regression_loss: 0.0802 - handedness_loss: 0.4462 - val_loss: 0.5378 - val_regression_loss: 0.0794 - val_handedness_loss: 0.4580\n",
      "Epoch 14/150\n",
      "9732/9732 [==============================] - 1s 136us/step - loss: 0.5261 - regression_loss: 0.0792 - handedness_loss: 0.4485 - val_loss: 0.5095 - val_regression_loss: 0.0783 - val_handedness_loss: 0.4408\n",
      "Epoch 15/150\n",
      "9732/9732 [==============================] - 1s 146us/step - loss: 0.5453 - regression_loss: 0.0792 - handedness_loss: 0.4662 - val_loss: 0.5274 - val_regression_loss: 0.0781 - val_handedness_loss: 0.4366\n",
      "Epoch 16/150\n",
      "9732/9732 [==============================] - 1s 133us/step - loss: 0.5451 - regression_loss: 0.0798 - handedness_loss: 0.4664 - val_loss: 0.5402 - val_regression_loss: 0.0785 - val_handedness_loss: 0.4583\n",
      "Epoch 17/150\n",
      "9732/9732 [==============================] - 1s 122us/step - loss: 0.5356 - regression_loss: 0.0790 - handedness_loss: 0.4572 - val_loss: 0.5380 - val_regression_loss: 0.0790 - val_handedness_loss: 0.4677\n",
      "Epoch 18/150\n",
      "9732/9732 [==============================] - 1s 136us/step - loss: 0.5261 - regression_loss: 0.0791 - handedness_loss: 0.4495 - val_loss: 0.5293 - val_regression_loss: 0.0782 - val_handedness_loss: 0.4500\n",
      "Epoch 19/150\n",
      "9732/9732 [==============================] - 1s 140us/step - loss: 0.5285 - regression_loss: 0.0792 - handedness_loss: 0.4528 - val_loss: 0.5180 - val_regression_loss: 0.0788 - val_handedness_loss: 0.4437\n",
      "Evaluating model with testing data...\n",
      "2064/2064 [==============================] - 0s 16us/step\n",
      "Getting distribution of predictions and covariance matrix...\n",
      "      1 of 20\n",
      "      2 of 20\n",
      "      3 of 20\n",
      "      4 of 20\n",
      "      5 of 20\n",
      "      6 of 20\n",
      "      7 of 20\n",
      "      8 of 20\n",
      "      9 of 20\n",
      "      10 of 20\n",
      "      11 of 20\n",
      "      12 of 20\n",
      "      13 of 20\n",
      "      14 of 20\n",
      "      15 of 20\n",
      "      16 of 20\n",
      "      17 of 20\n",
      "      18 of 20\n",
      "      19 of 20\n",
      "      20 of 20\n",
      "Computing ensemble means...\n",
      "Computing mean squared error...\n",
      "Iteration 67\n",
      "Train on 9872 samples, validate on 2094 samples\n",
      "Epoch 1/150\n",
      "9872/9872 [==============================] - 1s 137us/step - loss: 0.9393 - regression_loss: 0.2694 - handedness_loss: 0.6702 - val_loss: 0.7738 - val_regression_loss: 0.1576 - val_handedness_loss: 0.6128\n",
      "Epoch 2/150\n",
      "9872/9872 [==============================] - 1s 118us/step - loss: 0.6819 - regression_loss: 0.1433 - handedness_loss: 0.5386 - val_loss: 0.5916 - val_regression_loss: 0.1341 - val_handedness_loss: 0.4538\n",
      "Epoch 3/150\n",
      "9872/9872 [==============================] - 1s 141us/step - loss: 0.5353 - regression_loss: 0.1256 - handedness_loss: 0.4070 - val_loss: 0.4834 - val_regression_loss: 0.1211 - val_handedness_loss: 0.3604\n",
      "Epoch 4/150\n",
      "9872/9872 [==============================] - 1s 131us/step - loss: 0.4603 - regression_loss: 0.1157 - handedness_loss: 0.3441 - val_loss: 0.4545 - val_regression_loss: 0.1128 - val_handedness_loss: 0.3379\n",
      "Epoch 5/150\n",
      "9872/9872 [==============================] - 1s 137us/step - loss: 0.4166 - regression_loss: 0.1070 - handedness_loss: 0.3095 - val_loss: 0.3995 - val_regression_loss: 0.1023 - val_handedness_loss: 0.2921\n",
      "Epoch 6/150\n",
      "9872/9872 [==============================] - 1s 126us/step - loss: 0.3927 - regression_loss: 0.0993 - handedness_loss: 0.2909 - val_loss: 0.3927 - val_regression_loss: 0.0970 - val_handedness_loss: 0.2963\n",
      "Epoch 7/150\n",
      "9872/9872 [==============================] - 1s 138us/step - loss: 0.3668 - regression_loss: 0.0913 - handedness_loss: 0.2751 - val_loss: 0.3596 - val_regression_loss: 0.0874 - val_handedness_loss: 0.2691\n",
      "Epoch 8/150\n",
      "9872/9872 [==============================] - 1s 145us/step - loss: 0.3498 - regression_loss: 0.0857 - handedness_loss: 0.2647 - val_loss: 0.3790 - val_regression_loss: 0.0828 - val_handedness_loss: 0.2905\n",
      "Epoch 9/150\n",
      "9872/9872 [==============================] - 1s 141us/step - loss: 0.3507 - regression_loss: 0.0819 - handedness_loss: 0.2696 - val_loss: 0.3327 - val_regression_loss: 0.0768 - val_handedness_loss: 0.2530\n",
      "Epoch 10/150\n",
      "9872/9872 [==============================] - 1s 147us/step - loss: 0.3287 - regression_loss: 0.0780 - handedness_loss: 0.2504 - val_loss: 0.3373 - val_regression_loss: 0.0750 - val_handedness_loss: 0.2595\n",
      "Epoch 11/150\n",
      "9872/9872 [==============================] - 1s 148us/step - loss: 0.3042 - regression_loss: 0.0744 - handedness_loss: 0.2292 - val_loss: 0.3044 - val_regression_loss: 0.0711 - val_handedness_loss: 0.2283\n",
      "Epoch 12/150\n",
      "9872/9872 [==============================] - 1s 141us/step - loss: 0.2855 - regression_loss: 0.0723 - handedness_loss: 0.2126 - val_loss: 0.2761 - val_regression_loss: 0.0699 - val_handedness_loss: 0.2023\n",
      "Epoch 13/150\n",
      "9872/9872 [==============================] - 1s 147us/step - loss: 0.2745 - regression_loss: 0.0717 - handedness_loss: 0.2031 - val_loss: 0.2642 - val_regression_loss: 0.0695 - val_handedness_loss: 0.1937\n",
      "Epoch 14/150\n",
      "9872/9872 [==============================] - 1s 147us/step - loss: 0.2691 - regression_loss: 0.0711 - handedness_loss: 0.2003 - val_loss: 0.2763 - val_regression_loss: 0.0695 - val_handedness_loss: 0.2096\n",
      "Epoch 15/150\n",
      "9872/9872 [==============================] - 1s 148us/step - loss: 0.2757 - regression_loss: 0.0709 - handedness_loss: 0.2061 - val_loss: 0.2576 - val_regression_loss: 0.0681 - val_handedness_loss: 0.1882\n",
      "Epoch 16/150\n",
      "9872/9872 [==============================] - 1s 134us/step - loss: 0.2681 - regression_loss: 0.0709 - handedness_loss: 0.1979 - val_loss: 0.2660 - val_regression_loss: 0.0686 - val_handedness_loss: 0.1960\n",
      "Epoch 17/150\n",
      "9872/9872 [==============================] - 1s 143us/step - loss: 0.2637 - regression_loss: 0.0700 - handedness_loss: 0.1940 - val_loss: 0.2532 - val_regression_loss: 0.0683 - val_handedness_loss: 0.1854\n",
      "Epoch 18/150\n",
      "9872/9872 [==============================] - 1s 145us/step - loss: 0.2622 - regression_loss: 0.0702 - handedness_loss: 0.1911 - val_loss: 0.2772 - val_regression_loss: 0.0686 - val_handedness_loss: 0.2038\n",
      "Epoch 19/150\n",
      "9872/9872 [==============================] - 1s 147us/step - loss: 0.2545 - regression_loss: 0.0699 - handedness_loss: 0.1829 - val_loss: 0.2487 - val_regression_loss: 0.0693 - val_handedness_loss: 0.1773\n",
      "Evaluating model with testing data...\n",
      "2094/2094 [==============================] - 0s 17us/step\n",
      "Getting distribution of predictions and covariance matrix...\n",
      "      1 of 20\n",
      "      2 of 20\n",
      "      3 of 20\n",
      "      4 of 20\n",
      "      5 of 20\n",
      "      6 of 20\n",
      "      7 of 20\n",
      "      8 of 20\n",
      "      9 of 20\n",
      "      10 of 20\n",
      "      11 of 20\n",
      "      12 of 20\n",
      "      13 of 20\n",
      "      14 of 20\n",
      "      15 of 20\n",
      "      16 of 20\n",
      "      17 of 20\n",
      "      18 of 20\n",
      "      19 of 20\n",
      "      20 of 20\n",
      "Computing ensemble means...\n",
      "Computing mean squared error...\n",
      "Iteration 68\n",
      "Train on 10012 samples, validate on 2124 samples\n",
      "Epoch 1/150\n",
      "10012/10012 [==============================] - 1s 140us/step - loss: 1.1418 - regression_loss: 0.4522 - handedness_loss: 0.6870 - val_loss: 0.9435 - val_regression_loss: 0.2771 - val_handedness_loss: 0.6663\n",
      "Epoch 2/150\n",
      "10012/10012 [==============================] - 1s 137us/step - loss: 0.8876 - regression_loss: 0.2391 - handedness_loss: 0.6464 - val_loss: 0.8384 - val_regression_loss: 0.2094 - val_handedness_loss: 0.6292\n",
      "Epoch 3/150\n",
      "10012/10012 [==============================] - 1s 125us/step - loss: 0.7931 - regression_loss: 0.1929 - handedness_loss: 0.6001 - val_loss: 0.7400 - val_regression_loss: 0.1674 - val_handedness_loss: 0.5733\n",
      "Epoch 4/150\n",
      "10012/10012 [==============================] - 1s 142us/step - loss: 0.6981 - regression_loss: 0.1565 - handedness_loss: 0.5412 - val_loss: 0.6505 - val_regression_loss: 0.1454 - val_handedness_loss: 0.5049\n",
      "Epoch 5/150\n",
      "10012/10012 [==============================] - 1s 145us/step - loss: 0.6118 - regression_loss: 0.1361 - handedness_loss: 0.4761 - val_loss: 0.5801 - val_regression_loss: 0.1236 - val_handedness_loss: 0.4573\n",
      "Epoch 6/150\n",
      "10012/10012 [==============================] - 1s 148us/step - loss: 0.5326 - regression_loss: 0.1148 - handedness_loss: 0.4176 - val_loss: 0.5073 - val_regression_loss: 0.1067 - val_handedness_loss: 0.3998\n",
      "Epoch 7/150\n",
      "10012/10012 [==============================] - 1s 148us/step - loss: 0.5112 - regression_loss: 0.1052 - handedness_loss: 0.4052 - val_loss: 0.4778 - val_regression_loss: 0.0964 - val_handedness_loss: 0.3794\n",
      "Epoch 8/150\n",
      "10012/10012 [==============================] - 1s 146us/step - loss: 0.4822 - regression_loss: 0.0964 - handedness_loss: 0.3852 - val_loss: 0.4623 - val_regression_loss: 0.0903 - val_handedness_loss: 0.3720\n",
      "Epoch 9/150\n",
      "10012/10012 [==============================] - 1s 143us/step - loss: 0.4784 - regression_loss: 0.0904 - handedness_loss: 0.3875 - val_loss: 0.4570 - val_regression_loss: 0.0855 - val_handedness_loss: 0.3712\n",
      "Epoch 10/150\n",
      "10012/10012 [==============================] - 1s 147us/step - loss: 0.4624 - regression_loss: 0.0863 - handedness_loss: 0.3756 - val_loss: 0.4470 - val_regression_loss: 0.0820 - val_handedness_loss: 0.3648\n",
      "Epoch 11/150\n",
      "10012/10012 [==============================] - 1s 147us/step - loss: 0.4571 - regression_loss: 0.0829 - handedness_loss: 0.3737 - val_loss: 0.4522 - val_regression_loss: 0.0796 - val_handedness_loss: 0.3748\n",
      "Epoch 12/150\n",
      "10012/10012 [==============================] - 1s 136us/step - loss: 0.4393 - regression_loss: 0.0811 - handedness_loss: 0.3571 - val_loss: 0.4348 - val_regression_loss: 0.0772 - val_handedness_loss: 0.3576\n",
      "Epoch 13/150\n",
      "10012/10012 [==============================] - 1s 141us/step - loss: 0.4399 - regression_loss: 0.0793 - handedness_loss: 0.3628 - val_loss: 0.4252 - val_regression_loss: 0.0762 - val_handedness_loss: 0.3496\n",
      "Epoch 14/150\n",
      "10012/10012 [==============================] - 1s 131us/step - loss: 0.4389 - regression_loss: 0.0787 - handedness_loss: 0.3611 - val_loss: 0.4318 - val_regression_loss: 0.0762 - val_handedness_loss: 0.3566\n",
      "Epoch 15/150\n",
      "10012/10012 [==============================] - 1s 143us/step - loss: 0.4205 - regression_loss: 0.0782 - handedness_loss: 0.3433 - val_loss: 0.4177 - val_regression_loss: 0.0756 - val_handedness_loss: 0.3443\n",
      "Epoch 16/150\n",
      "10012/10012 [==============================] - 1s 141us/step - loss: 0.4287 - regression_loss: 0.0780 - handedness_loss: 0.3491 - val_loss: 0.4109 - val_regression_loss: 0.0759 - val_handedness_loss: 0.3354\n",
      "Epoch 17/150\n",
      "10012/10012 [==============================] - 1s 122us/step - loss: 0.4292 - regression_loss: 0.0774 - handedness_loss: 0.3514 - val_loss: 0.4301 - val_regression_loss: 0.0768 - val_handedness_loss: 0.3562\n",
      "Epoch 18/150\n",
      "10012/10012 [==============================] - 1s 128us/step - loss: 0.4289 - regression_loss: 0.0777 - handedness_loss: 0.3515 - val_loss: 0.4133 - val_regression_loss: 0.0748 - val_handedness_loss: 0.3393\n",
      "Epoch 19/150\n",
      "10012/10012 [==============================] - 1s 133us/step - loss: 0.4263 - regression_loss: 0.0779 - handedness_loss: 0.3488 - val_loss: 0.4279 - val_regression_loss: 0.0750 - val_handedness_loss: 0.3534\n",
      "Epoch 20/150\n",
      "10012/10012 [==============================] - 1s 142us/step - loss: 0.4181 - regression_loss: 0.0771 - handedness_loss: 0.3401 - val_loss: 0.4040 - val_regression_loss: 0.0749 - val_handedness_loss: 0.3308\n",
      "Epoch 21/150\n",
      "10012/10012 [==============================] - 1s 134us/step - loss: 0.4199 - regression_loss: 0.0773 - handedness_loss: 0.3429 - val_loss: 0.4218 - val_regression_loss: 0.0762 - val_handedness_loss: 0.3449\n",
      "Epoch 22/150\n",
      "10012/10012 [==============================] - 1s 124us/step - loss: 0.4216 - regression_loss: 0.0771 - handedness_loss: 0.3438 - val_loss: 0.4149 - val_regression_loss: 0.0745 - val_handedness_loss: 0.3415\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 23/150\n",
      "10012/10012 [==============================] - 1s 141us/step - loss: 0.4192 - regression_loss: 0.0770 - handedness_loss: 0.3425 - val_loss: 0.4113 - val_regression_loss: 0.0755 - val_handedness_loss: 0.3362\n",
      "Epoch 24/150\n",
      "10012/10012 [==============================] - 1s 145us/step - loss: 0.4186 - regression_loss: 0.0779 - handedness_loss: 0.3422 - val_loss: 0.4059 - val_regression_loss: 0.0751 - val_handedness_loss: 0.3331\n",
      "Evaluating model with testing data...\n",
      "2124/2124 [==============================] - 0s 16us/step\n",
      "Getting distribution of predictions and covariance matrix...\n",
      "      1 of 20\n",
      "      2 of 20\n",
      "      3 of 20\n",
      "      4 of 20\n",
      "      5 of 20\n",
      "      6 of 20\n",
      "      7 of 20\n",
      "      8 of 20\n",
      "      9 of 20\n",
      "      10 of 20\n",
      "      11 of 20\n",
      "      12 of 20\n",
      "      13 of 20\n",
      "      14 of 20\n",
      "      15 of 20\n",
      "      16 of 20\n",
      "      17 of 20\n",
      "      18 of 20\n",
      "      19 of 20\n",
      "      20 of 20\n",
      "Computing ensemble means...\n",
      "Computing mean squared error...\n",
      "Iteration 69\n",
      "Train on 10152 samples, validate on 2154 samples\n",
      "Epoch 1/150\n",
      "10152/10152 [==============================] - 1s 130us/step - loss: 1.1062 - regression_loss: 0.4174 - handedness_loss: 0.6872 - val_loss: 0.8988 - val_regression_loss: 0.2275 - val_handedness_loss: 0.6711\n",
      "Epoch 2/150\n",
      "10152/10152 [==============================] - 1s 136us/step - loss: 0.8597 - regression_loss: 0.1961 - handedness_loss: 0.6636 - val_loss: 0.8220 - val_regression_loss: 0.1693 - val_handedness_loss: 0.6527\n",
      "Epoch 3/150\n",
      "10152/10152 [==============================] - 1s 137us/step - loss: 0.7822 - regression_loss: 0.1525 - handedness_loss: 0.6298 - val_loss: 0.7307 - val_regression_loss: 0.1268 - val_handedness_loss: 0.6038\n",
      "Epoch 4/150\n",
      "10152/10152 [==============================] - 1s 139us/step - loss: 0.6885 - regression_loss: 0.1240 - handedness_loss: 0.5643 - val_loss: 0.6672 - val_regression_loss: 0.1159 - val_handedness_loss: 0.5507\n",
      "Epoch 5/150\n",
      "10152/10152 [==============================] - 1s 83us/step - loss: 0.6401 - regression_loss: 0.1169 - handedness_loss: 0.5235 - val_loss: 0.6347 - val_regression_loss: 0.1074 - val_handedness_loss: 0.5271\n",
      "Epoch 6/150\n",
      "10152/10152 [==============================] - 1s 90us/step - loss: 0.5971 - regression_loss: 0.1091 - handedness_loss: 0.4880 - val_loss: 0.5869 - val_regression_loss: 0.1026 - val_handedness_loss: 0.4839\n",
      "Epoch 7/150\n",
      "10152/10152 [==============================] - 1s 141us/step - loss: 0.5369 - regression_loss: 0.0994 - handedness_loss: 0.4364 - val_loss: 0.5169 - val_regression_loss: 0.0912 - val_handedness_loss: 0.4253\n",
      "Epoch 8/150\n",
      "10152/10152 [==============================] - 1s 125us/step - loss: 0.4989 - regression_loss: 0.0913 - handedness_loss: 0.4084 - val_loss: 0.5017 - val_regression_loss: 0.0889 - val_handedness_loss: 0.4126\n",
      "Epoch 9/150\n",
      "10152/10152 [==============================] - 1s 140us/step - loss: 0.4900 - regression_loss: 0.0879 - handedness_loss: 0.4028 - val_loss: 0.4728 - val_regression_loss: 0.0825 - val_handedness_loss: 0.3900\n",
      "Epoch 10/150\n",
      "10152/10152 [==============================] - 1s 124us/step - loss: 0.4918 - regression_loss: 0.0836 - handedness_loss: 0.4079 - val_loss: 0.4737 - val_regression_loss: 0.0767 - val_handedness_loss: 0.3962\n",
      "Epoch 11/150\n",
      "10152/10152 [==============================] - 1s 141us/step - loss: 0.4769 - regression_loss: 0.0808 - handedness_loss: 0.3967 - val_loss: 0.4618 - val_regression_loss: 0.0778 - val_handedness_loss: 0.3838\n",
      "Epoch 12/150\n",
      "10152/10152 [==============================] - 1s 141us/step - loss: 0.4621 - regression_loss: 0.0778 - handedness_loss: 0.3842 - val_loss: 0.4595 - val_regression_loss: 0.0739 - val_handedness_loss: 0.3856\n",
      "Epoch 13/150\n",
      "10152/10152 [==============================] - 1s 146us/step - loss: 0.4687 - regression_loss: 0.0774 - handedness_loss: 0.3917 - val_loss: 0.4886 - val_regression_loss: 0.0743 - val_handedness_loss: 0.4139\n",
      "Epoch 14/150\n",
      "10152/10152 [==============================] - 1s 146us/step - loss: 0.4584 - regression_loss: 0.0758 - handedness_loss: 0.3829 - val_loss: 0.4566 - val_regression_loss: 0.0738 - val_handedness_loss: 0.3823\n",
      "Epoch 15/150\n",
      "10152/10152 [==============================] - 1s 135us/step - loss: 0.4614 - regression_loss: 0.0770 - handedness_loss: 0.3845 - val_loss: 0.4415 - val_regression_loss: 0.0751 - val_handedness_loss: 0.3659\n",
      "Epoch 16/150\n",
      "10152/10152 [==============================] - 1s 140us/step - loss: 0.4498 - regression_loss: 0.0778 - handedness_loss: 0.3723 - val_loss: 0.4572 - val_regression_loss: 0.0767 - val_handedness_loss: 0.3800\n",
      "Epoch 17/150\n",
      "10152/10152 [==============================] - 1s 143us/step - loss: 0.4401 - regression_loss: 0.0787 - handedness_loss: 0.3613 - val_loss: 0.4310 - val_regression_loss: 0.0767 - val_handedness_loss: 0.3542\n",
      "Epoch 18/150\n",
      "10152/10152 [==============================] - 1s 145us/step - loss: 0.4349 - regression_loss: 0.0777 - handedness_loss: 0.3576 - val_loss: 0.4389 - val_regression_loss: 0.0739 - val_handedness_loss: 0.3647\n",
      "Evaluating model with testing data...\n",
      "2154/2154 [==============================] - 0s 16us/step\n",
      "Getting distribution of predictions and covariance matrix...\n",
      "      1 of 20\n",
      "      2 of 20\n",
      "      3 of 20\n",
      "      4 of 20\n",
      "      5 of 20\n",
      "      6 of 20\n",
      "      7 of 20\n",
      "      8 of 20\n",
      "      9 of 20\n",
      "      10 of 20\n",
      "      11 of 20\n",
      "      12 of 20\n",
      "      13 of 20\n",
      "      14 of 20\n",
      "      15 of 20\n",
      "      16 of 20\n",
      "      17 of 20\n",
      "      18 of 20\n",
      "      19 of 20\n",
      "      20 of 20\n",
      "Computing ensemble means...\n",
      "Computing mean squared error...\n",
      "Iteration 70\n",
      "Train on 10292 samples, validate on 2184 samples\n",
      "Epoch 1/150\n",
      "10292/10292 [==============================] - 1s 143us/step - loss: 1.0970 - regression_loss: 0.4009 - handedness_loss: 0.6946 - val_loss: 0.8879 - val_regression_loss: 0.2007 - val_handedness_loss: 0.6921\n",
      "Epoch 2/150\n",
      "10292/10292 [==============================] - 1s 128us/step - loss: 0.8586 - regression_loss: 0.1669 - handedness_loss: 0.6915 - val_loss: 0.8361 - val_regression_loss: 0.1454 - val_handedness_loss: 0.6934\n",
      "Epoch 3/150\n",
      "10292/10292 [==============================] - 1s 138us/step - loss: 0.8268 - regression_loss: 0.1383 - handedness_loss: 0.6884 - val_loss: 0.8151 - val_regression_loss: 0.1290 - val_handedness_loss: 0.6889\n",
      "Epoch 4/150\n",
      "10292/10292 [==============================] - 1s 145us/step - loss: 0.8054 - regression_loss: 0.1252 - handedness_loss: 0.6800 - val_loss: 0.7931 - val_regression_loss: 0.1230 - val_handedness_loss: 0.6680\n",
      "Epoch 5/150\n",
      "10292/10292 [==============================] - 1s 129us/step - loss: 0.7747 - regression_loss: 0.1232 - handedness_loss: 0.6511 - val_loss: 0.7503 - val_regression_loss: 0.1200 - val_handedness_loss: 0.6294\n",
      "Epoch 6/150\n",
      "10292/10292 [==============================] - 1s 141us/step - loss: 0.7137 - regression_loss: 0.1170 - handedness_loss: 0.5962 - val_loss: 0.6528 - val_regression_loss: 0.1139 - val_handedness_loss: 0.5291\n",
      "Epoch 7/150\n",
      "10292/10292 [==============================] - 1s 133us/step - loss: 0.6009 - regression_loss: 0.1103 - handedness_loss: 0.4906 - val_loss: 0.5468 - val_regression_loss: 0.1000 - val_handedness_loss: 0.4444\n",
      "Epoch 8/150\n",
      "10292/10292 [==============================] - 1s 142us/step - loss: 0.5397 - regression_loss: 0.0998 - handedness_loss: 0.4393 - val_loss: 0.5094 - val_regression_loss: 0.0942 - val_handedness_loss: 0.4214\n",
      "Epoch 9/150\n",
      "10292/10292 [==============================] - 1s 139us/step - loss: 0.5085 - regression_loss: 0.0916 - handedness_loss: 0.4173 - val_loss: 0.5051 - val_regression_loss: 0.0868 - val_handedness_loss: 0.4193\n",
      "Epoch 10/150\n",
      "10292/10292 [==============================] - 2s 146us/step - loss: 0.4898 - regression_loss: 0.0842 - handedness_loss: 0.4057 - val_loss: 0.4927 - val_regression_loss: 0.0810 - val_handedness_loss: 0.4192\n",
      "Epoch 11/150\n",
      "10292/10292 [==============================] - 1s 134us/step - loss: 0.4684 - regression_loss: 0.0807 - handedness_loss: 0.3873 - val_loss: 0.4419 - val_regression_loss: 0.0801 - val_handedness_loss: 0.3597\n",
      "Epoch 12/150\n",
      "10292/10292 [==============================] - 1s 125us/step - loss: 0.4440 - regression_loss: 0.0799 - handedness_loss: 0.3641 - val_loss: 0.4383 - val_regression_loss: 0.0827 - val_handedness_loss: 0.3599\n",
      "Epoch 13/150\n",
      "10292/10292 [==============================] - 1s 139us/step - loss: 0.4292 - regression_loss: 0.0779 - handedness_loss: 0.3509 - val_loss: 0.4207 - val_regression_loss: 0.0758 - val_handedness_loss: 0.3458\n",
      "Epoch 14/150\n",
      "10292/10292 [==============================] - 2s 146us/step - loss: 0.3976 - regression_loss: 0.0756 - handedness_loss: 0.3228 - val_loss: 0.4017 - val_regression_loss: 0.0748 - val_handedness_loss: 0.3160\n",
      "Epoch 15/150\n",
      "10292/10292 [==============================] - 2s 147us/step - loss: 0.3971 - regression_loss: 0.0754 - handedness_loss: 0.3216 - val_loss: 0.3871 - val_regression_loss: 0.0761 - val_handedness_loss: 0.3016\n",
      "Epoch 16/150\n",
      "10292/10292 [==============================] - 2s 147us/step - loss: 0.3849 - regression_loss: 0.0759 - handedness_loss: 0.3089 - val_loss: 0.3838 - val_regression_loss: 0.0744 - val_handedness_loss: 0.3083\n",
      "Epoch 17/150\n",
      "10292/10292 [==============================] - 2s 147us/step - loss: 0.3930 - regression_loss: 0.0755 - handedness_loss: 0.3184 - val_loss: 0.3771 - val_regression_loss: 0.0751 - val_handedness_loss: 0.3055\n",
      "Epoch 18/150\n",
      "10292/10292 [==============================] - 2s 147us/step - loss: 0.3919 - regression_loss: 0.0761 - handedness_loss: 0.3162 - val_loss: 0.3838 - val_regression_loss: 0.0760 - val_handedness_loss: 0.3065\n",
      "Epoch 19/150\n",
      "10292/10292 [==============================] - 2s 147us/step - loss: 0.3806 - regression_loss: 0.0761 - handedness_loss: 0.3038 - val_loss: 0.3816 - val_regression_loss: 0.0740 - val_handedness_loss: 0.2989\n",
      "Epoch 20/150\n",
      "10292/10292 [==============================] - 2s 148us/step - loss: 0.3776 - regression_loss: 0.0760 - handedness_loss: 0.3021 - val_loss: 0.3741 - val_regression_loss: 0.0751 - val_handedness_loss: 0.2982\n",
      "Epoch 21/150\n",
      "10292/10292 [==============================] - 1s 140us/step - loss: 0.3705 - regression_loss: 0.0764 - handedness_loss: 0.2949 - val_loss: 0.3672 - val_regression_loss: 0.0751 - val_handedness_loss: 0.2964\n",
      "Epoch 22/150\n",
      "10292/10292 [==============================] - 1s 145us/step - loss: 0.3716 - regression_loss: 0.0763 - handedness_loss: 0.2954 - val_loss: 0.3584 - val_regression_loss: 0.0761 - val_handedness_loss: 0.2799\n",
      "Epoch 23/150\n",
      "10292/10292 [==============================] - 2s 147us/step - loss: 0.3728 - regression_loss: 0.0765 - handedness_loss: 0.2962 - val_loss: 0.3805 - val_regression_loss: 0.0749 - val_handedness_loss: 0.3038\n",
      "Evaluating model with testing data...\n",
      "2184/2184 [==============================] - 0s 17us/step\n",
      "Getting distribution of predictions and covariance matrix...\n",
      "      1 of 20\n",
      "      2 of 20\n",
      "      3 of 20\n",
      "      4 of 20\n",
      "      5 of 20\n",
      "      6 of 20\n",
      "      7 of 20\n",
      "      8 of 20\n",
      "      9 of 20\n",
      "      10 of 20\n",
      "      11 of 20\n",
      "      12 of 20\n",
      "      13 of 20\n",
      "      14 of 20\n",
      "      15 of 20\n",
      "      16 of 20\n",
      "      17 of 20\n",
      "      18 of 20\n",
      "      19 of 20\n",
      "      20 of 20\n",
      "Computing ensemble means...\n",
      "Computing mean squared error...\n",
      "Iteration 71\n",
      "Train on 10432 samples, validate on 2214 samples\n",
      "Epoch 1/150\n",
      "10432/10432 [==============================] - 1s 137us/step - loss: 0.9837 - regression_loss: 0.3296 - handedness_loss: 0.6532 - val_loss: 0.8017 - val_regression_loss: 0.1897 - val_handedness_loss: 0.6163\n",
      "Epoch 2/150\n",
      "10432/10432 [==============================] - 1s 128us/step - loss: 0.7034 - regression_loss: 0.1645 - handedness_loss: 0.5383 - val_loss: 0.6320 - val_regression_loss: 0.1435 - val_handedness_loss: 0.4919\n",
      "Epoch 3/150\n",
      "10432/10432 [==============================] - 2s 144us/step - loss: 0.5748 - regression_loss: 0.1302 - handedness_loss: 0.4446 - val_loss: 0.5587 - val_regression_loss: 0.1198 - val_handedness_loss: 0.4425\n",
      "Epoch 4/150\n",
      "10432/10432 [==============================] - 2s 145us/step - loss: 0.5139 - regression_loss: 0.1172 - handedness_loss: 0.3970 - val_loss: 0.4994 - val_regression_loss: 0.1107 - val_handedness_loss: 0.3947\n",
      "Epoch 5/150\n",
      "10432/10432 [==============================] - 2s 146us/step - loss: 0.4738 - regression_loss: 0.1066 - handedness_loss: 0.3674 - val_loss: 0.4509 - val_regression_loss: 0.1046 - val_handedness_loss: 0.3533\n",
      "Epoch 6/150\n",
      "10432/10432 [==============================] - 2s 147us/step - loss: 0.4391 - regression_loss: 0.1023 - handedness_loss: 0.3364 - val_loss: 0.4228 - val_regression_loss: 0.0985 - val_handedness_loss: 0.3278\n",
      "Epoch 7/150\n",
      "10432/10432 [==============================] - 2s 147us/step - loss: 0.4121 - regression_loss: 0.0969 - handedness_loss: 0.3147 - val_loss: 0.4045 - val_regression_loss: 0.0934 - val_handedness_loss: 0.3176\n",
      "Epoch 8/150\n",
      "10432/10432 [==============================] - 2s 147us/step - loss: 0.3929 - regression_loss: 0.0896 - handedness_loss: 0.3034 - val_loss: 0.3930 - val_regression_loss: 0.0850 - val_handedness_loss: 0.3138\n",
      "Epoch 9/150\n",
      "10432/10432 [==============================] - 2s 146us/step - loss: 0.3821 - regression_loss: 0.0845 - handedness_loss: 0.2975 - val_loss: 0.3803 - val_regression_loss: 0.0811 - val_handedness_loss: 0.3046\n",
      "Epoch 10/150\n",
      "10432/10432 [==============================] - 2s 146us/step - loss: 0.3699 - regression_loss: 0.0795 - handedness_loss: 0.2901 - val_loss: 0.3861 - val_regression_loss: 0.0773 - val_handedness_loss: 0.3175\n",
      "Epoch 11/150\n",
      "10432/10432 [==============================] - 2s 147us/step - loss: 0.3656 - regression_loss: 0.0778 - handedness_loss: 0.2879 - val_loss: 0.3493 - val_regression_loss: 0.0750 - val_handedness_loss: 0.2795\n",
      "Epoch 12/150\n",
      "10432/10432 [==============================] - 2s 146us/step - loss: 0.3558 - regression_loss: 0.0759 - handedness_loss: 0.2799 - val_loss: 0.3470 - val_regression_loss: 0.0736 - val_handedness_loss: 0.2779\n",
      "Epoch 13/150\n",
      "10432/10432 [==============================] - 2s 147us/step - loss: 0.3585 - regression_loss: 0.0750 - handedness_loss: 0.2834 - val_loss: 0.3628 - val_regression_loss: 0.0726 - val_handedness_loss: 0.2964\n",
      "Epoch 14/150\n",
      "10432/10432 [==============================] - 1s 138us/step - loss: 0.3492 - regression_loss: 0.0740 - handedness_loss: 0.2751 - val_loss: 0.3437 - val_regression_loss: 0.0715 - val_handedness_loss: 0.2742\n",
      "Epoch 15/150\n",
      "10432/10432 [==============================] - 1s 140us/step - loss: 0.3469 - regression_loss: 0.0740 - handedness_loss: 0.2728 - val_loss: 0.3319 - val_regression_loss: 0.0710 - val_handedness_loss: 0.2644\n",
      "Epoch 16/150\n",
      "10432/10432 [==============================] - 1s 138us/step - loss: 0.3419 - regression_loss: 0.0736 - handedness_loss: 0.2681 - val_loss: 0.3372 - val_regression_loss: 0.0713 - val_handedness_loss: 0.2688\n",
      "Epoch 17/150\n",
      "10432/10432 [==============================] - 1s 143us/step - loss: 0.3382 - regression_loss: 0.0730 - handedness_loss: 0.2653 - val_loss: 0.3519 - val_regression_loss: 0.0711 - val_handedness_loss: 0.2918\n",
      "Epoch 18/150\n",
      "10432/10432 [==============================] - 1s 119us/step - loss: 0.3405 - regression_loss: 0.0741 - handedness_loss: 0.2662 - val_loss: 0.3307 - val_regression_loss: 0.0714 - val_handedness_loss: 0.2637\n",
      "Epoch 19/150\n",
      "10432/10432 [==============================] - 1s 136us/step - loss: 0.3432 - regression_loss: 0.0742 - handedness_loss: 0.2690 - val_loss: 0.3285 - val_regression_loss: 0.0724 - val_handedness_loss: 0.2661\n",
      "Evaluating model with testing data...\n",
      "2214/2214 [==============================] - 0s 15us/step\n",
      "Getting distribution of predictions and covariance matrix...\n",
      "      1 of 20\n",
      "      2 of 20\n",
      "      3 of 20\n",
      "      4 of 20\n",
      "      5 of 20\n",
      "      6 of 20\n",
      "      7 of 20\n",
      "      8 of 20\n",
      "      9 of 20\n",
      "      10 of 20\n",
      "      11 of 20\n",
      "      12 of 20\n",
      "      13 of 20\n",
      "      14 of 20\n",
      "      15 of 20\n",
      "      16 of 20\n",
      "      17 of 20\n",
      "      18 of 20\n",
      "      19 of 20\n",
      "      20 of 20\n",
      "Computing ensemble means...\n",
      "Computing mean squared error...\n",
      "Iteration 72\n",
      "Train on 10572 samples, validate on 2244 samples\n",
      "Epoch 1/150\n",
      "10572/10572 [==============================] - 2s 145us/step - loss: 0.9599 - regression_loss: 0.3302 - handedness_loss: 0.6286 - val_loss: 0.6847 - val_regression_loss: 0.1570 - val_handedness_loss: 0.5287\n",
      "Epoch 2/150\n",
      "10572/10572 [==============================] - 1s 126us/step - loss: 0.5991 - regression_loss: 0.1390 - handedness_loss: 0.4598 - val_loss: 0.5312 - val_regression_loss: 0.1225 - val_handedness_loss: 0.4077\n",
      "Epoch 3/150\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10572/10572 [==============================] - 1s 136us/step - loss: 0.4889 - regression_loss: 0.1201 - handedness_loss: 0.3685 - val_loss: 0.4668 - val_regression_loss: 0.1198 - val_handedness_loss: 0.3488\n",
      "Epoch 4/150\n",
      "10572/10572 [==============================] - 2s 144us/step - loss: 0.4237 - regression_loss: 0.1102 - handedness_loss: 0.3136 - val_loss: 0.3901 - val_regression_loss: 0.1069 - val_handedness_loss: 0.2848\n",
      "Epoch 5/150\n",
      "10572/10572 [==============================] - 2s 148us/step - loss: 0.3836 - regression_loss: 0.1025 - handedness_loss: 0.2815 - val_loss: 0.3626 - val_regression_loss: 0.0963 - val_handedness_loss: 0.2676\n",
      "Epoch 6/150\n",
      "10572/10572 [==============================] - 2s 149us/step - loss: 0.3647 - regression_loss: 0.0970 - handedness_loss: 0.2676 - val_loss: 0.3758 - val_regression_loss: 0.0949 - val_handedness_loss: 0.2811\n",
      "Epoch 7/150\n",
      "10572/10572 [==============================] - 2s 148us/step - loss: 0.3452 - regression_loss: 0.0891 - handedness_loss: 0.2560 - val_loss: 0.3284 - val_regression_loss: 0.0855 - val_handedness_loss: 0.2464\n",
      "Epoch 8/150\n",
      "10572/10572 [==============================] - 2s 149us/step - loss: 0.3313 - regression_loss: 0.0838 - handedness_loss: 0.2475 - val_loss: 0.3323 - val_regression_loss: 0.0807 - val_handedness_loss: 0.2499\n",
      "Epoch 9/150\n",
      "10572/10572 [==============================] - 1s 139us/step - loss: 0.3250 - regression_loss: 0.0808 - handedness_loss: 0.2445 - val_loss: 0.3223 - val_regression_loss: 0.0786 - val_handedness_loss: 0.2447\n",
      "Epoch 10/150\n",
      "10572/10572 [==============================] - 2s 146us/step - loss: 0.3131 - regression_loss: 0.0785 - handedness_loss: 0.2346 - val_loss: 0.3002 - val_regression_loss: 0.0766 - val_handedness_loss: 0.2230\n",
      "Epoch 11/150\n",
      "10572/10572 [==============================] - 2s 149us/step - loss: 0.3032 - regression_loss: 0.0760 - handedness_loss: 0.2274 - val_loss: 0.3101 - val_regression_loss: 0.0748 - val_handedness_loss: 0.2342\n",
      "Epoch 12/150\n",
      "10572/10572 [==============================] - 2s 149us/step - loss: 0.2927 - regression_loss: 0.0739 - handedness_loss: 0.2185 - val_loss: 0.2948 - val_regression_loss: 0.0722 - val_handedness_loss: 0.2227\n",
      "Epoch 13/150\n",
      "10572/10572 [==============================] - 2s 149us/step - loss: 0.2814 - regression_loss: 0.0725 - handedness_loss: 0.2091 - val_loss: 0.2767 - val_regression_loss: 0.0710 - val_handedness_loss: 0.2044\n",
      "Epoch 14/150\n",
      "10572/10572 [==============================] - 2s 150us/step - loss: 0.2796 - regression_loss: 0.0717 - handedness_loss: 0.2077 - val_loss: 0.2739 - val_regression_loss: 0.0704 - val_handedness_loss: 0.2040\n",
      "Epoch 15/150\n",
      "10572/10572 [==============================] - 2s 149us/step - loss: 0.2862 - regression_loss: 0.0715 - handedness_loss: 0.2146 - val_loss: 0.2734 - val_regression_loss: 0.0701 - val_handedness_loss: 0.2038\n",
      "Epoch 16/150\n",
      "10572/10572 [==============================] - 2s 148us/step - loss: 0.2756 - regression_loss: 0.0710 - handedness_loss: 0.2047 - val_loss: 0.2831 - val_regression_loss: 0.0703 - val_handedness_loss: 0.2127\n",
      "Epoch 17/150\n",
      "10572/10572 [==============================] - 1s 139us/step - loss: 0.2852 - regression_loss: 0.0709 - handedness_loss: 0.2143 - val_loss: 0.3043 - val_regression_loss: 0.0696 - val_handedness_loss: 0.2364\n",
      "Epoch 18/150\n",
      "10572/10572 [==============================] - 2s 148us/step - loss: 0.2758 - regression_loss: 0.0711 - handedness_loss: 0.2051 - val_loss: 0.2775 - val_regression_loss: 0.0696 - val_handedness_loss: 0.2098\n",
      "Epoch 19/150\n",
      "10572/10572 [==============================] - 1s 138us/step - loss: 0.2747 - regression_loss: 0.0712 - handedness_loss: 0.2031 - val_loss: 0.2693 - val_regression_loss: 0.0699 - val_handedness_loss: 0.2004\n",
      "Epoch 20/150\n",
      "10572/10572 [==============================] - 1s 129us/step - loss: 0.2589 - regression_loss: 0.0704 - handedness_loss: 0.1881 - val_loss: 0.2557 - val_regression_loss: 0.0699 - val_handedness_loss: 0.1862\n",
      "Epoch 21/150\n",
      "10572/10572 [==============================] - 2s 144us/step - loss: 0.2697 - regression_loss: 0.0709 - handedness_loss: 0.1986 - val_loss: 0.2654 - val_regression_loss: 0.0689 - val_handedness_loss: 0.1953\n",
      "Epoch 22/150\n",
      "10572/10572 [==============================] - 2s 148us/step - loss: 0.2603 - regression_loss: 0.0706 - handedness_loss: 0.1895 - val_loss: 0.2794 - val_regression_loss: 0.0689 - val_handedness_loss: 0.2113\n",
      "Epoch 23/150\n",
      "10572/10572 [==============================] - 1s 106us/step - loss: 0.2654 - regression_loss: 0.0708 - handedness_loss: 0.1948 - val_loss: 0.2825 - val_regression_loss: 0.0695 - val_handedness_loss: 0.2139\n",
      "Epoch 24/150\n",
      "10572/10572 [==============================] - 1s 85us/step - loss: 0.2650 - regression_loss: 0.0709 - handedness_loss: 0.1942 - val_loss: 0.2758 - val_regression_loss: 0.0704 - val_handedness_loss: 0.2053\n",
      "Evaluating model with testing data...\n",
      "2244/2244 [==============================] - 0s 15us/step\n",
      "Getting distribution of predictions and covariance matrix...\n",
      "      1 of 20\n",
      "      2 of 20\n",
      "      3 of 20\n",
      "      4 of 20\n",
      "      5 of 20\n",
      "      6 of 20\n",
      "      7 of 20\n",
      "      8 of 20\n",
      "      9 of 20\n",
      "      10 of 20\n",
      "      11 of 20\n",
      "      12 of 20\n",
      "      13 of 20\n",
      "      14 of 20\n",
      "      15 of 20\n",
      "      16 of 20\n",
      "      17 of 20\n",
      "      18 of 20\n",
      "      19 of 20\n",
      "      20 of 20\n",
      "Computing ensemble means...\n",
      "Computing mean squared error...\n",
      "Iteration 73\n",
      "Train on 10712 samples, validate on 2274 samples\n",
      "Epoch 1/150\n",
      "10712/10712 [==============================] - 1s 133us/step - loss: 1.0658 - regression_loss: 0.3809 - handedness_loss: 0.6843 - val_loss: 0.9370 - val_regression_loss: 0.2647 - val_handedness_loss: 0.6725\n",
      "Epoch 2/150\n",
      "10712/10712 [==============================] - 1s 134us/step - loss: 0.8766 - regression_loss: 0.2249 - handedness_loss: 0.6515 - val_loss: 0.8208 - val_regression_loss: 0.1896 - val_handedness_loss: 0.6312\n",
      "Epoch 3/150\n",
      "10712/10712 [==============================] - 2s 142us/step - loss: 0.7701 - regression_loss: 0.1729 - handedness_loss: 0.5970 - val_loss: 0.7109 - val_regression_loss: 0.1568 - val_handedness_loss: 0.5545\n",
      "Epoch 4/150\n",
      "10712/10712 [==============================] - 2s 145us/step - loss: 0.6845 - regression_loss: 0.1448 - handedness_loss: 0.5396 - val_loss: 0.6501 - val_regression_loss: 0.1311 - val_handedness_loss: 0.5188\n",
      "Epoch 5/150\n",
      "10712/10712 [==============================] - 1s 140us/step - loss: 0.6314 - regression_loss: 0.1252 - handedness_loss: 0.5062 - val_loss: 0.6118 - val_regression_loss: 0.1154 - val_handedness_loss: 0.4972\n",
      "Epoch 6/150\n",
      "10712/10712 [==============================] - 2s 143us/step - loss: 0.5974 - regression_loss: 0.1097 - handedness_loss: 0.4876 - val_loss: 0.5739 - val_regression_loss: 0.1013 - val_handedness_loss: 0.4728\n",
      "Epoch 7/150\n",
      "10712/10712 [==============================] - 2s 146us/step - loss: 0.5804 - regression_loss: 0.0996 - handedness_loss: 0.4810 - val_loss: 0.5775 - val_regression_loss: 0.0934 - val_handedness_loss: 0.4836\n",
      "Epoch 8/150\n",
      "10712/10712 [==============================] - 1s 137us/step - loss: 0.5538 - regression_loss: 0.0920 - handedness_loss: 0.4616 - val_loss: 0.5599 - val_regression_loss: 0.0879 - val_handedness_loss: 0.4715\n",
      "Epoch 9/150\n",
      "10712/10712 [==============================] - 2s 144us/step - loss: 0.5268 - regression_loss: 0.0859 - handedness_loss: 0.4407 - val_loss: 0.5203 - val_regression_loss: 0.0823 - val_handedness_loss: 0.4376\n",
      "Epoch 10/150\n",
      "10712/10712 [==============================] - 1s 131us/step - loss: 0.4888 - regression_loss: 0.0825 - handedness_loss: 0.4063 - val_loss: 0.4858 - val_regression_loss: 0.0792 - val_handedness_loss: 0.4059\n",
      "Epoch 11/150\n",
      "10712/10712 [==============================] - 1s 125us/step - loss: 0.4568 - regression_loss: 0.0795 - handedness_loss: 0.3774 - val_loss: 0.4497 - val_regression_loss: 0.0768 - val_handedness_loss: 0.3724\n",
      "Epoch 12/150\n",
      "10712/10712 [==============================] - 1s 136us/step - loss: 0.4515 - regression_loss: 0.0784 - handedness_loss: 0.3729 - val_loss: 0.4420 - val_regression_loss: 0.0756 - val_handedness_loss: 0.3656\n",
      "Epoch 13/150\n",
      "10712/10712 [==============================] - 1s 136us/step - loss: 0.4366 - regression_loss: 0.0775 - handedness_loss: 0.3589 - val_loss: 0.4215 - val_regression_loss: 0.0752 - val_handedness_loss: 0.3458\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 14/150\n",
      "10712/10712 [==============================] - 2s 142us/step - loss: 0.4355 - regression_loss: 0.0777 - handedness_loss: 0.3578 - val_loss: 0.4278 - val_regression_loss: 0.0752 - val_handedness_loss: 0.3524\n",
      "Epoch 15/150\n",
      "10712/10712 [==============================] - 2s 144us/step - loss: 0.4232 - regression_loss: 0.0771 - handedness_loss: 0.3463 - val_loss: 0.4162 - val_regression_loss: 0.0753 - val_handedness_loss: 0.3416\n",
      "Epoch 16/150\n",
      "10712/10712 [==============================] - 2s 146us/step - loss: 0.4249 - regression_loss: 0.0771 - handedness_loss: 0.3477 - val_loss: 0.4288 - val_regression_loss: 0.0752 - val_handedness_loss: 0.3534\n",
      "Epoch 17/150\n",
      "10712/10712 [==============================] - 2s 146us/step - loss: 0.4177 - regression_loss: 0.0771 - handedness_loss: 0.3405 - val_loss: 0.4094 - val_regression_loss: 0.0750 - val_handedness_loss: 0.3335\n",
      "Epoch 18/150\n",
      "10712/10712 [==============================] - 2s 146us/step - loss: 0.4175 - regression_loss: 0.0771 - handedness_loss: 0.3404 - val_loss: 0.4103 - val_regression_loss: 0.0752 - val_handedness_loss: 0.3347\n",
      "Epoch 19/150\n",
      "10712/10712 [==============================] - 2s 146us/step - loss: 0.4129 - regression_loss: 0.0771 - handedness_loss: 0.3359 - val_loss: 0.4076 - val_regression_loss: 0.0750 - val_handedness_loss: 0.3315\n",
      "Epoch 20/150\n",
      "10712/10712 [==============================] - 2s 148us/step - loss: 0.4048 - regression_loss: 0.0768 - handedness_loss: 0.3277 - val_loss: 0.3910 - val_regression_loss: 0.0749 - val_handedness_loss: 0.3162\n",
      "Epoch 21/150\n",
      "10712/10712 [==============================] - 2s 146us/step - loss: 0.4000 - regression_loss: 0.0771 - handedness_loss: 0.3227 - val_loss: 0.3795 - val_regression_loss: 0.0761 - val_handedness_loss: 0.3037\n",
      "Epoch 22/150\n",
      "10712/10712 [==============================] - 2s 146us/step - loss: 0.4070 - regression_loss: 0.0771 - handedness_loss: 0.3301 - val_loss: 0.3993 - val_regression_loss: 0.0748 - val_handedness_loss: 0.3251\n",
      "Epoch 23/150\n",
      "10712/10712 [==============================] - 2s 147us/step - loss: 0.3969 - regression_loss: 0.0770 - handedness_loss: 0.3199 - val_loss: 0.3952 - val_regression_loss: 0.0753 - val_handedness_loss: 0.3193\n",
      "Epoch 24/150\n",
      "10712/10712 [==============================] - 2s 147us/step - loss: 0.4002 - regression_loss: 0.0772 - handedness_loss: 0.3229 - val_loss: 0.3830 - val_regression_loss: 0.0760 - val_handedness_loss: 0.3065\n",
      "Epoch 25/150\n",
      "10712/10712 [==============================] - 2s 146us/step - loss: 0.3995 - regression_loss: 0.0773 - handedness_loss: 0.3223 - val_loss: 0.3754 - val_regression_loss: 0.0762 - val_handedness_loss: 0.2980\n",
      "Epoch 26/150\n",
      "10712/10712 [==============================] - 2s 146us/step - loss: 0.3930 - regression_loss: 0.0773 - handedness_loss: 0.3157 - val_loss: 0.3698 - val_regression_loss: 0.0749 - val_handedness_loss: 0.2941\n",
      "Evaluating model with testing data...\n",
      "2274/2274 [==============================] - 0s 16us/step\n",
      "Getting distribution of predictions and covariance matrix...\n",
      "      1 of 20\n",
      "      2 of 20\n",
      "      3 of 20\n",
      "      4 of 20\n",
      "      5 of 20\n",
      "      6 of 20\n",
      "      7 of 20\n",
      "      8 of 20\n",
      "      9 of 20\n",
      "      10 of 20\n",
      "      11 of 20\n",
      "      12 of 20\n",
      "      13 of 20\n",
      "      14 of 20\n",
      "      15 of 20\n",
      "      16 of 20\n",
      "      17 of 20\n",
      "      18 of 20\n",
      "      19 of 20\n",
      "      20 of 20\n",
      "Computing ensemble means...\n",
      "Computing mean squared error...\n",
      "Iteration 74\n",
      "Train on 10852 samples, validate on 2304 samples\n",
      "Epoch 1/150\n",
      "10852/10852 [==============================] - 1s 132us/step - loss: 0.9948 - regression_loss: 0.3311 - handedness_loss: 0.6633 - val_loss: 0.8129 - val_regression_loss: 0.1952 - val_handedness_loss: 0.6177\n",
      "Epoch 2/150\n",
      "10852/10852 [==============================] - 1s 132us/step - loss: 0.7111 - regression_loss: 0.1609 - handedness_loss: 0.5501 - val_loss: 0.6156 - val_regression_loss: 0.1401 - val_handedness_loss: 0.4756\n",
      "Epoch 3/150\n",
      "10852/10852 [==============================] - 1s 128us/step - loss: 0.5637 - regression_loss: 0.1289 - handedness_loss: 0.4345 - val_loss: 0.5048 - val_regression_loss: 0.1177 - val_handedness_loss: 0.3871\n",
      "Epoch 4/150\n",
      "10852/10852 [==============================] - 2s 139us/step - loss: 0.4807 - regression_loss: 0.1144 - handedness_loss: 0.3663 - val_loss: 0.4558 - val_regression_loss: 0.1087 - val_handedness_loss: 0.3471\n",
      "Epoch 5/150\n",
      "10852/10852 [==============================] - 2s 145us/step - loss: 0.4371 - regression_loss: 0.1052 - handedness_loss: 0.3319 - val_loss: 0.4267 - val_regression_loss: 0.1011 - val_handedness_loss: 0.3255\n",
      "Epoch 6/150\n",
      "10852/10852 [==============================] - 1s 136us/step - loss: 0.4126 - regression_loss: 0.0994 - handedness_loss: 0.3131 - val_loss: 0.3991 - val_regression_loss: 0.0931 - val_handedness_loss: 0.3060\n",
      "Epoch 7/150\n",
      "10852/10852 [==============================] - 1s 136us/step - loss: 0.3869 - regression_loss: 0.0914 - handedness_loss: 0.2953 - val_loss: 0.3817 - val_regression_loss: 0.0893 - val_handedness_loss: 0.2924\n",
      "Epoch 8/150\n",
      "10852/10852 [==============================] - 2s 144us/step - loss: 0.3760 - regression_loss: 0.0875 - handedness_loss: 0.2883 - val_loss: 0.3711 - val_regression_loss: 0.0855 - val_handedness_loss: 0.2856\n",
      "Epoch 9/150\n",
      "10852/10852 [==============================] - 2s 147us/step - loss: 0.3616 - regression_loss: 0.0834 - handedness_loss: 0.2783 - val_loss: 0.3438 - val_regression_loss: 0.0802 - val_handedness_loss: 0.2636\n",
      "Epoch 10/150\n",
      "10852/10852 [==============================] - 2s 148us/step - loss: 0.3405 - regression_loss: 0.0805 - handedness_loss: 0.2601 - val_loss: 0.3475 - val_regression_loss: 0.0775 - val_handedness_loss: 0.2700\n",
      "Epoch 11/150\n",
      "10852/10852 [==============================] - 1s 134us/step - loss: 0.3341 - regression_loss: 0.0781 - handedness_loss: 0.2561 - val_loss: 0.3243 - val_regression_loss: 0.0752 - val_handedness_loss: 0.2490\n",
      "Epoch 12/150\n",
      "10852/10852 [==============================] - 2s 144us/step - loss: 0.3256 - regression_loss: 0.0760 - handedness_loss: 0.2496 - val_loss: 0.3285 - val_regression_loss: 0.0741 - val_handedness_loss: 0.2545\n",
      "Epoch 13/150\n",
      "10852/10852 [==============================] - 1s 137us/step - loss: 0.3226 - regression_loss: 0.0752 - handedness_loss: 0.2475 - val_loss: 0.3032 - val_regression_loss: 0.0718 - val_handedness_loss: 0.2313\n",
      "Epoch 14/150\n",
      "10852/10852 [==============================] - 2s 148us/step - loss: 0.3161 - regression_loss: 0.0750 - handedness_loss: 0.2411 - val_loss: 0.3076 - val_regression_loss: 0.0737 - val_handedness_loss: 0.2339\n",
      "Epoch 15/150\n",
      "10852/10852 [==============================] - 1s 138us/step - loss: 0.3073 - regression_loss: 0.0736 - handedness_loss: 0.2336 - val_loss: 0.2886 - val_regression_loss: 0.0710 - val_handedness_loss: 0.2176\n",
      "Epoch 16/150\n",
      "10852/10852 [==============================] - 2s 145us/step - loss: 0.3001 - regression_loss: 0.0736 - handedness_loss: 0.2264 - val_loss: 0.2984 - val_regression_loss: 0.0707 - val_handedness_loss: 0.2277\n",
      "Epoch 17/150\n",
      "10852/10852 [==============================] - 2s 147us/step - loss: 0.3084 - regression_loss: 0.0743 - handedness_loss: 0.2341 - val_loss: 0.2984 - val_regression_loss: 0.0721 - val_handedness_loss: 0.2262\n",
      "Epoch 18/150\n",
      "10852/10852 [==============================] - 2s 142us/step - loss: 0.3030 - regression_loss: 0.0732 - handedness_loss: 0.2298 - val_loss: 0.2877 - val_regression_loss: 0.0705 - val_handedness_loss: 0.2172\n",
      "Epoch 19/150\n",
      "10852/10852 [==============================] - 2s 145us/step - loss: 0.3055 - regression_loss: 0.0735 - handedness_loss: 0.2320 - val_loss: 0.2905 - val_regression_loss: 0.0715 - val_handedness_loss: 0.2190\n",
      "Epoch 20/150\n",
      "10852/10852 [==============================] - 1s 132us/step - loss: 0.2984 - regression_loss: 0.0728 - handedness_loss: 0.2254 - val_loss: 0.2755 - val_regression_loss: 0.0704 - val_handedness_loss: 0.2051\n",
      "Epoch 21/150\n",
      "10852/10852 [==============================] - 1s 135us/step - loss: 0.2830 - regression_loss: 0.0724 - handedness_loss: 0.2106 - val_loss: 0.2832 - val_regression_loss: 0.0704 - val_handedness_loss: 0.2129\n",
      "Epoch 22/150\n",
      "10852/10852 [==============================] - 2s 145us/step - loss: 0.2801 - regression_loss: 0.0722 - handedness_loss: 0.2078 - val_loss: 0.2904 - val_regression_loss: 0.0709 - val_handedness_loss: 0.2194\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 23/150\n",
      "10852/10852 [==============================] - 2s 148us/step - loss: 0.2859 - regression_loss: 0.0723 - handedness_loss: 0.2136 - val_loss: 0.2992 - val_regression_loss: 0.0712 - val_handedness_loss: 0.2280\n",
      "Epoch 24/150\n",
      "10852/10852 [==============================] - 1s 137us/step - loss: 0.2779 - regression_loss: 0.0722 - handedness_loss: 0.2057 - val_loss: 0.2848 - val_regression_loss: 0.0710 - val_handedness_loss: 0.2138\n",
      "Evaluating model with testing data...\n",
      "2304/2304 [==============================] - 0s 16us/step\n",
      "Getting distribution of predictions and covariance matrix...\n",
      "      1 of 20\n",
      "      2 of 20\n",
      "      3 of 20\n",
      "      4 of 20\n",
      "      5 of 20\n",
      "      6 of 20\n",
      "      7 of 20\n",
      "      8 of 20\n",
      "      9 of 20\n",
      "      10 of 20\n",
      "      11 of 20\n",
      "      12 of 20\n",
      "      13 of 20\n",
      "      14 of 20\n",
      "      15 of 20\n",
      "      16 of 20\n",
      "      17 of 20\n",
      "      18 of 20\n",
      "      19 of 20\n",
      "      20 of 20\n",
      "Computing ensemble means...\n",
      "Computing mean squared error...\n",
      "Iteration 75\n",
      "Train on 10992 samples, validate on 2334 samples\n",
      "Epoch 1/150\n",
      "10992/10992 [==============================] - 2s 143us/step - loss: 1.0695 - regression_loss: 0.3760 - handedness_loss: 0.6933 - val_loss: 0.9381 - val_regression_loss: 0.2579 - val_handedness_loss: 0.6781\n",
      "Epoch 2/150\n",
      "10992/10992 [==============================] - 2s 138us/step - loss: 0.8880 - regression_loss: 0.2227 - handedness_loss: 0.6652 - val_loss: 0.8104 - val_regression_loss: 0.1553 - val_handedness_loss: 0.6548\n",
      "Epoch 3/150\n",
      "10992/10992 [==============================] - 1s 133us/step - loss: 0.7777 - regression_loss: 0.1408 - handedness_loss: 0.6368 - val_loss: 0.7474 - val_regression_loss: 0.1301 - val_handedness_loss: 0.6178\n",
      "Epoch 4/150\n",
      "10992/10992 [==============================] - 2s 142us/step - loss: 0.7418 - regression_loss: 0.1248 - handedness_loss: 0.6170 - val_loss: 0.7279 - val_regression_loss: 0.1174 - val_handedness_loss: 0.6110\n",
      "Epoch 5/150\n",
      "10992/10992 [==============================] - 2s 145us/step - loss: 0.7186 - regression_loss: 0.1156 - handedness_loss: 0.6029 - val_loss: 0.7053 - val_regression_loss: 0.1086 - val_handedness_loss: 0.5986\n",
      "Epoch 6/150\n",
      "10992/10992 [==============================] - 2s 148us/step - loss: 0.7086 - regression_loss: 0.1074 - handedness_loss: 0.6012 - val_loss: 0.6913 - val_regression_loss: 0.0980 - val_handedness_loss: 0.5924\n",
      "Epoch 7/150\n",
      "10992/10992 [==============================] - 2s 147us/step - loss: 0.6796 - regression_loss: 0.1025 - handedness_loss: 0.5772 - val_loss: 0.6716 - val_regression_loss: 0.0961 - val_handedness_loss: 0.5735\n",
      "Epoch 8/150\n",
      "10992/10992 [==============================] - 1s 121us/step - loss: 0.6467 - regression_loss: 0.0969 - handedness_loss: 0.5497 - val_loss: 0.6281 - val_regression_loss: 0.0908 - val_handedness_loss: 0.5368\n",
      "Epoch 9/150\n",
      "10992/10992 [==============================] - 2s 141us/step - loss: 0.6220 - regression_loss: 0.0901 - handedness_loss: 0.5320 - val_loss: 0.6091 - val_regression_loss: 0.0850 - val_handedness_loss: 0.5241\n",
      "Epoch 10/150\n",
      "10992/10992 [==============================] - 2s 145us/step - loss: 0.6160 - regression_loss: 0.0863 - handedness_loss: 0.5298 - val_loss: 0.6115 - val_regression_loss: 0.0828 - val_handedness_loss: 0.5266\n",
      "Epoch 11/150\n",
      "10992/10992 [==============================] - 2s 147us/step - loss: 0.6121 - regression_loss: 0.0843 - handedness_loss: 0.5278 - val_loss: 0.5928 - val_regression_loss: 0.0812 - val_handedness_loss: 0.5146\n",
      "Epoch 12/150\n",
      "10992/10992 [==============================] - 2s 147us/step - loss: 0.6001 - regression_loss: 0.0834 - handedness_loss: 0.5168 - val_loss: 0.5936 - val_regression_loss: 0.0889 - val_handedness_loss: 0.5029\n",
      "Epoch 13/150\n",
      "10992/10992 [==============================] - 2s 144us/step - loss: 0.5725 - regression_loss: 0.0830 - handedness_loss: 0.4896 - val_loss: 0.5511 - val_regression_loss: 0.0777 - val_handedness_loss: 0.4728\n",
      "Epoch 14/150\n",
      "10992/10992 [==============================] - 2s 147us/step - loss: 0.5475 - regression_loss: 0.0806 - handedness_loss: 0.4670 - val_loss: 0.5321 - val_regression_loss: 0.0791 - val_handedness_loss: 0.4520\n",
      "Epoch 15/150\n",
      "10992/10992 [==============================] - 2s 140us/step - loss: 0.5455 - regression_loss: 0.0806 - handedness_loss: 0.4648 - val_loss: 0.5479 - val_regression_loss: 0.0787 - val_handedness_loss: 0.4689\n",
      "Epoch 16/150\n",
      "10992/10992 [==============================] - 1s 136us/step - loss: 0.5394 - regression_loss: 0.0805 - handedness_loss: 0.4589 - val_loss: 0.5241 - val_regression_loss: 0.0791 - val_handedness_loss: 0.4480\n",
      "Epoch 17/150\n",
      "10992/10992 [==============================] - 2s 146us/step - loss: 0.5358 - regression_loss: 0.0814 - handedness_loss: 0.4544 - val_loss: 0.5347 - val_regression_loss: 0.0782 - val_handedness_loss: 0.4576\n",
      "Evaluating model with testing data...\n",
      "2334/2334 [==============================] - 0s 16us/step\n",
      "Getting distribution of predictions and covariance matrix...\n",
      "      1 of 20\n",
      "      2 of 20\n",
      "      3 of 20\n",
      "      4 of 20\n",
      "      5 of 20\n",
      "      6 of 20\n",
      "      7 of 20\n",
      "      8 of 20\n",
      "      9 of 20\n",
      "      10 of 20\n",
      "      11 of 20\n",
      "      12 of 20\n",
      "      13 of 20\n",
      "      14 of 20\n",
      "      15 of 20\n",
      "      16 of 20\n",
      "      17 of 20\n",
      "      18 of 20\n",
      "      19 of 20\n",
      "      20 of 20\n",
      "Computing ensemble means...\n",
      "Computing mean squared error...\n",
      "Iteration 76\n",
      "Train on 11132 samples, validate on 2364 samples\n",
      "Epoch 1/150\n",
      "11132/11132 [==============================] - 2s 144us/step - loss: 1.0839 - regression_loss: 0.4061 - handedness_loss: 0.6777 - val_loss: 0.8760 - val_regression_loss: 0.2149 - val_handedness_loss: 0.6622\n",
      "Epoch 2/150\n",
      "11132/11132 [==============================] - 1s 128us/step - loss: 0.8110 - regression_loss: 0.1840 - handedness_loss: 0.6270 - val_loss: 0.7527 - val_regression_loss: 0.1620 - val_handedness_loss: 0.5920\n",
      "Epoch 3/150\n",
      "11132/11132 [==============================] - 2s 145us/step - loss: 0.6835 - regression_loss: 0.1523 - handedness_loss: 0.5312 - val_loss: 0.6113 - val_regression_loss: 0.1377 - val_handedness_loss: 0.4733\n",
      "Epoch 4/150\n",
      "11132/11132 [==============================] - 2s 147us/step - loss: 0.5738 - regression_loss: 0.1349 - handedness_loss: 0.4388 - val_loss: 0.5387 - val_regression_loss: 0.1292 - val_handedness_loss: 0.4118\n",
      "Epoch 5/150\n",
      "11132/11132 [==============================] - 2s 148us/step - loss: 0.5185 - regression_loss: 0.1225 - handedness_loss: 0.3959 - val_loss: 0.4803 - val_regression_loss: 0.1136 - val_handedness_loss: 0.3660\n",
      "Epoch 6/150\n",
      "11132/11132 [==============================] - 1s 83us/step - loss: 0.4882 - regression_loss: 0.1084 - handedness_loss: 0.3798 - val_loss: 0.4722 - val_regression_loss: 0.1011 - val_handedness_loss: 0.3702\n",
      "Epoch 7/150\n",
      "11132/11132 [==============================] - 1s 97us/step - loss: 0.4634 - regression_loss: 0.0988 - handedness_loss: 0.3646 - val_loss: 0.4463 - val_regression_loss: 0.0923 - val_handedness_loss: 0.3529\n",
      "Epoch 8/150\n",
      "11132/11132 [==============================] - 2s 143us/step - loss: 0.4480 - regression_loss: 0.0909 - handedness_loss: 0.3570 - val_loss: 0.4489 - val_regression_loss: 0.0867 - val_handedness_loss: 0.3611\n",
      "Epoch 9/150\n",
      "11132/11132 [==============================] - 2s 139us/step - loss: 0.4367 - regression_loss: 0.0859 - handedness_loss: 0.3508 - val_loss: 0.4331 - val_regression_loss: 0.0818 - val_handedness_loss: 0.3531\n",
      "Epoch 10/150\n",
      "11132/11132 [==============================] - 1s 121us/step - loss: 0.4298 - regression_loss: 0.0822 - handedness_loss: 0.3476 - val_loss: 0.4236 - val_regression_loss: 0.0802 - val_handedness_loss: 0.3449\n",
      "Epoch 11/150\n",
      "11132/11132 [==============================] - 1s 128us/step - loss: 0.4233 - regression_loss: 0.0800 - handedness_loss: 0.3433 - val_loss: 0.4160 - val_regression_loss: 0.0786 - val_handedness_loss: 0.3376\n",
      "Epoch 12/150\n",
      "11132/11132 [==============================] - 1s 128us/step - loss: 0.4148 - regression_loss: 0.0787 - handedness_loss: 0.3361 - val_loss: 0.4167 - val_regression_loss: 0.0766 - val_handedness_loss: 0.3393\n",
      "Epoch 13/150\n",
      "11132/11132 [==============================] - 2s 137us/step - loss: 0.4104 - regression_loss: 0.0777 - handedness_loss: 0.3327 - val_loss: 0.4077 - val_regression_loss: 0.0759 - val_handedness_loss: 0.3310\n",
      "Epoch 14/150\n",
      "11132/11132 [==============================] - 2s 145us/step - loss: 0.4084 - regression_loss: 0.0774 - handedness_loss: 0.3309 - val_loss: 0.4029 - val_regression_loss: 0.0750 - val_handedness_loss: 0.3305\n",
      "Epoch 15/150\n",
      "11132/11132 [==============================] - 2s 147us/step - loss: 0.3998 - regression_loss: 0.0771 - handedness_loss: 0.3227 - val_loss: 0.4036 - val_regression_loss: 0.0758 - val_handedness_loss: 0.3278\n",
      "Epoch 16/150\n",
      "11132/11132 [==============================] - 2s 148us/step - loss: 0.4091 - regression_loss: 0.0772 - handedness_loss: 0.3319 - val_loss: 0.4166 - val_regression_loss: 0.0753 - val_handedness_loss: 0.3397\n",
      "Epoch 17/150\n",
      "11132/11132 [==============================] - 2s 148us/step - loss: 0.4071 - regression_loss: 0.0769 - handedness_loss: 0.3302 - val_loss: 0.4065 - val_regression_loss: 0.0761 - val_handedness_loss: 0.3301\n",
      "Epoch 18/150\n",
      "11132/11132 [==============================] - 2s 148us/step - loss: 0.4027 - regression_loss: 0.0771 - handedness_loss: 0.3256 - val_loss: 0.4239 - val_regression_loss: 0.0763 - val_handedness_loss: 0.3497\n",
      "Evaluating model with testing data...\n",
      "2364/2364 [==============================] - 0s 16us/step\n",
      "Getting distribution of predictions and covariance matrix...\n",
      "      1 of 20\n",
      "      2 of 20\n",
      "      3 of 20\n",
      "      4 of 20\n",
      "      5 of 20\n",
      "      6 of 20\n",
      "      7 of 20\n",
      "      8 of 20\n",
      "      9 of 20\n",
      "      10 of 20\n",
      "      11 of 20\n",
      "      12 of 20\n",
      "      13 of 20\n",
      "      14 of 20\n",
      "      15 of 20\n",
      "      16 of 20\n",
      "      17 of 20\n",
      "      18 of 20\n",
      "      19 of 20\n",
      "      20 of 20\n",
      "Computing ensemble means...\n",
      "Computing mean squared error...\n",
      "Iteration 77\n",
      "Train on 11272 samples, validate on 2394 samples\n",
      "Epoch 1/150\n",
      "11272/11272 [==============================] - 1s 125us/step - loss: 1.0057 - regression_loss: 0.3339 - handedness_loss: 0.6718 - val_loss: 0.8345 - val_regression_loss: 0.1912 - val_handedness_loss: 0.6439\n",
      "Epoch 2/150\n",
      "11272/11272 [==============================] - 1s 133us/step - loss: 0.7592 - regression_loss: 0.1715 - handedness_loss: 0.5867 - val_loss: 0.6890 - val_regression_loss: 0.1579 - val_handedness_loss: 0.5315\n",
      "Epoch 3/150\n",
      "11272/11272 [==============================] - 2s 143us/step - loss: 0.6138 - regression_loss: 0.1387 - handedness_loss: 0.4727 - val_loss: 0.5525 - val_regression_loss: 0.1251 - val_handedness_loss: 0.4277\n",
      "Epoch 4/150\n",
      "11272/11272 [==============================] - 2s 145us/step - loss: 0.5291 - regression_loss: 0.1185 - handedness_loss: 0.4113 - val_loss: 0.4937 - val_regression_loss: 0.1123 - val_handedness_loss: 0.3820\n",
      "Epoch 5/150\n",
      "11272/11272 [==============================] - 2s 147us/step - loss: 0.4898 - regression_loss: 0.1120 - handedness_loss: 0.3859 - val_loss: 0.4576 - val_regression_loss: 0.1085 - val_handedness_loss: 0.3497\n",
      "Epoch 6/150\n",
      "11272/11272 [==============================] - 2s 147us/step - loss: 0.4539 - regression_loss: 0.1041 - handedness_loss: 0.3491 - val_loss: 0.4184 - val_regression_loss: 0.0981 - val_handedness_loss: 0.3200\n",
      "Epoch 7/150\n",
      "11272/11272 [==============================] - 2s 147us/step - loss: 0.4052 - regression_loss: 0.0931 - handedness_loss: 0.3141 - val_loss: 0.4146 - val_regression_loss: 0.0922 - val_handedness_loss: 0.3232\n",
      "Epoch 8/150\n",
      "11272/11272 [==============================] - 2s 147us/step - loss: 0.3941 - regression_loss: 0.0862 - handedness_loss: 0.3075 - val_loss: 0.3847 - val_regression_loss: 0.0834 - val_handedness_loss: 0.3015\n",
      "Epoch 9/150\n",
      "11272/11272 [==============================] - 2s 147us/step - loss: 0.3612 - regression_loss: 0.0800 - handedness_loss: 0.2803 - val_loss: 0.3441 - val_regression_loss: 0.0766 - val_handedness_loss: 0.2674\n",
      "Epoch 10/150\n",
      "11272/11272 [==============================] - 2s 146us/step - loss: 0.3417 - regression_loss: 0.0763 - handedness_loss: 0.2668 - val_loss: 0.3228 - val_regression_loss: 0.0741 - val_handedness_loss: 0.2506\n",
      "Epoch 11/150\n",
      "11272/11272 [==============================] - 2s 147us/step - loss: 0.3278 - regression_loss: 0.0736 - handedness_loss: 0.2548 - val_loss: 0.3284 - val_regression_loss: 0.0724 - val_handedness_loss: 0.2575\n",
      "Epoch 12/150\n",
      "11272/11272 [==============================] - 2s 147us/step - loss: 0.3148 - regression_loss: 0.0727 - handedness_loss: 0.2402 - val_loss: 0.3049 - val_regression_loss: 0.0721 - val_handedness_loss: 0.2346\n",
      "Epoch 13/150\n",
      "11272/11272 [==============================] - 2s 140us/step - loss: 0.3095 - regression_loss: 0.0725 - handedness_loss: 0.2353 - val_loss: 0.3371 - val_regression_loss: 0.0730 - val_handedness_loss: 0.2644\n",
      "Epoch 14/150\n",
      "11272/11272 [==============================] - 2s 136us/step - loss: 0.3154 - regression_loss: 0.0725 - handedness_loss: 0.2423 - val_loss: 0.3153 - val_regression_loss: 0.0711 - val_handedness_loss: 0.2449\n",
      "Epoch 15/150\n",
      "11272/11272 [==============================] - 2s 142us/step - loss: 0.3085 - regression_loss: 0.0721 - handedness_loss: 0.2361 - val_loss: 0.2876 - val_regression_loss: 0.0712 - val_handedness_loss: 0.2184\n",
      "Epoch 16/150\n",
      "11272/11272 [==============================] - 2s 147us/step - loss: 0.2993 - regression_loss: 0.0714 - handedness_loss: 0.2265 - val_loss: 0.2906 - val_regression_loss: 0.0704 - val_handedness_loss: 0.2221\n",
      "Epoch 17/150\n",
      "11272/11272 [==============================] - 2s 136us/step - loss: 0.2996 - regression_loss: 0.0719 - handedness_loss: 0.2272 - val_loss: 0.2928 - val_regression_loss: 0.0711 - val_handedness_loss: 0.2230\n",
      "Epoch 18/150\n",
      "11272/11272 [==============================] - 2s 147us/step - loss: 0.3010 - regression_loss: 0.0732 - handedness_loss: 0.2263 - val_loss: 0.2910 - val_regression_loss: 0.0717 - val_handedness_loss: 0.2202\n",
      "Epoch 19/150\n",
      "11272/11272 [==============================] - 1s 130us/step - loss: 0.2907 - regression_loss: 0.0723 - handedness_loss: 0.2169 - val_loss: 0.2827 - val_regression_loss: 0.0715 - val_handedness_loss: 0.2114\n",
      "Epoch 20/150\n",
      "11272/11272 [==============================] - 2s 142us/step - loss: 0.2914 - regression_loss: 0.0725 - handedness_loss: 0.2190 - val_loss: 0.2799 - val_regression_loss: 0.0724 - val_handedness_loss: 0.2081\n",
      "Evaluating model with testing data...\n",
      "2394/2394 [==============================] - 0s 16us/step\n",
      "Getting distribution of predictions and covariance matrix...\n",
      "      1 of 20\n",
      "      2 of 20\n",
      "      3 of 20\n",
      "      4 of 20\n",
      "      5 of 20\n",
      "      6 of 20\n",
      "      7 of 20\n",
      "      8 of 20\n",
      "      9 of 20\n",
      "      10 of 20\n",
      "      11 of 20\n",
      "      12 of 20\n",
      "      13 of 20\n",
      "      14 of 20\n",
      "      15 of 20\n",
      "      16 of 20\n",
      "      17 of 20\n",
      "      18 of 20\n",
      "      19 of 20\n",
      "      20 of 20\n",
      "Computing ensemble means...\n",
      "Computing mean squared error...\n",
      "Iteration 78\n",
      "Train on 11412 samples, validate on 2424 samples\n",
      "Epoch 1/150\n",
      "11412/11412 [==============================] - 2s 133us/step - loss: 1.0702 - regression_loss: 0.3771 - handedness_loss: 0.6911 - val_loss: 0.8660 - val_regression_loss: 0.1938 - val_handedness_loss: 0.6721\n",
      "Epoch 2/150\n",
      "11412/11412 [==============================] - 2s 132us/step - loss: 0.7811 - regression_loss: 0.1526 - handedness_loss: 0.6286 - val_loss: 0.7121 - val_regression_loss: 0.1385 - val_handedness_loss: 0.5735\n",
      "Epoch 3/150\n",
      "11412/11412 [==============================] - 2s 142us/step - loss: 0.6677 - regression_loss: 0.1286 - handedness_loss: 0.5393 - val_loss: 0.6198 - val_regression_loss: 0.1221 - val_handedness_loss: 0.4975\n",
      "Epoch 4/150\n",
      "11412/11412 [==============================] - 2s 145us/step - loss: 0.5954 - regression_loss: 0.1213 - handedness_loss: 0.4744 - val_loss: 0.5714 - val_regression_loss: 0.1183 - val_handedness_loss: 0.4530\n",
      "Epoch 5/150\n",
      "11412/11412 [==============================] - 1s 128us/step - loss: 0.5518 - regression_loss: 0.1096 - handedness_loss: 0.4412 - val_loss: 0.5290 - val_regression_loss: 0.1055 - val_handedness_loss: 0.4232\n",
      "Epoch 6/150\n",
      "11412/11412 [==============================] - 1s 126us/step - loss: 0.5159 - regression_loss: 0.1006 - handedness_loss: 0.4142 - val_loss: 0.5004 - val_regression_loss: 0.0992 - val_handedness_loss: 0.4010\n",
      "Epoch 7/150\n",
      "11412/11412 [==============================] - 2s 133us/step - loss: 0.4916 - regression_loss: 0.0983 - handedness_loss: 0.3933 - val_loss: 0.4734 - val_regression_loss: 0.0933 - val_handedness_loss: 0.3803\n",
      "Epoch 8/150\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11412/11412 [==============================] - 2s 140us/step - loss: 0.4672 - regression_loss: 0.0911 - handedness_loss: 0.3750 - val_loss: 0.4619 - val_regression_loss: 0.0871 - val_handedness_loss: 0.3747\n",
      "Epoch 9/150\n",
      "11412/11412 [==============================] - 2s 146us/step - loss: 0.4502 - regression_loss: 0.0851 - handedness_loss: 0.3655 - val_loss: 0.4209 - val_regression_loss: 0.0807 - val_handedness_loss: 0.3401\n",
      "Epoch 10/150\n",
      "11412/11412 [==============================] - 2s 147us/step - loss: 0.4323 - regression_loss: 0.0819 - handedness_loss: 0.3510 - val_loss: 0.4466 - val_regression_loss: 0.0795 - val_handedness_loss: 0.3670\n",
      "Epoch 11/150\n",
      "11412/11412 [==============================] - 2s 147us/step - loss: 0.4336 - regression_loss: 0.0793 - handedness_loss: 0.3546 - val_loss: 0.4176 - val_regression_loss: 0.0767 - val_handedness_loss: 0.3409\n",
      "Epoch 12/150\n",
      "11412/11412 [==============================] - 2s 146us/step - loss: 0.4262 - regression_loss: 0.0779 - handedness_loss: 0.3487 - val_loss: 0.4243 - val_regression_loss: 0.0765 - val_handedness_loss: 0.3478\n",
      "Epoch 13/150\n",
      "11412/11412 [==============================] - 2s 146us/step - loss: 0.4260 - regression_loss: 0.0779 - handedness_loss: 0.3485 - val_loss: 0.4167 - val_regression_loss: 0.0765 - val_handedness_loss: 0.3401\n",
      "Evaluating model with testing data...\n",
      "2424/2424 [==============================] - 0s 16us/step\n",
      "Getting distribution of predictions and covariance matrix...\n",
      "      1 of 20\n",
      "      2 of 20\n",
      "      3 of 20\n",
      "      4 of 20\n",
      "      5 of 20\n",
      "      6 of 20\n",
      "      7 of 20\n",
      "      8 of 20\n",
      "      9 of 20\n",
      "      10 of 20\n",
      "      11 of 20\n",
      "      12 of 20\n",
      "      13 of 20\n",
      "      14 of 20\n",
      "      15 of 20\n",
      "      16 of 20\n",
      "      17 of 20\n",
      "      18 of 20\n",
      "      19 of 20\n",
      "      20 of 20\n",
      "Computing ensemble means...\n",
      "Computing mean squared error...\n",
      "Iteration 79\n",
      "Train on 11552 samples, validate on 2454 samples\n",
      "Epoch 1/150\n",
      "11552/11552 [==============================] - 2s 143us/step - loss: 0.9254 - regression_loss: 0.3379 - handedness_loss: 0.5854 - val_loss: 0.6701 - val_regression_loss: 0.1883 - val_handedness_loss: 0.4835\n",
      "Epoch 2/150\n",
      "11552/11552 [==============================] - 1s 124us/step - loss: 0.5342 - regression_loss: 0.1504 - handedness_loss: 0.3827 - val_loss: 0.4620 - val_regression_loss: 0.1337 - val_handedness_loss: 0.3280\n",
      "Epoch 3/150\n",
      "11552/11552 [==============================] - 2s 136us/step - loss: 0.4174 - regression_loss: 0.1216 - handedness_loss: 0.2959 - val_loss: 0.3719 - val_regression_loss: 0.1108 - val_handedness_loss: 0.2623\n",
      "Epoch 4/150\n",
      "11552/11552 [==============================] - 2s 143us/step - loss: 0.3561 - regression_loss: 0.1057 - handedness_loss: 0.2501 - val_loss: 0.3390 - val_regression_loss: 0.1006 - val_handedness_loss: 0.2410\n",
      "Epoch 5/150\n",
      "11552/11552 [==============================] - 2s 146us/step - loss: 0.3278 - regression_loss: 0.0974 - handedness_loss: 0.2307 - val_loss: 0.3251 - val_regression_loss: 0.0956 - val_handedness_loss: 0.2326\n",
      "Epoch 6/150\n",
      "11552/11552 [==============================] - 2s 133us/step - loss: 0.3112 - regression_loss: 0.0904 - handedness_loss: 0.2208 - val_loss: 0.3178 - val_regression_loss: 0.0857 - val_handedness_loss: 0.2285\n",
      "Epoch 7/150\n",
      "11552/11552 [==============================] - 2s 146us/step - loss: 0.2928 - regression_loss: 0.0862 - handedness_loss: 0.2064 - val_loss: 0.2896 - val_regression_loss: 0.0864 - val_handedness_loss: 0.2069\n",
      "Epoch 8/150\n",
      "11552/11552 [==============================] - 2s 139us/step - loss: 0.2825 - regression_loss: 0.0819 - handedness_loss: 0.2003 - val_loss: 0.2688 - val_regression_loss: 0.0790 - val_handedness_loss: 0.1908\n",
      "Epoch 9/150\n",
      "11552/11552 [==============================] - 2s 147us/step - loss: 0.2731 - regression_loss: 0.0782 - handedness_loss: 0.1952 - val_loss: 0.2691 - val_regression_loss: 0.0760 - val_handedness_loss: 0.1969\n",
      "Epoch 10/150\n",
      "11552/11552 [==============================] - 2s 147us/step - loss: 0.2594 - regression_loss: 0.0753 - handedness_loss: 0.1859 - val_loss: 0.2525 - val_regression_loss: 0.0730 - val_handedness_loss: 0.1775\n",
      "Epoch 11/150\n",
      "11552/11552 [==============================] - 2s 147us/step - loss: 0.2564 - regression_loss: 0.0734 - handedness_loss: 0.1830 - val_loss: 0.2534 - val_regression_loss: 0.0713 - val_handedness_loss: 0.1815\n",
      "Epoch 12/150\n",
      "11552/11552 [==============================] - 2s 143us/step - loss: 0.2490 - regression_loss: 0.0718 - handedness_loss: 0.1766 - val_loss: 0.2351 - val_regression_loss: 0.0693 - val_handedness_loss: 0.1614\n",
      "Epoch 13/150\n",
      "11552/11552 [==============================] - 2s 147us/step - loss: 0.2489 - regression_loss: 0.0711 - handedness_loss: 0.1780 - val_loss: 0.2528 - val_regression_loss: 0.0693 - val_handedness_loss: 0.1833\n",
      "Epoch 14/150\n",
      "11552/11552 [==============================] - 2s 147us/step - loss: 0.2522 - regression_loss: 0.0706 - handedness_loss: 0.1817 - val_loss: 0.2496 - val_regression_loss: 0.0680 - val_handedness_loss: 0.1808\n",
      "Epoch 15/150\n",
      "11552/11552 [==============================] - 2s 147us/step - loss: 0.2520 - regression_loss: 0.0704 - handedness_loss: 0.1820 - val_loss: 0.2407 - val_regression_loss: 0.0679 - val_handedness_loss: 0.1698\n",
      "Epoch 16/150\n",
      "11552/11552 [==============================] - 2s 143us/step - loss: 0.2451 - regression_loss: 0.0701 - handedness_loss: 0.1745 - val_loss: 0.2478 - val_regression_loss: 0.0687 - val_handedness_loss: 0.1773\n",
      "Evaluating model with testing data...\n",
      "2454/2454 [==============================] - 0s 16us/step\n",
      "Getting distribution of predictions and covariance matrix...\n",
      "      1 of 20\n",
      "      2 of 20\n",
      "      3 of 20\n",
      "      4 of 20\n",
      "      5 of 20\n",
      "      6 of 20\n",
      "      7 of 20\n",
      "      8 of 20\n",
      "      9 of 20\n",
      "      10 of 20\n",
      "      11 of 20\n",
      "      12 of 20\n",
      "      13 of 20\n",
      "      14 of 20\n",
      "      15 of 20\n",
      "      16 of 20\n",
      "      17 of 20\n",
      "      18 of 20\n",
      "      19 of 20\n",
      "      20 of 20\n",
      "Computing ensemble means...\n",
      "Computing mean squared error...\n",
      "Iteration 80\n",
      "Train on 11692 samples, validate on 2484 samples\n",
      "Epoch 1/150\n",
      "11692/11692 [==============================] - 2s 140us/step - loss: 1.0299 - regression_loss: 0.3594 - handedness_loss: 0.6691 - val_loss: 0.8342 - val_regression_loss: 0.1840 - val_handedness_loss: 0.6510\n",
      "Epoch 2/150\n",
      "11692/11692 [==============================] - 2s 137us/step - loss: 0.7865 - regression_loss: 0.1696 - handedness_loss: 0.6166 - val_loss: 0.7450 - val_regression_loss: 0.1541 - val_handedness_loss: 0.5927\n",
      "Epoch 3/150\n",
      "11692/11692 [==============================] - 2s 138us/step - loss: 0.7000 - regression_loss: 0.1419 - handedness_loss: 0.5576 - val_loss: 0.6824 - val_regression_loss: 0.1318 - val_handedness_loss: 0.5540\n",
      "Epoch 4/150\n",
      "11692/11692 [==============================] - 1s 128us/step - loss: 0.6612 - regression_loss: 0.1238 - handedness_loss: 0.5377 - val_loss: 0.6652 - val_regression_loss: 0.1214 - val_handedness_loss: 0.5453\n",
      "Epoch 5/150\n",
      "11692/11692 [==============================] - 2s 130us/step - loss: 0.6401 - regression_loss: 0.1152 - handedness_loss: 0.5251 - val_loss: 0.6267 - val_regression_loss: 0.1147 - val_handedness_loss: 0.5134\n",
      "Epoch 6/150\n",
      "11692/11692 [==============================] - 2s 143us/step - loss: 0.6102 - regression_loss: 0.1106 - handedness_loss: 0.4998 - val_loss: 0.6013 - val_regression_loss: 0.1054 - val_handedness_loss: 0.4983\n",
      "Epoch 7/150\n",
      "11692/11692 [==============================] - 1s 120us/step - loss: 0.5676 - regression_loss: 0.0988 - handedness_loss: 0.4684 - val_loss: 0.5537 - val_regression_loss: 0.0943 - val_handedness_loss: 0.4610\n",
      "Epoch 8/150\n",
      "11692/11692 [==============================] - 1s 127us/step - loss: 0.5496 - regression_loss: 0.0904 - handedness_loss: 0.4593 - val_loss: 0.5600 - val_regression_loss: 0.0872 - val_handedness_loss: 0.4772\n",
      "Epoch 9/150\n",
      "11692/11692 [==============================] - 2s 143us/step - loss: 0.5409 - regression_loss: 0.0851 - handedness_loss: 0.4555 - val_loss: 0.5465 - val_regression_loss: 0.0839 - val_handedness_loss: 0.4626\n",
      "Epoch 10/150\n",
      "11692/11692 [==============================] - 1s 70us/step - loss: 0.5311 - regression_loss: 0.0821 - handedness_loss: 0.4495 - val_loss: 0.5276 - val_regression_loss: 0.0808 - val_handedness_loss: 0.4490\n",
      "Epoch 11/150\n",
      "11692/11692 [==============================] - 1s 115us/step - loss: 0.5245 - regression_loss: 0.0806 - handedness_loss: 0.4441 - val_loss: 0.5142 - val_regression_loss: 0.0792 - val_handedness_loss: 0.4366\n",
      "Epoch 12/150\n",
      "11692/11692 [==============================] - 2s 141us/step - loss: 0.5198 - regression_loss: 0.0801 - handedness_loss: 0.4396 - val_loss: 0.5391 - val_regression_loss: 0.0785 - val_handedness_loss: 0.4611\n",
      "Epoch 13/150\n",
      "11692/11692 [==============================] - 2s 143us/step - loss: 0.5133 - regression_loss: 0.0797 - handedness_loss: 0.4330 - val_loss: 0.5242 - val_regression_loss: 0.0781 - val_handedness_loss: 0.4495\n",
      "Epoch 14/150\n",
      "11692/11692 [==============================] - 2s 147us/step - loss: 0.5185 - regression_loss: 0.0802 - handedness_loss: 0.4383 - val_loss: 0.5072 - val_regression_loss: 0.0788 - val_handedness_loss: 0.4310\n",
      "Epoch 15/150\n",
      "11692/11692 [==============================] - 2s 147us/step - loss: 0.5090 - regression_loss: 0.0799 - handedness_loss: 0.4294 - val_loss: 0.5132 - val_regression_loss: 0.0786 - val_handedness_loss: 0.4378\n",
      "Epoch 16/150\n",
      "11692/11692 [==============================] - 2s 146us/step - loss: 0.5132 - regression_loss: 0.0802 - handedness_loss: 0.4335 - val_loss: 0.5003 - val_regression_loss: 0.0781 - val_handedness_loss: 0.4265\n",
      "Epoch 17/150\n",
      "11692/11692 [==============================] - 2s 146us/step - loss: 0.5065 - regression_loss: 0.0801 - handedness_loss: 0.4266 - val_loss: 0.5001 - val_regression_loss: 0.0787 - val_handedness_loss: 0.4215\n",
      "Evaluating model with testing data...\n",
      "2484/2484 [==============================] - 0s 16us/step\n",
      "Getting distribution of predictions and covariance matrix...\n",
      "      1 of 20\n",
      "      2 of 20\n",
      "      3 of 20\n",
      "      4 of 20\n",
      "      5 of 20\n",
      "      6 of 20\n",
      "      7 of 20\n",
      "      8 of 20\n",
      "      9 of 20\n",
      "      10 of 20\n",
      "      11 of 20\n",
      "      12 of 20\n",
      "      13 of 20\n",
      "      14 of 20\n",
      "      15 of 20\n",
      "      16 of 20\n",
      "      17 of 20\n",
      "      18 of 20\n",
      "      19 of 20\n",
      "      20 of 20\n",
      "Computing ensemble means...\n",
      "Computing mean squared error...\n",
      "Iteration 81\n",
      "Train on 11832 samples, validate on 2514 samples\n",
      "Epoch 1/150\n",
      "11832/11832 [==============================] - 2s 141us/step - loss: 0.9588 - regression_loss: 0.2866 - handedness_loss: 0.6711 - val_loss: 0.8007 - val_regression_loss: 0.1642 - val_handedness_loss: 0.6368\n",
      "Epoch 2/150\n",
      "11832/11832 [==============================] - 2s 137us/step - loss: 0.7555 - regression_loss: 0.1432 - handedness_loss: 0.6120 - val_loss: 0.7207 - val_regression_loss: 0.1329 - val_handedness_loss: 0.5886\n",
      "Epoch 3/150\n",
      "11832/11832 [==============================] - 2s 142us/step - loss: 0.6885 - regression_loss: 0.1283 - handedness_loss: 0.5599 - val_loss: 0.6374 - val_regression_loss: 0.1210 - val_handedness_loss: 0.5163\n",
      "Epoch 4/150\n",
      "11832/11832 [==============================] - 2s 145us/step - loss: 0.6304 - regression_loss: 0.1197 - handedness_loss: 0.5107 - val_loss: 0.5981 - val_regression_loss: 0.1153 - val_handedness_loss: 0.4828\n",
      "Epoch 5/150\n",
      "11832/11832 [==============================] - 2s 142us/step - loss: 0.5705 - regression_loss: 0.1124 - handedness_loss: 0.4579 - val_loss: 0.5492 - val_regression_loss: 0.1098 - val_handedness_loss: 0.4398\n",
      "Epoch 6/150\n",
      "11832/11832 [==============================] - 2s 143us/step - loss: 0.5301 - regression_loss: 0.1040 - handedness_loss: 0.4257 - val_loss: 0.5211 - val_regression_loss: 0.0961 - val_handedness_loss: 0.4253\n",
      "Epoch 7/150\n",
      "11832/11832 [==============================] - 2s 146us/step - loss: 0.5057 - regression_loss: 0.0933 - handedness_loss: 0.4122 - val_loss: 0.5030 - val_regression_loss: 0.0873 - val_handedness_loss: 0.4150\n",
      "Epoch 8/150\n",
      "11832/11832 [==============================] - 2s 145us/step - loss: 0.4812 - regression_loss: 0.0863 - handedness_loss: 0.3945 - val_loss: 0.4691 - val_regression_loss: 0.0810 - val_handedness_loss: 0.3868\n",
      "Epoch 9/150\n",
      "11832/11832 [==============================] - 2s 147us/step - loss: 0.4755 - regression_loss: 0.0820 - handedness_loss: 0.3933 - val_loss: 0.4533 - val_regression_loss: 0.0791 - val_handedness_loss: 0.3740\n",
      "Epoch 10/150\n",
      "11832/11832 [==============================] - 2s 137us/step - loss: 0.4668 - regression_loss: 0.0802 - handedness_loss: 0.3861 - val_loss: 0.4599 - val_regression_loss: 0.0782 - val_handedness_loss: 0.3809\n",
      "Epoch 11/150\n",
      "11832/11832 [==============================] - 2s 147us/step - loss: 0.4570 - regression_loss: 0.0792 - handedness_loss: 0.3776 - val_loss: 0.4528 - val_regression_loss: 0.0768 - val_handedness_loss: 0.3766\n",
      "Epoch 12/150\n",
      "11832/11832 [==============================] - 2s 144us/step - loss: 0.4500 - regression_loss: 0.0786 - handedness_loss: 0.3714 - val_loss: 0.4517 - val_regression_loss: 0.0776 - val_handedness_loss: 0.3751\n",
      "Epoch 13/150\n",
      "11832/11832 [==============================] - 2s 136us/step - loss: 0.4569 - regression_loss: 0.0793 - handedness_loss: 0.3773 - val_loss: 0.4617 - val_regression_loss: 0.0774 - val_handedness_loss: 0.3850\n",
      "Evaluating model with testing data...\n",
      "2514/2514 [==============================] - 0s 15us/step\n",
      "Getting distribution of predictions and covariance matrix...\n",
      "      1 of 20\n",
      "      2 of 20\n",
      "      3 of 20\n",
      "      4 of 20\n",
      "      5 of 20\n",
      "      6 of 20\n",
      "      7 of 20\n",
      "      8 of 20\n",
      "      9 of 20\n",
      "      10 of 20\n",
      "      11 of 20\n",
      "      12 of 20\n",
      "      13 of 20\n",
      "      14 of 20\n",
      "      15 of 20\n",
      "      16 of 20\n",
      "      17 of 20\n",
      "      18 of 20\n",
      "      19 of 20\n",
      "      20 of 20\n",
      "Computing ensemble means...\n",
      "Computing mean squared error...\n",
      "Iteration 82\n",
      "Train on 11972 samples, validate on 2544 samples\n",
      "Epoch 1/150\n",
      "11972/11972 [==============================] - 2s 137us/step - loss: 0.8611 - regression_loss: 0.1990 - handedness_loss: 0.6613 - val_loss: 0.7142 - val_regression_loss: 0.1229 - val_handedness_loss: 0.5912\n",
      "Epoch 2/150\n",
      "11972/11972 [==============================] - 1s 111us/step - loss: 0.6015 - regression_loss: 0.1252 - handedness_loss: 0.4757 - val_loss: 0.4865 - val_regression_loss: 0.1196 - val_handedness_loss: 0.3666\n",
      "Epoch 3/150\n",
      "11972/11972 [==============================] - 2s 142us/step - loss: 0.4153 - regression_loss: 0.1076 - handedness_loss: 0.3075 - val_loss: 0.3673 - val_regression_loss: 0.1023 - val_handedness_loss: 0.2648\n",
      "Epoch 4/150\n",
      "11972/11972 [==============================] - 2s 146us/step - loss: 0.3410 - regression_loss: 0.0935 - handedness_loss: 0.2473 - val_loss: 0.3225 - val_regression_loss: 0.0860 - val_handedness_loss: 0.2362\n",
      "Epoch 5/150\n",
      "11972/11972 [==============================] - 1s 122us/step - loss: 0.2995 - regression_loss: 0.0853 - handedness_loss: 0.2142 - val_loss: 0.3000 - val_regression_loss: 0.0801 - val_handedness_loss: 0.2199\n",
      "Epoch 6/150\n",
      "11972/11972 [==============================] - 2s 126us/step - loss: 0.2748 - regression_loss: 0.0797 - handedness_loss: 0.1950 - val_loss: 0.2578 - val_regression_loss: 0.0763 - val_handedness_loss: 0.1811\n",
      "Epoch 7/150\n",
      "11972/11972 [==============================] - 2s 136us/step - loss: 0.2646 - regression_loss: 0.0758 - handedness_loss: 0.1889 - val_loss: 0.2664 - val_regression_loss: 0.0721 - val_handedness_loss: 0.1940\n",
      "Epoch 8/150\n",
      "11972/11972 [==============================] - 2s 138us/step - loss: 0.2428 - regression_loss: 0.0713 - handedness_loss: 0.1711 - val_loss: 0.2333 - val_regression_loss: 0.0693 - val_handedness_loss: 0.1636\n",
      "Epoch 9/150\n",
      "11972/11972 [==============================] - 2s 138us/step - loss: 0.2305 - regression_loss: 0.0684 - handedness_loss: 0.1617 - val_loss: 0.2255 - val_regression_loss: 0.0659 - val_handedness_loss: 0.1597\n",
      "Epoch 10/150\n",
      "11972/11972 [==============================] - 2s 126us/step - loss: 0.2250 - regression_loss: 0.0669 - handedness_loss: 0.1580 - val_loss: 0.2527 - val_regression_loss: 0.0662 - val_handedness_loss: 0.1864\n",
      "Epoch 11/150\n",
      "11972/11972 [==============================] - 2s 135us/step - loss: 0.2143 - regression_loss: 0.0664 - handedness_loss: 0.1478 - val_loss: 0.2179 - val_regression_loss: 0.0662 - val_handedness_loss: 0.1517\n",
      "Epoch 12/150\n",
      "11972/11972 [==============================] - 2s 143us/step - loss: 0.2139 - regression_loss: 0.0658 - handedness_loss: 0.1478 - val_loss: 0.2187 - val_regression_loss: 0.0645 - val_handedness_loss: 0.1541\n",
      "Epoch 13/150\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11972/11972 [==============================] - 2s 147us/step - loss: 0.2048 - regression_loss: 0.0654 - handedness_loss: 0.1393 - val_loss: 0.1931 - val_regression_loss: 0.0626 - val_handedness_loss: 0.1304\n",
      "Epoch 14/150\n",
      "11972/11972 [==============================] - 2s 147us/step - loss: 0.2053 - regression_loss: 0.0650 - handedness_loss: 0.1401 - val_loss: 0.2034 - val_regression_loss: 0.0639 - val_handedness_loss: 0.1391\n",
      "Epoch 15/150\n",
      "11972/11972 [==============================] - 2s 147us/step - loss: 0.1919 - regression_loss: 0.0647 - handedness_loss: 0.1270 - val_loss: 0.1862 - val_regression_loss: 0.0628 - val_handedness_loss: 0.1232\n",
      "Epoch 16/150\n",
      "11972/11972 [==============================] - 2s 144us/step - loss: 0.1947 - regression_loss: 0.0650 - handedness_loss: 0.1295 - val_loss: 0.1941 - val_regression_loss: 0.0632 - val_handedness_loss: 0.1305\n",
      "Epoch 17/150\n",
      "11972/11972 [==============================] - 2s 146us/step - loss: 0.1883 - regression_loss: 0.0651 - handedness_loss: 0.1236 - val_loss: 0.1850 - val_regression_loss: 0.0650 - val_handedness_loss: 0.1201\n",
      "Evaluating model with testing data...\n",
      "2544/2544 [==============================] - 0s 16us/step\n",
      "Getting distribution of predictions and covariance matrix...\n",
      "      1 of 20\n",
      "      2 of 20\n",
      "      3 of 20\n",
      "      4 of 20\n",
      "      5 of 20\n",
      "      6 of 20\n",
      "      7 of 20\n",
      "      8 of 20\n",
      "      9 of 20\n",
      "      10 of 20\n",
      "      11 of 20\n",
      "      12 of 20\n",
      "      13 of 20\n",
      "      14 of 20\n",
      "      15 of 20\n",
      "      16 of 20\n",
      "      17 of 20\n",
      "      18 of 20\n",
      "      19 of 20\n",
      "      20 of 20\n",
      "Computing ensemble means...\n",
      "Computing mean squared error...\n",
      "Iteration 83\n",
      "Train on 12112 samples, validate on 2574 samples\n",
      "Epoch 1/150\n",
      "12112/12112 [==============================] - 2s 134us/step - loss: 1.0910 - regression_loss: 0.3973 - handedness_loss: 0.6928 - val_loss: 0.8572 - val_regression_loss: 0.1924 - val_handedness_loss: 0.6668\n",
      "Epoch 2/150\n",
      "12112/12112 [==============================] - 2s 130us/step - loss: 0.7855 - regression_loss: 0.1460 - handedness_loss: 0.6393 - val_loss: 0.7480 - val_regression_loss: 0.1380 - val_handedness_loss: 0.6072\n",
      "Epoch 3/150\n",
      "12112/12112 [==============================] - 2s 141us/step - loss: 0.6916 - regression_loss: 0.1386 - handedness_loss: 0.5526 - val_loss: 0.6488 - val_regression_loss: 0.1386 - val_handedness_loss: 0.5066\n",
      "Epoch 4/150\n",
      "12112/12112 [==============================] - 2s 135us/step - loss: 0.5998 - regression_loss: 0.1328 - handedness_loss: 0.4669 - val_loss: 0.5789 - val_regression_loss: 0.1275 - val_handedness_loss: 0.4579\n",
      "Epoch 5/150\n",
      "12112/12112 [==============================] - 2s 147us/step - loss: 0.5488 - regression_loss: 0.1174 - handedness_loss: 0.4314 - val_loss: 0.5329 - val_regression_loss: 0.1112 - val_handedness_loss: 0.4245\n",
      "Epoch 6/150\n",
      "12112/12112 [==============================] - 2s 148us/step - loss: 0.5219 - regression_loss: 0.1046 - handedness_loss: 0.4172 - val_loss: 0.5043 - val_regression_loss: 0.0973 - val_handedness_loss: 0.4117\n",
      "Epoch 7/150\n",
      "12112/12112 [==============================] - 2s 149us/step - loss: 0.4960 - regression_loss: 0.0939 - handedness_loss: 0.4020 - val_loss: 0.4820 - val_regression_loss: 0.0899 - val_handedness_loss: 0.4007\n",
      "Epoch 8/150\n",
      "12112/12112 [==============================] - 2s 148us/step - loss: 0.4818 - regression_loss: 0.0876 - handedness_loss: 0.3941 - val_loss: 0.4723 - val_regression_loss: 0.0831 - val_handedness_loss: 0.3897\n",
      "Epoch 9/150\n",
      "12112/12112 [==============================] - 2s 148us/step - loss: 0.4765 - regression_loss: 0.0832 - handedness_loss: 0.3933 - val_loss: 0.4764 - val_regression_loss: 0.0817 - val_handedness_loss: 0.3977\n",
      "Epoch 10/150\n",
      "12112/12112 [==============================] - 2s 148us/step - loss: 0.4776 - regression_loss: 0.0808 - handedness_loss: 0.3970 - val_loss: 0.4727 - val_regression_loss: 0.0785 - val_handedness_loss: 0.3966\n",
      "Epoch 11/150\n",
      "12112/12112 [==============================] - 2s 139us/step - loss: 0.4710 - regression_loss: 0.0797 - handedness_loss: 0.3913 - val_loss: 0.4558 - val_regression_loss: 0.0770 - val_handedness_loss: 0.3810\n",
      "Epoch 12/150\n",
      "12112/12112 [==============================] - 2s 147us/step - loss: 0.4626 - regression_loss: 0.0791 - handedness_loss: 0.3836 - val_loss: 0.4586 - val_regression_loss: 0.0771 - val_handedness_loss: 0.3837\n",
      "Epoch 13/150\n",
      "12112/12112 [==============================] - 2s 148us/step - loss: 0.4676 - regression_loss: 0.0784 - handedness_loss: 0.3891 - val_loss: 0.4576 - val_regression_loss: 0.0764 - val_handedness_loss: 0.3842\n",
      "Epoch 14/150\n",
      "12112/12112 [==============================] - 2s 147us/step - loss: 0.4548 - regression_loss: 0.0783 - handedness_loss: 0.3763 - val_loss: 0.4556 - val_regression_loss: 0.0766 - val_handedness_loss: 0.3793\n",
      "Epoch 15/150\n",
      "12112/12112 [==============================] - 2s 141us/step - loss: 0.4607 - regression_loss: 0.0783 - handedness_loss: 0.3825 - val_loss: 0.4579 - val_regression_loss: 0.0758 - val_handedness_loss: 0.3851\n",
      "Epoch 16/150\n",
      "12112/12112 [==============================] - 2s 147us/step - loss: 0.4589 - regression_loss: 0.0781 - handedness_loss: 0.3811 - val_loss: 0.4485 - val_regression_loss: 0.0764 - val_handedness_loss: 0.3753\n",
      "Epoch 17/150\n",
      "12112/12112 [==============================] - 2s 148us/step - loss: 0.4543 - regression_loss: 0.0787 - handedness_loss: 0.3755 - val_loss: 0.4432 - val_regression_loss: 0.0760 - val_handedness_loss: 0.3694\n",
      "Epoch 18/150\n",
      "12112/12112 [==============================] - 2s 134us/step - loss: 0.4563 - regression_loss: 0.0785 - handedness_loss: 0.3781 - val_loss: 0.4513 - val_regression_loss: 0.0763 - val_handedness_loss: 0.3748\n",
      "Epoch 19/150\n",
      "12112/12112 [==============================] - 2s 140us/step - loss: 0.4594 - regression_loss: 0.0785 - handedness_loss: 0.3810 - val_loss: 0.4554 - val_regression_loss: 0.0769 - val_handedness_loss: 0.3783\n",
      "Evaluating model with testing data...\n",
      "2574/2574 [==============================] - 0s 16us/step\n",
      "Getting distribution of predictions and covariance matrix...\n",
      "      1 of 20\n",
      "      2 of 20\n",
      "      3 of 20\n",
      "      4 of 20\n",
      "      5 of 20\n",
      "      6 of 20\n",
      "      7 of 20\n",
      "      8 of 20\n",
      "      9 of 20\n",
      "      10 of 20\n",
      "      11 of 20\n",
      "      12 of 20\n",
      "      13 of 20\n",
      "      14 of 20\n",
      "      15 of 20\n",
      "      16 of 20\n",
      "      17 of 20\n",
      "      18 of 20\n",
      "      19 of 20\n",
      "      20 of 20\n",
      "Computing ensemble means...\n",
      "Computing mean squared error...\n",
      "Iteration 84\n",
      "Train on 12252 samples, validate on 2604 samples\n",
      "Epoch 1/150\n",
      "12252/12252 [==============================] - 2s 143us/step - loss: 0.8428 - regression_loss: 0.2048 - handedness_loss: 0.6376 - val_loss: 0.6678 - val_regression_loss: 0.1328 - val_handedness_loss: 0.5375\n",
      "Epoch 2/150\n",
      "12252/12252 [==============================] - 2s 141us/step - loss: 0.5364 - regression_loss: 0.1235 - handedness_loss: 0.4124 - val_loss: 0.4150 - val_regression_loss: 0.1081 - val_handedness_loss: 0.3089\n",
      "Epoch 3/150\n",
      "12252/12252 [==============================] - 2s 145us/step - loss: 0.3809 - regression_loss: 0.1009 - handedness_loss: 0.2802 - val_loss: 0.3447 - val_regression_loss: 0.0935 - val_handedness_loss: 0.2557\n",
      "Epoch 4/150\n",
      "12252/12252 [==============================] - 2s 125us/step - loss: 0.3225 - regression_loss: 0.0897 - handedness_loss: 0.2327 - val_loss: 0.2980 - val_regression_loss: 0.0834 - val_handedness_loss: 0.2174\n",
      "Epoch 5/150\n",
      "12252/12252 [==============================] - 2s 130us/step - loss: 0.2937 - regression_loss: 0.0823 - handedness_loss: 0.2112 - val_loss: 0.3105 - val_regression_loss: 0.0787 - val_handedness_loss: 0.2354\n",
      "Epoch 6/150\n",
      "12252/12252 [==============================] - 2s 131us/step - loss: 0.2704 - regression_loss: 0.0766 - handedness_loss: 0.1936 - val_loss: 0.2673 - val_regression_loss: 0.0735 - val_handedness_loss: 0.1954\n",
      "Epoch 7/150\n",
      "12252/12252 [==============================] - 2s 136us/step - loss: 0.2555 - regression_loss: 0.0721 - handedness_loss: 0.1833 - val_loss: 0.2538 - val_regression_loss: 0.0681 - val_handedness_loss: 0.1873\n",
      "Epoch 8/150\n",
      "12252/12252 [==============================] - 2s 145us/step - loss: 0.2432 - regression_loss: 0.0690 - handedness_loss: 0.1744 - val_loss: 0.2417 - val_regression_loss: 0.0667 - val_handedness_loss: 0.1781\n",
      "Epoch 9/150\n",
      "12252/12252 [==============================] - 2s 142us/step - loss: 0.2446 - regression_loss: 0.0682 - handedness_loss: 0.1764 - val_loss: 0.2176 - val_regression_loss: 0.0646 - val_handedness_loss: 0.1550\n",
      "Epoch 10/150\n",
      "12252/12252 [==============================] - 2s 143us/step - loss: 0.2281 - regression_loss: 0.0663 - handedness_loss: 0.1618 - val_loss: 0.2231 - val_regression_loss: 0.0636 - val_handedness_loss: 0.1619\n",
      "Epoch 11/150\n",
      "12252/12252 [==============================] - 1s 66us/step - loss: 0.2186 - regression_loss: 0.0650 - handedness_loss: 0.1534 - val_loss: 0.2261 - val_regression_loss: 0.0630 - val_handedness_loss: 0.1640\n",
      "Epoch 12/150\n",
      "12252/12252 [==============================] - 2s 133us/step - loss: 0.2146 - regression_loss: 0.0646 - handedness_loss: 0.1500 - val_loss: 0.2108 - val_regression_loss: 0.0633 - val_handedness_loss: 0.1477\n",
      "Epoch 13/150\n",
      "12252/12252 [==============================] - 2s 140us/step - loss: 0.2097 - regression_loss: 0.0641 - handedness_loss: 0.1456 - val_loss: 0.2091 - val_regression_loss: 0.0617 - val_handedness_loss: 0.1505\n",
      "Epoch 14/150\n",
      "12252/12252 [==============================] - 2s 146us/step - loss: 0.2090 - regression_loss: 0.0650 - handedness_loss: 0.1442 - val_loss: 0.2051 - val_regression_loss: 0.0622 - val_handedness_loss: 0.1441\n",
      "Epoch 15/150\n",
      "12252/12252 [==============================] - 2s 147us/step - loss: 0.2084 - regression_loss: 0.0652 - handedness_loss: 0.1433 - val_loss: 0.1968 - val_regression_loss: 0.0627 - val_handedness_loss: 0.1349\n",
      "Epoch 16/150\n",
      "12252/12252 [==============================] - 2s 148us/step - loss: 0.1980 - regression_loss: 0.0648 - handedness_loss: 0.1332 - val_loss: 0.1994 - val_regression_loss: 0.0624 - val_handedness_loss: 0.1414\n",
      "Epoch 17/150\n",
      "12252/12252 [==============================] - 2s 139us/step - loss: 0.2060 - regression_loss: 0.0653 - handedness_loss: 0.1407 - val_loss: 0.2141 - val_regression_loss: 0.0634 - val_handedness_loss: 0.1541\n",
      "Evaluating model with testing data...\n",
      "2604/2604 [==============================] - 0s 16us/step\n",
      "Getting distribution of predictions and covariance matrix...\n",
      "      1 of 20\n",
      "      2 of 20\n",
      "      3 of 20\n",
      "      4 of 20\n",
      "      5 of 20\n",
      "      6 of 20\n",
      "      7 of 20\n",
      "      8 of 20\n",
      "      9 of 20\n",
      "      10 of 20\n",
      "      11 of 20\n",
      "      12 of 20\n",
      "      13 of 20\n",
      "      14 of 20\n",
      "      15 of 20\n",
      "      16 of 20\n",
      "      17 of 20\n",
      "      18 of 20\n",
      "      19 of 20\n",
      "      20 of 20\n",
      "Computing ensemble means...\n",
      "Computing mean squared error...\n",
      "Iteration 85\n",
      "Train on 12392 samples, validate on 2634 samples\n",
      "Epoch 1/150\n",
      "12392/12392 [==============================] - 2s 144us/step - loss: 1.0340 - regression_loss: 0.3589 - handedness_loss: 0.6748 - val_loss: 0.8092 - val_regression_loss: 0.1709 - val_handedness_loss: 0.6383\n",
      "Epoch 2/150\n",
      "12392/12392 [==============================] - 2s 141us/step - loss: 0.7411 - regression_loss: 0.1559 - handedness_loss: 0.5850 - val_loss: 0.6754 - val_regression_loss: 0.1432 - val_handedness_loss: 0.5316\n",
      "Epoch 3/150\n",
      "12392/12392 [==============================] - 2s 145us/step - loss: 0.6174 - regression_loss: 0.1340 - handedness_loss: 0.4830 - val_loss: 0.5473 - val_regression_loss: 0.1225 - val_handedness_loss: 0.4251\n",
      "Epoch 4/150\n",
      "12392/12392 [==============================] - 2s 147us/step - loss: 0.5178 - regression_loss: 0.1164 - handedness_loss: 0.4013 - val_loss: 0.4975 - val_regression_loss: 0.1148 - val_handedness_loss: 0.3821\n",
      "Epoch 5/150\n",
      "12392/12392 [==============================] - 2s 148us/step - loss: 0.4702 - regression_loss: 0.1089 - handedness_loss: 0.3612 - val_loss: 0.4355 - val_regression_loss: 0.1033 - val_handedness_loss: 0.3331\n",
      "Epoch 6/150\n",
      "12392/12392 [==============================] - 2s 147us/step - loss: 0.4220 - regression_loss: 0.0994 - handedness_loss: 0.3225 - val_loss: 0.4095 - val_regression_loss: 0.0940 - val_handedness_loss: 0.3165\n",
      "Epoch 7/150\n",
      "12392/12392 [==============================] - 2s 147us/step - loss: 0.3986 - regression_loss: 0.0913 - handedness_loss: 0.3072 - val_loss: 0.3823 - val_regression_loss: 0.0865 - val_handedness_loss: 0.2961\n",
      "Epoch 8/150\n",
      "12392/12392 [==============================] - 2s 124us/step - loss: 0.3780 - regression_loss: 0.0844 - handedness_loss: 0.2936 - val_loss: 0.3683 - val_regression_loss: 0.0805 - val_handedness_loss: 0.2880\n",
      "Epoch 9/150\n",
      "12392/12392 [==============================] - 2s 133us/step - loss: 0.3655 - regression_loss: 0.0803 - handedness_loss: 0.2852 - val_loss: 0.3673 - val_regression_loss: 0.0765 - val_handedness_loss: 0.2921\n",
      "Epoch 10/150\n",
      "12392/12392 [==============================] - 2s 135us/step - loss: 0.3644 - regression_loss: 0.0776 - handedness_loss: 0.2867 - val_loss: 0.3601 - val_regression_loss: 0.0737 - val_handedness_loss: 0.2879\n",
      "Epoch 11/150\n",
      "12392/12392 [==============================] - 2s 142us/step - loss: 0.3502 - regression_loss: 0.0757 - handedness_loss: 0.2744 - val_loss: 0.3480 - val_regression_loss: 0.0725 - val_handedness_loss: 0.2776\n",
      "Epoch 12/150\n",
      "12392/12392 [==============================] - 2s 130us/step - loss: 0.3488 - regression_loss: 0.0747 - handedness_loss: 0.2740 - val_loss: 0.3615 - val_regression_loss: 0.0723 - val_handedness_loss: 0.2890\n",
      "Epoch 13/150\n",
      "12392/12392 [==============================] - 2s 142us/step - loss: 0.3407 - regression_loss: 0.0745 - handedness_loss: 0.2662 - val_loss: 0.3423 - val_regression_loss: 0.0710 - val_handedness_loss: 0.2726\n",
      "Epoch 14/150\n",
      "12392/12392 [==============================] - 2s 145us/step - loss: 0.3391 - regression_loss: 0.0737 - handedness_loss: 0.2655 - val_loss: 0.3407 - val_regression_loss: 0.0719 - val_handedness_loss: 0.2698\n",
      "Epoch 15/150\n",
      "12392/12392 [==============================] - 2s 147us/step - loss: 0.3417 - regression_loss: 0.0738 - handedness_loss: 0.2679 - val_loss: 0.3413 - val_regression_loss: 0.0702 - val_handedness_loss: 0.2707\n",
      "Epoch 16/150\n",
      "12392/12392 [==============================] - 2s 130us/step - loss: 0.3321 - regression_loss: 0.0737 - handedness_loss: 0.2583 - val_loss: 0.3400 - val_regression_loss: 0.0716 - val_handedness_loss: 0.2694\n",
      "Epoch 17/150\n",
      "12392/12392 [==============================] - 2s 134us/step - loss: 0.3353 - regression_loss: 0.0739 - handedness_loss: 0.2614 - val_loss: 0.3392 - val_regression_loss: 0.0713 - val_handedness_loss: 0.2694\n",
      "Epoch 18/150\n",
      "12392/12392 [==============================] - 2s 143us/step - loss: 0.3395 - regression_loss: 0.0746 - handedness_loss: 0.2649 - val_loss: 0.3399 - val_regression_loss: 0.0715 - val_handedness_loss: 0.2691\n",
      "Epoch 19/150\n",
      "12392/12392 [==============================] - 2s 146us/step - loss: 0.3321 - regression_loss: 0.0741 - handedness_loss: 0.2581 - val_loss: 0.3304 - val_regression_loss: 0.0706 - val_handedness_loss: 0.2622\n",
      "Evaluating model with testing data...\n",
      "2634/2634 [==============================] - 0s 16us/step\n",
      "Getting distribution of predictions and covariance matrix...\n",
      "      1 of 20\n",
      "      2 of 20\n",
      "      3 of 20\n",
      "      4 of 20\n",
      "      5 of 20\n",
      "      6 of 20\n",
      "      7 of 20\n",
      "      8 of 20\n",
      "      9 of 20\n",
      "      10 of 20\n",
      "      11 of 20\n",
      "      12 of 20\n",
      "      13 of 20\n",
      "      14 of 20\n",
      "      15 of 20\n",
      "      16 of 20\n",
      "      17 of 20\n",
      "      18 of 20\n",
      "      19 of 20\n",
      "      20 of 20\n",
      "Computing ensemble means...\n",
      "Computing mean squared error...\n",
      "Iteration 86\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/narock/.local/lib/python3.6/site-packages/ipykernel_launcher.py:28: RuntimeWarning: invalid value encountered in double_scalars\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ignoring (phi,theta):  0.0 0.0\n",
      "Train on 12532 samples, validate on 2664 samples\n",
      "Epoch 1/150\n",
      "12532/12532 [==============================] - 2s 139us/step - loss: 1.0268 - regression_loss: 0.3322 - handedness_loss: 0.6943 - val_loss: 0.7996 - val_regression_loss: 0.1040 - val_handedness_loss: 0.6958\n",
      "Epoch 2/150\n",
      "12532/12532 [==============================] - 2s 135us/step - loss: 0.7973 - regression_loss: 0.1020 - handedness_loss: 0.6953 - val_loss: 0.7945 - val_regression_loss: 0.0985 - val_handedness_loss: 0.6961\n",
      "Epoch 3/150\n",
      "12532/12532 [==============================] - 2s 144us/step - loss: 0.7948 - regression_loss: 0.0999 - handedness_loss: 0.6948 - val_loss: 0.7914 - val_regression_loss: 0.0958 - val_handedness_loss: 0.6957\n",
      "Epoch 4/150\n",
      "12532/12532 [==============================] - 2s 145us/step - loss: 0.7909 - regression_loss: 0.0969 - handedness_loss: 0.6940 - val_loss: 0.7874 - val_regression_loss: 0.0934 - val_handedness_loss: 0.6942\n",
      "Epoch 5/150\n",
      "12532/12532 [==============================] - 2s 146us/step - loss: 0.7893 - regression_loss: 0.0950 - handedness_loss: 0.6943 - val_loss: 0.7836 - val_regression_loss: 0.0898 - val_handedness_loss: 0.6939\n",
      "Epoch 6/150\n",
      "12532/12532 [==============================] - 2s 138us/step - loss: 0.7876 - regression_loss: 0.0936 - handedness_loss: 0.6940 - val_loss: 0.7845 - val_regression_loss: 0.0901 - val_handedness_loss: 0.6945\n",
      "Epoch 7/150\n",
      "12532/12532 [==============================] - 2s 146us/step - loss: 0.7859 - regression_loss: 0.0922 - handedness_loss: 0.6936 - val_loss: 0.7829 - val_regression_loss: 0.0898 - val_handedness_loss: 0.6932\n",
      "Epoch 8/150\n",
      "12532/12532 [==============================] - 2s 148us/step - loss: 0.7851 - regression_loss: 0.0911 - handedness_loss: 0.6941 - val_loss: 0.7816 - val_regression_loss: 0.0885 - val_handedness_loss: 0.6931\n",
      "Epoch 9/150\n",
      "12532/12532 [==============================] - 2s 148us/step - loss: 0.7845 - regression_loss: 0.0906 - handedness_loss: 0.6939 - val_loss: 0.7812 - val_regression_loss: 0.0872 - val_handedness_loss: 0.6941\n",
      "Epoch 10/150\n",
      "12532/12532 [==============================] - 2s 149us/step - loss: 0.7833 - regression_loss: 0.0899 - handedness_loss: 0.6934 - val_loss: 0.7809 - val_regression_loss: 0.0868 - val_handedness_loss: 0.6942\n",
      "Epoch 11/150\n",
      "12532/12532 [==============================] - 2s 148us/step - loss: 0.7814 - regression_loss: 0.0887 - handedness_loss: 0.6927 - val_loss: 0.7802 - val_regression_loss: 0.0860 - val_handedness_loss: 0.6944\n",
      "Epoch 12/150\n",
      "12532/12532 [==============================] - 2s 148us/step - loss: 0.7816 - regression_loss: 0.0880 - handedness_loss: 0.6937 - val_loss: 0.7791 - val_regression_loss: 0.0849 - val_handedness_loss: 0.6943\n",
      "Evaluating model with testing data...\n",
      "2664/2664 [==============================] - 0s 16us/step\n",
      "Getting distribution of predictions and covariance matrix...\n",
      "      1 of 20\n",
      "      2 of 20\n",
      "      3 of 20\n",
      "      4 of 20\n",
      "      5 of 20\n",
      "      6 of 20\n",
      "      7 of 20\n",
      "      8 of 20\n",
      "      9 of 20\n",
      "      10 of 20\n",
      "      11 of 20\n",
      "      12 of 20\n",
      "      13 of 20\n",
      "      14 of 20\n",
      "      15 of 20\n",
      "      16 of 20\n",
      "      17 of 20\n",
      "      18 of 20\n",
      "      19 of 20\n",
      "      20 of 20\n",
      "Computing ensemble means...\n",
      "Computing mean squared error...\n",
      "Iteration 87\n",
      "Train on 12672 samples, validate on 2694 samples\n",
      "Epoch 1/150\n",
      "12672/12672 [==============================] - 2s 135us/step - loss: 0.9572 - regression_loss: 0.2974 - handedness_loss: 0.6598 - val_loss: 0.9707 - val_regression_loss: 0.2797 - val_handedness_loss: 0.6930\n",
      "Epoch 2/150\n",
      "12672/12672 [==============================] - 2s 132us/step - loss: 0.8326 - regression_loss: 0.1376 - handedness_loss: 0.6949 - val_loss: 0.8061 - val_regression_loss: 0.1113 - val_handedness_loss: 0.6944\n",
      "Epoch 3/150\n",
      "12672/12672 [==============================] - 2s 133us/step - loss: 0.8022 - regression_loss: 0.1074 - handedness_loss: 0.6948 - val_loss: 0.7991 - val_regression_loss: 0.1031 - val_handedness_loss: 0.6955\n",
      "Epoch 4/150\n",
      "12672/12672 [==============================] - 2s 139us/step - loss: 0.7974 - regression_loss: 0.1035 - handedness_loss: 0.6940 - val_loss: 0.7927 - val_regression_loss: 0.0987 - val_handedness_loss: 0.6929\n",
      "Epoch 5/150\n",
      "12672/12672 [==============================] - 2s 143us/step - loss: 0.7925 - regression_loss: 0.0988 - handedness_loss: 0.6937 - val_loss: 0.7891 - val_regression_loss: 0.0952 - val_handedness_loss: 0.6932\n",
      "Epoch 6/150\n",
      "12672/12672 [==============================] - 2s 146us/step - loss: 0.7901 - regression_loss: 0.0964 - handedness_loss: 0.6937 - val_loss: 0.7867 - val_regression_loss: 0.0915 - val_handedness_loss: 0.6942\n",
      "Epoch 7/150\n",
      "12672/12672 [==============================] - 2s 132us/step - loss: 0.7879 - regression_loss: 0.0946 - handedness_loss: 0.6933 - val_loss: 0.7855 - val_regression_loss: 0.0906 - val_handedness_loss: 0.6945\n",
      "Epoch 8/150\n",
      "12672/12672 [==============================] - 2s 132us/step - loss: 0.7864 - regression_loss: 0.0925 - handedness_loss: 0.6939 - val_loss: 0.7828 - val_regression_loss: 0.0884 - val_handedness_loss: 0.6943\n",
      "Evaluating model with testing data...\n",
      "2694/2694 [==============================] - 0s 16us/step\n",
      "Getting distribution of predictions and covariance matrix...\n",
      "      1 of 20\n",
      "      2 of 20\n",
      "      3 of 20\n",
      "      4 of 20\n",
      "      5 of 20\n",
      "      6 of 20\n",
      "      7 of 20\n",
      "      8 of 20\n",
      "      9 of 20\n",
      "      10 of 20\n",
      "      11 of 20\n",
      "      12 of 20\n",
      "      13 of 20\n",
      "      14 of 20\n",
      "      15 of 20\n",
      "      16 of 20\n",
      "      17 of 20\n",
      "      18 of 20\n",
      "      19 of 20\n",
      "      20 of 20\n",
      "Computing ensemble means...\n",
      "Computing mean squared error...\n",
      "Iteration 88\n",
      "Train on 12812 samples, validate on 2724 samples\n",
      "Epoch 1/150\n",
      "12812/12812 [==============================] - 2s 138us/step - loss: 0.9527 - regression_loss: 0.2756 - handedness_loss: 0.6758 - val_loss: 0.7967 - val_regression_loss: 0.1025 - val_handedness_loss: 0.6946\n",
      "Epoch 2/150\n",
      "12812/12812 [==============================] - 2s 141us/step - loss: 0.7928 - regression_loss: 0.0979 - handedness_loss: 0.6949 - val_loss: 0.7894 - val_regression_loss: 0.0935 - val_handedness_loss: 0.6959\n",
      "Epoch 3/150\n",
      "12812/12812 [==============================] - 2s 131us/step - loss: 0.7893 - regression_loss: 0.0945 - handedness_loss: 0.6949 - val_loss: 0.7866 - val_regression_loss: 0.0909 - val_handedness_loss: 0.6964\n",
      "Epoch 4/150\n",
      "12812/12812 [==============================] - 2s 142us/step - loss: 0.7872 - regression_loss: 0.0935 - handedness_loss: 0.6937 - val_loss: 0.7863 - val_regression_loss: 0.0908 - val_handedness_loss: 0.6955\n",
      "Epoch 5/150\n",
      "12812/12812 [==============================] - 2s 132us/step - loss: 0.7860 - regression_loss: 0.0919 - handedness_loss: 0.6938 - val_loss: 0.7820 - val_regression_loss: 0.0878 - val_handedness_loss: 0.6942\n",
      "Epoch 6/150\n",
      "12812/12812 [==============================] - 2s 126us/step - loss: 0.7849 - regression_loss: 0.0910 - handedness_loss: 0.6940 - val_loss: 0.7817 - val_regression_loss: 0.0879 - val_handedness_loss: 0.6946\n",
      "Epoch 7/150\n",
      "12812/12812 [==============================] - 2s 144us/step - loss: 0.7839 - regression_loss: 0.0903 - handedness_loss: 0.6937 - val_loss: 0.7828 - val_regression_loss: 0.0883 - val_handedness_loss: 0.6948\n",
      "Epoch 8/150\n",
      "12812/12812 [==============================] - 2s 146us/step - loss: 0.7829 - regression_loss: 0.0895 - handedness_loss: 0.6933 - val_loss: 0.7822 - val_regression_loss: 0.0868 - val_handedness_loss: 0.6957\n",
      "Epoch 9/150\n",
      "12812/12812 [==============================] - 2s 139us/step - loss: 0.7820 - regression_loss: 0.0889 - handedness_loss: 0.6932 - val_loss: 0.7798 - val_regression_loss: 0.0871 - val_handedness_loss: 0.6929\n",
      "Epoch 10/150\n",
      "12812/12812 [==============================] - 2s 123us/step - loss: 0.7817 - regression_loss: 0.0880 - handedness_loss: 0.6936 - val_loss: 0.7791 - val_regression_loss: 0.0856 - val_handedness_loss: 0.6937\n",
      "Epoch 11/150\n",
      "12812/12812 [==============================] - 2s 129us/step - loss: 0.7810 - regression_loss: 0.0877 - handedness_loss: 0.6933 - val_loss: 0.7782 - val_regression_loss: 0.0848 - val_handedness_loss: 0.6935\n",
      "Epoch 12/150\n",
      "12812/12812 [==============================] - 2s 135us/step - loss: 0.7806 - regression_loss: 0.0872 - handedness_loss: 0.6934 - val_loss: 0.7800 - val_regression_loss: 0.0854 - val_handedness_loss: 0.6949\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 13/150\n",
      "12812/12812 [==============================] - 2s 138us/step - loss: 0.7803 - regression_loss: 0.0870 - handedness_loss: 0.6933 - val_loss: 0.7789 - val_regression_loss: 0.0853 - val_handedness_loss: 0.6940\n",
      "Evaluating model with testing data...\n",
      "2724/2724 [==============================] - 0s 16us/step\n",
      "Getting distribution of predictions and covariance matrix...\n",
      "      1 of 20\n",
      "      2 of 20\n",
      "      3 of 20\n",
      "      4 of 20\n",
      "      5 of 20\n",
      "      6 of 20\n",
      "      7 of 20\n",
      "      8 of 20\n",
      "      9 of 20\n",
      "      10 of 20\n",
      "      11 of 20\n",
      "      12 of 20\n",
      "      13 of 20\n",
      "      14 of 20\n",
      "      15 of 20\n",
      "      16 of 20\n",
      "      17 of 20\n",
      "      18 of 20\n",
      "      19 of 20\n",
      "      20 of 20\n",
      "Computing ensemble means...\n",
      "Computing mean squared error...\n",
      "Iteration 89\n",
      "Train on 12952 samples, validate on 2754 samples\n",
      "Epoch 1/150\n",
      "12952/12952 [==============================] - 2s 142us/step - loss: 1.0609 - regression_loss: 0.3662 - handedness_loss: 0.6939 - val_loss: 0.9491 - val_regression_loss: 0.2562 - val_handedness_loss: 0.6928\n",
      "Epoch 2/150\n",
      "12952/12952 [==============================] - 2s 131us/step - loss: 0.9162 - regression_loss: 0.2229 - handedness_loss: 0.6931 - val_loss: 0.8820 - val_regression_loss: 0.1884 - val_handedness_loss: 0.6935\n",
      "Epoch 3/150\n",
      "12952/12952 [==============================] - 2s 142us/step - loss: 0.8591 - regression_loss: 0.1653 - handedness_loss: 0.6935 - val_loss: 0.8342 - val_regression_loss: 0.1413 - val_handedness_loss: 0.6926\n",
      "Epoch 4/150\n",
      "12952/12952 [==============================] - 2s 139us/step - loss: 0.8210 - regression_loss: 0.1275 - handedness_loss: 0.6934 - val_loss: 0.8066 - val_regression_loss: 0.1134 - val_handedness_loss: 0.6932\n",
      "Epoch 5/150\n",
      "12952/12952 [==============================] - 1s 67us/step - loss: 0.8007 - regression_loss: 0.1075 - handedness_loss: 0.6933 - val_loss: 0.7933 - val_regression_loss: 0.0999 - val_handedness_loss: 0.6934\n",
      "Epoch 6/150\n",
      "12952/12952 [==============================] - 2s 141us/step - loss: 0.7912 - regression_loss: 0.0977 - handedness_loss: 0.6934 - val_loss: 0.7871 - val_regression_loss: 0.0930 - val_handedness_loss: 0.6941\n",
      "Epoch 7/150\n",
      "12952/12952 [==============================] - 2s 138us/step - loss: 0.7854 - regression_loss: 0.0923 - handedness_loss: 0.6930 - val_loss: 0.7820 - val_regression_loss: 0.0889 - val_handedness_loss: 0.6932\n",
      "Evaluating model with testing data...\n",
      "2754/2754 [==============================] - 0s 16us/step\n",
      "Getting distribution of predictions and covariance matrix...\n",
      "      1 of 20\n",
      "      2 of 20\n",
      "      3 of 20\n",
      "      4 of 20\n",
      "      5 of 20\n",
      "      6 of 20\n",
      "      7 of 20\n",
      "      8 of 20\n",
      "      9 of 20\n",
      "      10 of 20\n",
      "      11 of 20\n",
      "      12 of 20\n",
      "      13 of 20\n",
      "      14 of 20\n",
      "      15 of 20\n",
      "      16 of 20\n",
      "      17 of 20\n",
      "      18 of 20\n",
      "      19 of 20\n",
      "      20 of 20\n",
      "Computing ensemble means...\n",
      "Computing mean squared error...\n",
      "Iteration 90\n",
      "Train on 13092 samples, validate on 2784 samples\n",
      "Epoch 1/150\n",
      "13092/13092 [==============================] - 2s 128us/step - loss: 0.9748 - regression_loss: 0.3033 - handedness_loss: 0.6703 - val_loss: 0.8266 - val_regression_loss: 0.1137 - val_handedness_loss: 0.7129\n",
      "Epoch 2/150\n",
      "13092/13092 [==============================] - 2s 138us/step - loss: 0.8004 - regression_loss: 0.1040 - handedness_loss: 0.6963 - val_loss: 0.7919 - val_regression_loss: 0.0979 - val_handedness_loss: 0.6941\n",
      "Epoch 3/150\n",
      "13092/13092 [==============================] - 2s 139us/step - loss: 0.7912 - regression_loss: 0.0974 - handedness_loss: 0.6937 - val_loss: 0.7887 - val_regression_loss: 0.0943 - val_handedness_loss: 0.6943\n",
      "Epoch 4/150\n",
      "13092/13092 [==============================] - 2s 146us/step - loss: 0.7893 - regression_loss: 0.0953 - handedness_loss: 0.6939 - val_loss: 0.7869 - val_regression_loss: 0.0928 - val_handedness_loss: 0.6941\n",
      "Epoch 5/150\n",
      "13092/13092 [==============================] - 2s 148us/step - loss: 0.7877 - regression_loss: 0.0941 - handedness_loss: 0.6937 - val_loss: 0.7850 - val_regression_loss: 0.0922 - val_handedness_loss: 0.6930\n",
      "Epoch 6/150\n",
      "13092/13092 [==============================] - 2s 149us/step - loss: 0.7864 - regression_loss: 0.0923 - handedness_loss: 0.6941 - val_loss: 0.7827 - val_regression_loss: 0.0889 - val_handedness_loss: 0.6939\n",
      "Epoch 7/150\n",
      "13092/13092 [==============================] - 2s 149us/step - loss: 0.7846 - regression_loss: 0.0911 - handedness_loss: 0.6935 - val_loss: 0.7832 - val_regression_loss: 0.0886 - val_handedness_loss: 0.6947\n",
      "Epoch 8/150\n",
      "13092/13092 [==============================] - 2s 148us/step - loss: 0.7836 - regression_loss: 0.0899 - handedness_loss: 0.6938 - val_loss: 0.7824 - val_regression_loss: 0.0889 - val_handedness_loss: 0.6936\n",
      "Epoch 9/150\n",
      "13092/13092 [==============================] - 2s 149us/step - loss: 0.7824 - regression_loss: 0.0892 - handedness_loss: 0.6933 - val_loss: 0.7817 - val_regression_loss: 0.0878 - val_handedness_loss: 0.6939\n",
      "Evaluating model with testing data...\n",
      "2784/2784 [==============================] - 0s 16us/step\n",
      "Getting distribution of predictions and covariance matrix...\n",
      "      1 of 20\n",
      "      2 of 20\n",
      "      3 of 20\n",
      "      4 of 20\n",
      "      5 of 20\n",
      "      6 of 20\n",
      "      7 of 20\n",
      "      8 of 20\n",
      "      9 of 20\n",
      "      10 of 20\n",
      "      11 of 20\n",
      "      12 of 20\n",
      "      13 of 20\n",
      "      14 of 20\n",
      "      15 of 20\n",
      "      16 of 20\n",
      "      17 of 20\n",
      "      18 of 20\n",
      "      19 of 20\n",
      "      20 of 20\n",
      "Computing ensemble means...\n",
      "Computing mean squared error...\n",
      "Iteration 91\n",
      "Train on 13232 samples, validate on 2814 samples\n",
      "Epoch 1/150\n",
      "13232/13232 [==============================] - 2s 139us/step - loss: 1.0154 - regression_loss: 0.3222 - handedness_loss: 0.6919 - val_loss: 0.8006 - val_regression_loss: 0.1054 - val_handedness_loss: 0.6951\n",
      "Epoch 2/150\n",
      "13232/13232 [==============================] - 2s 137us/step - loss: 0.8005 - regression_loss: 0.1059 - handedness_loss: 0.6947 - val_loss: 0.7948 - val_regression_loss: 0.1020 - val_handedness_loss: 0.6927\n",
      "Epoch 3/150\n",
      "13232/13232 [==============================] - 2s 145us/step - loss: 0.7974 - regression_loss: 0.1033 - handedness_loss: 0.6940 - val_loss: 0.7965 - val_regression_loss: 0.1019 - val_handedness_loss: 0.6947\n",
      "Epoch 4/150\n",
      "13232/13232 [==============================] - 2s 144us/step - loss: 0.7940 - regression_loss: 0.1008 - handedness_loss: 0.6931 - val_loss: 0.7918 - val_regression_loss: 0.0975 - val_handedness_loss: 0.6943\n",
      "Epoch 5/150\n",
      "13232/13232 [==============================] - 2s 141us/step - loss: 0.7919 - regression_loss: 0.0987 - handedness_loss: 0.6933 - val_loss: 0.7903 - val_regression_loss: 0.0969 - val_handedness_loss: 0.6934\n",
      "Epoch 6/150\n",
      "13232/13232 [==============================] - 2s 147us/step - loss: 0.7893 - regression_loss: 0.0957 - handedness_loss: 0.6935 - val_loss: 0.7882 - val_regression_loss: 0.0936 - val_handedness_loss: 0.6946\n",
      "Evaluating model with testing data...\n",
      "2814/2814 [==============================] - 0s 16us/step\n",
      "Getting distribution of predictions and covariance matrix...\n",
      "      1 of 20\n",
      "      2 of 20\n",
      "      3 of 20\n",
      "      4 of 20\n",
      "      5 of 20\n",
      "      6 of 20\n",
      "      7 of 20\n",
      "      8 of 20\n",
      "      9 of 20\n",
      "      10 of 20\n",
      "      11 of 20\n",
      "      12 of 20\n",
      "      13 of 20\n",
      "      14 of 20\n",
      "      15 of 20\n",
      "      16 of 20\n",
      "      17 of 20\n",
      "      18 of 20\n",
      "      19 of 20\n",
      "      20 of 20\n",
      "Computing ensemble means...\n",
      "Computing mean squared error...\n",
      "Iteration 92\n",
      "Train on 13372 samples, validate on 2844 samples\n",
      "Epoch 1/150\n",
      "13372/13372 [==============================] - 2s 127us/step - loss: 0.9832 - regression_loss: 0.2864 - handedness_loss: 0.6959 - val_loss: 0.7926 - val_regression_loss: 0.0964 - val_handedness_loss: 0.6950\n",
      "Epoch 2/150\n",
      "13372/13372 [==============================] - 2s 125us/step - loss: 0.7924 - regression_loss: 0.0977 - handedness_loss: 0.6948 - val_loss: 0.7906 - val_regression_loss: 0.0945 - val_handedness_loss: 0.6949\n",
      "Epoch 3/150\n",
      "13372/13372 [==============================] - 2s 126us/step - loss: 0.7899 - regression_loss: 0.0960 - handedness_loss: 0.6938 - val_loss: 0.7892 - val_regression_loss: 0.0943 - val_handedness_loss: 0.6943\n",
      "Epoch 4/150\n",
      "13372/13372 [==============================] - 2s 129us/step - loss: 0.7893 - regression_loss: 0.0955 - handedness_loss: 0.6939 - val_loss: 0.7860 - val_regression_loss: 0.0913 - val_handedness_loss: 0.6942\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5/150\n",
      "13372/13372 [==============================] - 2s 142us/step - loss: 0.7878 - regression_loss: 0.0943 - handedness_loss: 0.6936 - val_loss: 0.7859 - val_regression_loss: 0.0912 - val_handedness_loss: 0.6937\n",
      "Epoch 6/150\n",
      "13372/13372 [==============================] - 2s 146us/step - loss: 0.7866 - regression_loss: 0.0928 - handedness_loss: 0.6938 - val_loss: 0.7837 - val_regression_loss: 0.0900 - val_handedness_loss: 0.6928\n",
      "Epoch 7/150\n",
      "13372/13372 [==============================] - 2s 138us/step - loss: 0.7850 - regression_loss: 0.0917 - handedness_loss: 0.6932 - val_loss: 0.7855 - val_regression_loss: 0.0901 - val_handedness_loss: 0.6943\n",
      "Epoch 8/150\n",
      "13372/13372 [==============================] - 2s 145us/step - loss: 0.7844 - regression_loss: 0.0911 - handedness_loss: 0.6933 - val_loss: 0.7836 - val_regression_loss: 0.0886 - val_handedness_loss: 0.6939\n",
      "Epoch 9/150\n",
      "13372/13372 [==============================] - 2s 148us/step - loss: 0.7835 - regression_loss: 0.0902 - handedness_loss: 0.6933 - val_loss: 0.7816 - val_regression_loss: 0.0870 - val_handedness_loss: 0.6938\n",
      "Epoch 10/150\n",
      "13372/13372 [==============================] - 2s 147us/step - loss: 0.7824 - regression_loss: 0.0895 - handedness_loss: 0.6930 - val_loss: 0.7821 - val_regression_loss: 0.0873 - val_handedness_loss: 0.6939\n",
      "Evaluating model with testing data...\n",
      "2844/2844 [==============================] - 0s 17us/step\n",
      "Getting distribution of predictions and covariance matrix...\n",
      "      1 of 20\n",
      "      2 of 20\n",
      "      3 of 20\n",
      "      4 of 20\n",
      "      5 of 20\n",
      "      6 of 20\n",
      "      7 of 20\n",
      "      8 of 20\n",
      "      9 of 20\n",
      "      10 of 20\n",
      "      11 of 20\n",
      "      12 of 20\n",
      "      13 of 20\n",
      "      14 of 20\n",
      "      15 of 20\n",
      "      16 of 20\n",
      "      17 of 20\n",
      "      18 of 20\n",
      "      19 of 20\n",
      "      20 of 20\n",
      "Computing ensemble means...\n",
      "Computing mean squared error...\n",
      "Iteration 93\n",
      "Train on 13512 samples, validate on 2874 samples\n",
      "Epoch 1/150\n",
      "13512/13512 [==============================] - 2s 138us/step - loss: 0.9920 - regression_loss: 0.3048 - handedness_loss: 0.6868 - val_loss: 0.8798 - val_regression_loss: 0.1841 - val_handedness_loss: 0.6953\n",
      "Epoch 2/150\n",
      "13512/13512 [==============================] - 2s 136us/step - loss: 0.8093 - regression_loss: 0.1152 - handedness_loss: 0.6939 - val_loss: 0.7955 - val_regression_loss: 0.1011 - val_handedness_loss: 0.6939\n",
      "Epoch 3/150\n",
      "13512/13512 [==============================] - 2s 145us/step - loss: 0.7963 - regression_loss: 0.1025 - handedness_loss: 0.6938 - val_loss: 0.7923 - val_regression_loss: 0.0970 - val_handedness_loss: 0.6949\n",
      "Epoch 4/150\n",
      "13512/13512 [==============================] - 2s 147us/step - loss: 0.7921 - regression_loss: 0.0990 - handedness_loss: 0.6931 - val_loss: 0.7910 - val_regression_loss: 0.0957 - val_handedness_loss: 0.6953\n",
      "Epoch 5/150\n",
      "13512/13512 [==============================] - 2s 137us/step - loss: 0.7908 - regression_loss: 0.0975 - handedness_loss: 0.6933 - val_loss: 0.7885 - val_regression_loss: 0.0933 - val_handedness_loss: 0.6951\n",
      "Epoch 6/150\n",
      "13512/13512 [==============================] - 2s 133us/step - loss: 0.7878 - regression_loss: 0.0944 - handedness_loss: 0.6934 - val_loss: 0.7856 - val_regression_loss: 0.0915 - val_handedness_loss: 0.6936\n",
      "Epoch 7/150\n",
      "13512/13512 [==============================] - 2s 145us/step - loss: 0.7869 - regression_loss: 0.0934 - handedness_loss: 0.6935 - val_loss: 0.7846 - val_regression_loss: 0.0903 - val_handedness_loss: 0.6940\n",
      "Epoch 8/150\n",
      "13512/13512 [==============================] - 2s 147us/step - loss: 0.7847 - regression_loss: 0.0916 - handedness_loss: 0.6931 - val_loss: 0.7834 - val_regression_loss: 0.0896 - val_handedness_loss: 0.6936\n",
      "Epoch 9/150\n",
      "13512/13512 [==============================] - 2s 147us/step - loss: 0.7835 - regression_loss: 0.0901 - handedness_loss: 0.6935 - val_loss: 0.7820 - val_regression_loss: 0.0882 - val_handedness_loss: 0.6934\n",
      "Epoch 10/150\n",
      "13512/13512 [==============================] - 2s 143us/step - loss: 0.7823 - regression_loss: 0.0891 - handedness_loss: 0.6932 - val_loss: 0.7811 - val_regression_loss: 0.0871 - val_handedness_loss: 0.6938\n",
      "Epoch 11/150\n",
      "13512/13512 [==============================] - 2s 127us/step - loss: 0.7812 - regression_loss: 0.0880 - handedness_loss: 0.6931 - val_loss: 0.7796 - val_regression_loss: 0.0856 - val_handedness_loss: 0.6937\n",
      "Epoch 12/150\n",
      "13512/13512 [==============================] - 2s 135us/step - loss: 0.7804 - regression_loss: 0.0873 - handedness_loss: 0.6931 - val_loss: 0.7796 - val_regression_loss: 0.0850 - val_handedness_loss: 0.6944\n",
      "Epoch 13/150\n",
      "13512/13512 [==============================] - 2s 135us/step - loss: 0.7797 - regression_loss: 0.0864 - handedness_loss: 0.6933 - val_loss: 0.7793 - val_regression_loss: 0.0850 - val_handedness_loss: 0.6941\n",
      "Evaluating model with testing data...\n",
      "2874/2874 [==============================] - 0s 16us/step\n",
      "Getting distribution of predictions and covariance matrix...\n",
      "      1 of 20\n",
      "      2 of 20\n",
      "      3 of 20\n",
      "      4 of 20\n",
      "      5 of 20\n",
      "      6 of 20\n",
      "      7 of 20\n",
      "      8 of 20\n",
      "      9 of 20\n",
      "      10 of 20\n",
      "      11 of 20\n",
      "      12 of 20\n",
      "      13 of 20\n",
      "      14 of 20\n",
      "      15 of 20\n",
      "      16 of 20\n",
      "      17 of 20\n",
      "      18 of 20\n",
      "      19 of 20\n",
      "      20 of 20\n",
      "Computing ensemble means...\n",
      "Computing mean squared error...\n",
      "Iteration 94\n",
      "Train on 13652 samples, validate on 2904 samples\n",
      "Epoch 1/150\n",
      "13652/13652 [==============================] - 2s 131us/step - loss: 1.0025 - regression_loss: 0.3089 - handedness_loss: 0.6934 - val_loss: 0.9235 - val_regression_loss: 0.2305 - val_handedness_loss: 0.6934\n",
      "Epoch 2/150\n",
      "13652/13652 [==============================] - 2s 130us/step - loss: 0.8746 - regression_loss: 0.1812 - handedness_loss: 0.6934 - val_loss: 0.8314 - val_regression_loss: 0.1380 - val_handedness_loss: 0.6938\n",
      "Epoch 3/150\n",
      "13652/13652 [==============================] - 2s 138us/step - loss: 0.8123 - regression_loss: 0.1187 - handedness_loss: 0.6936 - val_loss: 0.8006 - val_regression_loss: 0.1063 - val_handedness_loss: 0.6944\n",
      "Epoch 4/150\n",
      "13652/13652 [==============================] - 2s 136us/step - loss: 0.7956 - regression_loss: 0.1022 - handedness_loss: 0.6934 - val_loss: 0.7908 - val_regression_loss: 0.0968 - val_handedness_loss: 0.6941\n",
      "Epoch 5/150\n",
      "13652/13652 [==============================] - 2s 147us/step - loss: 0.7902 - regression_loss: 0.0968 - handedness_loss: 0.6935 - val_loss: 0.7883 - val_regression_loss: 0.0942 - val_handedness_loss: 0.6941\n",
      "Evaluating model with testing data...\n",
      "2904/2904 [==============================] - 0s 16us/step\n",
      "Getting distribution of predictions and covariance matrix...\n",
      "      1 of 20\n",
      "      2 of 20\n",
      "      3 of 20\n",
      "      4 of 20\n",
      "      5 of 20\n",
      "      6 of 20\n",
      "      7 of 20\n",
      "      8 of 20\n",
      "      9 of 20\n",
      "      10 of 20\n",
      "      11 of 20\n",
      "      12 of 20\n",
      "      13 of 20\n",
      "      14 of 20\n",
      "      15 of 20\n",
      "      16 of 20\n",
      "      17 of 20\n",
      "      18 of 20\n",
      "      19 of 20\n",
      "      20 of 20\n",
      "Computing ensemble means...\n",
      "Computing mean squared error...\n",
      "Iteration 95\n",
      "Train on 13792 samples, validate on 2934 samples\n",
      "Epoch 1/150\n",
      "13792/13792 [==============================] - 2s 134us/step - loss: 1.0829 - regression_loss: 0.3997 - handedness_loss: 0.6829 - val_loss: 0.9508 - val_regression_loss: 0.2576 - val_handedness_loss: 0.6932\n",
      "Epoch 2/150\n",
      "13792/13792 [==============================] - 2s 123us/step - loss: 0.9027 - regression_loss: 0.2086 - handedness_loss: 0.6939 - val_loss: 0.8488 - val_regression_loss: 0.1560 - val_handedness_loss: 0.6928\n",
      "Epoch 3/150\n",
      "13792/13792 [==============================] - 2s 141us/step - loss: 0.8207 - regression_loss: 0.1265 - handedness_loss: 0.6942 - val_loss: 0.8013 - val_regression_loss: 0.1072 - val_handedness_loss: 0.6941\n",
      "Epoch 4/150\n",
      "13792/13792 [==============================] - 2s 130us/step - loss: 0.7986 - regression_loss: 0.1051 - handedness_loss: 0.6936 - val_loss: 0.7972 - val_regression_loss: 0.1020 - val_handedness_loss: 0.6953\n",
      "Epoch 5/150\n",
      "13792/13792 [==============================] - 2s 130us/step - loss: 0.7951 - regression_loss: 0.1009 - handedness_loss: 0.6942 - val_loss: 0.7930 - val_regression_loss: 0.0973 - val_handedness_loss: 0.6957\n",
      "Epoch 6/150\n",
      "13792/13792 [==============================] - 2s 142us/step - loss: 0.7910 - regression_loss: 0.0972 - handedness_loss: 0.6937 - val_loss: 0.7885 - val_regression_loss: 0.0945 - val_handedness_loss: 0.6940\n",
      "Evaluating model with testing data...\n",
      "2934/2934 [==============================] - 0s 16us/step\n",
      "Getting distribution of predictions and covariance matrix...\n",
      "      1 of 20\n",
      "      2 of 20\n",
      "      3 of 20\n",
      "      4 of 20\n",
      "      5 of 20\n",
      "      6 of 20\n",
      "      7 of 20\n",
      "      8 of 20\n",
      "      9 of 20\n",
      "      10 of 20\n",
      "      11 of 20\n",
      "      12 of 20\n",
      "      13 of 20\n",
      "      14 of 20\n",
      "      15 of 20\n",
      "      16 of 20\n",
      "      17 of 20\n",
      "      18 of 20\n",
      "      19 of 20\n",
      "      20 of 20\n",
      "Computing ensemble means...\n",
      "Computing mean squared error...\n",
      "Iteration 96\n",
      "Train on 13932 samples, validate on 2964 samples\n",
      "Epoch 1/150\n",
      "13932/13932 [==============================] - 2s 133us/step - loss: 0.9798 - regression_loss: 0.2962 - handedness_loss: 0.6836 - val_loss: 0.9333 - val_regression_loss: 0.2407 - val_handedness_loss: 0.6935\n",
      "Epoch 2/150\n",
      "13932/13932 [==============================] - 2s 142us/step - loss: 0.8691 - regression_loss: 0.1757 - handedness_loss: 0.6934 - val_loss: 0.8178 - val_regression_loss: 0.1232 - val_handedness_loss: 0.6955\n",
      "Epoch 3/150\n",
      "13932/13932 [==============================] - 2s 145us/step - loss: 0.8020 - regression_loss: 0.1083 - handedness_loss: 0.6938 - val_loss: 0.7959 - val_regression_loss: 0.1014 - val_handedness_loss: 0.6957\n",
      "Epoch 4/150\n",
      "13932/13932 [==============================] - 2s 146us/step - loss: 0.7929 - regression_loss: 0.0992 - handedness_loss: 0.6936 - val_loss: 0.7906 - val_regression_loss: 0.0970 - val_handedness_loss: 0.6943\n",
      "Epoch 5/150\n",
      "13932/13932 [==============================] - 2s 114us/step - loss: 0.7893 - regression_loss: 0.0957 - handedness_loss: 0.6936 - val_loss: 0.7899 - val_regression_loss: 0.0946 - val_handedness_loss: 0.6952\n",
      "Evaluating model with testing data...\n",
      "2964/2964 [==============================] - 0s 16us/step\n",
      "Getting distribution of predictions and covariance matrix...\n",
      "      1 of 20\n",
      "      2 of 20\n",
      "      3 of 20\n",
      "      4 of 20\n",
      "      5 of 20\n",
      "      6 of 20\n",
      "      7 of 20\n",
      "      8 of 20\n",
      "      9 of 20\n",
      "      10 of 20\n",
      "      11 of 20\n",
      "      12 of 20\n",
      "      13 of 20\n",
      "      14 of 20\n",
      "      15 of 20\n",
      "      16 of 20\n",
      "      17 of 20\n",
      "      18 of 20\n",
      "      19 of 20\n",
      "      20 of 20\n",
      "Computing ensemble means...\n",
      "Computing mean squared error...\n",
      "Iteration 97\n",
      "Train on 14072 samples, validate on 2994 samples\n",
      "Epoch 1/150\n",
      "14072/14072 [==============================] - 2s 127us/step - loss: 1.0722 - regression_loss: 0.3779 - handedness_loss: 0.6942 - val_loss: 0.7976 - val_regression_loss: 0.1029 - val_handedness_loss: 0.6945\n",
      "Epoch 2/150\n",
      "14072/14072 [==============================] - 2s 141us/step - loss: 0.7938 - regression_loss: 0.0997 - handedness_loss: 0.6941 - val_loss: 0.7926 - val_regression_loss: 0.0987 - val_handedness_loss: 0.6938\n",
      "Epoch 3/150\n",
      "14072/14072 [==============================] - 2s 146us/step - loss: 0.7918 - regression_loss: 0.0983 - handedness_loss: 0.6935 - val_loss: 0.7892 - val_regression_loss: 0.0967 - val_handedness_loss: 0.6924\n",
      "Epoch 4/150\n",
      "14072/14072 [==============================] - 2s 147us/step - loss: 0.7907 - regression_loss: 0.0969 - handedness_loss: 0.6938 - val_loss: 0.7878 - val_regression_loss: 0.0943 - val_handedness_loss: 0.6937\n",
      "Epoch 5/150\n",
      "14072/14072 [==============================] - 2s 147us/step - loss: 0.7895 - regression_loss: 0.0956 - handedness_loss: 0.6939 - val_loss: 0.7890 - val_regression_loss: 0.0945 - val_handedness_loss: 0.6946\n",
      "Epoch 6/150\n",
      "14072/14072 [==============================] - 2s 133us/step - loss: 0.7882 - regression_loss: 0.0945 - handedness_loss: 0.6937 - val_loss: 0.7872 - val_regression_loss: 0.0933 - val_handedness_loss: 0.6938\n",
      "Epoch 7/150\n",
      "14072/14072 [==============================] - 2s 134us/step - loss: 0.7867 - regression_loss: 0.0931 - handedness_loss: 0.6936 - val_loss: 0.7858 - val_regression_loss: 0.0914 - val_handedness_loss: 0.6942\n",
      "Evaluating model with testing data...\n",
      "2994/2994 [==============================] - 0s 16us/step\n",
      "Getting distribution of predictions and covariance matrix...\n",
      "      1 of 20\n",
      "      2 of 20\n",
      "      3 of 20\n",
      "      4 of 20\n",
      "      5 of 20\n",
      "      6 of 20\n",
      "      7 of 20\n",
      "      8 of 20\n",
      "      9 of 20\n",
      "      10 of 20\n",
      "      11 of 20\n",
      "      12 of 20\n",
      "      13 of 20\n",
      "      14 of 20\n",
      "      15 of 20\n",
      "      16 of 20\n",
      "      17 of 20\n",
      "      18 of 20\n",
      "      19 of 20\n",
      "      20 of 20\n",
      "Computing ensemble means...\n",
      "Computing mean squared error...\n",
      "Iteration 98\n",
      "Train on 14212 samples, validate on 3024 samples\n",
      "Epoch 1/150\n",
      "14212/14212 [==============================] - 2s 141us/step - loss: 1.0509 - regression_loss: 0.3555 - handedness_loss: 0.6940 - val_loss: 0.9467 - val_regression_loss: 0.2539 - val_handedness_loss: 0.6933\n",
      "Epoch 2/150\n",
      "14212/14212 [==============================] - 2s 137us/step - loss: 0.9054 - regression_loss: 0.2121 - handedness_loss: 0.6932 - val_loss: 0.8667 - val_regression_loss: 0.1735 - val_handedness_loss: 0.6936\n",
      "Epoch 3/150\n",
      "14212/14212 [==============================] - 2s 147us/step - loss: 0.8384 - regression_loss: 0.1448 - handedness_loss: 0.6931 - val_loss: 0.8182 - val_regression_loss: 0.1248 - val_handedness_loss: 0.6936\n",
      "Epoch 4/150\n",
      "14212/14212 [==============================] - 2s 138us/step - loss: 0.8077 - regression_loss: 0.1148 - handedness_loss: 0.6932 - val_loss: 0.8007 - val_regression_loss: 0.1073 - val_handedness_loss: 0.6938\n",
      "Epoch 5/150\n",
      "14212/14212 [==============================] - 2s 147us/step - loss: 0.7961 - regression_loss: 0.1029 - handedness_loss: 0.6931 - val_loss: 0.7937 - val_regression_loss: 0.1001 - val_handedness_loss: 0.6937\n",
      "Evaluating model with testing data...\n",
      "3024/3024 [==============================] - 0s 16us/step\n",
      "Getting distribution of predictions and covariance matrix...\n",
      "      1 of 20\n",
      "      2 of 20\n",
      "      3 of 20\n",
      "      4 of 20\n",
      "      5 of 20\n",
      "      6 of 20\n",
      "      7 of 20\n",
      "      8 of 20\n",
      "      9 of 20\n",
      "      10 of 20\n",
      "      11 of 20\n",
      "      12 of 20\n",
      "      13 of 20\n",
      "      14 of 20\n",
      "      15 of 20\n",
      "      16 of 20\n",
      "      17 of 20\n",
      "      18 of 20\n",
      "      19 of 20\n",
      "      20 of 20\n",
      "Computing ensemble means...\n",
      "Computing mean squared error...\n",
      "Iteration 99\n",
      "Train on 14352 samples, validate on 3054 samples\n",
      "Epoch 1/150\n",
      "14352/14352 [==============================] - 2s 129us/step - loss: 1.1041 - regression_loss: 0.4050 - handedness_loss: 0.6978 - val_loss: 0.9527 - val_regression_loss: 0.2595 - val_handedness_loss: 0.6931\n",
      "Epoch 2/150\n",
      "14352/14352 [==============================] - 2s 125us/step - loss: 0.9113 - regression_loss: 0.2181 - handedness_loss: 0.6931 - val_loss: 0.8727 - val_regression_loss: 0.1793 - val_handedness_loss: 0.6934\n",
      "Epoch 3/150\n",
      "14352/14352 [==============================] - 2s 142us/step - loss: 0.8445 - regression_loss: 0.1510 - handedness_loss: 0.6930 - val_loss: 0.8239 - val_regression_loss: 0.1303 - val_handedness_loss: 0.6936\n",
      "Epoch 4/150\n",
      "14352/14352 [==============================] - 2s 128us/step - loss: 0.8124 - regression_loss: 0.1192 - handedness_loss: 0.6930 - val_loss: 0.8043 - val_regression_loss: 0.1107 - val_handedness_loss: 0.6936\n",
      "Epoch 5/150\n",
      "14352/14352 [==============================] - 2s 134us/step - loss: 0.7995 - regression_loss: 0.1064 - handedness_loss: 0.6930 - val_loss: 0.7962 - val_regression_loss: 0.1023 - val_handedness_loss: 0.6938\n",
      "Evaluating model with testing data...\n",
      "3054/3054 [==============================] - 0s 16us/step\n",
      "Getting distribution of predictions and covariance matrix...\n",
      "      1 of 20\n",
      "      2 of 20\n",
      "      3 of 20\n",
      "      4 of 20\n",
      "      5 of 20\n",
      "      6 of 20\n",
      "      7 of 20\n",
      "      8 of 20\n",
      "      9 of 20\n",
      "      10 of 20\n",
      "      11 of 20\n",
      "      12 of 20\n",
      "      13 of 20\n",
      "      14 of 20\n",
      "      15 of 20\n",
      "      16 of 20\n",
      "      17 of 20\n",
      "      18 of 20\n",
      "      19 of 20\n",
      "      20 of 20\n",
      "Computing ensemble means...\n",
      "Computing mean squared error...\n",
      "Iteration 100\n",
      "Train on 14492 samples, validate on 3084 samples\n",
      "Epoch 1/150\n",
      "14492/14492 [==============================] - 2s 130us/step - loss: 0.9255 - regression_loss: 0.2279 - handedness_loss: 0.6970 - val_loss: 0.7965 - val_regression_loss: 0.1036 - val_handedness_loss: 0.6956\n",
      "Epoch 2/150\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14492/14492 [==============================] - 2s 132us/step - loss: 0.7969 - regression_loss: 0.1020 - handedness_loss: 0.6947 - val_loss: 0.7954 - val_regression_loss: 0.1000 - val_handedness_loss: 0.6960\n",
      "Epoch 3/150\n",
      "14492/14492 [==============================] - 2s 140us/step - loss: 0.7932 - regression_loss: 0.0985 - handedness_loss: 0.6944 - val_loss: 0.7904 - val_regression_loss: 0.0980 - val_handedness_loss: 0.6934\n",
      "Epoch 4/150\n",
      "14492/14492 [==============================] - 2s 119us/step - loss: 0.7907 - regression_loss: 0.0967 - handedness_loss: 0.6940 - val_loss: 0.7902 - val_regression_loss: 0.0965 - val_handedness_loss: 0.6944\n",
      "Epoch 5/150\n",
      "14492/14492 [==============================] - 2s 133us/step - loss: 0.7885 - regression_loss: 0.0943 - handedness_loss: 0.6942 - val_loss: 0.7879 - val_regression_loss: 0.0945 - val_handedness_loss: 0.6935\n",
      "Epoch 6/150\n",
      "14492/14492 [==============================] - 2s 135us/step - loss: 0.7867 - regression_loss: 0.0927 - handedness_loss: 0.6939 - val_loss: 0.7861 - val_regression_loss: 0.0922 - val_handedness_loss: 0.6942\n",
      "Epoch 7/150\n",
      "14492/14492 [==============================] - 2s 143us/step - loss: 0.7850 - regression_loss: 0.0914 - handedness_loss: 0.6936 - val_loss: 0.7839 - val_regression_loss: 0.0903 - val_handedness_loss: 0.6947\n",
      "Evaluating model with testing data...\n",
      "3084/3084 [==============================] - 0s 16us/step\n",
      "Getting distribution of predictions and covariance matrix...\n",
      "      1 of 20\n",
      "      2 of 20\n",
      "      3 of 20\n",
      "      4 of 20\n",
      "      5 of 20\n",
      "      6 of 20\n",
      "      7 of 20\n",
      "      8 of 20\n",
      "      9 of 20\n",
      "      10 of 20\n",
      "      11 of 20\n",
      "      12 of 20\n",
      "      13 of 20\n",
      "      14 of 20\n",
      "      15 of 20\n",
      "      16 of 20\n",
      "      17 of 20\n",
      "      18 of 20\n",
      "      19 of 20\n",
      "      20 of 20\n",
      "Computing ensemble means...\n",
      "Computing mean squared error...\n",
      "Iteration 101\n",
      "Train on 14632 samples, validate on 3114 samples\n",
      "Epoch 1/150\n",
      "14632/14632 [==============================] - 2s 141us/step - loss: 0.9997 - regression_loss: 0.3261 - handedness_loss: 0.6724 - val_loss: 0.8013 - val_regression_loss: 0.1039 - val_handedness_loss: 0.6973\n",
      "Epoch 2/150\n",
      "14632/14632 [==============================] - 2s 129us/step - loss: 0.7916 - regression_loss: 0.0969 - handedness_loss: 0.6947 - val_loss: 0.7911 - val_regression_loss: 0.0949 - val_handedness_loss: 0.6965\n",
      "Epoch 3/150\n",
      "14632/14632 [==============================] - 2s 144us/step - loss: 0.7889 - regression_loss: 0.0942 - handedness_loss: 0.6947 - val_loss: 0.7881 - val_regression_loss: 0.0942 - val_handedness_loss: 0.6938\n",
      "Epoch 4/150\n",
      "14632/14632 [==============================] - 2s 126us/step - loss: 0.7872 - regression_loss: 0.0928 - handedness_loss: 0.6943 - val_loss: 0.7888 - val_regression_loss: 0.0921 - val_handedness_loss: 0.6967\n",
      "Epoch 5/150\n",
      "14632/14632 [==============================] - 2s 144us/step - loss: 0.7856 - regression_loss: 0.0917 - handedness_loss: 0.6940 - val_loss: 0.7852 - val_regression_loss: 0.0920 - val_handedness_loss: 0.6935\n",
      "Epoch 6/150\n",
      "14632/14632 [==============================] - 2s 149us/step - loss: 0.7846 - regression_loss: 0.0910 - handedness_loss: 0.6937 - val_loss: 0.7833 - val_regression_loss: 0.0893 - val_handedness_loss: 0.6940\n",
      "Epoch 7/150\n",
      "14632/14632 [==============================] - 2s 146us/step - loss: 0.7842 - regression_loss: 0.0905 - handedness_loss: 0.6938 - val_loss: 0.7842 - val_regression_loss: 0.0900 - val_handedness_loss: 0.6943\n",
      "Epoch 8/150\n",
      "14632/14632 [==============================] - 2s 141us/step - loss: 0.7828 - regression_loss: 0.0894 - handedness_loss: 0.6933 - val_loss: 0.7826 - val_regression_loss: 0.0894 - val_handedness_loss: 0.6936\n",
      "Epoch 9/150\n",
      "14632/14632 [==============================] - 2s 138us/step - loss: 0.7826 - regression_loss: 0.0890 - handedness_loss: 0.6937 - val_loss: 0.7819 - val_regression_loss: 0.0882 - val_handedness_loss: 0.6938\n",
      "Evaluating model with testing data...\n",
      "3114/3114 [==============================] - 0s 16us/step\n",
      "Getting distribution of predictions and covariance matrix...\n",
      "      1 of 20\n",
      "      2 of 20\n",
      "      3 of 20\n",
      "      4 of 20\n",
      "      5 of 20\n",
      "      6 of 20\n",
      "      7 of 20\n",
      "      8 of 20\n",
      "      9 of 20\n",
      "      10 of 20\n",
      "      11 of 20\n",
      "      12 of 20\n",
      "      13 of 20\n",
      "      14 of 20\n",
      "      15 of 20\n",
      "      16 of 20\n",
      "      17 of 20\n",
      "      18 of 20\n",
      "      19 of 20\n",
      "      20 of 20\n",
      "Computing ensemble means...\n",
      "Computing mean squared error...\n",
      "Iteration 102\n",
      "Train on 14772 samples, validate on 3144 samples\n",
      "Epoch 1/150\n",
      "14772/14772 [==============================] - 2s 138us/step - loss: 0.9664 - regression_loss: 0.3315 - handedness_loss: 0.6347 - val_loss: 0.9469 - val_regression_loss: 0.2530 - val_handedness_loss: 0.6933\n",
      "Epoch 2/150\n",
      "14772/14772 [==============================] - 2s 141us/step - loss: 0.8759 - regression_loss: 0.1810 - handedness_loss: 0.6945 - val_loss: 0.8174 - val_regression_loss: 0.1212 - val_handedness_loss: 0.6960\n",
      "Epoch 3/150\n",
      "14772/14772 [==============================] - 2s 134us/step - loss: 0.7989 - regression_loss: 0.1027 - handedness_loss: 0.6962 - val_loss: 0.7943 - val_regression_loss: 0.0969 - val_handedness_loss: 0.6972\n",
      "Epoch 4/150\n",
      "14772/14772 [==============================] - 2s 143us/step - loss: 0.7900 - regression_loss: 0.0953 - handedness_loss: 0.6947 - val_loss: 0.7890 - val_regression_loss: 0.0940 - val_handedness_loss: 0.6949\n",
      "Epoch 5/150\n",
      "14772/14772 [==============================] - 2s 142us/step - loss: 0.7884 - regression_loss: 0.0933 - handedness_loss: 0.6952 - val_loss: 0.7863 - val_regression_loss: 0.0923 - val_handedness_loss: 0.6941\n",
      "Evaluating model with testing data...\n",
      "3144/3144 [==============================] - 0s 17us/step\n",
      "Getting distribution of predictions and covariance matrix...\n",
      "      1 of 20\n",
      "      2 of 20\n",
      "      3 of 20\n",
      "      4 of 20\n",
      "      5 of 20\n",
      "      6 of 20\n",
      "      7 of 20\n",
      "      8 of 20\n",
      "      9 of 20\n",
      "      10 of 20\n",
      "      11 of 20\n",
      "      12 of 20\n",
      "      13 of 20\n",
      "      14 of 20\n",
      "      15 of 20\n",
      "      16 of 20\n",
      "      17 of 20\n",
      "      18 of 20\n",
      "      19 of 20\n",
      "      20 of 20\n",
      "Computing ensemble means...\n",
      "Computing mean squared error...\n",
      "Iteration 103\n",
      "Train on 14912 samples, validate on 3174 samples\n",
      "Epoch 1/150\n",
      "14912/14912 [==============================] - 2s 128us/step - loss: 0.8841 - regression_loss: 0.2210 - handedness_loss: 0.6628 - val_loss: 0.8044 - val_regression_loss: 0.1097 - val_handedness_loss: 0.6948\n",
      "Epoch 2/150\n",
      "14912/14912 [==============================] - 2s 110us/step - loss: 0.7910 - regression_loss: 0.0970 - handedness_loss: 0.6940 - val_loss: 0.7908 - val_regression_loss: 0.0953 - val_handedness_loss: 0.6955\n",
      "Epoch 3/150\n",
      "14912/14912 [==============================] - 2s 141us/step - loss: 0.7881 - regression_loss: 0.0939 - handedness_loss: 0.6942 - val_loss: 0.7864 - val_regression_loss: 0.0921 - val_handedness_loss: 0.6943\n",
      "Epoch 4/150\n",
      "14912/14912 [==============================] - 2s 145us/step - loss: 0.7871 - regression_loss: 0.0926 - handedness_loss: 0.6945 - val_loss: 0.7856 - val_regression_loss: 0.0916 - val_handedness_loss: 0.6940\n",
      "Epoch 5/150\n",
      "14912/14912 [==============================] - 2s 137us/step - loss: 0.7849 - regression_loss: 0.0910 - handedness_loss: 0.6939 - val_loss: 0.7842 - val_regression_loss: 0.0901 - val_handedness_loss: 0.6942\n",
      "Epoch 6/150\n",
      "14912/14912 [==============================] - 2s 127us/step - loss: 0.7828 - regression_loss: 0.0896 - handedness_loss: 0.6932 - val_loss: 0.7828 - val_regression_loss: 0.0891 - val_handedness_loss: 0.6937\n",
      "Epoch 7/150\n",
      "14912/14912 [==============================] - 2s 128us/step - loss: 0.7826 - regression_loss: 0.0889 - handedness_loss: 0.6937 - val_loss: 0.7819 - val_regression_loss: 0.0875 - val_handedness_loss: 0.6945\n",
      "Epoch 8/150\n",
      "14912/14912 [==============================] - 2s 141us/step - loss: 0.7816 - regression_loss: 0.0879 - handedness_loss: 0.6937 - val_loss: 0.7810 - val_regression_loss: 0.0876 - val_handedness_loss: 0.6935\n",
      "Epoch 9/150\n",
      "14912/14912 [==============================] - 2s 126us/step - loss: 0.7811 - regression_loss: 0.0877 - handedness_loss: 0.6934 - val_loss: 0.7804 - val_regression_loss: 0.0870 - val_handedness_loss: 0.6935\n",
      "Epoch 10/150\n",
      "14912/14912 [==============================] - 2s 134us/step - loss: 0.7806 - regression_loss: 0.0869 - handedness_loss: 0.6937 - val_loss: 0.7803 - val_regression_loss: 0.0863 - val_handedness_loss: 0.6941\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 11/150\n",
      "14912/14912 [==============================] - 2s 135us/step - loss: 0.7797 - regression_loss: 0.0865 - handedness_loss: 0.6933 - val_loss: 0.7798 - val_regression_loss: 0.0862 - val_handedness_loss: 0.6937\n",
      "Epoch 12/150\n",
      "14912/14912 [==============================] - 2s 144us/step - loss: 0.7795 - regression_loss: 0.0861 - handedness_loss: 0.6934 - val_loss: 0.7789 - val_regression_loss: 0.0854 - val_handedness_loss: 0.6936\n",
      "Epoch 13/150\n",
      "14912/14912 [==============================] - 2s 147us/step - loss: 0.7785 - regression_loss: 0.0855 - handedness_loss: 0.6931 - val_loss: 0.7784 - val_regression_loss: 0.0852 - val_handedness_loss: 0.6933\n",
      "Epoch 14/150\n",
      "14912/14912 [==============================] - 2s 145us/step - loss: 0.7790 - regression_loss: 0.0859 - handedness_loss: 0.6931 - val_loss: 0.7784 - val_regression_loss: 0.0847 - val_handedness_loss: 0.6937\n",
      "Epoch 15/150\n",
      "14912/14912 [==============================] - 1s 90us/step - loss: 0.7785 - regression_loss: 0.0852 - handedness_loss: 0.6932 - val_loss: 0.7782 - val_regression_loss: 0.0850 - val_handedness_loss: 0.6933\n",
      "Epoch 16/150\n",
      "14912/14912 [==============================] - 2s 123us/step - loss: 0.7781 - regression_loss: 0.0849 - handedness_loss: 0.6932 - val_loss: 0.7779 - val_regression_loss: 0.0844 - val_handedness_loss: 0.6936\n",
      "Epoch 17/150\n",
      "14912/14912 [==============================] - 2s 137us/step - loss: 0.7778 - regression_loss: 0.0847 - handedness_loss: 0.6931 - val_loss: 0.7778 - val_regression_loss: 0.0844 - val_handedness_loss: 0.6935\n",
      "Epoch 18/150\n",
      "14912/14912 [==============================] - 2s 130us/step - loss: 0.7775 - regression_loss: 0.0842 - handedness_loss: 0.6932 - val_loss: 0.7779 - val_regression_loss: 0.0843 - val_handedness_loss: 0.6936\n",
      "Epoch 19/150\n",
      "14912/14912 [==============================] - 2s 141us/step - loss: 0.7775 - regression_loss: 0.0843 - handedness_loss: 0.6932 - val_loss: 0.7773 - val_regression_loss: 0.0838 - val_handedness_loss: 0.6935\n",
      "Evaluating model with testing data...\n",
      "3174/3174 [==============================] - 0s 16us/step\n",
      "Getting distribution of predictions and covariance matrix...\n",
      "      1 of 20\n",
      "      2 of 20\n",
      "      3 of 20\n",
      "      4 of 20\n",
      "      5 of 20\n",
      "      6 of 20\n",
      "      7 of 20\n",
      "      8 of 20\n",
      "      9 of 20\n",
      "      10 of 20\n",
      "      11 of 20\n",
      "      12 of 20\n",
      "      13 of 20\n",
      "      14 of 20\n",
      "      15 of 20\n",
      "      16 of 20\n",
      "      17 of 20\n",
      "      18 of 20\n",
      "      19 of 20\n",
      "      20 of 20\n",
      "Computing ensemble means...\n",
      "Computing mean squared error...\n",
      "Iteration 104\n",
      "Train on 15052 samples, validate on 3204 samples\n",
      "Epoch 1/150\n",
      "15052/15052 [==============================] - 2s 141us/step - loss: 1.0281 - regression_loss: 0.3314 - handedness_loss: 0.6964 - val_loss: 0.9169 - val_regression_loss: 0.2208 - val_handedness_loss: 0.6934\n",
      "Epoch 2/150\n",
      "15052/15052 [==============================] - 2s 142us/step - loss: 0.8638 - regression_loss: 0.1704 - handedness_loss: 0.6933 - val_loss: 0.8258 - val_regression_loss: 0.1313 - val_handedness_loss: 0.6937\n",
      "Epoch 3/150\n",
      "15052/15052 [==============================] - 2s 146us/step - loss: 0.8134 - regression_loss: 0.1203 - handedness_loss: 0.6932 - val_loss: 0.8044 - val_regression_loss: 0.1100 - val_handedness_loss: 0.6939\n",
      "Epoch 4/150\n",
      "15052/15052 [==============================] - 2s 145us/step - loss: 0.7994 - regression_loss: 0.1061 - handedness_loss: 0.6932 - val_loss: 0.7969 - val_regression_loss: 0.1033 - val_handedness_loss: 0.6937\n",
      "Epoch 5/150\n",
      "15052/15052 [==============================] - 2s 136us/step - loss: 0.7941 - regression_loss: 0.1009 - handedness_loss: 0.6932 - val_loss: 0.7914 - val_regression_loss: 0.0969 - val_handedness_loss: 0.6939\n",
      "Evaluating model with testing data...\n",
      "3204/3204 [==============================] - 0s 16us/step\n",
      "Getting distribution of predictions and covariance matrix...\n",
      "      1 of 20\n",
      "      2 of 20\n",
      "      3 of 20\n",
      "      4 of 20\n",
      "      5 of 20\n",
      "      6 of 20\n",
      "      7 of 20\n",
      "      8 of 20\n",
      "      9 of 20\n",
      "      10 of 20\n",
      "      11 of 20\n",
      "      12 of 20\n",
      "      13 of 20\n",
      "      14 of 20\n",
      "      15 of 20\n",
      "      16 of 20\n",
      "      17 of 20\n",
      "      18 of 20\n",
      "      19 of 20\n",
      "      20 of 20\n",
      "Computing ensemble means...\n",
      "Computing mean squared error...\n",
      "Iteration 105\n",
      "Train on 15192 samples, validate on 3234 samples\n",
      "Epoch 1/150\n",
      "15192/15192 [==============================] - 2s 142us/step - loss: 0.9354 - regression_loss: 0.2365 - handedness_loss: 0.6985 - val_loss: 0.7899 - val_regression_loss: 0.0957 - val_handedness_loss: 0.6944\n",
      "Epoch 2/150\n",
      "15192/15192 [==============================] - 2s 136us/step - loss: 0.7915 - regression_loss: 0.0966 - handedness_loss: 0.6949 - val_loss: 0.7899 - val_regression_loss: 0.0949 - val_handedness_loss: 0.6946\n",
      "Epoch 3/150\n",
      "15192/15192 [==============================] - 2s 148us/step - loss: 0.7880 - regression_loss: 0.0942 - handedness_loss: 0.6937 - val_loss: 0.7859 - val_regression_loss: 0.0921 - val_handedness_loss: 0.6927\n",
      "Epoch 4/150\n",
      "15192/15192 [==============================] - 2s 145us/step - loss: 0.7871 - regression_loss: 0.0928 - handedness_loss: 0.6942 - val_loss: 0.7882 - val_regression_loss: 0.0914 - val_handedness_loss: 0.6966\n",
      "Epoch 5/150\n",
      "15192/15192 [==============================] - 2s 129us/step - loss: 0.7857 - regression_loss: 0.0918 - handedness_loss: 0.6938 - val_loss: 0.7863 - val_regression_loss: 0.0899 - val_handedness_loss: 0.6957\n",
      "Epoch 6/150\n",
      "15192/15192 [==============================] - 2s 142us/step - loss: 0.7845 - regression_loss: 0.0909 - handedness_loss: 0.6937 - val_loss: 0.7848 - val_regression_loss: 0.0886 - val_handedness_loss: 0.6951\n",
      "Epoch 7/150\n",
      "15192/15192 [==============================] - 2s 140us/step - loss: 0.7836 - regression_loss: 0.0898 - handedness_loss: 0.6938 - val_loss: 0.7822 - val_regression_loss: 0.0880 - val_handedness_loss: 0.6934\n",
      "Evaluating model with testing data...\n",
      "3234/3234 [==============================] - 0s 17us/step\n",
      "Getting distribution of predictions and covariance matrix...\n",
      "      1 of 20\n",
      "      2 of 20\n",
      "      3 of 20\n",
      "      4 of 20\n",
      "      5 of 20\n",
      "      6 of 20\n",
      "      7 of 20\n",
      "      8 of 20\n",
      "      9 of 20\n",
      "      10 of 20\n",
      "      11 of 20\n",
      "      12 of 20\n",
      "      13 of 20\n",
      "      14 of 20\n",
      "      15 of 20\n",
      "      16 of 20\n",
      "      17 of 20\n",
      "      18 of 20\n",
      "      19 of 20\n",
      "      20 of 20\n",
      "Computing ensemble means...\n",
      "Computing mean squared error...\n",
      "Iteration 106\n",
      "Train on 15332 samples, validate on 3264 samples\n",
      "Epoch 1/150\n",
      "15332/15332 [==============================] - 2s 127us/step - loss: 1.0468 - regression_loss: 0.3550 - handedness_loss: 0.6917 - val_loss: 0.9422 - val_regression_loss: 0.2491 - val_handedness_loss: 0.6929\n",
      "Epoch 2/150\n",
      "15332/15332 [==============================] - 2s 139us/step - loss: 0.8989 - regression_loss: 0.2051 - handedness_loss: 0.6937 - val_loss: 0.8550 - val_regression_loss: 0.1623 - val_handedness_loss: 0.6927\n",
      "Epoch 3/150\n",
      "15332/15332 [==============================] - 2s 122us/step - loss: 0.8308 - regression_loss: 0.1371 - handedness_loss: 0.6937 - val_loss: 0.8127 - val_regression_loss: 0.1193 - val_handedness_loss: 0.6936\n",
      "Epoch 4/150\n",
      "15332/15332 [==============================] - 2s 138us/step - loss: 0.8057 - regression_loss: 0.1120 - handedness_loss: 0.6936 - val_loss: 0.8005 - val_regression_loss: 0.1070 - val_handedness_loss: 0.6936\n",
      "Epoch 5/150\n",
      "15332/15332 [==============================] - 2s 130us/step - loss: 0.7954 - regression_loss: 0.1022 - handedness_loss: 0.6933 - val_loss: 0.7910 - val_regression_loss: 0.0976 - val_handedness_loss: 0.6936\n",
      "Epoch 6/150\n",
      "15332/15332 [==============================] - 2s 141us/step - loss: 0.7887 - regression_loss: 0.0954 - handedness_loss: 0.6933 - val_loss: 0.7870 - val_regression_loss: 0.0927 - val_handedness_loss: 0.6944\n",
      "Evaluating model with testing data...\n",
      "3264/3264 [==============================] - 0s 17us/step\n",
      "Getting distribution of predictions and covariance matrix...\n",
      "      1 of 20\n",
      "      2 of 20\n",
      "      3 of 20\n",
      "      4 of 20\n",
      "      5 of 20\n",
      "      6 of 20\n",
      "      7 of 20\n",
      "      8 of 20\n",
      "      9 of 20\n",
      "      10 of 20\n",
      "      11 of 20\n",
      "      12 of 20\n",
      "      13 of 20\n",
      "      14 of 20\n",
      "      15 of 20\n",
      "      16 of 20\n",
      "      17 of 20\n",
      "      18 of 20\n",
      "      19 of 20\n",
      "      20 of 20\n",
      "Computing ensemble means...\n",
      "Computing mean squared error...\n",
      "Iteration 107\n",
      "Train on 15472 samples, validate on 3294 samples\n",
      "Epoch 1/150\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15472/15472 [==============================] - 2s 136us/step - loss: 0.9904 - regression_loss: 0.3353 - handedness_loss: 0.6550 - val_loss: 0.9477 - val_regression_loss: 0.2544 - val_handedness_loss: 0.6930\n",
      "Epoch 2/150\n",
      "15472/15472 [==============================] - 2s 130us/step - loss: 0.8924 - regression_loss: 0.1986 - handedness_loss: 0.6938 - val_loss: 0.8424 - val_regression_loss: 0.1472 - val_handedness_loss: 0.6950\n",
      "Epoch 3/150\n",
      "15472/15472 [==============================] - 2s 139us/step - loss: 0.8164 - regression_loss: 0.1217 - handedness_loss: 0.6947 - val_loss: 0.7979 - val_regression_loss: 0.1041 - val_handedness_loss: 0.6937\n",
      "Epoch 4/150\n",
      "15472/15472 [==============================] - 2s 145us/step - loss: 0.7949 - regression_loss: 0.1007 - handedness_loss: 0.6942 - val_loss: 0.7922 - val_regression_loss: 0.0969 - val_handedness_loss: 0.6952\n",
      "Epoch 5/150\n",
      "15472/15472 [==============================] - 2s 147us/step - loss: 0.7894 - regression_loss: 0.0952 - handedness_loss: 0.6942 - val_loss: 0.7888 - val_regression_loss: 0.0935 - val_handedness_loss: 0.6953\n",
      "Evaluating model with testing data...\n",
      "3294/3294 [==============================] - 0s 17us/step\n",
      "Getting distribution of predictions and covariance matrix...\n",
      "      1 of 20\n",
      "      2 of 20\n",
      "      3 of 20\n",
      "      4 of 20\n",
      "      5 of 20\n",
      "      6 of 20\n",
      "      7 of 20\n",
      "      8 of 20\n",
      "      9 of 20\n",
      "      10 of 20\n",
      "      11 of 20\n",
      "      12 of 20\n",
      "      13 of 20\n",
      "      14 of 20\n",
      "      15 of 20\n",
      "      16 of 20\n",
      "      17 of 20\n",
      "      18 of 20\n",
      "      19 of 20\n",
      "      20 of 20\n",
      "Computing ensemble means...\n",
      "Computing mean squared error...\n",
      "Iteration 108\n",
      "Train on 15612 samples, validate on 3324 samples\n",
      "Epoch 1/150\n",
      "15612/15612 [==============================] - 2s 142us/step - loss: 1.0100 - regression_loss: 0.3167 - handedness_loss: 0.6934 - val_loss: 0.9481 - val_regression_loss: 0.2541 - val_handedness_loss: 0.6939\n",
      "Epoch 2/150\n",
      "15612/15612 [==============================] - 2s 135us/step - loss: 0.8935 - regression_loss: 0.2002 - handedness_loss: 0.6932 - val_loss: 0.8454 - val_regression_loss: 0.1526 - val_handedness_loss: 0.6928\n",
      "Epoch 3/150\n",
      "15612/15612 [==============================] - 2s 146us/step - loss: 0.8221 - regression_loss: 0.1288 - handedness_loss: 0.6932 - val_loss: 0.8047 - val_regression_loss: 0.1110 - val_handedness_loss: 0.6936\n",
      "Epoch 4/150\n",
      "15612/15612 [==============================] - 2s 148us/step - loss: 0.7978 - regression_loss: 0.1045 - handedness_loss: 0.6933 - val_loss: 0.7910 - val_regression_loss: 0.0977 - val_handedness_loss: 0.6933\n",
      "Epoch 5/150\n",
      "15612/15612 [==============================] - 2s 149us/step - loss: 0.7901 - regression_loss: 0.0972 - handedness_loss: 0.6929 - val_loss: 0.7885 - val_regression_loss: 0.0940 - val_handedness_loss: 0.6944\n",
      "Epoch 6/150\n",
      "15612/15612 [==============================] - 2s 145us/step - loss: 0.7867 - regression_loss: 0.0933 - handedness_loss: 0.6934 - val_loss: 0.7849 - val_regression_loss: 0.0914 - val_handedness_loss: 0.6935\n",
      "Evaluating model with testing data...\n",
      "3324/3324 [==============================] - 0s 17us/step\n",
      "Getting distribution of predictions and covariance matrix...\n",
      "      1 of 20\n",
      "      2 of 20\n",
      "      3 of 20\n",
      "      4 of 20\n",
      "      5 of 20\n",
      "      6 of 20\n",
      "      7 of 20\n",
      "      8 of 20\n",
      "      9 of 20\n",
      "      10 of 20\n",
      "      11 of 20\n",
      "      12 of 20\n",
      "      13 of 20\n",
      "      14 of 20\n",
      "      15 of 20\n",
      "      16 of 20\n",
      "      17 of 20\n",
      "      18 of 20\n",
      "      19 of 20\n",
      "      20 of 20\n",
      "Computing ensemble means...\n",
      "Computing mean squared error...\n",
      "Iteration 109\n",
      "Train on 15752 samples, validate on 3354 samples\n",
      "Epoch 1/150\n",
      "15752/15752 [==============================] - 2s 142us/step - loss: 1.0188 - regression_loss: 0.3216 - handedness_loss: 0.6955 - val_loss: 0.7954 - val_regression_loss: 0.0992 - val_handedness_loss: 0.6960\n",
      "Epoch 2/150\n",
      "15752/15752 [==============================] - 2s 144us/step - loss: 0.7942 - regression_loss: 0.0999 - handedness_loss: 0.6943 - val_loss: 0.7934 - val_regression_loss: 0.0985 - val_handedness_loss: 0.6948\n",
      "Epoch 3/150\n",
      "15752/15752 [==============================] - 2s 146us/step - loss: 0.7912 - regression_loss: 0.0967 - handedness_loss: 0.6939 - val_loss: 0.7900 - val_regression_loss: 0.0948 - val_handedness_loss: 0.6948\n",
      "Epoch 4/150\n",
      "15752/15752 [==============================] - 2s 147us/step - loss: 0.7888 - regression_loss: 0.0948 - handedness_loss: 0.6939 - val_loss: 0.7861 - val_regression_loss: 0.0927 - val_handedness_loss: 0.6933\n",
      "Epoch 5/150\n",
      "15752/15752 [==============================] - 2s 147us/step - loss: 0.7879 - regression_loss: 0.0941 - handedness_loss: 0.6941 - val_loss: 0.7866 - val_regression_loss: 0.0928 - val_handedness_loss: 0.6940\n",
      "Epoch 6/150\n",
      "15752/15752 [==============================] - 2s 139us/step - loss: 0.7868 - regression_loss: 0.0931 - handedness_loss: 0.6941 - val_loss: 0.7857 - val_regression_loss: 0.0914 - val_handedness_loss: 0.6945\n",
      "Epoch 7/150\n",
      "15752/15752 [==============================] - 2s 143us/step - loss: 0.7848 - regression_loss: 0.0917 - handedness_loss: 0.6935 - val_loss: 0.7848 - val_regression_loss: 0.0908 - val_handedness_loss: 0.6935\n",
      "Epoch 8/150\n",
      "15752/15752 [==============================] - 2s 140us/step - loss: 0.7846 - regression_loss: 0.0912 - handedness_loss: 0.6934 - val_loss: 0.7830 - val_regression_loss: 0.0895 - val_handedness_loss: 0.6938\n",
      "Evaluating model with testing data...\n",
      "3354/3354 [==============================] - 0s 16us/step\n",
      "Getting distribution of predictions and covariance matrix...\n",
      "      1 of 20\n",
      "      2 of 20\n",
      "      3 of 20\n",
      "      4 of 20\n",
      "      5 of 20\n",
      "      6 of 20\n",
      "      7 of 20\n",
      "      8 of 20\n",
      "      9 of 20\n",
      "      10 of 20\n",
      "      11 of 20\n",
      "      12 of 20\n",
      "      13 of 20\n",
      "      14 of 20\n",
      "      15 of 20\n",
      "      16 of 20\n",
      "      17 of 20\n",
      "      18 of 20\n",
      "      19 of 20\n",
      "      20 of 20\n",
      "Computing ensemble means...\n",
      "Computing mean squared error...\n",
      "Iteration 110\n",
      "Train on 15892 samples, validate on 3384 samples\n",
      "Epoch 1/150\n",
      "15892/15892 [==============================] - 2s 139us/step - loss: 1.0110 - regression_loss: 0.3290 - handedness_loss: 0.6807 - val_loss: 0.8133 - val_regression_loss: 0.1154 - val_handedness_loss: 0.6973\n",
      "Epoch 2/150\n",
      "15892/15892 [==============================] - 2s 146us/step - loss: 0.8009 - regression_loss: 0.1053 - handedness_loss: 0.6957 - val_loss: 0.7936 - val_regression_loss: 0.0990 - val_handedness_loss: 0.6943\n",
      "Epoch 3/150\n",
      "15892/15892 [==============================] - 2s 132us/step - loss: 0.7929 - regression_loss: 0.0992 - handedness_loss: 0.6940 - val_loss: 0.7891 - val_regression_loss: 0.0958 - val_handedness_loss: 0.6932\n",
      "Epoch 4/150\n",
      "15892/15892 [==============================] - 2s 143us/step - loss: 0.7905 - regression_loss: 0.0964 - handedness_loss: 0.6941 - val_loss: 0.7866 - val_regression_loss: 0.0930 - val_handedness_loss: 0.6934\n",
      "Epoch 5/150\n",
      "15892/15892 [==============================] - 2s 137us/step - loss: 0.7877 - regression_loss: 0.0942 - handedness_loss: 0.6937 - val_loss: 0.7866 - val_regression_loss: 0.0928 - val_handedness_loss: 0.6937\n",
      "Epoch 6/150\n",
      "15892/15892 [==============================] - 2s 145us/step - loss: 0.7861 - regression_loss: 0.0926 - handedness_loss: 0.6936 - val_loss: 0.7843 - val_regression_loss: 0.0911 - val_handedness_loss: 0.6930\n",
      "Epoch 7/150\n",
      "15892/15892 [==============================] - 2s 106us/step - loss: 0.7848 - regression_loss: 0.0913 - handedness_loss: 0.6935 - val_loss: 0.7829 - val_regression_loss: 0.0891 - val_handedness_loss: 0.6936\n",
      "Epoch 8/150\n",
      "15892/15892 [==============================] - 2s 97us/step - loss: 0.7832 - regression_loss: 0.0898 - handedness_loss: 0.6934 - val_loss: 0.7837 - val_regression_loss: 0.0894 - val_handedness_loss: 0.6940\n",
      "Epoch 9/150\n",
      "15892/15892 [==============================] - 2s 130us/step - loss: 0.7821 - regression_loss: 0.0888 - handedness_loss: 0.6933 - val_loss: 0.7804 - val_regression_loss: 0.0874 - val_handedness_loss: 0.6927\n",
      "Epoch 10/150\n",
      "15892/15892 [==============================] - 2s 126us/step - loss: 0.7818 - regression_loss: 0.0885 - handedness_loss: 0.6933 - val_loss: 0.7806 - val_regression_loss: 0.0867 - val_handedness_loss: 0.6937\n",
      "Epoch 11/150\n",
      "15892/15892 [==============================] - 2s 126us/step - loss: 0.7809 - regression_loss: 0.0878 - handedness_loss: 0.6933 - val_loss: 0.7791 - val_regression_loss: 0.0861 - val_handedness_loss: 0.6928\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 12/150\n",
      "15892/15892 [==============================] - 2s 133us/step - loss: 0.7801 - regression_loss: 0.0867 - handedness_loss: 0.6934 - val_loss: 0.7785 - val_regression_loss: 0.0846 - val_handedness_loss: 0.6937\n",
      "Epoch 13/150\n",
      "15892/15892 [==============================] - 2s 143us/step - loss: 0.7796 - regression_loss: 0.0863 - handedness_loss: 0.6933 - val_loss: 0.7786 - val_regression_loss: 0.0846 - val_handedness_loss: 0.6937\n",
      "Evaluating model with testing data...\n",
      "3384/3384 [==============================] - 0s 16us/step\n",
      "Getting distribution of predictions and covariance matrix...\n",
      "      1 of 20\n",
      "      2 of 20\n",
      "      3 of 20\n",
      "      4 of 20\n",
      "      5 of 20\n",
      "      6 of 20\n",
      "      7 of 20\n",
      "      8 of 20\n",
      "      9 of 20\n",
      "      10 of 20\n",
      "      11 of 20\n",
      "      12 of 20\n",
      "      13 of 20\n",
      "      14 of 20\n",
      "      15 of 20\n",
      "      16 of 20\n",
      "      17 of 20\n",
      "      18 of 20\n",
      "      19 of 20\n",
      "      20 of 20\n",
      "Computing ensemble means...\n",
      "Computing mean squared error...\n",
      "Iteration 111\n",
      "Train on 16032 samples, validate on 3414 samples\n",
      "Epoch 1/150\n",
      "16032/16032 [==============================] - 2s 144us/step - loss: 0.9532 - regression_loss: 0.2770 - handedness_loss: 0.6752 - val_loss: 0.7882 - val_regression_loss: 0.0941 - val_handedness_loss: 0.6942\n",
      "Epoch 2/150\n",
      "16032/16032 [==============================] - 2s 145us/step - loss: 0.7892 - regression_loss: 0.0947 - handedness_loss: 0.6946 - val_loss: 0.7869 - val_regression_loss: 0.0920 - val_handedness_loss: 0.6949\n",
      "Epoch 3/150\n",
      "16032/16032 [==============================] - 2s 147us/step - loss: 0.7874 - regression_loss: 0.0933 - handedness_loss: 0.6941 - val_loss: 0.7852 - val_regression_loss: 0.0907 - val_handedness_loss: 0.6945\n",
      "Epoch 4/150\n",
      "16032/16032 [==============================] - 2s 147us/step - loss: 0.7846 - regression_loss: 0.0914 - handedness_loss: 0.6933 - val_loss: 0.7839 - val_regression_loss: 0.0897 - val_handedness_loss: 0.6942\n",
      "Epoch 5/150\n",
      "16032/16032 [==============================] - 2s 147us/step - loss: 0.7839 - regression_loss: 0.0904 - handedness_loss: 0.6935 - val_loss: 0.7818 - val_regression_loss: 0.0890 - val_handedness_loss: 0.6928\n",
      "Epoch 6/150\n",
      "16032/16032 [==============================] - 2s 147us/step - loss: 0.7831 - regression_loss: 0.0894 - handedness_loss: 0.6937 - val_loss: 0.7815 - val_regression_loss: 0.0877 - val_handedness_loss: 0.6937\n",
      "Epoch 7/150\n",
      "16032/16032 [==============================] - 2s 147us/step - loss: 0.7825 - regression_loss: 0.0891 - handedness_loss: 0.6933 - val_loss: 0.7812 - val_regression_loss: 0.0876 - val_handedness_loss: 0.6936\n",
      "Epoch 8/150\n",
      "16032/16032 [==============================] - 2s 148us/step - loss: 0.7818 - regression_loss: 0.0885 - handedness_loss: 0.6933 - val_loss: 0.7802 - val_regression_loss: 0.0865 - val_handedness_loss: 0.6936\n",
      "Epoch 9/150\n",
      "16032/16032 [==============================] - 2s 141us/step - loss: 0.7814 - regression_loss: 0.0881 - handedness_loss: 0.6933 - val_loss: 0.7821 - val_regression_loss: 0.0876 - val_handedness_loss: 0.6945\n",
      "Evaluating model with testing data...\n",
      "3414/3414 [==============================] - 0s 17us/step\n",
      "Getting distribution of predictions and covariance matrix...\n",
      "      1 of 20\n",
      "      2 of 20\n",
      "      3 of 20\n",
      "      4 of 20\n",
      "      5 of 20\n",
      "      6 of 20\n",
      "      7 of 20\n",
      "      8 of 20\n",
      "      9 of 20\n",
      "      10 of 20\n",
      "      11 of 20\n",
      "      12 of 20\n",
      "      13 of 20\n",
      "      14 of 20\n",
      "      15 of 20\n",
      "      16 of 20\n",
      "      17 of 20\n",
      "      18 of 20\n",
      "      19 of 20\n",
      "      20 of 20\n",
      "Computing ensemble means...\n",
      "Computing mean squared error...\n",
      "Iteration 112\n",
      "Train on 16172 samples, validate on 3444 samples\n",
      "Epoch 1/150\n",
      "16172/16172 [==============================] - 2s 144us/step - loss: 0.9413 - regression_loss: 0.2502 - handedness_loss: 0.6904 - val_loss: 0.7943 - val_regression_loss: 0.0994 - val_handedness_loss: 0.6949\n",
      "Epoch 2/150\n",
      "16172/16172 [==============================] - 2s 145us/step - loss: 0.7951 - regression_loss: 0.1000 - handedness_loss: 0.6952 - val_loss: 0.7911 - val_regression_loss: 0.0953 - val_handedness_loss: 0.6958\n",
      "Epoch 3/150\n",
      "16172/16172 [==============================] - 2s 148us/step - loss: 0.7904 - regression_loss: 0.0961 - handedness_loss: 0.6943 - val_loss: 0.7874 - val_regression_loss: 0.0934 - val_handedness_loss: 0.6940\n",
      "Epoch 4/150\n",
      "16172/16172 [==============================] - 2s 148us/step - loss: 0.7884 - regression_loss: 0.0946 - handedness_loss: 0.6938 - val_loss: 0.7851 - val_regression_loss: 0.0914 - val_handedness_loss: 0.6937\n",
      "Epoch 5/150\n",
      "16172/16172 [==============================] - 2s 148us/step - loss: 0.7859 - regression_loss: 0.0926 - handedness_loss: 0.6933 - val_loss: 0.7837 - val_regression_loss: 0.0902 - val_handedness_loss: 0.6936\n",
      "Epoch 6/150\n",
      "16172/16172 [==============================] - 2s 137us/step - loss: 0.7852 - regression_loss: 0.0915 - handedness_loss: 0.6936 - val_loss: 0.7824 - val_regression_loss: 0.0886 - val_handedness_loss: 0.6939\n",
      "Epoch 7/150\n",
      "16172/16172 [==============================] - 2s 133us/step - loss: 0.7832 - regression_loss: 0.0900 - handedness_loss: 0.6933 - val_loss: 0.7828 - val_regression_loss: 0.0882 - val_handedness_loss: 0.6946\n",
      "Epoch 8/150\n",
      "16172/16172 [==============================] - 2s 147us/step - loss: 0.7825 - regression_loss: 0.0889 - handedness_loss: 0.6936 - val_loss: 0.7813 - val_regression_loss: 0.0873 - val_handedness_loss: 0.6941\n",
      "Epoch 9/150\n",
      "16172/16172 [==============================] - 2s 148us/step - loss: 0.7816 - regression_loss: 0.0883 - handedness_loss: 0.6933 - val_loss: 0.7783 - val_regression_loss: 0.0858 - val_handedness_loss: 0.6925\n",
      "Epoch 10/150\n",
      "16172/16172 [==============================] - 2s 148us/step - loss: 0.7810 - regression_loss: 0.0876 - handedness_loss: 0.6933 - val_loss: 0.7797 - val_regression_loss: 0.0859 - val_handedness_loss: 0.6939\n",
      "Epoch 11/150\n",
      "16172/16172 [==============================] - 2s 148us/step - loss: 0.7799 - regression_loss: 0.0866 - handedness_loss: 0.6932 - val_loss: 0.7779 - val_regression_loss: 0.0844 - val_handedness_loss: 0.6935\n",
      "Epoch 12/150\n",
      "16172/16172 [==============================] - 2s 148us/step - loss: 0.7798 - regression_loss: 0.0865 - handedness_loss: 0.6934 - val_loss: 0.7788 - val_regression_loss: 0.0851 - val_handedness_loss: 0.6938\n",
      "Epoch 13/150\n",
      "16172/16172 [==============================] - 2s 148us/step - loss: 0.7793 - regression_loss: 0.0859 - handedness_loss: 0.6934 - val_loss: 0.7778 - val_regression_loss: 0.0843 - val_handedness_loss: 0.6936\n",
      "Evaluating model with testing data...\n",
      "3444/3444 [==============================] - 0s 17us/step\n",
      "Getting distribution of predictions and covariance matrix...\n",
      "      1 of 20\n",
      "      2 of 20\n",
      "      3 of 20\n",
      "      4 of 20\n",
      "      5 of 20\n",
      "      6 of 20\n",
      "      7 of 20\n",
      "      8 of 20\n",
      "      9 of 20\n",
      "      10 of 20\n",
      "      11 of 20\n",
      "      12 of 20\n",
      "      13 of 20\n",
      "      14 of 20\n",
      "      15 of 20\n",
      "      16 of 20\n",
      "      17 of 20\n",
      "      18 of 20\n",
      "      19 of 20\n",
      "      20 of 20\n",
      "Computing ensemble means...\n",
      "Computing mean squared error...\n",
      "Iteration 113\n",
      "Train on 16312 samples, validate on 3474 samples\n",
      "Epoch 1/150\n",
      "16312/16312 [==============================] - 2s 128us/step - loss: 0.9902 - regression_loss: 0.3087 - handedness_loss: 0.6813 - val_loss: 0.9289 - val_regression_loss: 0.2370 - val_handedness_loss: 0.6932\n",
      "Epoch 2/150\n",
      "16312/16312 [==============================] - 2s 136us/step - loss: 0.8901 - regression_loss: 0.1967 - handedness_loss: 0.6932 - val_loss: 0.8478 - val_regression_loss: 0.1554 - val_handedness_loss: 0.6933\n",
      "Epoch 3/150\n",
      "16312/16312 [==============================] - 2s 138us/step - loss: 0.8271 - regression_loss: 0.1338 - handedness_loss: 0.6932 - val_loss: 0.8055 - val_regression_loss: 0.1125 - val_handedness_loss: 0.6933\n",
      "Epoch 4/150\n",
      "16312/16312 [==============================] - 2s 132us/step - loss: 0.7989 - regression_loss: 0.1057 - handedness_loss: 0.6932 - val_loss: 0.7908 - val_regression_loss: 0.0974 - val_handedness_loss: 0.6936\n",
      "Epoch 5/150\n",
      "16312/16312 [==============================] - 2s 132us/step - loss: 0.7883 - regression_loss: 0.0952 - handedness_loss: 0.6932 - val_loss: 0.7842 - val_regression_loss: 0.0910 - val_handedness_loss: 0.6934\n",
      "Evaluating model with testing data...\n",
      "3474/3474 [==============================] - 0s 16us/step\n",
      "Getting distribution of predictions and covariance matrix...\n",
      "      1 of 20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      2 of 20\n",
      "      3 of 20\n",
      "      4 of 20\n",
      "      5 of 20\n",
      "      6 of 20\n",
      "      7 of 20\n",
      "      8 of 20\n",
      "      9 of 20\n",
      "      10 of 20\n",
      "      11 of 20\n",
      "      12 of 20\n",
      "      13 of 20\n",
      "      14 of 20\n",
      "      15 of 20\n",
      "      16 of 20\n",
      "      17 of 20\n",
      "      18 of 20\n",
      "      19 of 20\n",
      "      20 of 20\n",
      "Computing ensemble means...\n",
      "Computing mean squared error...\n",
      "Iteration 114\n",
      "Train on 16452 samples, validate on 3504 samples\n",
      "Epoch 1/150\n",
      "16452/16452 [==============================] - 2s 130us/step - loss: 0.9534 - regression_loss: 0.2774 - handedness_loss: 0.6757 - val_loss: 0.8420 - val_regression_loss: 0.1412 - val_handedness_loss: 0.7008\n",
      "Epoch 2/150\n",
      "16452/16452 [==============================] - 2s 144us/step - loss: 0.8180 - regression_loss: 0.1209 - handedness_loss: 0.6970 - val_loss: 0.8043 - val_regression_loss: 0.1077 - val_handedness_loss: 0.6963\n",
      "Epoch 3/150\n",
      "16452/16452 [==============================] - 2s 146us/step - loss: 0.7995 - regression_loss: 0.1048 - handedness_loss: 0.6948 - val_loss: 0.7965 - val_regression_loss: 0.1013 - val_handedness_loss: 0.6954\n",
      "Epoch 4/150\n",
      "16452/16452 [==============================] - 2s 135us/step - loss: 0.7932 - regression_loss: 0.0988 - handedness_loss: 0.6943 - val_loss: 0.7899 - val_regression_loss: 0.0950 - val_handedness_loss: 0.6951\n",
      "Epoch 5/150\n",
      "16452/16452 [==============================] - 2s 145us/step - loss: 0.7894 - regression_loss: 0.0954 - handedness_loss: 0.6939 - val_loss: 0.7865 - val_regression_loss: 0.0926 - val_handedness_loss: 0.6939\n",
      "Epoch 6/150\n",
      "16452/16452 [==============================] - 2s 147us/step - loss: 0.7863 - regression_loss: 0.0926 - handedness_loss: 0.6937 - val_loss: 0.7852 - val_regression_loss: 0.0903 - val_handedness_loss: 0.6951\n",
      "Epoch 7/150\n",
      "16452/16452 [==============================] - 2s 127us/step - loss: 0.7837 - regression_loss: 0.0904 - handedness_loss: 0.6932 - val_loss: 0.7828 - val_regression_loss: 0.0888 - val_handedness_loss: 0.6941\n",
      "Epoch 8/150\n",
      "16452/16452 [==============================] - 2s 136us/step - loss: 0.7821 - regression_loss: 0.0889 - handedness_loss: 0.6933 - val_loss: 0.7801 - val_regression_loss: 0.0865 - val_handedness_loss: 0.6936\n",
      "Epoch 9/150\n",
      "16452/16452 [==============================] - 2s 139us/step - loss: 0.7803 - regression_loss: 0.0872 - handedness_loss: 0.6932 - val_loss: 0.7791 - val_regression_loss: 0.0854 - val_handedness_loss: 0.6937\n",
      "Epoch 10/150\n",
      "16452/16452 [==============================] - 2s 139us/step - loss: 0.7795 - regression_loss: 0.0861 - handedness_loss: 0.6934 - val_loss: 0.7780 - val_regression_loss: 0.0844 - val_handedness_loss: 0.6936\n",
      "Epoch 11/150\n",
      "16452/16452 [==============================] - 2s 136us/step - loss: 0.7784 - regression_loss: 0.0854 - handedness_loss: 0.6930 - val_loss: 0.7777 - val_regression_loss: 0.0841 - val_handedness_loss: 0.6937\n",
      "Epoch 12/150\n",
      "16452/16452 [==============================] - 2s 131us/step - loss: 0.7781 - regression_loss: 0.0850 - handedness_loss: 0.6932 - val_loss: 0.7771 - val_regression_loss: 0.0838 - val_handedness_loss: 0.6934\n",
      "Epoch 13/150\n",
      "16452/16452 [==============================] - 2s 140us/step - loss: 0.7776 - regression_loss: 0.0844 - handedness_loss: 0.6931 - val_loss: 0.7774 - val_regression_loss: 0.0839 - val_handedness_loss: 0.6936\n",
      "Epoch 14/150\n",
      "16452/16452 [==============================] - 2s 142us/step - loss: 0.7772 - regression_loss: 0.0841 - handedness_loss: 0.6931 - val_loss: 0.7766 - val_regression_loss: 0.0832 - val_handedness_loss: 0.6935\n",
      "Epoch 15/150\n",
      "16452/16452 [==============================] - 2s 141us/step - loss: 0.7772 - regression_loss: 0.0840 - handedness_loss: 0.6932 - val_loss: 0.7765 - val_regression_loss: 0.0830 - val_handedness_loss: 0.6936\n",
      "Epoch 16/150\n",
      "16452/16452 [==============================] - 2s 93us/step - loss: 0.7769 - regression_loss: 0.0838 - handedness_loss: 0.6932 - val_loss: 0.7765 - val_regression_loss: 0.0829 - val_handedness_loss: 0.6936\n",
      "Evaluating model with testing data...\n",
      "3504/3504 [==============================] - 0s 16us/step\n",
      "Getting distribution of predictions and covariance matrix...\n",
      "      1 of 20\n",
      "      2 of 20\n",
      "      3 of 20\n",
      "      4 of 20\n",
      "      5 of 20\n",
      "      6 of 20\n",
      "      7 of 20\n",
      "      8 of 20\n",
      "      9 of 20\n",
      "      10 of 20\n",
      "      11 of 20\n",
      "      12 of 20\n",
      "      13 of 20\n",
      "      14 of 20\n",
      "      15 of 20\n",
      "      16 of 20\n",
      "      17 of 20\n",
      "      18 of 20\n",
      "      19 of 20\n",
      "      20 of 20\n",
      "Computing ensemble means...\n",
      "Computing mean squared error...\n",
      "Iteration 115\n",
      "Train on 16592 samples, validate on 3534 samples\n",
      "Epoch 1/150\n",
      "16592/16592 [==============================] - 2s 126us/step - loss: 0.9930 - regression_loss: 0.2996 - handedness_loss: 0.6930 - val_loss: 0.8866 - val_regression_loss: 0.1938 - val_handedness_loss: 0.6934\n",
      "Epoch 2/150\n",
      "16592/16592 [==============================] - 2s 139us/step - loss: 0.8309 - regression_loss: 0.1369 - handedness_loss: 0.6939 - val_loss: 0.8001 - val_regression_loss: 0.1059 - val_handedness_loss: 0.6942\n",
      "Epoch 3/150\n",
      "16592/16592 [==============================] - 2s 141us/step - loss: 0.7963 - regression_loss: 0.1030 - handedness_loss: 0.6934 - val_loss: 0.7931 - val_regression_loss: 0.0997 - val_handedness_loss: 0.6935\n",
      "Epoch 4/150\n",
      "16592/16592 [==============================] - 2s 144us/step - loss: 0.7925 - regression_loss: 0.0989 - handedness_loss: 0.6936 - val_loss: 0.7902 - val_regression_loss: 0.0963 - val_handedness_loss: 0.6939\n",
      "Epoch 5/150\n",
      "16592/16592 [==============================] - 2s 147us/step - loss: 0.7894 - regression_loss: 0.0961 - handedness_loss: 0.6933 - val_loss: 0.7856 - val_regression_loss: 0.0918 - val_handedness_loss: 0.6938\n",
      "Evaluating model with testing data...\n",
      "3534/3534 [==============================] - 0s 17us/step\n",
      "Getting distribution of predictions and covariance matrix...\n",
      "      1 of 20\n",
      "      2 of 20\n",
      "      3 of 20\n",
      "      4 of 20\n",
      "      5 of 20\n",
      "      6 of 20\n",
      "      7 of 20\n",
      "      8 of 20\n",
      "      9 of 20\n",
      "      10 of 20\n",
      "      11 of 20\n",
      "      12 of 20\n",
      "      13 of 20\n",
      "      14 of 20\n",
      "      15 of 20\n",
      "      16 of 20\n",
      "      17 of 20\n",
      "      18 of 20\n",
      "      19 of 20\n",
      "      20 of 20\n",
      "Computing ensemble means...\n",
      "Computing mean squared error...\n",
      "Iteration 116\n",
      "Train on 16732 samples, validate on 3564 samples\n",
      "Epoch 1/150\n",
      "16732/16732 [==============================] - 2s 134us/step - loss: 1.0139 - regression_loss: 0.3340 - handedness_loss: 0.6797 - val_loss: 0.9282 - val_regression_loss: 0.2353 - val_handedness_loss: 0.6932\n",
      "Epoch 2/150\n",
      "16732/16732 [==============================] - 2s 134us/step - loss: 0.8833 - regression_loss: 0.1899 - handedness_loss: 0.6934 - val_loss: 0.8360 - val_regression_loss: 0.1410 - val_handedness_loss: 0.6952\n",
      "Epoch 3/150\n",
      "16732/16732 [==============================] - 2s 139us/step - loss: 0.8125 - regression_loss: 0.1187 - handedness_loss: 0.6937 - val_loss: 0.7999 - val_regression_loss: 0.1041 - val_handedness_loss: 0.6959\n",
      "Epoch 4/150\n",
      "16732/16732 [==============================] - 2s 131us/step - loss: 0.7951 - regression_loss: 0.1013 - handedness_loss: 0.6937 - val_loss: 0.7918 - val_regression_loss: 0.0980 - val_handedness_loss: 0.6939\n",
      "Epoch 5/150\n",
      "16732/16732 [==============================] - 2s 144us/step - loss: 0.7898 - regression_loss: 0.0963 - handedness_loss: 0.6935 - val_loss: 0.7879 - val_regression_loss: 0.0936 - val_handedness_loss: 0.6944\n",
      "Evaluating model with testing data...\n",
      "3564/3564 [==============================] - 0s 17us/step\n",
      "Getting distribution of predictions and covariance matrix...\n",
      "      1 of 20\n",
      "      2 of 20\n",
      "      3 of 20\n",
      "      4 of 20\n",
      "      5 of 20\n",
      "      6 of 20\n",
      "      7 of 20\n",
      "      8 of 20\n",
      "      9 of 20\n",
      "      10 of 20\n",
      "      11 of 20\n",
      "      12 of 20\n",
      "      13 of 20\n",
      "      14 of 20\n",
      "      15 of 20\n",
      "      16 of 20\n",
      "      17 of 20\n",
      "      18 of 20\n",
      "      19 of 20\n",
      "      20 of 20\n",
      "Computing ensemble means...\n",
      "Computing mean squared error...\n",
      "Iteration 117\n",
      "Train on 16872 samples, validate on 3594 samples\n",
      "Epoch 1/150\n",
      "16872/16872 [==============================] - 2s 139us/step - loss: 0.9901 - regression_loss: 0.3201 - handedness_loss: 0.6699 - val_loss: 0.8937 - val_regression_loss: 0.1996 - val_handedness_loss: 0.6930\n",
      "Epoch 2/150\n",
      "16872/16872 [==============================] - 2s 137us/step - loss: 0.8360 - regression_loss: 0.1417 - handedness_loss: 0.6942 - val_loss: 0.7988 - val_regression_loss: 0.1030 - val_handedness_loss: 0.6946\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3/150\n",
      "16872/16872 [==============================] - 2s 136us/step - loss: 0.7953 - regression_loss: 0.1004 - handedness_loss: 0.6948 - val_loss: 0.7927 - val_regression_loss: 0.0968 - val_handedness_loss: 0.6950\n",
      "Epoch 4/150\n",
      "16872/16872 [==============================] - 2s 133us/step - loss: 0.7909 - regression_loss: 0.0964 - handedness_loss: 0.6944 - val_loss: 0.7867 - val_regression_loss: 0.0934 - val_handedness_loss: 0.6929\n",
      "Epoch 5/150\n",
      "16872/16872 [==============================] - 2s 133us/step - loss: 0.7881 - regression_loss: 0.0942 - handedness_loss: 0.6939 - val_loss: 0.7862 - val_regression_loss: 0.0916 - val_handedness_loss: 0.6942\n",
      "Epoch 6/150\n",
      "16872/16872 [==============================] - 2s 137us/step - loss: 0.7859 - regression_loss: 0.0918 - handedness_loss: 0.6941 - val_loss: 0.7837 - val_regression_loss: 0.0898 - val_handedness_loss: 0.6945\n",
      "Epoch 7/150\n",
      "16872/16872 [==============================] - 2s 126us/step - loss: 0.7840 - regression_loss: 0.0905 - handedness_loss: 0.6935 - val_loss: 0.7825 - val_regression_loss: 0.0888 - val_handedness_loss: 0.6935\n",
      "Epoch 8/150\n",
      "16872/16872 [==============================] - 2s 138us/step - loss: 0.7828 - regression_loss: 0.0893 - handedness_loss: 0.6936 - val_loss: 0.7807 - val_regression_loss: 0.0865 - val_handedness_loss: 0.6939\n",
      "Evaluating model with testing data...\n",
      "3594/3594 [==============================] - 0s 16us/step\n",
      "Getting distribution of predictions and covariance matrix...\n",
      "      1 of 20\n",
      "      2 of 20\n",
      "      3 of 20\n",
      "      4 of 20\n",
      "      5 of 20\n",
      "      6 of 20\n",
      "      7 of 20\n",
      "      8 of 20\n",
      "      9 of 20\n",
      "      10 of 20\n",
      "      11 of 20\n",
      "      12 of 20\n",
      "      13 of 20\n",
      "      14 of 20\n",
      "      15 of 20\n",
      "      16 of 20\n",
      "      17 of 20\n",
      "      18 of 20\n",
      "      19 of 20\n",
      "      20 of 20\n",
      "Computing ensemble means...\n",
      "Computing mean squared error...\n",
      "Iteration 118\n",
      "Train on 17012 samples, validate on 3624 samples\n",
      "Epoch 1/150\n",
      "17012/17012 [==============================] - 2s 136us/step - loss: 1.0724 - regression_loss: 0.3842 - handedness_loss: 0.6881 - val_loss: 0.9202 - val_regression_loss: 0.2261 - val_handedness_loss: 0.6941\n",
      "Epoch 2/150\n",
      "17012/17012 [==============================] - 2s 134us/step - loss: 0.8736 - regression_loss: 0.1801 - handedness_loss: 0.6934 - val_loss: 0.8295 - val_regression_loss: 0.1348 - val_handedness_loss: 0.6948\n",
      "Epoch 3/150\n",
      "17012/17012 [==============================] - 2s 145us/step - loss: 0.8156 - regression_loss: 0.1222 - handedness_loss: 0.6934 - val_loss: 0.8010 - val_regression_loss: 0.1079 - val_handedness_loss: 0.6929\n",
      "Epoch 4/150\n",
      "17012/17012 [==============================] - 2s 143us/step - loss: 0.7990 - regression_loss: 0.1055 - handedness_loss: 0.6935 - val_loss: 0.7916 - val_regression_loss: 0.0983 - val_handedness_loss: 0.6934\n",
      "Epoch 5/150\n",
      "17012/17012 [==============================] - 2s 146us/step - loss: 0.7920 - regression_loss: 0.0987 - handedness_loss: 0.6932 - val_loss: 0.7863 - val_regression_loss: 0.0934 - val_handedness_loss: 0.6929\n",
      "Epoch 6/150\n",
      "17012/17012 [==============================] - 2s 144us/step - loss: 0.7876 - regression_loss: 0.0942 - handedness_loss: 0.6934 - val_loss: 0.7839 - val_regression_loss: 0.0909 - val_handedness_loss: 0.6930\n",
      "Epoch 7/150\n",
      "17012/17012 [==============================] - 3s 148us/step - loss: 0.7846 - regression_loss: 0.0912 - handedness_loss: 0.6934 - val_loss: 0.7820 - val_regression_loss: 0.0884 - val_handedness_loss: 0.6934\n",
      "Evaluating model with testing data...\n",
      "3624/3624 [==============================] - 0s 16us/step\n",
      "Getting distribution of predictions and covariance matrix...\n",
      "      1 of 20\n",
      "      2 of 20\n",
      "      3 of 20\n",
      "      4 of 20\n",
      "      5 of 20\n",
      "      6 of 20\n",
      "      7 of 20\n",
      "      8 of 20\n",
      "      9 of 20\n",
      "      10 of 20\n",
      "      11 of 20\n",
      "      12 of 20\n",
      "      13 of 20\n",
      "      14 of 20\n",
      "      15 of 20\n",
      "      16 of 20\n",
      "      17 of 20\n",
      "      18 of 20\n",
      "      19 of 20\n",
      "      20 of 20\n",
      "Computing ensemble means...\n",
      "Computing mean squared error...\n",
      "Iteration 119\n",
      "Train on 17152 samples, validate on 3654 samples\n",
      "Epoch 1/150\n",
      "17152/17152 [==============================] - 2s 134us/step - loss: 0.9822 - regression_loss: 0.3024 - handedness_loss: 0.6799 - val_loss: 0.7964 - val_regression_loss: 0.0996 - val_handedness_loss: 0.6972\n",
      "Epoch 2/150\n",
      "17152/17152 [==============================] - 2s 140us/step - loss: 0.7934 - regression_loss: 0.0982 - handedness_loss: 0.6953 - val_loss: 0.7894 - val_regression_loss: 0.0964 - val_handedness_loss: 0.6931\n",
      "Epoch 3/150\n",
      "17152/17152 [==============================] - 2s 145us/step - loss: 0.7900 - regression_loss: 0.0956 - handedness_loss: 0.6944 - val_loss: 0.7876 - val_regression_loss: 0.0940 - val_handedness_loss: 0.6940\n",
      "Epoch 4/150\n",
      "17152/17152 [==============================] - 2s 130us/step - loss: 0.7883 - regression_loss: 0.0942 - handedness_loss: 0.6941 - val_loss: 0.7866 - val_regression_loss: 0.0924 - val_handedness_loss: 0.6946\n",
      "Epoch 5/150\n",
      "17152/17152 [==============================] - 2s 141us/step - loss: 0.7866 - regression_loss: 0.0924 - handedness_loss: 0.6942 - val_loss: 0.7840 - val_regression_loss: 0.0911 - val_handedness_loss: 0.6930\n",
      "Epoch 6/150\n",
      "17152/17152 [==============================] - 2s 136us/step - loss: 0.7845 - regression_loss: 0.0908 - handedness_loss: 0.6937 - val_loss: 0.7833 - val_regression_loss: 0.0901 - val_handedness_loss: 0.6933\n",
      "Epoch 7/150\n",
      "17152/17152 [==============================] - 2s 144us/step - loss: 0.7836 - regression_loss: 0.0899 - handedness_loss: 0.6937 - val_loss: 0.7827 - val_regression_loss: 0.0888 - val_handedness_loss: 0.6941\n",
      "Epoch 8/150\n",
      "17152/17152 [==============================] - 2s 144us/step - loss: 0.7823 - regression_loss: 0.0890 - handedness_loss: 0.6933 - val_loss: 0.7809 - val_regression_loss: 0.0876 - val_handedness_loss: 0.6935\n",
      "Epoch 9/150\n",
      "17152/17152 [==============================] - 2s 140us/step - loss: 0.7817 - regression_loss: 0.0882 - handedness_loss: 0.6935 - val_loss: 0.7801 - val_regression_loss: 0.0871 - val_handedness_loss: 0.6933\n",
      "Evaluating model with testing data...\n",
      "3654/3654 [==============================] - 0s 16us/step\n",
      "Getting distribution of predictions and covariance matrix...\n",
      "      1 of 20\n",
      "      2 of 20\n",
      "      3 of 20\n",
      "      4 of 20\n",
      "      5 of 20\n",
      "      6 of 20\n",
      "      7 of 20\n",
      "      8 of 20\n",
      "      9 of 20\n",
      "      10 of 20\n",
      "      11 of 20\n",
      "      12 of 20\n",
      "      13 of 20\n",
      "      14 of 20\n",
      "      15 of 20\n",
      "      16 of 20\n",
      "      17 of 20\n",
      "      18 of 20\n",
      "      19 of 20\n",
      "      20 of 20\n",
      "Computing ensemble means...\n",
      "Computing mean squared error...\n",
      "Iteration 120\n",
      "Train on 17292 samples, validate on 3684 samples\n",
      "Epoch 1/150\n",
      "17292/17292 [==============================] - 2s 134us/step - loss: 0.9304 - regression_loss: 0.2410 - handedness_loss: 0.6885 - val_loss: 0.8103 - val_regression_loss: 0.1099 - val_handedness_loss: 0.7003\n",
      "Epoch 2/150\n",
      "17292/17292 [==============================] - 2s 138us/step - loss: 0.8046 - regression_loss: 0.1088 - handedness_loss: 0.6957 - val_loss: 0.7980 - val_regression_loss: 0.1031 - val_handedness_loss: 0.6948\n",
      "Epoch 3/150\n",
      "17292/17292 [==============================] - 2s 139us/step - loss: 0.7975 - regression_loss: 0.1027 - handedness_loss: 0.6948 - val_loss: 0.7912 - val_regression_loss: 0.0986 - val_handedness_loss: 0.6926\n",
      "Epoch 4/150\n",
      "17292/17292 [==============================] - 2s 141us/step - loss: 0.7922 - regression_loss: 0.0983 - handedness_loss: 0.6940 - val_loss: 0.7897 - val_regression_loss: 0.0963 - val_handedness_loss: 0.6934\n",
      "Epoch 5/150\n",
      "17292/17292 [==============================] - 2s 132us/step - loss: 0.7889 - regression_loss: 0.0950 - handedness_loss: 0.6937 - val_loss: 0.7859 - val_regression_loss: 0.0919 - val_handedness_loss: 0.6940\n",
      "Epoch 6/150\n",
      "17292/17292 [==============================] - 2s 136us/step - loss: 0.7864 - regression_loss: 0.0927 - handedness_loss: 0.6939 - val_loss: 0.7832 - val_regression_loss: 0.0903 - val_handedness_loss: 0.6929\n",
      "Epoch 7/150\n",
      "17292/17292 [==============================] - 2s 134us/step - loss: 0.7842 - regression_loss: 0.0910 - handedness_loss: 0.6932 - val_loss: 0.7831 - val_regression_loss: 0.0895 - val_handedness_loss: 0.6936\n",
      "Evaluating model with testing data...\n",
      "3684/3684 [==============================] - 0s 16us/step\n",
      "Getting distribution of predictions and covariance matrix...\n",
      "      1 of 20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      2 of 20\n",
      "      3 of 20\n",
      "      4 of 20\n",
      "      5 of 20\n",
      "      6 of 20\n",
      "      7 of 20\n",
      "      8 of 20\n",
      "      9 of 20\n",
      "      10 of 20\n",
      "      11 of 20\n",
      "      12 of 20\n",
      "      13 of 20\n",
      "      14 of 20\n",
      "      15 of 20\n",
      "      16 of 20\n",
      "      17 of 20\n",
      "      18 of 20\n",
      "      19 of 20\n",
      "      20 of 20\n",
      "Computing ensemble means...\n",
      "Computing mean squared error...\n",
      "Iteration 121\n",
      "Train on 17432 samples, validate on 3714 samples\n",
      "Epoch 1/150\n",
      "17432/17432 [==============================] - 2s 139us/step - loss: 1.0839 - regression_loss: 0.3842 - handedness_loss: 0.6990 - val_loss: 0.9236 - val_regression_loss: 0.2247 - val_handedness_loss: 0.6937\n",
      "Epoch 2/150\n",
      "17432/17432 [==============================] - 3s 146us/step - loss: 0.8774 - regression_loss: 0.1838 - handedness_loss: 0.6931 - val_loss: 0.8311 - val_regression_loss: 0.1343 - val_handedness_loss: 0.6938\n",
      "Epoch 3/150\n",
      "17432/17432 [==============================] - 2s 96us/step - loss: 0.8201 - regression_loss: 0.1270 - handedness_loss: 0.6930 - val_loss: 0.8066 - val_regression_loss: 0.1107 - val_handedness_loss: 0.6937\n",
      "Epoch 4/150\n",
      "17432/17432 [==============================] - 2s 128us/step - loss: 0.8039 - regression_loss: 0.1108 - handedness_loss: 0.6932 - val_loss: 0.7974 - val_regression_loss: 0.1020 - val_handedness_loss: 0.6935\n",
      "Epoch 5/150\n",
      "17432/17432 [==============================] - 2s 137us/step - loss: 0.7950 - regression_loss: 0.1017 - handedness_loss: 0.6932 - val_loss: 0.7891 - val_regression_loss: 0.0959 - val_handedness_loss: 0.6926\n",
      "Epoch 6/150\n",
      "17432/17432 [==============================] - 2s 140us/step - loss: 0.7885 - regression_loss: 0.0954 - handedness_loss: 0.6932 - val_loss: 0.7833 - val_regression_loss: 0.0901 - val_handedness_loss: 0.6929\n",
      "Epoch 7/150\n",
      "17432/17432 [==============================] - 3s 145us/step - loss: 0.7837 - regression_loss: 0.0906 - handedness_loss: 0.6932 - val_loss: 0.7811 - val_regression_loss: 0.0878 - val_handedness_loss: 0.6932\n",
      "Epoch 8/150\n",
      "17432/17432 [==============================] - 3s 147us/step - loss: 0.7808 - regression_loss: 0.0876 - handedness_loss: 0.6932 - val_loss: 0.7790 - val_regression_loss: 0.0865 - val_handedness_loss: 0.6933\n",
      "Epoch 9/150\n",
      "17432/17432 [==============================] - 2s 141us/step - loss: 0.7789 - regression_loss: 0.0859 - handedness_loss: 0.6931 - val_loss: 0.7782 - val_regression_loss: 0.0844 - val_handedness_loss: 0.6935\n",
      "Evaluating model with testing data...\n",
      "3714/3714 [==============================] - 0s 17us/step\n",
      "Getting distribution of predictions and covariance matrix...\n",
      "      1 of 20\n",
      "      2 of 20\n",
      "      3 of 20\n",
      "      4 of 20\n",
      "      5 of 20\n",
      "      6 of 20\n",
      "      7 of 20\n",
      "      8 of 20\n",
      "      9 of 20\n",
      "      10 of 20\n",
      "      11 of 20\n",
      "      12 of 20\n",
      "      13 of 20\n",
      "      14 of 20\n",
      "      15 of 20\n",
      "      16 of 20\n",
      "      17 of 20\n",
      "      18 of 20\n",
      "      19 of 20\n",
      "      20 of 20\n",
      "Computing ensemble means...\n",
      "Computing mean squared error...\n",
      "Iteration 122\n",
      "Train on 17572 samples, validate on 3744 samples\n",
      "Epoch 1/150\n",
      "17572/17572 [==============================] - 2s 139us/step - loss: 1.0591 - regression_loss: 0.3645 - handedness_loss: 0.6938 - val_loss: 0.9314 - val_regression_loss: 0.2379 - val_handedness_loss: 0.6933\n",
      "Epoch 2/150\n",
      "17572/17572 [==============================] - 3s 145us/step - loss: 0.8994 - regression_loss: 0.2062 - handedness_loss: 0.6931 - val_loss: 0.8601 - val_regression_loss: 0.1665 - val_handedness_loss: 0.6934\n",
      "Epoch 3/150\n",
      "17572/17572 [==============================] - 3s 142us/step - loss: 0.8409 - regression_loss: 0.1478 - handedness_loss: 0.6931 - val_loss: 0.8169 - val_regression_loss: 0.1234 - val_handedness_loss: 0.6933\n",
      "Epoch 4/150\n",
      "17572/17572 [==============================] - 2s 138us/step - loss: 0.8070 - regression_loss: 0.1139 - handedness_loss: 0.6931 - val_loss: 0.7939 - val_regression_loss: 0.1003 - val_handedness_loss: 0.6934\n",
      "Epoch 5/150\n",
      "17572/17572 [==============================] - 2s 136us/step - loss: 0.7895 - regression_loss: 0.0964 - handedness_loss: 0.6931 - val_loss: 0.7831 - val_regression_loss: 0.0894 - val_handedness_loss: 0.6934\n",
      "Evaluating model with testing data...\n",
      "3744/3744 [==============================] - 0s 16us/step\n",
      "Getting distribution of predictions and covariance matrix...\n",
      "      1 of 20\n",
      "      2 of 20\n",
      "      3 of 20\n",
      "      4 of 20\n",
      "      5 of 20\n",
      "      6 of 20\n",
      "      7 of 20\n",
      "      8 of 20\n",
      "      9 of 20\n",
      "      10 of 20\n",
      "      11 of 20\n",
      "      12 of 20\n",
      "      13 of 20\n",
      "      14 of 20\n",
      "      15 of 20\n",
      "      16 of 20\n",
      "      17 of 20\n",
      "      18 of 20\n",
      "      19 of 20\n",
      "      20 of 20\n",
      "Computing ensemble means...\n",
      "Computing mean squared error...\n",
      "Iteration 123\n",
      "Train on 17712 samples, validate on 3774 samples\n",
      "Epoch 1/150\n",
      "17712/17712 [==============================] - 2s 139us/step - loss: 0.9301 - regression_loss: 0.2317 - handedness_loss: 0.6978 - val_loss: 0.7978 - val_regression_loss: 0.1047 - val_handedness_loss: 0.6933\n",
      "Epoch 2/150\n",
      "17712/17712 [==============================] - 2s 137us/step - loss: 0.7946 - regression_loss: 0.1013 - handedness_loss: 0.6934 - val_loss: 0.7918 - val_regression_loss: 0.0984 - val_handedness_loss: 0.6937\n",
      "Epoch 3/150\n",
      "17712/17712 [==============================] - 3s 141us/step - loss: 0.7909 - regression_loss: 0.0975 - handedness_loss: 0.6935 - val_loss: 0.7918 - val_regression_loss: 0.0964 - val_handedness_loss: 0.6958\n",
      "Epoch 4/150\n",
      "17712/17712 [==============================] - 2s 128us/step - loss: 0.7878 - regression_loss: 0.0942 - handedness_loss: 0.6937 - val_loss: 0.7877 - val_regression_loss: 0.0942 - val_handedness_loss: 0.6936\n",
      "Epoch 5/150\n",
      "17712/17712 [==============================] - 2s 130us/step - loss: 0.7861 - regression_loss: 0.0926 - handedness_loss: 0.6935 - val_loss: 0.7840 - val_regression_loss: 0.0908 - val_handedness_loss: 0.6935\n",
      "Evaluating model with testing data...\n",
      "3774/3774 [==============================] - 0s 16us/step\n",
      "Getting distribution of predictions and covariance matrix...\n",
      "      1 of 20\n",
      "      2 of 20\n",
      "      3 of 20\n",
      "      4 of 20\n",
      "      5 of 20\n",
      "      6 of 20\n",
      "      7 of 20\n",
      "      8 of 20\n",
      "      9 of 20\n",
      "      10 of 20\n",
      "      11 of 20\n",
      "      12 of 20\n",
      "      13 of 20\n",
      "      14 of 20\n",
      "      15 of 20\n",
      "      16 of 20\n",
      "      17 of 20\n",
      "      18 of 20\n",
      "      19 of 20\n",
      "      20 of 20\n",
      "Computing ensemble means...\n",
      "Computing mean squared error...\n",
      "Iteration 124\n",
      "Train on 17852 samples, validate on 3804 samples\n",
      "Epoch 1/150\n",
      "17852/17852 [==============================] - 2s 133us/step - loss: 0.9276 - regression_loss: 0.2378 - handedness_loss: 0.6893 - val_loss: 0.7885 - val_regression_loss: 0.0947 - val_handedness_loss: 0.6937\n",
      "Epoch 2/150\n",
      "17852/17852 [==============================] - 2s 132us/step - loss: 0.7884 - regression_loss: 0.0943 - handedness_loss: 0.6942 - val_loss: 0.7870 - val_regression_loss: 0.0937 - val_handedness_loss: 0.6932\n",
      "Epoch 3/150\n",
      "17852/17852 [==============================] - 2s 136us/step - loss: 0.7869 - regression_loss: 0.0931 - handedness_loss: 0.6938 - val_loss: 0.7860 - val_regression_loss: 0.0918 - val_handedness_loss: 0.6943\n",
      "Epoch 4/150\n",
      "17852/17852 [==============================] - 3s 142us/step - loss: 0.7853 - regression_loss: 0.0919 - handedness_loss: 0.6935 - val_loss: 0.7845 - val_regression_loss: 0.0908 - val_handedness_loss: 0.6937\n",
      "Epoch 5/150\n",
      "17852/17852 [==============================] - 3s 141us/step - loss: 0.7844 - regression_loss: 0.0908 - handedness_loss: 0.6936 - val_loss: 0.7847 - val_regression_loss: 0.0902 - val_handedness_loss: 0.6944\n",
      "Epoch 6/150\n",
      "17852/17852 [==============================] - 3s 142us/step - loss: 0.7836 - regression_loss: 0.0900 - handedness_loss: 0.6936 - val_loss: 0.7840 - val_regression_loss: 0.0899 - val_handedness_loss: 0.6941\n",
      "Evaluating model with testing data...\n",
      "3804/3804 [==============================] - 0s 16us/step\n",
      "Getting distribution of predictions and covariance matrix...\n",
      "      1 of 20\n",
      "      2 of 20\n",
      "      3 of 20\n",
      "      4 of 20\n",
      "      5 of 20\n",
      "      6 of 20\n",
      "      7 of 20\n",
      "      8 of 20\n",
      "      9 of 20\n",
      "      10 of 20\n",
      "      11 of 20\n",
      "      12 of 20\n",
      "      13 of 20\n",
      "      14 of 20\n",
      "      15 of 20\n",
      "      16 of 20\n",
      "      17 of 20\n",
      "      18 of 20\n",
      "      19 of 20\n",
      "      20 of 20\n",
      "Computing ensemble means...\n",
      "Computing mean squared error...\n",
      "Iteration 125\n",
      "Train on 17992 samples, validate on 3834 samples\n",
      "Epoch 1/150\n",
      "17992/17992 [==============================] - 2s 132us/step - loss: 0.9343 - regression_loss: 0.2371 - handedness_loss: 0.6968 - val_loss: 0.8046 - val_regression_loss: 0.1092 - val_handedness_loss: 0.6954\n",
      "Epoch 2/150\n",
      "17992/17992 [==============================] - 2s 137us/step - loss: 0.7988 - regression_loss: 0.1045 - handedness_loss: 0.6942 - val_loss: 0.7937 - val_regression_loss: 0.0992 - val_handedness_loss: 0.6946\n",
      "Epoch 3/150\n",
      "17992/17992 [==============================] - 3s 145us/step - loss: 0.7934 - regression_loss: 0.0993 - handedness_loss: 0.6940 - val_loss: 0.7898 - val_regression_loss: 0.0958 - val_handedness_loss: 0.6940\n",
      "Epoch 4/150\n",
      "17992/17992 [==============================] - 3s 147us/step - loss: 0.7890 - regression_loss: 0.0953 - handedness_loss: 0.6937 - val_loss: 0.7870 - val_regression_loss: 0.0926 - val_handedness_loss: 0.6944\n",
      "Epoch 5/150\n",
      "17992/17992 [==============================] - 3s 147us/step - loss: 0.7867 - regression_loss: 0.0931 - handedness_loss: 0.6936 - val_loss: 0.7858 - val_regression_loss: 0.0913 - val_handedness_loss: 0.6945\n",
      "Epoch 6/150\n",
      "17992/17992 [==============================] - 3s 147us/step - loss: 0.7848 - regression_loss: 0.0914 - handedness_loss: 0.6935 - val_loss: 0.7839 - val_regression_loss: 0.0901 - val_handedness_loss: 0.6938\n",
      "Epoch 7/150\n",
      "17992/17992 [==============================] - 3s 147us/step - loss: 0.7827 - regression_loss: 0.0893 - handedness_loss: 0.6934 - val_loss: 0.7814 - val_regression_loss: 0.0879 - val_handedness_loss: 0.6934\n",
      "Epoch 8/150\n",
      "17992/17992 [==============================] - 3s 147us/step - loss: 0.7816 - regression_loss: 0.0884 - handedness_loss: 0.6932 - val_loss: 0.7808 - val_regression_loss: 0.0877 - val_handedness_loss: 0.6931\n",
      "Epoch 9/150\n",
      "17992/17992 [==============================] - 3s 147us/step - loss: 0.7808 - regression_loss: 0.0877 - handedness_loss: 0.6931 - val_loss: 0.7813 - val_regression_loss: 0.0873 - val_handedness_loss: 0.6940\n",
      "Epoch 10/150\n",
      "17992/17992 [==============================] - 3s 147us/step - loss: 0.7804 - regression_loss: 0.0869 - handedness_loss: 0.6934 - val_loss: 0.7796 - val_regression_loss: 0.0863 - val_handedness_loss: 0.6933\n",
      "Epoch 11/150\n",
      "17992/17992 [==============================] - 3s 147us/step - loss: 0.7796 - regression_loss: 0.0863 - handedness_loss: 0.6932 - val_loss: 0.7792 - val_regression_loss: 0.0856 - val_handedness_loss: 0.6935\n",
      "Epoch 12/150\n",
      "17992/17992 [==============================] - 3s 147us/step - loss: 0.7789 - regression_loss: 0.0858 - handedness_loss: 0.6931 - val_loss: 0.7782 - val_regression_loss: 0.0848 - val_handedness_loss: 0.6935\n",
      "Evaluating model with testing data...\n",
      "3834/3834 [==============================] - 0s 17us/step\n",
      "Getting distribution of predictions and covariance matrix...\n",
      "      1 of 20\n",
      "      2 of 20\n",
      "      3 of 20\n",
      "      4 of 20\n",
      "      5 of 20\n",
      "      6 of 20\n",
      "      7 of 20\n",
      "      8 of 20\n",
      "      9 of 20\n",
      "      10 of 20\n",
      "      11 of 20\n",
      "      12 of 20\n",
      "      13 of 20\n",
      "      14 of 20\n",
      "      15 of 20\n",
      "      16 of 20\n",
      "      17 of 20\n",
      "      18 of 20\n",
      "      19 of 20\n",
      "      20 of 20\n",
      "Computing ensemble means...\n",
      "Computing mean squared error...\n",
      "Iteration 126\n",
      "Train on 18132 samples, validate on 3864 samples\n",
      "Epoch 1/150\n",
      "18132/18132 [==============================] - 2s 135us/step - loss: 1.0034 - regression_loss: 0.3117 - handedness_loss: 0.6915 - val_loss: 0.9030 - val_regression_loss: 0.2106 - val_handedness_loss: 0.6932\n",
      "Epoch 2/150\n",
      "18132/18132 [==============================] - 3s 141us/step - loss: 0.8454 - regression_loss: 0.1510 - handedness_loss: 0.6943 - val_loss: 0.8047 - val_regression_loss: 0.1120 - val_handedness_loss: 0.6936\n",
      "Epoch 3/150\n",
      "18132/18132 [==============================] - 3s 145us/step - loss: 0.7993 - regression_loss: 0.1059 - handedness_loss: 0.6934 - val_loss: 0.7960 - val_regression_loss: 0.1026 - val_handedness_loss: 0.6941\n",
      "Epoch 4/150\n",
      "18132/18132 [==============================] - 3s 147us/step - loss: 0.7933 - regression_loss: 0.0998 - handedness_loss: 0.6935 - val_loss: 0.7898 - val_regression_loss: 0.0967 - val_handedness_loss: 0.6938\n",
      "Epoch 5/150\n",
      "18132/18132 [==============================] - 2s 115us/step - loss: 0.7886 - regression_loss: 0.0953 - handedness_loss: 0.6932 - val_loss: 0.7869 - val_regression_loss: 0.0935 - val_handedness_loss: 0.6937\n",
      "Evaluating model with testing data...\n",
      "3864/3864 [==============================] - 0s 16us/step\n",
      "Getting distribution of predictions and covariance matrix...\n",
      "      1 of 20\n",
      "      2 of 20\n",
      "      3 of 20\n",
      "      4 of 20\n",
      "      5 of 20\n",
      "      6 of 20\n",
      "      7 of 20\n",
      "      8 of 20\n",
      "      9 of 20\n",
      "      10 of 20\n",
      "      11 of 20\n",
      "      12 of 20\n",
      "      13 of 20\n",
      "      14 of 20\n",
      "      15 of 20\n",
      "      16 of 20\n",
      "      17 of 20\n",
      "      18 of 20\n",
      "      19 of 20\n",
      "      20 of 20\n",
      "Computing ensemble means...\n",
      "Computing mean squared error...\n",
      "Iteration 127\n",
      "Train on 18272 samples, validate on 3894 samples\n",
      "Epoch 1/150\n",
      "18272/18272 [==============================] - 2s 134us/step - loss: 1.0063 - regression_loss: 0.3121 - handedness_loss: 0.6940 - val_loss: 0.8972 - val_regression_loss: 0.2045 - val_handedness_loss: 0.6927\n",
      "Epoch 2/150\n",
      "18272/18272 [==============================] - 3s 140us/step - loss: 0.8443 - regression_loss: 0.1508 - handedness_loss: 0.6935 - val_loss: 0.8057 - val_regression_loss: 0.1125 - val_handedness_loss: 0.6932\n",
      "Epoch 3/150\n",
      "18272/18272 [==============================] - 2s 120us/step - loss: 0.7972 - regression_loss: 0.1036 - handedness_loss: 0.6936 - val_loss: 0.7923 - val_regression_loss: 0.0984 - val_handedness_loss: 0.6935\n",
      "Epoch 4/150\n",
      "18272/18272 [==============================] - 2s 107us/step - loss: 0.7907 - regression_loss: 0.0974 - handedness_loss: 0.6933 - val_loss: 0.7885 - val_regression_loss: 0.0947 - val_handedness_loss: 0.6938\n",
      "Epoch 5/150\n",
      "18272/18272 [==============================] - 2s 133us/step - loss: 0.7877 - regression_loss: 0.0943 - handedness_loss: 0.6934 - val_loss: 0.7864 - val_regression_loss: 0.0925 - val_handedness_loss: 0.6937\n",
      "Evaluating model with testing data...\n",
      "3894/3894 [==============================] - 0s 16us/step\n",
      "Getting distribution of predictions and covariance matrix...\n",
      "      1 of 20\n",
      "      2 of 20\n",
      "      3 of 20\n",
      "      4 of 20\n",
      "      5 of 20\n",
      "      6 of 20\n",
      "      7 of 20\n",
      "      8 of 20\n",
      "      9 of 20\n",
      "      10 of 20\n",
      "      11 of 20\n",
      "      12 of 20\n",
      "      13 of 20\n",
      "      14 of 20\n",
      "      15 of 20\n",
      "      16 of 20\n",
      "      17 of 20\n",
      "      18 of 20\n",
      "      19 of 20\n",
      "      20 of 20\n",
      "Computing ensemble means...\n",
      "Computing mean squared error...\n",
      "Iteration 128\n",
      "Train on 18412 samples, validate on 3924 samples\n",
      "Epoch 1/150\n",
      "18412/18412 [==============================] - 2s 125us/step - loss: 0.8695 - regression_loss: 0.1749 - handedness_loss: 0.6946 - val_loss: 0.7944 - val_regression_loss: 0.0995 - val_handedness_loss: 0.6949\n",
      "Epoch 2/150\n",
      "18412/18412 [==============================] - 3s 141us/step - loss: 0.7928 - regression_loss: 0.0974 - handedness_loss: 0.6955 - val_loss: 0.7926 - val_regression_loss: 0.0961 - val_handedness_loss: 0.6966\n",
      "Epoch 3/150\n",
      "18412/18412 [==============================] - 3s 141us/step - loss: 0.7891 - regression_loss: 0.0948 - handedness_loss: 0.6943 - val_loss: 0.7881 - val_regression_loss: 0.0933 - val_handedness_loss: 0.6947\n",
      "Epoch 4/150\n",
      "18412/18412 [==============================] - 3s 142us/step - loss: 0.7872 - regression_loss: 0.0930 - handedness_loss: 0.6941 - val_loss: 0.7872 - val_regression_loss: 0.0925 - val_handedness_loss: 0.6949\n",
      "Epoch 5/150\n",
      "18412/18412 [==============================] - 2s 130us/step - loss: 0.7848 - regression_loss: 0.0911 - handedness_loss: 0.6937 - val_loss: 0.7855 - val_regression_loss: 0.0912 - val_handedness_loss: 0.6943\n",
      "Epoch 6/150\n",
      "18412/18412 [==============================] - 3s 142us/step - loss: 0.7836 - regression_loss: 0.0902 - handedness_loss: 0.6934 - val_loss: 0.7823 - val_regression_loss: 0.0885 - val_handedness_loss: 0.6938\n",
      "Epoch 7/150\n",
      "18412/18412 [==============================] - 2s 133us/step - loss: 0.7821 - regression_loss: 0.0886 - handedness_loss: 0.6934 - val_loss: 0.7813 - val_regression_loss: 0.0876 - val_handedness_loss: 0.6937\n",
      "Epoch 8/150\n",
      "18412/18412 [==============================] - 2s 130us/step - loss: 0.7811 - regression_loss: 0.0875 - handedness_loss: 0.6936 - val_loss: 0.7801 - val_regression_loss: 0.0867 - val_handedness_loss: 0.6934\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9/150\n",
      "18412/18412 [==============================] - 3s 142us/step - loss: 0.7804 - regression_loss: 0.0871 - handedness_loss: 0.6933 - val_loss: 0.7800 - val_regression_loss: 0.0865 - val_handedness_loss: 0.6935\n",
      "Epoch 10/150\n",
      "18412/18412 [==============================] - 3s 146us/step - loss: 0.7797 - regression_loss: 0.0864 - handedness_loss: 0.6933 - val_loss: 0.7809 - val_regression_loss: 0.0870 - val_handedness_loss: 0.6940\n",
      "Epoch 11/150\n",
      "18412/18412 [==============================] - 3s 142us/step - loss: 0.7790 - regression_loss: 0.0858 - handedness_loss: 0.6932 - val_loss: 0.7790 - val_regression_loss: 0.0851 - val_handedness_loss: 0.6939\n",
      "Epoch 12/150\n",
      "18412/18412 [==============================] - 3s 143us/step - loss: 0.7786 - regression_loss: 0.0854 - handedness_loss: 0.6932 - val_loss: 0.7783 - val_regression_loss: 0.0851 - val_handedness_loss: 0.6931\n",
      "Epoch 13/150\n",
      "18412/18412 [==============================] - 3s 146us/step - loss: 0.7782 - regression_loss: 0.0849 - handedness_loss: 0.6933 - val_loss: 0.7781 - val_regression_loss: 0.0848 - val_handedness_loss: 0.6933\n",
      "Epoch 14/150\n",
      "18412/18412 [==============================] - 3s 139us/step - loss: 0.7778 - regression_loss: 0.0847 - handedness_loss: 0.6931 - val_loss: 0.7777 - val_regression_loss: 0.0843 - val_handedness_loss: 0.6934\n",
      "Epoch 15/150\n",
      "18412/18412 [==============================] - 3s 145us/step - loss: 0.7776 - regression_loss: 0.0845 - handedness_loss: 0.6931 - val_loss: 0.7784 - val_regression_loss: 0.0846 - val_handedness_loss: 0.6938\n",
      "Epoch 16/150\n",
      "18412/18412 [==============================] - 3s 144us/step - loss: 0.7774 - regression_loss: 0.0842 - handedness_loss: 0.6932 - val_loss: 0.7786 - val_regression_loss: 0.0846 - val_handedness_loss: 0.6940\n",
      "Evaluating model with testing data...\n",
      "3924/3924 [==============================] - 0s 17us/step\n",
      "Getting distribution of predictions and covariance matrix...\n",
      "      1 of 20\n",
      "      2 of 20\n",
      "      3 of 20\n",
      "      4 of 20\n",
      "      5 of 20\n",
      "      6 of 20\n",
      "      7 of 20\n",
      "      8 of 20\n",
      "      9 of 20\n",
      "      10 of 20\n",
      "      11 of 20\n",
      "      12 of 20\n",
      "      13 of 20\n",
      "      14 of 20\n",
      "      15 of 20\n",
      "      16 of 20\n",
      "      17 of 20\n",
      "      18 of 20\n",
      "      19 of 20\n",
      "      20 of 20\n",
      "Computing ensemble means...\n",
      "Computing mean squared error...\n",
      "Iteration 129\n",
      "Train on 18552 samples, validate on 3954 samples\n",
      "Epoch 1/150\n",
      "18552/18552 [==============================] - 3s 141us/step - loss: 1.0198 - regression_loss: 0.3279 - handedness_loss: 0.6918 - val_loss: 0.8996 - val_regression_loss: 0.2056 - val_handedness_loss: 0.6940\n",
      "Epoch 2/150\n",
      "18552/18552 [==============================] - 3s 138us/step - loss: 0.8409 - regression_loss: 0.1473 - handedness_loss: 0.6936 - val_loss: 0.8036 - val_regression_loss: 0.1091 - val_handedness_loss: 0.6945\n",
      "Epoch 3/150\n",
      "18552/18552 [==============================] - 3s 141us/step - loss: 0.7988 - regression_loss: 0.1054 - handedness_loss: 0.6934 - val_loss: 0.7956 - val_regression_loss: 0.1015 - val_handedness_loss: 0.6941\n",
      "Epoch 4/150\n",
      "18552/18552 [==============================] - 3s 144us/step - loss: 0.7933 - regression_loss: 0.0999 - handedness_loss: 0.6934 - val_loss: 0.7905 - val_regression_loss: 0.0969 - val_handedness_loss: 0.6936\n",
      "Epoch 5/150\n",
      "18552/18552 [==============================] - 3s 136us/step - loss: 0.7893 - regression_loss: 0.0960 - handedness_loss: 0.6933 - val_loss: 0.7878 - val_regression_loss: 0.0941 - val_handedness_loss: 0.6937\n",
      "Epoch 6/150\n",
      "18552/18552 [==============================] - 3s 145us/step - loss: 0.7865 - regression_loss: 0.0929 - handedness_loss: 0.6935 - val_loss: 0.7849 - val_regression_loss: 0.0914 - val_handedness_loss: 0.6934\n",
      "Epoch 7/150\n",
      "18552/18552 [==============================] - 2s 133us/step - loss: 0.7838 - regression_loss: 0.0904 - handedness_loss: 0.6934 - val_loss: 0.7814 - val_regression_loss: 0.0883 - val_handedness_loss: 0.6931\n",
      "Epoch 8/150\n",
      "18552/18552 [==============================] - 3s 143us/step - loss: 0.7818 - regression_loss: 0.0887 - handedness_loss: 0.6930 - val_loss: 0.7821 - val_regression_loss: 0.0879 - val_handedness_loss: 0.6942\n",
      "Epoch 9/150\n",
      "18552/18552 [==============================] - 3s 145us/step - loss: 0.7804 - regression_loss: 0.0872 - handedness_loss: 0.6932 - val_loss: 0.7797 - val_regression_loss: 0.0863 - val_handedness_loss: 0.6933\n",
      "Epoch 10/150\n",
      "18552/18552 [==============================] - 3s 135us/step - loss: 0.7796 - regression_loss: 0.0864 - handedness_loss: 0.6932 - val_loss: 0.7794 - val_regression_loss: 0.0857 - val_handedness_loss: 0.6937\n",
      "Epoch 11/150\n",
      "18552/18552 [==============================] - 3s 138us/step - loss: 0.7785 - regression_loss: 0.0854 - handedness_loss: 0.6931 - val_loss: 0.7784 - val_regression_loss: 0.0847 - val_handedness_loss: 0.6936\n",
      "Evaluating model with testing data...\n",
      "3954/3954 [==============================] - 0s 17us/step\n",
      "Getting distribution of predictions and covariance matrix...\n",
      "      1 of 20\n",
      "      2 of 20\n",
      "      3 of 20\n",
      "      4 of 20\n",
      "      5 of 20\n",
      "      6 of 20\n",
      "      7 of 20\n",
      "      8 of 20\n",
      "      9 of 20\n",
      "      10 of 20\n",
      "      11 of 20\n",
      "      12 of 20\n",
      "      13 of 20\n",
      "      14 of 20\n",
      "      15 of 20\n",
      "      16 of 20\n",
      "      17 of 20\n",
      "      18 of 20\n",
      "      19 of 20\n",
      "      20 of 20\n",
      "Computing ensemble means...\n",
      "Computing mean squared error...\n",
      "Iteration 130\n",
      "Train on 18692 samples, validate on 3984 samples\n",
      "Epoch 1/150\n",
      "18692/18692 [==============================] - 3s 140us/step - loss: 1.0237 - regression_loss: 0.3436 - handedness_loss: 0.6790 - val_loss: 0.9243 - val_regression_loss: 0.2319 - val_handedness_loss: 0.6930\n",
      "Epoch 2/150\n",
      "18692/18692 [==============================] - 3s 145us/step - loss: 0.8729 - regression_loss: 0.1793 - handedness_loss: 0.6935 - val_loss: 0.8263 - val_regression_loss: 0.1319 - val_handedness_loss: 0.6947\n",
      "Epoch 3/150\n",
      "18692/18692 [==============================] - 2s 133us/step - loss: 0.8094 - regression_loss: 0.1153 - handedness_loss: 0.6940 - val_loss: 0.7992 - val_regression_loss: 0.1048 - val_handedness_loss: 0.6946\n",
      "Epoch 4/150\n",
      "18692/18692 [==============================] - 3s 135us/step - loss: 0.7955 - regression_loss: 0.1013 - handedness_loss: 0.6942 - val_loss: 0.7907 - val_regression_loss: 0.0965 - val_handedness_loss: 0.6942\n",
      "Epoch 5/150\n",
      "18692/18692 [==============================] - 2s 116us/step - loss: 0.7893 - regression_loss: 0.0957 - handedness_loss: 0.6935 - val_loss: 0.7862 - val_regression_loss: 0.0929 - val_handedness_loss: 0.6930\n",
      "Evaluating model with testing data...\n",
      "3984/3984 [==============================] - 0s 16us/step\n",
      "Getting distribution of predictions and covariance matrix...\n",
      "      1 of 20\n",
      "      2 of 20\n",
      "      3 of 20\n",
      "      4 of 20\n",
      "      5 of 20\n",
      "      6 of 20\n",
      "      7 of 20\n",
      "      8 of 20\n",
      "      9 of 20\n",
      "      10 of 20\n",
      "      11 of 20\n",
      "      12 of 20\n",
      "      13 of 20\n",
      "      14 of 20\n",
      "      15 of 20\n",
      "      16 of 20\n",
      "      17 of 20\n",
      "      18 of 20\n",
      "      19 of 20\n",
      "      20 of 20\n",
      "Computing ensemble means...\n",
      "Computing mean squared error...\n",
      "Iteration 131\n",
      "Train on 18832 samples, validate on 4014 samples\n",
      "Epoch 1/150\n",
      "18832/18832 [==============================] - 2s 131us/step - loss: 0.9999 - regression_loss: 0.3124 - handedness_loss: 0.6872 - val_loss: 0.9034 - val_regression_loss: 0.2100 - val_handedness_loss: 0.6936\n",
      "Epoch 2/150\n",
      "18832/18832 [==============================] - 3s 137us/step - loss: 0.8480 - regression_loss: 0.1543 - handedness_loss: 0.6936 - val_loss: 0.8055 - val_regression_loss: 0.1111 - val_handedness_loss: 0.6945\n",
      "Epoch 3/150\n",
      "18832/18832 [==============================] - 2s 131us/step - loss: 0.7979 - regression_loss: 0.1040 - handedness_loss: 0.6937 - val_loss: 0.7949 - val_regression_loss: 0.1007 - val_handedness_loss: 0.6942\n",
      "Epoch 4/150\n",
      "18832/18832 [==============================] - 3s 136us/step - loss: 0.7917 - regression_loss: 0.0980 - handedness_loss: 0.6939 - val_loss: 0.7900 - val_regression_loss: 0.0960 - val_handedness_loss: 0.6940\n",
      "Epoch 5/150\n",
      "18832/18832 [==============================] - 2s 132us/step - loss: 0.7881 - regression_loss: 0.0943 - handedness_loss: 0.6938 - val_loss: 0.7856 - val_regression_loss: 0.0919 - val_handedness_loss: 0.6939\n",
      "Evaluating model with testing data...\n",
      "4014/4014 [==============================] - 0s 16us/step\n",
      "Getting distribution of predictions and covariance matrix...\n",
      "      1 of 20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      2 of 20\n",
      "      3 of 20\n",
      "      4 of 20\n",
      "      5 of 20\n",
      "      6 of 20\n",
      "      7 of 20\n",
      "      8 of 20\n",
      "      9 of 20\n",
      "      10 of 20\n",
      "      11 of 20\n",
      "      12 of 20\n",
      "      13 of 20\n",
      "      14 of 20\n",
      "      15 of 20\n",
      "      16 of 20\n",
      "      17 of 20\n",
      "      18 of 20\n",
      "      19 of 20\n",
      "      20 of 20\n",
      "Computing ensemble means...\n",
      "Computing mean squared error...\n",
      "Iteration 132\n",
      "Train on 18972 samples, validate on 4044 samples\n",
      "Epoch 1/150\n",
      "18972/18972 [==============================] - 3s 140us/step - loss: 0.9974 - regression_loss: 0.3126 - handedness_loss: 0.6843 - val_loss: 0.9083 - val_regression_loss: 0.2136 - val_handedness_loss: 0.6949\n",
      "Epoch 2/150\n",
      "18972/18972 [==============================] - 3s 145us/step - loss: 0.8515 - regression_loss: 0.1571 - handedness_loss: 0.6943 - val_loss: 0.8109 - val_regression_loss: 0.1166 - val_handedness_loss: 0.6944\n",
      "Epoch 3/150\n",
      "18972/18972 [==============================] - 2s 123us/step - loss: 0.8023 - regression_loss: 0.1081 - handedness_loss: 0.6942 - val_loss: 0.7962 - val_regression_loss: 0.1027 - val_handedness_loss: 0.6936\n",
      "Epoch 4/150\n",
      "18972/18972 [==============================] - 2s 107us/step - loss: 0.7939 - regression_loss: 0.0998 - handedness_loss: 0.6939 - val_loss: 0.7911 - val_regression_loss: 0.0977 - val_handedness_loss: 0.6936\n",
      "Epoch 5/150\n",
      "18972/18972 [==============================] - 3s 136us/step - loss: 0.7892 - regression_loss: 0.0953 - handedness_loss: 0.6939 - val_loss: 0.7866 - val_regression_loss: 0.0935 - val_handedness_loss: 0.6933\n",
      "Epoch 6/150\n",
      "18972/18972 [==============================] - 3s 143us/step - loss: 0.7857 - regression_loss: 0.0919 - handedness_loss: 0.6937 - val_loss: 0.7838 - val_regression_loss: 0.0908 - val_handedness_loss: 0.6932\n",
      "Epoch 7/150\n",
      "18972/18972 [==============================] - 3s 146us/step - loss: 0.7825 - regression_loss: 0.0892 - handedness_loss: 0.6932 - val_loss: 0.7818 - val_regression_loss: 0.0887 - val_handedness_loss: 0.6932\n",
      "Epoch 8/150\n",
      "18972/18972 [==============================] - 3s 146us/step - loss: 0.7808 - regression_loss: 0.0875 - handedness_loss: 0.6932 - val_loss: 0.7802 - val_regression_loss: 0.0874 - val_handedness_loss: 0.6929\n",
      "Epoch 9/150\n",
      "18972/18972 [==============================] - 3s 147us/step - loss: 0.7794 - regression_loss: 0.0864 - handedness_loss: 0.6931 - val_loss: 0.7791 - val_regression_loss: 0.0860 - val_handedness_loss: 0.6932\n",
      "Epoch 10/150\n",
      "18972/18972 [==============================] - 3s 147us/step - loss: 0.7788 - regression_loss: 0.0854 - handedness_loss: 0.6934 - val_loss: 0.7791 - val_regression_loss: 0.0858 - val_handedness_loss: 0.6935\n",
      "Epoch 11/150\n",
      "18972/18972 [==============================] - 3s 146us/step - loss: 0.7781 - regression_loss: 0.0850 - handedness_loss: 0.6931 - val_loss: 0.7783 - val_regression_loss: 0.0851 - val_handedness_loss: 0.6933\n",
      "Epoch 12/150\n",
      "18972/18972 [==============================] - 3s 146us/step - loss: 0.7778 - regression_loss: 0.0846 - handedness_loss: 0.6931 - val_loss: 0.7780 - val_regression_loss: 0.0849 - val_handedness_loss: 0.6933\n",
      "Evaluating model with testing data...\n",
      "4044/4044 [==============================] - 0s 17us/step\n",
      "Getting distribution of predictions and covariance matrix...\n",
      "      1 of 20\n",
      "      2 of 20\n",
      "      3 of 20\n",
      "      4 of 20\n",
      "      5 of 20\n",
      "      6 of 20\n",
      "      7 of 20\n",
      "      8 of 20\n",
      "      9 of 20\n",
      "      10 of 20\n",
      "      11 of 20\n",
      "      12 of 20\n",
      "      13 of 20\n",
      "      14 of 20\n",
      "      15 of 20\n",
      "      16 of 20\n",
      "      17 of 20\n",
      "      18 of 20\n",
      "      19 of 20\n",
      "      20 of 20\n",
      "Computing ensemble means...\n",
      "Computing mean squared error...\n",
      "Iteration 133\n",
      "Train on 19112 samples, validate on 4074 samples\n",
      "Epoch 1/150\n",
      "19112/19112 [==============================] - 3s 144us/step - loss: 0.8802 - regression_loss: 0.2768 - handedness_loss: 0.6031 - val_loss: 0.8125 - val_regression_loss: 0.1179 - val_handedness_loss: 0.6946\n",
      "Epoch 2/150\n",
      "19112/19112 [==============================] - 3s 145us/step - loss: 0.7953 - regression_loss: 0.1005 - handedness_loss: 0.6948 - val_loss: 0.7898 - val_regression_loss: 0.0954 - val_handedness_loss: 0.6945\n",
      "Epoch 3/150\n",
      "19112/19112 [==============================] - 3s 146us/step - loss: 0.7887 - regression_loss: 0.0942 - handedness_loss: 0.6946 - val_loss: 0.7859 - val_regression_loss: 0.0937 - val_handedness_loss: 0.6923\n",
      "Epoch 4/150\n",
      "19112/19112 [==============================] - 3s 146us/step - loss: 0.7866 - regression_loss: 0.0925 - handedness_loss: 0.6941 - val_loss: 0.7884 - val_regression_loss: 0.0935 - val_handedness_loss: 0.6949\n",
      "Epoch 5/150\n",
      "19112/19112 [==============================] - 3s 146us/step - loss: 0.7856 - regression_loss: 0.0916 - handedness_loss: 0.6940 - val_loss: 0.7854 - val_regression_loss: 0.0914 - val_handedness_loss: 0.6941\n",
      "Epoch 6/150\n",
      "19112/19112 [==============================] - 2s 130us/step - loss: 0.7836 - regression_loss: 0.0901 - handedness_loss: 0.6935 - val_loss: 0.7852 - val_regression_loss: 0.0910 - val_handedness_loss: 0.6942\n",
      "Epoch 7/150\n",
      "19112/19112 [==============================] - 3s 141us/step - loss: 0.7827 - regression_loss: 0.0889 - handedness_loss: 0.6939 - val_loss: 0.7846 - val_regression_loss: 0.0904 - val_handedness_loss: 0.6942\n",
      "Evaluating model with testing data...\n",
      "4074/4074 [==============================] - 0s 16us/step\n",
      "Getting distribution of predictions and covariance matrix...\n",
      "      1 of 20\n",
      "      2 of 20\n",
      "      3 of 20\n",
      "      4 of 20\n",
      "      5 of 20\n",
      "      6 of 20\n",
      "      7 of 20\n",
      "      8 of 20\n",
      "      9 of 20\n",
      "      10 of 20\n",
      "      11 of 20\n",
      "      12 of 20\n",
      "      13 of 20\n",
      "      14 of 20\n",
      "      15 of 20\n",
      "      16 of 20\n",
      "      17 of 20\n",
      "      18 of 20\n",
      "      19 of 20\n",
      "      20 of 20\n",
      "Computing ensemble means...\n",
      "Computing mean squared error...\n",
      "Iteration 134\n",
      "Train on 19252 samples, validate on 4104 samples\n",
      "Epoch 1/150\n",
      "19252/19252 [==============================] - 3s 136us/step - loss: 0.9699 - regression_loss: 0.2722 - handedness_loss: 0.6971 - val_loss: 0.8075 - val_regression_loss: 0.1137 - val_handedness_loss: 0.6954\n",
      "Epoch 2/150\n",
      "19252/19252 [==============================] - 3s 144us/step - loss: 0.8015 - regression_loss: 0.1066 - handedness_loss: 0.6949 - val_loss: 0.7982 - val_regression_loss: 0.1041 - val_handedness_loss: 0.6944\n",
      "Epoch 3/150\n",
      "19252/19252 [==============================] - 3s 144us/step - loss: 0.7947 - regression_loss: 0.1004 - handedness_loss: 0.6941 - val_loss: 0.7920 - val_regression_loss: 0.0978 - val_handedness_loss: 0.6930\n",
      "Epoch 4/150\n",
      "19252/19252 [==============================] - 3s 137us/step - loss: 0.7900 - regression_loss: 0.0961 - handedness_loss: 0.6940 - val_loss: 0.7911 - val_regression_loss: 0.0958 - val_handedness_loss: 0.6949\n",
      "Epoch 5/150\n",
      "19252/19252 [==============================] - 3s 130us/step - loss: 0.7880 - regression_loss: 0.0939 - handedness_loss: 0.6941 - val_loss: 0.7868 - val_regression_loss: 0.0928 - val_handedness_loss: 0.6940\n",
      "Epoch 6/150\n",
      "19252/19252 [==============================] - 3s 139us/step - loss: 0.7858 - regression_loss: 0.0923 - handedness_loss: 0.6935 - val_loss: 0.7857 - val_regression_loss: 0.0922 - val_handedness_loss: 0.6935\n",
      "Epoch 7/150\n",
      "19252/19252 [==============================] - 3s 133us/step - loss: 0.7839 - regression_loss: 0.0905 - handedness_loss: 0.6934 - val_loss: 0.7845 - val_regression_loss: 0.0900 - val_handedness_loss: 0.6941\n",
      "Evaluating model with testing data...\n",
      "4104/4104 [==============================] - 0s 16us/step\n",
      "Getting distribution of predictions and covariance matrix...\n",
      "      1 of 20\n",
      "      2 of 20\n",
      "      3 of 20\n",
      "      4 of 20\n",
      "      5 of 20\n",
      "      6 of 20\n",
      "      7 of 20\n",
      "      8 of 20\n",
      "      9 of 20\n",
      "      10 of 20\n",
      "      11 of 20\n",
      "      12 of 20\n",
      "      13 of 20\n",
      "      14 of 20\n",
      "      15 of 20\n",
      "      16 of 20\n",
      "      17 of 20\n",
      "      18 of 20\n",
      "      19 of 20\n",
      "      20 of 20\n",
      "Computing ensemble means...\n",
      "Computing mean squared error...\n",
      "Iteration 135\n",
      "Train on 19392 samples, validate on 4134 samples\n",
      "Epoch 1/150\n",
      "19392/19392 [==============================] - 3s 138us/step - loss: 0.9666 - regression_loss: 0.2714 - handedness_loss: 0.6947 - val_loss: 0.8035 - val_regression_loss: 0.1069 - val_handedness_loss: 0.6967\n",
      "Epoch 2/150\n",
      "19392/19392 [==============================] - 2s 125us/step - loss: 0.7998 - regression_loss: 0.1046 - handedness_loss: 0.6953 - val_loss: 0.7985 - val_regression_loss: 0.1026 - val_handedness_loss: 0.6959\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3/150\n",
      "19392/19392 [==============================] - 3s 138us/step - loss: 0.7951 - regression_loss: 0.1004 - handedness_loss: 0.6947 - val_loss: 0.7902 - val_regression_loss: 0.0968 - val_handedness_loss: 0.6931\n",
      "Epoch 4/150\n",
      "19392/19392 [==============================] - 3s 142us/step - loss: 0.7898 - regression_loss: 0.0962 - handedness_loss: 0.6936 - val_loss: 0.7884 - val_regression_loss: 0.0956 - val_handedness_loss: 0.6926\n",
      "Epoch 5/150\n",
      "19392/19392 [==============================] - 3s 145us/step - loss: 0.7875 - regression_loss: 0.0941 - handedness_loss: 0.6933 - val_loss: 0.7873 - val_regression_loss: 0.0937 - val_handedness_loss: 0.6937\n",
      "Epoch 6/150\n",
      "19392/19392 [==============================] - 3s 145us/step - loss: 0.7851 - regression_loss: 0.0918 - handedness_loss: 0.6933 - val_loss: 0.7852 - val_regression_loss: 0.0920 - val_handedness_loss: 0.6933\n",
      "Epoch 7/150\n",
      "19392/19392 [==============================] - 3s 145us/step - loss: 0.7843 - regression_loss: 0.0910 - handedness_loss: 0.6933 - val_loss: 0.7852 - val_regression_loss: 0.0912 - val_handedness_loss: 0.6942\n",
      "Epoch 8/150\n",
      "19392/19392 [==============================] - 3s 145us/step - loss: 0.7826 - regression_loss: 0.0893 - handedness_loss: 0.6933 - val_loss: 0.7834 - val_regression_loss: 0.0896 - val_handedness_loss: 0.6939\n",
      "Evaluating model with testing data...\n",
      "4134/4134 [==============================] - 0s 17us/step\n",
      "Getting distribution of predictions and covariance matrix...\n",
      "      1 of 20\n",
      "      2 of 20\n",
      "      3 of 20\n",
      "      4 of 20\n",
      "      5 of 20\n",
      "      6 of 20\n",
      "      7 of 20\n",
      "      8 of 20\n",
      "      9 of 20\n",
      "      10 of 20\n",
      "      11 of 20\n",
      "      12 of 20\n",
      "      13 of 20\n",
      "      14 of 20\n",
      "      15 of 20\n",
      "      16 of 20\n",
      "      17 of 20\n",
      "      18 of 20\n",
      "      19 of 20\n",
      "      20 of 20\n",
      "Computing ensemble means...\n",
      "Computing mean squared error...\n",
      "Iteration 136\n",
      "Train on 19532 samples, validate on 4164 samples\n",
      "Epoch 1/150\n",
      "19532/19532 [==============================] - 3s 142us/step - loss: 0.9367 - regression_loss: 0.3058 - handedness_loss: 0.6309 - val_loss: 0.9174 - val_regression_loss: 0.2247 - val_handedness_loss: 0.6929\n",
      "Epoch 2/150\n",
      "19532/19532 [==============================] - 3s 146us/step - loss: 0.8495 - regression_loss: 0.1553 - handedness_loss: 0.6941 - val_loss: 0.8059 - val_regression_loss: 0.1094 - val_handedness_loss: 0.6966\n",
      "Epoch 3/150\n",
      "19532/19532 [==============================] - 3s 147us/step - loss: 0.7952 - regression_loss: 0.0995 - handedness_loss: 0.6956 - val_loss: 0.7923 - val_regression_loss: 0.0957 - val_handedness_loss: 0.6965\n",
      "Epoch 4/150\n",
      "19532/19532 [==============================] - 3s 145us/step - loss: 0.7881 - regression_loss: 0.0935 - handedness_loss: 0.6946 - val_loss: 0.7862 - val_regression_loss: 0.0926 - val_handedness_loss: 0.6936\n",
      "Epoch 5/150\n",
      "19532/19532 [==============================] - 3s 145us/step - loss: 0.7864 - regression_loss: 0.0913 - handedness_loss: 0.6950 - val_loss: 0.7858 - val_regression_loss: 0.0911 - val_handedness_loss: 0.6945\n",
      "Evaluating model with testing data...\n",
      "4164/4164 [==============================] - 0s 16us/step\n",
      "Getting distribution of predictions and covariance matrix...\n",
      "      1 of 20\n",
      "      2 of 20\n",
      "      3 of 20\n",
      "      4 of 20\n",
      "      5 of 20\n",
      "      6 of 20\n",
      "      7 of 20\n",
      "      8 of 20\n",
      "      9 of 20\n",
      "      10 of 20\n",
      "      11 of 20\n",
      "      12 of 20\n",
      "      13 of 20\n",
      "      14 of 20\n",
      "      15 of 20\n",
      "      16 of 20\n",
      "      17 of 20\n",
      "      18 of 20\n",
      "      19 of 20\n",
      "      20 of 20\n",
      "Computing ensemble means...\n",
      "Computing mean squared error...\n",
      "Iteration 137\n",
      "Train on 19672 samples, validate on 4194 samples\n",
      "Epoch 1/150\n",
      "19672/19672 [==============================] - 3s 137us/step - loss: 0.9044 - regression_loss: 0.2598 - handedness_loss: 0.6446 - val_loss: 0.9310 - val_regression_loss: 0.2366 - val_handedness_loss: 0.6941\n",
      "Epoch 2/150\n",
      "19672/19672 [==============================] - 3s 135us/step - loss: 0.7943 - regression_loss: 0.1000 - handedness_loss: 0.6943 - val_loss: 0.7868 - val_regression_loss: 0.0923 - val_handedness_loss: 0.6943\n",
      "Epoch 3/150\n",
      "19672/19672 [==============================] - 3s 129us/step - loss: 0.7862 - regression_loss: 0.0922 - handedness_loss: 0.6940 - val_loss: 0.7839 - val_regression_loss: 0.0913 - val_handedness_loss: 0.6925\n",
      "Epoch 4/150\n",
      "19672/19672 [==============================] - 2s 87us/step - loss: 0.7849 - regression_loss: 0.0911 - handedness_loss: 0.6939 - val_loss: 0.7849 - val_regression_loss: 0.0905 - val_handedness_loss: 0.6943\n",
      "Epoch 5/150\n",
      "19672/19672 [==============================] - 3s 132us/step - loss: 0.7838 - regression_loss: 0.0903 - handedness_loss: 0.6936 - val_loss: 0.7829 - val_regression_loss: 0.0894 - val_handedness_loss: 0.6934\n",
      "Epoch 6/150\n",
      "19672/19672 [==============================] - 2s 92us/step - loss: 0.7825 - regression_loss: 0.0889 - handedness_loss: 0.6936 - val_loss: 0.7830 - val_regression_loss: 0.0892 - val_handedness_loss: 0.6937\n",
      "Epoch 7/150\n",
      "19672/19672 [==============================] - 3s 135us/step - loss: 0.7822 - regression_loss: 0.0889 - handedness_loss: 0.6933 - val_loss: 0.7823 - val_regression_loss: 0.0880 - val_handedness_loss: 0.6942\n",
      "Evaluating model with testing data...\n",
      "4194/4194 [==============================] - 0s 19us/step\n",
      "Getting distribution of predictions and covariance matrix...\n",
      "      1 of 20\n",
      "      2 of 20\n",
      "      3 of 20\n",
      "      4 of 20\n",
      "      5 of 20\n",
      "      6 of 20\n",
      "      7 of 20\n",
      "      8 of 20\n",
      "      9 of 20\n",
      "      10 of 20\n",
      "      11 of 20\n",
      "      12 of 20\n",
      "      13 of 20\n",
      "      14 of 20\n",
      "      15 of 20\n",
      "      16 of 20\n",
      "      17 of 20\n",
      "      18 of 20\n",
      "      19 of 20\n",
      "      20 of 20\n",
      "Computing ensemble means...\n",
      "Computing mean squared error...\n",
      "Iteration 138\n",
      "Train on 19812 samples, validate on 4224 samples\n",
      "Epoch 1/150\n",
      "19812/19812 [==============================] - 3s 137us/step - loss: 0.9414 - regression_loss: 0.2809 - handedness_loss: 0.6604 - val_loss: 0.8860 - val_regression_loss: 0.1928 - val_handedness_loss: 0.6932\n",
      "Epoch 2/150\n",
      "19812/19812 [==============================] - 2s 125us/step - loss: 0.8254 - regression_loss: 0.1310 - handedness_loss: 0.6944 - val_loss: 0.7952 - val_regression_loss: 0.1001 - val_handedness_loss: 0.6951\n",
      "Epoch 3/150\n",
      "19812/19812 [==============================] - 3s 131us/step - loss: 0.7931 - regression_loss: 0.0980 - handedness_loss: 0.6952 - val_loss: 0.7877 - val_regression_loss: 0.0952 - val_handedness_loss: 0.6925\n",
      "Epoch 4/150\n",
      "19812/19812 [==============================] - 3s 130us/step - loss: 0.7884 - regression_loss: 0.0946 - handedness_loss: 0.6938 - val_loss: 0.7876 - val_regression_loss: 0.0931 - val_handedness_loss: 0.6945\n",
      "Epoch 5/150\n",
      "19812/19812 [==============================] - 3s 130us/step - loss: 0.7859 - regression_loss: 0.0922 - handedness_loss: 0.6937 - val_loss: 0.7844 - val_regression_loss: 0.0906 - val_handedness_loss: 0.6937\n",
      "Epoch 6/150\n",
      "19812/19812 [==============================] - 3s 137us/step - loss: 0.7841 - regression_loss: 0.0905 - handedness_loss: 0.6936 - val_loss: 0.7829 - val_regression_loss: 0.0897 - val_handedness_loss: 0.6932\n",
      "Epoch 7/150\n",
      "19812/19812 [==============================] - 3s 134us/step - loss: 0.7824 - regression_loss: 0.0887 - handedness_loss: 0.6936 - val_loss: 0.7812 - val_regression_loss: 0.0882 - val_handedness_loss: 0.6930\n",
      "Evaluating model with testing data...\n",
      "4224/4224 [==============================] - 0s 16us/step\n",
      "Getting distribution of predictions and covariance matrix...\n",
      "      1 of 20\n",
      "      2 of 20\n",
      "      3 of 20\n",
      "      4 of 20\n",
      "      5 of 20\n",
      "      6 of 20\n",
      "      7 of 20\n",
      "      8 of 20\n",
      "      9 of 20\n",
      "      10 of 20\n",
      "      11 of 20\n",
      "      12 of 20\n",
      "      13 of 20\n",
      "      14 of 20\n",
      "      15 of 20\n",
      "      16 of 20\n",
      "      17 of 20\n",
      "      18 of 20\n",
      "      19 of 20\n",
      "      20 of 20\n",
      "Computing ensemble means...\n",
      "Computing mean squared error...\n",
      "Iteration 139\n",
      "Train on 19952 samples, validate on 4254 samples\n",
      "Epoch 1/150\n",
      "19952/19952 [==============================] - 3s 136us/step - loss: 0.9634 - regression_loss: 0.2995 - handedness_loss: 0.6639 - val_loss: 0.9087 - val_regression_loss: 0.2158 - val_handedness_loss: 0.6926\n",
      "Epoch 2/150\n",
      "19952/19952 [==============================] - 3s 133us/step - loss: 0.8509 - regression_loss: 0.1569 - handedness_loss: 0.6940 - val_loss: 0.8055 - val_regression_loss: 0.1110 - val_handedness_loss: 0.6940\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3/150\n",
      "19952/19952 [==============================] - 3s 137us/step - loss: 0.7967 - regression_loss: 0.1021 - handedness_loss: 0.6946 - val_loss: 0.7914 - val_regression_loss: 0.0977 - val_handedness_loss: 0.6938\n",
      "Epoch 4/150\n",
      "19952/19952 [==============================] - 3s 142us/step - loss: 0.7892 - regression_loss: 0.0951 - handedness_loss: 0.6941 - val_loss: 0.7873 - val_regression_loss: 0.0939 - val_handedness_loss: 0.6939\n",
      "Epoch 5/150\n",
      "19952/19952 [==============================] - 3s 146us/step - loss: 0.7864 - regression_loss: 0.0924 - handedness_loss: 0.6940 - val_loss: 0.7847 - val_regression_loss: 0.0901 - val_handedness_loss: 0.6942\n",
      "Evaluating model with testing data...\n",
      "4254/4254 [==============================] - 0s 17us/step\n",
      "Getting distribution of predictions and covariance matrix...\n",
      "      1 of 20\n",
      "      2 of 20\n",
      "      3 of 20\n",
      "      4 of 20\n",
      "      5 of 20\n",
      "      6 of 20\n",
      "      7 of 20\n",
      "      8 of 20\n",
      "      9 of 20\n",
      "      10 of 20\n",
      "      11 of 20\n",
      "      12 of 20\n",
      "      13 of 20\n",
      "      14 of 20\n",
      "      15 of 20\n",
      "      16 of 20\n",
      "      17 of 20\n",
      "      18 of 20\n",
      "      19 of 20\n",
      "      20 of 20\n",
      "Computing ensemble means...\n",
      "Computing mean squared error...\n",
      "Iteration 140\n",
      "Train on 20092 samples, validate on 4284 samples\n",
      "Epoch 1/150\n",
      "20092/20092 [==============================] - 3s 137us/step - loss: 0.9028 - regression_loss: 0.2383 - handedness_loss: 0.6645 - val_loss: 0.8213 - val_regression_loss: 0.1234 - val_handedness_loss: 0.6975\n",
      "Epoch 2/150\n",
      "20092/20092 [==============================] - 3s 144us/step - loss: 0.8069 - regression_loss: 0.1100 - handedness_loss: 0.6969 - val_loss: 0.7992 - val_regression_loss: 0.1032 - val_handedness_loss: 0.6958\n",
      "Epoch 3/150\n",
      "20092/20092 [==============================] - 3s 146us/step - loss: 0.7945 - regression_loss: 0.1002 - handedness_loss: 0.6943 - val_loss: 0.7925 - val_regression_loss: 0.0976 - val_handedness_loss: 0.6949\n",
      "Epoch 4/150\n",
      "20092/20092 [==============================] - 3s 140us/step - loss: 0.7899 - regression_loss: 0.0957 - handedness_loss: 0.6942 - val_loss: 0.7882 - val_regression_loss: 0.0939 - val_handedness_loss: 0.6942\n",
      "Epoch 5/150\n",
      "20092/20092 [==============================] - 3s 141us/step - loss: 0.7866 - regression_loss: 0.0925 - handedness_loss: 0.6941 - val_loss: 0.7849 - val_regression_loss: 0.0908 - val_handedness_loss: 0.6940\n",
      "Epoch 6/150\n",
      "20092/20092 [==============================] - 3s 144us/step - loss: 0.7834 - regression_loss: 0.0898 - handedness_loss: 0.6936 - val_loss: 0.7829 - val_regression_loss: 0.0891 - val_handedness_loss: 0.6938\n",
      "Epoch 7/150\n",
      "20092/20092 [==============================] - 3s 146us/step - loss: 0.7813 - regression_loss: 0.0881 - handedness_loss: 0.6932 - val_loss: 0.7808 - val_regression_loss: 0.0869 - val_handedness_loss: 0.6937\n",
      "Epoch 8/150\n",
      "20092/20092 [==============================] - 3s 144us/step - loss: 0.7799 - regression_loss: 0.0867 - handedness_loss: 0.6932 - val_loss: 0.7797 - val_regression_loss: 0.0862 - val_handedness_loss: 0.6935\n",
      "Epoch 9/150\n",
      "20092/20092 [==============================] - 3s 134us/step - loss: 0.7789 - regression_loss: 0.0856 - handedness_loss: 0.6933 - val_loss: 0.7781 - val_regression_loss: 0.0851 - val_handedness_loss: 0.6929\n",
      "Epoch 10/150\n",
      "20092/20092 [==============================] - 3s 145us/step - loss: 0.7781 - regression_loss: 0.0849 - handedness_loss: 0.6932 - val_loss: 0.7782 - val_regression_loss: 0.0848 - val_handedness_loss: 0.6934\n",
      "Epoch 11/150\n",
      "20092/20092 [==============================] - 3s 139us/step - loss: 0.7778 - regression_loss: 0.0845 - handedness_loss: 0.6933 - val_loss: 0.7778 - val_regression_loss: 0.0843 - val_handedness_loss: 0.6934\n",
      "Epoch 12/150\n",
      "20092/20092 [==============================] - 3s 144us/step - loss: 0.7774 - regression_loss: 0.0841 - handedness_loss: 0.6933 - val_loss: 0.7771 - val_regression_loss: 0.0839 - val_handedness_loss: 0.6931\n",
      "Epoch 13/150\n",
      "20092/20092 [==============================] - 3s 146us/step - loss: 0.7770 - regression_loss: 0.0839 - handedness_loss: 0.6931 - val_loss: 0.7772 - val_regression_loss: 0.0838 - val_handedness_loss: 0.6933\n",
      "Evaluating model with testing data...\n",
      "4284/4284 [==============================] - 0s 16us/step\n",
      "Getting distribution of predictions and covariance matrix...\n",
      "      1 of 20\n",
      "      2 of 20\n",
      "      3 of 20\n",
      "      4 of 20\n",
      "      5 of 20\n",
      "      6 of 20\n",
      "      7 of 20\n",
      "      8 of 20\n",
      "      9 of 20\n",
      "      10 of 20\n",
      "      11 of 20\n",
      "      12 of 20\n",
      "      13 of 20\n",
      "      14 of 20\n",
      "      15 of 20\n",
      "      16 of 20\n",
      "      17 of 20\n",
      "      18 of 20\n",
      "      19 of 20\n",
      "      20 of 20\n",
      "Computing ensemble means...\n",
      "Computing mean squared error...\n",
      "Iteration 141\n",
      "Train on 20232 samples, validate on 4314 samples\n",
      "Epoch 1/150\n",
      "20232/20232 [==============================] - 3s 137us/step - loss: 0.9576 - regression_loss: 0.2963 - handedness_loss: 0.6605 - val_loss: 0.9000 - val_regression_loss: 0.2068 - val_handedness_loss: 0.6934\n",
      "Epoch 2/150\n",
      "20232/20232 [==============================] - 3s 141us/step - loss: 0.8446 - regression_loss: 0.1499 - handedness_loss: 0.6943 - val_loss: 0.8073 - val_regression_loss: 0.1096 - val_handedness_loss: 0.6977\n",
      "Epoch 3/150\n",
      "20232/20232 [==============================] - 3s 142us/step - loss: 0.7959 - regression_loss: 0.1015 - handedness_loss: 0.6943 - val_loss: 0.7924 - val_regression_loss: 0.0964 - val_handedness_loss: 0.6960\n",
      "Epoch 4/150\n",
      "20232/20232 [==============================] - 3s 136us/step - loss: 0.7882 - regression_loss: 0.0941 - handedness_loss: 0.6943 - val_loss: 0.7869 - val_regression_loss: 0.0929 - val_handedness_loss: 0.6940\n",
      "Epoch 5/150\n",
      "20232/20232 [==============================] - 3s 140us/step - loss: 0.7857 - regression_loss: 0.0913 - handedness_loss: 0.6943 - val_loss: 0.7830 - val_regression_loss: 0.0898 - val_handedness_loss: 0.6932\n",
      "Epoch 6/150\n",
      "20232/20232 [==============================] - 3s 134us/step - loss: 0.7835 - regression_loss: 0.0895 - handedness_loss: 0.6938 - val_loss: 0.7829 - val_regression_loss: 0.0884 - val_handedness_loss: 0.6945\n",
      "Epoch 7/150\n",
      "20232/20232 [==============================] - 3s 138us/step - loss: 0.7815 - regression_loss: 0.0880 - handedness_loss: 0.6936 - val_loss: 0.7800 - val_regression_loss: 0.0868 - val_handedness_loss: 0.6931\n",
      "Epoch 8/150\n",
      "20232/20232 [==============================] - 3s 128us/step - loss: 0.7803 - regression_loss: 0.0867 - handedness_loss: 0.6934 - val_loss: 0.7790 - val_regression_loss: 0.0856 - val_handedness_loss: 0.6934\n",
      "Epoch 9/150\n",
      "20232/20232 [==============================] - 3s 136us/step - loss: 0.7793 - regression_loss: 0.0858 - handedness_loss: 0.6935 - val_loss: 0.7786 - val_regression_loss: 0.0850 - val_handedness_loss: 0.6936\n",
      "Epoch 10/150\n",
      "20232/20232 [==============================] - 3s 131us/step - loss: 0.7783 - regression_loss: 0.0852 - handedness_loss: 0.6930 - val_loss: 0.7784 - val_regression_loss: 0.0848 - val_handedness_loss: 0.6935\n",
      "Epoch 11/150\n",
      "20232/20232 [==============================] - 3s 136us/step - loss: 0.7781 - regression_loss: 0.0846 - handedness_loss: 0.6933 - val_loss: 0.7782 - val_regression_loss: 0.0843 - val_handedness_loss: 0.6939\n",
      "Evaluating model with testing data...\n",
      "4314/4314 [==============================] - 0s 16us/step\n",
      "Getting distribution of predictions and covariance matrix...\n",
      "      1 of 20\n",
      "      2 of 20\n",
      "      3 of 20\n",
      "      4 of 20\n",
      "      5 of 20\n",
      "      6 of 20\n",
      "      7 of 20\n",
      "      8 of 20\n",
      "      9 of 20\n",
      "      10 of 20\n",
      "      11 of 20\n",
      "      12 of 20\n",
      "      13 of 20\n",
      "      14 of 20\n",
      "      15 of 20\n",
      "      16 of 20\n",
      "      17 of 20\n",
      "      18 of 20\n",
      "      19 of 20\n",
      "      20 of 20\n",
      "Computing ensemble means...\n",
      "Computing mean squared error...\n",
      "Iteration 142\n",
      "Train on 20372 samples, validate on 4344 samples\n",
      "Epoch 1/150\n",
      "20372/20372 [==============================] - 3s 129us/step - loss: 0.9157 - regression_loss: 0.2697 - handedness_loss: 0.6463 - val_loss: 0.9341 - val_regression_loss: 0.2411 - val_handedness_loss: 0.6929\n",
      "Epoch 2/150\n",
      "20372/20372 [==============================] - 3s 140us/step - loss: 0.8358 - regression_loss: 0.1377 - handedness_loss: 0.6981 - val_loss: 0.8083 - val_regression_loss: 0.1147 - val_handedness_loss: 0.6936\n",
      "Epoch 3/150\n",
      "20372/20372 [==============================] - 3s 141us/step - loss: 0.8043 - regression_loss: 0.1096 - handedness_loss: 0.6948 - val_loss: 0.7973 - val_regression_loss: 0.1037 - val_handedness_loss: 0.6935\n",
      "Epoch 4/150\n",
      "20372/20372 [==============================] - 3s 145us/step - loss: 0.7943 - regression_loss: 0.1001 - handedness_loss: 0.6940 - val_loss: 0.7902 - val_regression_loss: 0.0962 - val_handedness_loss: 0.6940\n",
      "Epoch 5/150\n",
      "20372/20372 [==============================] - 3s 144us/step - loss: 0.7877 - regression_loss: 0.0940 - handedness_loss: 0.6935 - val_loss: 0.7849 - val_regression_loss: 0.0909 - val_handedness_loss: 0.6940\n",
      "Evaluating model with testing data...\n",
      "4344/4344 [==============================] - 0s 17us/step\n",
      "Getting distribution of predictions and covariance matrix...\n",
      "      1 of 20\n",
      "      2 of 20\n",
      "      3 of 20\n",
      "      4 of 20\n",
      "      5 of 20\n",
      "      6 of 20\n",
      "      7 of 20\n",
      "      8 of 20\n",
      "      9 of 20\n",
      "      10 of 20\n",
      "      11 of 20\n",
      "      12 of 20\n",
      "      13 of 20\n",
      "      14 of 20\n",
      "      15 of 20\n",
      "      16 of 20\n",
      "      17 of 20\n",
      "      18 of 20\n",
      "      19 of 20\n",
      "      20 of 20\n",
      "Computing ensemble means...\n",
      "Computing mean squared error...\n",
      "Iteration 143\n",
      "Train on 20512 samples, validate on 4374 samples\n",
      "Epoch 1/150\n",
      "20512/20512 [==============================] - 3s 140us/step - loss: 1.0091 - regression_loss: 0.3151 - handedness_loss: 0.6936 - val_loss: 0.9126 - val_regression_loss: 0.2202 - val_handedness_loss: 0.6932\n",
      "Epoch 2/150\n",
      "20512/20512 [==============================] - 3s 134us/step - loss: 0.8769 - regression_loss: 0.1837 - handedness_loss: 0.6931 - val_loss: 0.8392 - val_regression_loss: 0.1465 - val_handedness_loss: 0.6933\n",
      "Epoch 3/150\n",
      "20512/20512 [==============================] - 3s 145us/step - loss: 0.8207 - regression_loss: 0.1276 - handedness_loss: 0.6931 - val_loss: 0.8013 - val_regression_loss: 0.1085 - val_handedness_loss: 0.6934\n",
      "Epoch 4/150\n",
      "20512/20512 [==============================] - 3s 135us/step - loss: 0.7934 - regression_loss: 0.1003 - handedness_loss: 0.6931 - val_loss: 0.7849 - val_regression_loss: 0.0919 - val_handedness_loss: 0.6933\n",
      "Epoch 5/150\n",
      "20512/20512 [==============================] - 3s 136us/step - loss: 0.7821 - regression_loss: 0.0890 - handedness_loss: 0.6931 - val_loss: 0.7792 - val_regression_loss: 0.0860 - val_handedness_loss: 0.6934\n",
      "Evaluating model with testing data...\n",
      "4374/4374 [==============================] - 0s 16us/step\n",
      "Getting distribution of predictions and covariance matrix...\n",
      "      1 of 20\n",
      "      2 of 20\n",
      "      3 of 20\n",
      "      4 of 20\n",
      "      5 of 20\n",
      "      6 of 20\n",
      "      7 of 20\n",
      "      8 of 20\n",
      "      9 of 20\n",
      "      10 of 20\n",
      "      11 of 20\n",
      "      12 of 20\n",
      "      13 of 20\n",
      "      14 of 20\n",
      "      15 of 20\n",
      "      16 of 20\n",
      "      17 of 20\n",
      "      18 of 20\n",
      "      19 of 20\n",
      "      20 of 20\n",
      "Computing ensemble means...\n",
      "Computing mean squared error...\n",
      "Iteration 144\n",
      "Train on 20652 samples, validate on 4404 samples\n",
      "Epoch 1/150\n",
      "20652/20652 [==============================] - 3s 133us/step - loss: 0.7259 - regression_loss: 0.1874 - handedness_loss: 0.5391 - val_loss: 0.8759 - val_regression_loss: 0.1810 - val_handedness_loss: 0.6947\n",
      "Epoch 2/150\n",
      "20652/20652 [==============================] - 3s 146us/step - loss: 0.8044 - regression_loss: 0.1066 - handedness_loss: 0.6976 - val_loss: 0.7897 - val_regression_loss: 0.0957 - val_handedness_loss: 0.6938\n",
      "Epoch 3/150\n",
      "20652/20652 [==============================] - 3s 148us/step - loss: 0.7890 - regression_loss: 0.0942 - handedness_loss: 0.6947 - val_loss: 0.7852 - val_regression_loss: 0.0913 - val_handedness_loss: 0.6938\n",
      "Epoch 4/150\n",
      "20652/20652 [==============================] - 3s 147us/step - loss: 0.7853 - regression_loss: 0.0906 - handedness_loss: 0.6945 - val_loss: 0.7841 - val_regression_loss: 0.0899 - val_handedness_loss: 0.6941\n",
      "Epoch 5/150\n",
      "20652/20652 [==============================] - 3s 146us/step - loss: 0.7831 - regression_loss: 0.0890 - handedness_loss: 0.6941 - val_loss: 0.7826 - val_regression_loss: 0.0878 - val_handedness_loss: 0.6946\n",
      "Epoch 6/150\n",
      "20652/20652 [==============================] - 3s 146us/step - loss: 0.7815 - regression_loss: 0.0876 - handedness_loss: 0.6939 - val_loss: 0.7802 - val_regression_loss: 0.0870 - val_handedness_loss: 0.6932\n",
      "Epoch 7/150\n",
      "20652/20652 [==============================] - 3s 136us/step - loss: 0.7801 - regression_loss: 0.0865 - handedness_loss: 0.6936 - val_loss: 0.7798 - val_regression_loss: 0.0862 - val_handedness_loss: 0.6937\n",
      "Epoch 8/150\n",
      "20652/20652 [==============================] - 3s 141us/step - loss: 0.7796 - regression_loss: 0.0860 - handedness_loss: 0.6936 - val_loss: 0.7779 - val_regression_loss: 0.0856 - val_handedness_loss: 0.6925\n",
      "Epoch 9/150\n",
      "20652/20652 [==============================] - 3s 132us/step - loss: 0.7787 - regression_loss: 0.0856 - handedness_loss: 0.6931 - val_loss: 0.7792 - val_regression_loss: 0.0856 - val_handedness_loss: 0.6935\n",
      "Epoch 10/150\n",
      "20652/20652 [==============================] - 3s 144us/step - loss: 0.7784 - regression_loss: 0.0851 - handedness_loss: 0.6933 - val_loss: 0.7792 - val_regression_loss: 0.0855 - val_handedness_loss: 0.6938\n",
      "Epoch 11/150\n",
      "20652/20652 [==============================] - 3s 133us/step - loss: 0.7783 - regression_loss: 0.0848 - handedness_loss: 0.6935 - val_loss: 0.7781 - val_regression_loss: 0.0847 - val_handedness_loss: 0.6933\n",
      "Epoch 12/150\n",
      "20652/20652 [==============================] - 3s 134us/step - loss: 0.7777 - regression_loss: 0.0844 - handedness_loss: 0.6933 - val_loss: 0.7778 - val_regression_loss: 0.0845 - val_handedness_loss: 0.6933\n",
      "Evaluating model with testing data...\n",
      "4404/4404 [==============================] - 0s 16us/step\n",
      "Getting distribution of predictions and covariance matrix...\n",
      "      1 of 20\n",
      "      2 of 20\n",
      "      3 of 20\n",
      "      4 of 20\n",
      "      5 of 20\n",
      "      6 of 20\n",
      "      7 of 20\n",
      "      8 of 20\n",
      "      9 of 20\n",
      "      10 of 20\n",
      "      11 of 20\n",
      "      12 of 20\n",
      "      13 of 20\n",
      "      14 of 20\n",
      "      15 of 20\n",
      "      16 of 20\n",
      "      17 of 20\n",
      "      18 of 20\n",
      "      19 of 20\n",
      "      20 of 20\n",
      "Computing ensemble means...\n",
      "Computing mean squared error...\n",
      "Iteration 145\n",
      "Train on 20792 samples, validate on 4434 samples\n",
      "Epoch 1/150\n",
      "20792/20792 [==============================] - 3s 130us/step - loss: 0.9318 - regression_loss: 0.2715 - handedness_loss: 0.6598 - val_loss: 0.7923 - val_regression_loss: 0.0970 - val_handedness_loss: 0.6951\n",
      "Epoch 2/150\n",
      "20792/20792 [==============================] - 3s 144us/step - loss: 0.7907 - regression_loss: 0.0955 - handedness_loss: 0.6952 - val_loss: 0.7878 - val_regression_loss: 0.0931 - val_handedness_loss: 0.6945\n",
      "Epoch 3/150\n",
      "20792/20792 [==============================] - 3s 144us/step - loss: 0.7863 - regression_loss: 0.0920 - handedness_loss: 0.6943 - val_loss: 0.7874 - val_regression_loss: 0.0929 - val_handedness_loss: 0.6945\n",
      "Epoch 4/150\n",
      "20792/20792 [==============================] - 3s 147us/step - loss: 0.7847 - regression_loss: 0.0909 - handedness_loss: 0.6938 - val_loss: 0.7841 - val_regression_loss: 0.0909 - val_handedness_loss: 0.6932\n",
      "Epoch 5/150\n",
      "20792/20792 [==============================] - 3s 134us/step - loss: 0.7838 - regression_loss: 0.0899 - handedness_loss: 0.6938 - val_loss: 0.7827 - val_regression_loss: 0.0884 - val_handedness_loss: 0.6942\n",
      "Epoch 6/150\n",
      "20792/20792 [==============================] - 3s 129us/step - loss: 0.7829 - regression_loss: 0.0893 - handedness_loss: 0.6936 - val_loss: 0.7819 - val_regression_loss: 0.0883 - val_handedness_loss: 0.6935\n",
      "Epoch 7/150\n",
      "20792/20792 [==============================] - 3s 133us/step - loss: 0.7816 - regression_loss: 0.0883 - handedness_loss: 0.6933 - val_loss: 0.7813 - val_regression_loss: 0.0872 - val_handedness_loss: 0.6939\n",
      "Epoch 8/150\n",
      "20792/20792 [==============================] - 3s 140us/step - loss: 0.7810 - regression_loss: 0.0876 - handedness_loss: 0.6935 - val_loss: 0.7811 - val_regression_loss: 0.0876 - val_handedness_loss: 0.6934\n",
      "Evaluating model with testing data...\n",
      "4434/4434 [==============================] - 0s 17us/step\n",
      "Getting distribution of predictions and covariance matrix...\n",
      "      1 of 20\n",
      "      2 of 20\n",
      "      3 of 20\n",
      "      4 of 20\n",
      "      5 of 20\n",
      "      6 of 20\n",
      "      7 of 20\n",
      "      8 of 20\n",
      "      9 of 20\n",
      "      10 of 20\n",
      "      11 of 20\n",
      "      12 of 20\n",
      "      13 of 20\n",
      "      14 of 20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      15 of 20\n",
      "      16 of 20\n",
      "      17 of 20\n",
      "      18 of 20\n",
      "      19 of 20\n",
      "      20 of 20\n",
      "Computing ensemble means...\n",
      "Computing mean squared error...\n",
      "Iteration 146\n",
      "Train on 20932 samples, validate on 4464 samples\n",
      "Epoch 1/150\n",
      "20932/20932 [==============================] - 3s 133us/step - loss: 1.0237 - regression_loss: 0.3350 - handedness_loss: 0.6884 - val_loss: 0.9247 - val_regression_loss: 0.2319 - val_handedness_loss: 0.6931\n",
      "Epoch 2/150\n",
      "20932/20932 [==============================] - 3s 145us/step - loss: 0.8759 - regression_loss: 0.1826 - handedness_loss: 0.6932 - val_loss: 0.8332 - val_regression_loss: 0.1402 - val_handedness_loss: 0.6932\n",
      "Epoch 3/150\n",
      "20932/20932 [==============================] - 3s 144us/step - loss: 0.8125 - regression_loss: 0.1193 - handedness_loss: 0.6932 - val_loss: 0.7984 - val_regression_loss: 0.1053 - val_handedness_loss: 0.6932\n",
      "Epoch 4/150\n",
      "20932/20932 [==============================] - 3s 142us/step - loss: 0.7922 - regression_loss: 0.0990 - handedness_loss: 0.6932 - val_loss: 0.7872 - val_regression_loss: 0.0941 - val_handedness_loss: 0.6932\n",
      "Epoch 5/150\n",
      "20932/20932 [==============================] - 3s 144us/step - loss: 0.7846 - regression_loss: 0.0915 - handedness_loss: 0.6932 - val_loss: 0.7830 - val_regression_loss: 0.0898 - val_handedness_loss: 0.6932\n",
      "Evaluating model with testing data...\n",
      "4464/4464 [==============================] - 0s 17us/step\n",
      "Getting distribution of predictions and covariance matrix...\n",
      "      1 of 20\n",
      "      2 of 20\n",
      "      3 of 20\n",
      "      4 of 20\n",
      "      5 of 20\n",
      "      6 of 20\n",
      "      7 of 20\n",
      "      8 of 20\n",
      "      9 of 20\n",
      "      10 of 20\n",
      "      11 of 20\n",
      "      12 of 20\n",
      "      13 of 20\n",
      "      14 of 20\n",
      "      15 of 20\n",
      "      16 of 20\n",
      "      17 of 20\n",
      "      18 of 20\n",
      "      19 of 20\n",
      "      20 of 20\n",
      "Computing ensemble means...\n",
      "Computing mean squared error...\n",
      "Iteration 147\n",
      "Train on 21072 samples, validate on 4494 samples\n",
      "Epoch 1/150\n",
      "21072/21072 [==============================] - 3s 137us/step - loss: 1.0033 - regression_loss: 0.3087 - handedness_loss: 0.6943 - val_loss: 0.8809 - val_regression_loss: 0.1876 - val_handedness_loss: 0.6937\n",
      "Epoch 2/150\n",
      "21072/21072 [==============================] - 2s 89us/step - loss: 0.8337 - regression_loss: 0.1403 - handedness_loss: 0.6933 - val_loss: 0.8046 - val_regression_loss: 0.1107 - val_handedness_loss: 0.6938\n",
      "Epoch 3/150\n",
      "21072/21072 [==============================] - 3s 134us/step - loss: 0.7991 - regression_loss: 0.1056 - handedness_loss: 0.6935 - val_loss: 0.7936 - val_regression_loss: 0.1011 - val_handedness_loss: 0.6931\n",
      "Epoch 4/150\n",
      "21072/21072 [==============================] - 3s 142us/step - loss: 0.7913 - regression_loss: 0.0982 - handedness_loss: 0.6932 - val_loss: 0.7895 - val_regression_loss: 0.0959 - val_handedness_loss: 0.6933\n",
      "Epoch 5/150\n",
      "21072/21072 [==============================] - 3s 147us/step - loss: 0.7867 - regression_loss: 0.0935 - handedness_loss: 0.6932 - val_loss: 0.7854 - val_regression_loss: 0.0922 - val_handedness_loss: 0.6932\n",
      "Epoch 6/150\n",
      "21072/21072 [==============================] - 3s 147us/step - loss: 0.7840 - regression_loss: 0.0908 - handedness_loss: 0.6932 - val_loss: 0.7831 - val_regression_loss: 0.0896 - val_handedness_loss: 0.6932\n",
      "Epoch 7/150\n",
      "21072/21072 [==============================] - 3s 146us/step - loss: 0.7816 - regression_loss: 0.0885 - handedness_loss: 0.6931 - val_loss: 0.7803 - val_regression_loss: 0.0867 - val_handedness_loss: 0.6933\n",
      "Evaluating model with testing data...\n",
      "4494/4494 [==============================] - 0s 17us/step\n",
      "Getting distribution of predictions and covariance matrix...\n",
      "      1 of 20\n",
      "      2 of 20\n",
      "      3 of 20\n",
      "      4 of 20\n",
      "      5 of 20\n",
      "      6 of 20\n",
      "      7 of 20\n",
      "      8 of 20\n",
      "      9 of 20\n",
      "      10 of 20\n",
      "      11 of 20\n",
      "      12 of 20\n",
      "      13 of 20\n",
      "      14 of 20\n",
      "      15 of 20\n",
      "      16 of 20\n",
      "      17 of 20\n",
      "      18 of 20\n",
      "      19 of 20\n",
      "      20 of 20\n",
      "Computing ensemble means...\n",
      "Computing mean squared error...\n",
      "Iteration 148\n",
      "Train on 21212 samples, validate on 4524 samples\n",
      "Epoch 1/150\n",
      "21212/21212 [==============================] - 3s 137us/step - loss: 0.8354 - regression_loss: 0.2187 - handedness_loss: 0.6167 - val_loss: 0.7950 - val_regression_loss: 0.0992 - val_handedness_loss: 0.6956\n",
      "Epoch 2/150\n",
      "21212/21212 [==============================] - 3s 145us/step - loss: 0.7891 - regression_loss: 0.0943 - handedness_loss: 0.6948 - val_loss: 0.7873 - val_regression_loss: 0.0927 - val_handedness_loss: 0.6943\n",
      "Epoch 3/150\n",
      "21212/21212 [==============================] - 3s 146us/step - loss: 0.7866 - regression_loss: 0.0924 - handedness_loss: 0.6942 - val_loss: 0.7842 - val_regression_loss: 0.0910 - val_handedness_loss: 0.6931\n",
      "Epoch 4/150\n",
      "21212/21212 [==============================] - 3s 140us/step - loss: 0.7844 - regression_loss: 0.0906 - handedness_loss: 0.6937 - val_loss: 0.7835 - val_regression_loss: 0.0895 - val_handedness_loss: 0.6940\n",
      "Epoch 5/150\n",
      "21212/21212 [==============================] - 3s 128us/step - loss: 0.7834 - regression_loss: 0.0897 - handedness_loss: 0.6937 - val_loss: 0.7820 - val_regression_loss: 0.0886 - val_handedness_loss: 0.6933\n",
      "Epoch 6/150\n",
      "21212/21212 [==============================] - 3s 142us/step - loss: 0.7826 - regression_loss: 0.0888 - handedness_loss: 0.6938 - val_loss: 0.7812 - val_regression_loss: 0.0877 - val_handedness_loss: 0.6933\n",
      "Epoch 7/150\n",
      "21212/21212 [==============================] - 3s 135us/step - loss: 0.7810 - regression_loss: 0.0877 - handedness_loss: 0.6934 - val_loss: 0.7800 - val_regression_loss: 0.0865 - val_handedness_loss: 0.6935\n",
      "Evaluating model with testing data...\n",
      "4524/4524 [==============================] - 0s 16us/step\n",
      "Getting distribution of predictions and covariance matrix...\n",
      "      1 of 20\n",
      "      2 of 20\n",
      "      3 of 20\n",
      "      4 of 20\n",
      "      5 of 20\n",
      "      6 of 20\n",
      "      7 of 20\n",
      "      8 of 20\n",
      "      9 of 20\n",
      "      10 of 20\n",
      "      11 of 20\n",
      "      12 of 20\n",
      "      13 of 20\n",
      "      14 of 20\n",
      "      15 of 20\n",
      "      16 of 20\n",
      "      17 of 20\n",
      "      18 of 20\n",
      "      19 of 20\n",
      "      20 of 20\n",
      "Computing ensemble means...\n",
      "Computing mean squared error...\n",
      "Iteration 149\n",
      "Train on 21352 samples, validate on 4554 samples\n",
      "Epoch 1/150\n",
      "21352/21352 [==============================] - 3s 138us/step - loss: 0.9267 - regression_loss: 0.2509 - handedness_loss: 0.6756 - val_loss: 0.7878 - val_regression_loss: 0.0948 - val_handedness_loss: 0.6929\n",
      "Epoch 2/150\n",
      "21352/21352 [==============================] - 3s 138us/step - loss: 0.7886 - regression_loss: 0.0946 - handedness_loss: 0.6940 - val_loss: 0.7899 - val_regression_loss: 0.0954 - val_handedness_loss: 0.6945\n",
      "Epoch 3/150\n",
      "21352/21352 [==============================] - 3s 127us/step - loss: 0.7866 - regression_loss: 0.0927 - handedness_loss: 0.6939 - val_loss: 0.7868 - val_regression_loss: 0.0916 - val_handedness_loss: 0.6951\n",
      "Epoch 4/150\n",
      "21352/21352 [==============================] - 3s 136us/step - loss: 0.7851 - regression_loss: 0.0913 - handedness_loss: 0.6938 - val_loss: 0.7837 - val_regression_loss: 0.0899 - val_handedness_loss: 0.6937\n",
      "Epoch 5/150\n",
      "21352/21352 [==============================] - 3s 144us/step - loss: 0.7837 - regression_loss: 0.0902 - handedness_loss: 0.6935 - val_loss: 0.7830 - val_regression_loss: 0.0895 - val_handedness_loss: 0.6934\n",
      "Evaluating model with testing data...\n",
      "4554/4554 [==============================] - 0s 17us/step\n",
      "Getting distribution of predictions and covariance matrix...\n",
      "      1 of 20\n",
      "      2 of 20\n",
      "      3 of 20\n",
      "      4 of 20\n",
      "      5 of 20\n",
      "      6 of 20\n",
      "      7 of 20\n",
      "      8 of 20\n",
      "      9 of 20\n",
      "      10 of 20\n",
      "      11 of 20\n",
      "      12 of 20\n",
      "      13 of 20\n",
      "      14 of 20\n",
      "      15 of 20\n",
      "      16 of 20\n",
      "      17 of 20\n",
      "      18 of 20\n",
      "      19 of 20\n",
      "      20 of 20\n",
      "Computing ensemble means...\n",
      "Computing mean squared error...\n",
      "Iteration 150\n",
      "Train on 21492 samples, validate on 4584 samples\n",
      "Epoch 1/150\n",
      "21492/21492 [==============================] - 3s 123us/step - loss: 0.9434 - regression_loss: 0.2971 - handedness_loss: 0.6464 - val_loss: 0.8973 - val_regression_loss: 0.2032 - val_handedness_loss: 0.6941\n",
      "Epoch 2/150\n",
      "21492/21492 [==============================] - 3s 127us/step - loss: 0.8348 - regression_loss: 0.1401 - handedness_loss: 0.6947 - val_loss: 0.7966 - val_regression_loss: 0.1022 - val_handedness_loss: 0.6945\n",
      "Epoch 3/150\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "21492/21492 [==============================] - 3s 137us/step - loss: 0.7937 - regression_loss: 0.0982 - handedness_loss: 0.6956 - val_loss: 0.7900 - val_regression_loss: 0.0952 - val_handedness_loss: 0.6949\n",
      "Epoch 4/150\n",
      "21492/21492 [==============================] - 3s 143us/step - loss: 0.7884 - regression_loss: 0.0939 - handedness_loss: 0.6945 - val_loss: 0.7869 - val_regression_loss: 0.0927 - val_handedness_loss: 0.6943\n",
      "Epoch 5/150\n",
      "21492/21492 [==============================] - 3s 146us/step - loss: 0.7854 - regression_loss: 0.0915 - handedness_loss: 0.6938 - val_loss: 0.7840 - val_regression_loss: 0.0900 - val_handedness_loss: 0.6940\n",
      "Epoch 6/150\n",
      "21492/21492 [==============================] - 3s 146us/step - loss: 0.7836 - regression_loss: 0.0896 - handedness_loss: 0.6940 - val_loss: 0.7834 - val_regression_loss: 0.0884 - val_handedness_loss: 0.6951\n",
      "Epoch 7/150\n",
      "21492/21492 [==============================] - 3s 144us/step - loss: 0.7814 - regression_loss: 0.0879 - handedness_loss: 0.6935 - val_loss: 0.7810 - val_regression_loss: 0.0872 - val_handedness_loss: 0.6938\n",
      "Epoch 8/150\n",
      "21492/21492 [==============================] - 3s 145us/step - loss: 0.7802 - regression_loss: 0.0868 - handedness_loss: 0.6934 - val_loss: 0.7796 - val_regression_loss: 0.0865 - val_handedness_loss: 0.6931\n",
      "Epoch 9/150\n",
      "21492/21492 [==============================] - 3s 146us/step - loss: 0.7791 - regression_loss: 0.0857 - handedness_loss: 0.6934 - val_loss: 0.7788 - val_regression_loss: 0.0852 - val_handedness_loss: 0.6936\n",
      "Epoch 10/150\n",
      "21492/21492 [==============================] - 3s 146us/step - loss: 0.7784 - regression_loss: 0.0851 - handedness_loss: 0.6933 - val_loss: 0.7783 - val_regression_loss: 0.0849 - val_handedness_loss: 0.6934\n",
      "Epoch 11/150\n",
      "21492/21492 [==============================] - 3s 146us/step - loss: 0.7776 - regression_loss: 0.0846 - handedness_loss: 0.6931 - val_loss: 0.7776 - val_regression_loss: 0.0845 - val_handedness_loss: 0.6931\n",
      "Epoch 12/150\n",
      "21492/21492 [==============================] - 3s 146us/step - loss: 0.7777 - regression_loss: 0.0843 - handedness_loss: 0.6934 - val_loss: 0.7777 - val_regression_loss: 0.0843 - val_handedness_loss: 0.6934\n",
      "Epoch 13/150\n",
      "21492/21492 [==============================] - 3s 140us/step - loss: 0.7774 - regression_loss: 0.0842 - handedness_loss: 0.6932 - val_loss: 0.7772 - val_regression_loss: 0.0840 - val_handedness_loss: 0.6932\n",
      "Epoch 14/150\n",
      "21492/21492 [==============================] - 3s 143us/step - loss: 0.7772 - regression_loss: 0.0840 - handedness_loss: 0.6932 - val_loss: 0.7772 - val_regression_loss: 0.0840 - val_handedness_loss: 0.6933\n",
      "Epoch 15/150\n",
      "21492/21492 [==============================] - 3s 146us/step - loss: 0.7772 - regression_loss: 0.0839 - handedness_loss: 0.6933 - val_loss: 0.7770 - val_regression_loss: 0.0838 - val_handedness_loss: 0.6932\n",
      "Evaluating model with testing data...\n",
      "4584/4584 [==============================] - 0s 17us/step\n",
      "Getting distribution of predictions and covariance matrix...\n",
      "      1 of 20\n",
      "      2 of 20\n",
      "      3 of 20\n",
      "      4 of 20\n",
      "      5 of 20\n",
      "      6 of 20\n",
      "      7 of 20\n",
      "      8 of 20\n",
      "      9 of 20\n",
      "      10 of 20\n",
      "      11 of 20\n",
      "      12 of 20\n",
      "      13 of 20\n",
      "      14 of 20\n",
      "      15 of 20\n",
      "      16 of 20\n",
      "      17 of 20\n",
      "      18 of 20\n",
      "      19 of 20\n",
      "      20 of 20\n",
      "Computing ensemble means...\n",
      "Computing mean squared error...\n",
      "Iteration 151\n",
      "Train on 21632 samples, validate on 4614 samples\n",
      "Epoch 1/150\n",
      "21632/21632 [==============================] - 3s 138us/step - loss: 0.9489 - regression_loss: 0.2547 - handedness_loss: 0.6942 - val_loss: 0.7931 - val_regression_loss: 0.0981 - val_handedness_loss: 0.6944\n",
      "Epoch 2/150\n",
      "21632/21632 [==============================] - 3s 142us/step - loss: 0.7925 - regression_loss: 0.0977 - handedness_loss: 0.6947 - val_loss: 0.7910 - val_regression_loss: 0.0968 - val_handedness_loss: 0.6944\n",
      "Epoch 3/150\n",
      "21632/21632 [==============================] - 3s 147us/step - loss: 0.7894 - regression_loss: 0.0955 - handedness_loss: 0.6940 - val_loss: 0.7883 - val_regression_loss: 0.0943 - val_handedness_loss: 0.6934\n",
      "Epoch 4/150\n",
      "21632/21632 [==============================] - 2s 105us/step - loss: 0.7872 - regression_loss: 0.0940 - handedness_loss: 0.6932 - val_loss: 0.7867 - val_regression_loss: 0.0926 - val_handedness_loss: 0.6930\n",
      "Epoch 5/150\n",
      "21632/21632 [==============================] - 3s 121us/step - loss: 0.7855 - regression_loss: 0.0919 - handedness_loss: 0.6936 - val_loss: 0.7851 - val_regression_loss: 0.0912 - val_handedness_loss: 0.6932\n",
      "Epoch 6/150\n",
      "21632/21632 [==============================] - 3s 140us/step - loss: 0.7840 - regression_loss: 0.0906 - handedness_loss: 0.6934 - val_loss: 0.7840 - val_regression_loss: 0.0897 - val_handedness_loss: 0.6939\n",
      "Epoch 7/150\n",
      "21632/21632 [==============================] - 3s 144us/step - loss: 0.7829 - regression_loss: 0.0895 - handedness_loss: 0.6934 - val_loss: 0.7826 - val_regression_loss: 0.0888 - val_handedness_loss: 0.6937\n",
      "Epoch 8/150\n",
      "21632/21632 [==============================] - 3s 147us/step - loss: 0.7818 - regression_loss: 0.0884 - handedness_loss: 0.6935 - val_loss: 0.7815 - val_regression_loss: 0.0884 - val_handedness_loss: 0.6929\n",
      "Epoch 9/150\n",
      "21632/21632 [==============================] - 3s 142us/step - loss: 0.7808 - regression_loss: 0.0877 - handedness_loss: 0.6931 - val_loss: 0.7810 - val_regression_loss: 0.0869 - val_handedness_loss: 0.6936\n",
      "Epoch 10/150\n",
      "21632/21632 [==============================] - 3s 143us/step - loss: 0.7800 - regression_loss: 0.0869 - handedness_loss: 0.6931 - val_loss: 0.7802 - val_regression_loss: 0.0864 - val_handedness_loss: 0.6934\n",
      "Epoch 11/150\n",
      "21632/21632 [==============================] - 3s 148us/step - loss: 0.7797 - regression_loss: 0.0865 - handedness_loss: 0.6932 - val_loss: 0.7800 - val_regression_loss: 0.0861 - val_handedness_loss: 0.6935\n",
      "Epoch 12/150\n",
      "21632/21632 [==============================] - 3s 141us/step - loss: 0.7790 - regression_loss: 0.0859 - handedness_loss: 0.6931 - val_loss: 0.7791 - val_regression_loss: 0.0852 - val_handedness_loss: 0.6935\n",
      "Evaluating model with testing data...\n",
      "4614/4614 [==============================] - 0s 20us/step\n",
      "Getting distribution of predictions and covariance matrix...\n",
      "      1 of 20\n",
      "      2 of 20\n",
      "      3 of 20\n",
      "      4 of 20\n",
      "      5 of 20\n",
      "      6 of 20\n",
      "      7 of 20\n",
      "      8 of 20\n",
      "      9 of 20\n",
      "      10 of 20\n",
      "      11 of 20\n",
      "      12 of 20\n",
      "      13 of 20\n",
      "      14 of 20\n",
      "      15 of 20\n",
      "      16 of 20\n",
      "      17 of 20\n",
      "      18 of 20\n",
      "      19 of 20\n",
      "      20 of 20\n",
      "Computing ensemble means...\n",
      "Computing mean squared error...\n",
      "Iteration 152\n",
      "Train on 21772 samples, validate on 4644 samples\n",
      "Epoch 1/150\n",
      "21772/21772 [==============================] - 3s 138us/step - loss: 1.0023 - regression_loss: 0.3332 - handedness_loss: 0.6687 - val_loss: 0.9005 - val_regression_loss: 0.2070 - val_handedness_loss: 0.6932\n",
      "Epoch 2/150\n",
      "21772/21772 [==============================] - 3s 141us/step - loss: 0.8393 - regression_loss: 0.1454 - handedness_loss: 0.6938 - val_loss: 0.8041 - val_regression_loss: 0.1102 - val_handedness_loss: 0.6939\n",
      "Epoch 3/150\n",
      "21772/21772 [==============================] - 3s 146us/step - loss: 0.7976 - regression_loss: 0.1037 - handedness_loss: 0.6937 - val_loss: 0.7917 - val_regression_loss: 0.0976 - val_handedness_loss: 0.6940\n",
      "Epoch 4/150\n",
      "21772/21772 [==============================] - 3s 131us/step - loss: 0.7899 - regression_loss: 0.0962 - handedness_loss: 0.6936 - val_loss: 0.7877 - val_regression_loss: 0.0941 - val_handedness_loss: 0.6938\n",
      "Epoch 5/150\n",
      "21772/21772 [==============================] - 3s 134us/step - loss: 0.7862 - regression_loss: 0.0928 - handedness_loss: 0.6934 - val_loss: 0.7850 - val_regression_loss: 0.0912 - val_handedness_loss: 0.6937\n",
      "Evaluating model with testing data...\n",
      "4644/4644 [==============================] - 0s 17us/step\n",
      "Getting distribution of predictions and covariance matrix...\n",
      "      1 of 20\n",
      "      2 of 20\n",
      "      3 of 20\n",
      "      4 of 20\n",
      "      5 of 20\n",
      "      6 of 20\n",
      "      7 of 20\n",
      "      8 of 20\n",
      "      9 of 20\n",
      "      10 of 20\n",
      "      11 of 20\n",
      "      12 of 20\n",
      "      13 of 20\n",
      "      14 of 20\n",
      "      15 of 20\n",
      "      16 of 20\n",
      "      17 of 20\n",
      "      18 of 20\n",
      "      19 of 20\n",
      "      20 of 20\n",
      "Computing ensemble means...\n",
      "Computing mean squared error...\n",
      "Iteration 153\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 21912 samples, validate on 4674 samples\n",
      "Epoch 1/150\n",
      "21912/21912 [==============================] - 3s 132us/step - loss: 0.9679 - regression_loss: 0.2806 - handedness_loss: 0.6865 - val_loss: 0.7906 - val_regression_loss: 0.0962 - val_handedness_loss: 0.6942\n",
      "Epoch 2/150\n",
      "21912/21912 [==============================] - 3s 122us/step - loss: 0.7888 - regression_loss: 0.0946 - handedness_loss: 0.6943 - val_loss: 0.7874 - val_regression_loss: 0.0936 - val_handedness_loss: 0.6937\n",
      "Epoch 3/150\n",
      "21912/21912 [==============================] - 3s 145us/step - loss: 0.7865 - regression_loss: 0.0928 - handedness_loss: 0.6937 - val_loss: 0.7859 - val_regression_loss: 0.0921 - val_handedness_loss: 0.6937\n",
      "Epoch 4/150\n",
      "21912/21912 [==============================] - 3s 148us/step - loss: 0.7855 - regression_loss: 0.0921 - handedness_loss: 0.6934 - val_loss: 0.7852 - val_regression_loss: 0.0909 - val_handedness_loss: 0.6942\n",
      "Epoch 5/150\n",
      "21912/21912 [==============================] - 3s 148us/step - loss: 0.7842 - regression_loss: 0.0906 - handedness_loss: 0.6936 - val_loss: 0.7835 - val_regression_loss: 0.0901 - val_handedness_loss: 0.6934\n",
      "Epoch 6/150\n",
      "21912/21912 [==============================] - 3s 148us/step - loss: 0.7832 - regression_loss: 0.0896 - handedness_loss: 0.6938 - val_loss: 0.7827 - val_regression_loss: 0.0894 - val_handedness_loss: 0.6932\n",
      "Epoch 7/150\n",
      "21912/21912 [==============================] - 3s 141us/step - loss: 0.7819 - regression_loss: 0.0885 - handedness_loss: 0.6933 - val_loss: 0.7815 - val_regression_loss: 0.0883 - val_handedness_loss: 0.6931\n",
      "Epoch 8/150\n",
      "21912/21912 [==============================] - 3s 142us/step - loss: 0.7809 - regression_loss: 0.0877 - handedness_loss: 0.6932 - val_loss: 0.7810 - val_regression_loss: 0.0877 - val_handedness_loss: 0.6932\n",
      "Epoch 9/150\n",
      "21912/21912 [==============================] - 3s 148us/step - loss: 0.7806 - regression_loss: 0.0875 - handedness_loss: 0.6932 - val_loss: 0.7811 - val_regression_loss: 0.0875 - val_handedness_loss: 0.6934\n",
      "Epoch 10/150\n",
      "21912/21912 [==============================] - 3s 146us/step - loss: 0.7800 - regression_loss: 0.0866 - handedness_loss: 0.6933 - val_loss: 0.7795 - val_regression_loss: 0.0861 - val_handedness_loss: 0.6933\n",
      "Epoch 11/150\n",
      "21912/21912 [==============================] - 3s 145us/step - loss: 0.7792 - regression_loss: 0.0860 - handedness_loss: 0.6932 - val_loss: 0.7791 - val_regression_loss: 0.0860 - val_handedness_loss: 0.6930\n",
      "Epoch 12/150\n",
      "21912/21912 [==============================] - 3s 145us/step - loss: 0.7788 - regression_loss: 0.0857 - handedness_loss: 0.6932 - val_loss: 0.7795 - val_regression_loss: 0.0860 - val_handedness_loss: 0.6934\n",
      "Epoch 13/150\n",
      "21912/21912 [==============================] - 3s 148us/step - loss: 0.7784 - regression_loss: 0.0853 - handedness_loss: 0.6931 - val_loss: 0.7783 - val_regression_loss: 0.0850 - val_handedness_loss: 0.6933\n",
      "Epoch 14/150\n",
      "21912/21912 [==============================] - 3s 145us/step - loss: 0.7781 - regression_loss: 0.0849 - handedness_loss: 0.6932 - val_loss: 0.7784 - val_regression_loss: 0.0851 - val_handedness_loss: 0.6933\n",
      "Epoch 15/150\n",
      "21912/21912 [==============================] - 3s 149us/step - loss: 0.7777 - regression_loss: 0.0845 - handedness_loss: 0.6931 - val_loss: 0.7784 - val_regression_loss: 0.0851 - val_handedness_loss: 0.6932\n",
      "Evaluating model with testing data...\n",
      "4674/4674 [==============================] - 0s 17us/step\n",
      "Getting distribution of predictions and covariance matrix...\n",
      "      1 of 20\n",
      "      2 of 20\n",
      "      3 of 20\n",
      "      4 of 20\n",
      "      5 of 20\n",
      "      6 of 20\n",
      "      7 of 20\n",
      "      8 of 20\n",
      "      9 of 20\n",
      "      10 of 20\n",
      "      11 of 20\n",
      "      12 of 20\n",
      "      13 of 20\n",
      "      14 of 20\n",
      "      15 of 20\n",
      "      16 of 20\n",
      "      17 of 20\n",
      "      18 of 20\n",
      "      19 of 20\n",
      "      20 of 20\n",
      "Computing ensemble means...\n",
      "Computing mean squared error...\n",
      "Iteration 154\n",
      "Train on 22052 samples, validate on 4704 samples\n",
      "Epoch 1/150\n",
      "22052/22052 [==============================] - 3s 134us/step - loss: 0.9977 - regression_loss: 0.3028 - handedness_loss: 0.6944 - val_loss: 0.8678 - val_regression_loss: 0.1743 - val_handedness_loss: 0.6935\n",
      "Epoch 2/150\n",
      "22052/22052 [==============================] - 3s 130us/step - loss: 0.8245 - regression_loss: 0.1309 - handedness_loss: 0.6934 - val_loss: 0.8039 - val_regression_loss: 0.1100 - val_handedness_loss: 0.6939\n",
      "Epoch 3/150\n",
      "22052/22052 [==============================] - 3s 136us/step - loss: 0.7976 - regression_loss: 0.1042 - handedness_loss: 0.6934 - val_loss: 0.7939 - val_regression_loss: 0.1003 - val_handedness_loss: 0.6936\n",
      "Epoch 4/150\n",
      "22052/22052 [==============================] - 3s 146us/step - loss: 0.7904 - regression_loss: 0.0969 - handedness_loss: 0.6934 - val_loss: 0.7869 - val_regression_loss: 0.0936 - val_handedness_loss: 0.6932\n",
      "Epoch 5/150\n",
      "22052/22052 [==============================] - 3s 140us/step - loss: 0.7861 - regression_loss: 0.0928 - handedness_loss: 0.6933 - val_loss: 0.7855 - val_regression_loss: 0.0920 - val_handedness_loss: 0.6935\n",
      "Epoch 6/150\n",
      "22052/22052 [==============================] - 3s 147us/step - loss: 0.7826 - regression_loss: 0.0895 - handedness_loss: 0.6932 - val_loss: 0.7813 - val_regression_loss: 0.0883 - val_handedness_loss: 0.6930\n",
      "Epoch 7/150\n",
      "22052/22052 [==============================] - 3s 147us/step - loss: 0.7810 - regression_loss: 0.0878 - handedness_loss: 0.6933 - val_loss: 0.7802 - val_regression_loss: 0.0871 - val_handedness_loss: 0.6930\n",
      "Epoch 8/150\n",
      "22052/22052 [==============================] - 3s 121us/step - loss: 0.7794 - regression_loss: 0.0862 - handedness_loss: 0.6932 - val_loss: 0.7792 - val_regression_loss: 0.0858 - val_handedness_loss: 0.6933\n",
      "Epoch 9/150\n",
      "22052/22052 [==============================] - 2s 112us/step - loss: 0.7787 - regression_loss: 0.0856 - handedness_loss: 0.6932 - val_loss: 0.7785 - val_regression_loss: 0.0853 - val_handedness_loss: 0.6932\n",
      "Epoch 10/150\n",
      "22052/22052 [==============================] - 3s 123us/step - loss: 0.7780 - regression_loss: 0.0848 - handedness_loss: 0.6932 - val_loss: 0.7780 - val_regression_loss: 0.0848 - val_handedness_loss: 0.6932\n",
      "Epoch 11/150\n",
      "22052/22052 [==============================] - 3s 133us/step - loss: 0.7775 - regression_loss: 0.0843 - handedness_loss: 0.6932 - val_loss: 0.7776 - val_regression_loss: 0.0844 - val_handedness_loss: 0.6932\n",
      "Evaluating model with testing data...\n",
      "4704/4704 [==============================] - 0s 16us/step\n",
      "Getting distribution of predictions and covariance matrix...\n",
      "      1 of 20\n",
      "      2 of 20\n",
      "      3 of 20\n",
      "      4 of 20\n",
      "      5 of 20\n",
      "      6 of 20\n",
      "      7 of 20\n",
      "      8 of 20\n",
      "      9 of 20\n",
      "      10 of 20\n",
      "      11 of 20\n",
      "      12 of 20\n",
      "      13 of 20\n",
      "      14 of 20\n",
      "      15 of 20\n",
      "      16 of 20\n",
      "      17 of 20\n",
      "      18 of 20\n",
      "      19 of 20\n",
      "      20 of 20\n",
      "Computing ensemble means...\n",
      "Computing mean squared error...\n",
      "Iteration 155\n",
      "Train on 22192 samples, validate on 4734 samples\n",
      "Epoch 1/150\n",
      "22192/22192 [==============================] - 3s 137us/step - loss: 0.8926 - regression_loss: 0.2218 - handedness_loss: 0.6705 - val_loss: 0.7905 - val_regression_loss: 0.0966 - val_handedness_loss: 0.6938\n",
      "Epoch 2/150\n",
      "22192/22192 [==============================] - 3s 130us/step - loss: 0.7896 - regression_loss: 0.0946 - handedness_loss: 0.6948 - val_loss: 0.7872 - val_regression_loss: 0.0929 - val_handedness_loss: 0.6943\n",
      "Epoch 3/150\n",
      "22192/22192 [==============================] - 3s 137us/step - loss: 0.7866 - regression_loss: 0.0926 - handedness_loss: 0.6940 - val_loss: 0.7853 - val_regression_loss: 0.0913 - val_handedness_loss: 0.6940\n",
      "Epoch 4/150\n",
      "22192/22192 [==============================] - 3s 137us/step - loss: 0.7848 - regression_loss: 0.0910 - handedness_loss: 0.6938 - val_loss: 0.7852 - val_regression_loss: 0.0911 - val_handedness_loss: 0.6942\n",
      "Epoch 5/150\n",
      "22192/22192 [==============================] - 3s 129us/step - loss: 0.7834 - regression_loss: 0.0896 - handedness_loss: 0.6938 - val_loss: 0.7830 - val_regression_loss: 0.0896 - val_handedness_loss: 0.6935\n",
      "Epoch 6/150\n",
      "22192/22192 [==============================] - 3s 135us/step - loss: 0.7823 - regression_loss: 0.0887 - handedness_loss: 0.6936 - val_loss: 0.7821 - val_regression_loss: 0.0883 - val_handedness_loss: 0.6937\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7/150\n",
      "22192/22192 [==============================] - 3s 147us/step - loss: 0.7814 - regression_loss: 0.0878 - handedness_loss: 0.6936 - val_loss: 0.7808 - val_regression_loss: 0.0875 - val_handedness_loss: 0.6933\n",
      "Epoch 8/150\n",
      "22192/22192 [==============================] - 3s 148us/step - loss: 0.7803 - regression_loss: 0.0871 - handedness_loss: 0.6933 - val_loss: 0.7803 - val_regression_loss: 0.0865 - val_handedness_loss: 0.6938\n",
      "Epoch 9/150\n",
      "22192/22192 [==============================] - 3s 148us/step - loss: 0.7795 - regression_loss: 0.0864 - handedness_loss: 0.6931 - val_loss: 0.7798 - val_regression_loss: 0.0860 - val_handedness_loss: 0.6937\n",
      "Epoch 10/150\n",
      "22192/22192 [==============================] - 3s 145us/step - loss: 0.7792 - regression_loss: 0.0860 - handedness_loss: 0.6932 - val_loss: 0.7792 - val_regression_loss: 0.0859 - val_handedness_loss: 0.6933\n",
      "Epoch 11/150\n",
      "22192/22192 [==============================] - 3s 148us/step - loss: 0.7790 - regression_loss: 0.0856 - handedness_loss: 0.6934 - val_loss: 0.7787 - val_regression_loss: 0.0853 - val_handedness_loss: 0.6934\n",
      "Evaluating model with testing data...\n",
      "4734/4734 [==============================] - 0s 17us/step\n",
      "Getting distribution of predictions and covariance matrix...\n",
      "      1 of 20\n",
      "      2 of 20\n",
      "      3 of 20\n",
      "      4 of 20\n",
      "      5 of 20\n",
      "      6 of 20\n",
      "      7 of 20\n",
      "      8 of 20\n",
      "      9 of 20\n",
      "      10 of 20\n",
      "      11 of 20\n",
      "      12 of 20\n",
      "      13 of 20\n",
      "      14 of 20\n",
      "      15 of 20\n",
      "      16 of 20\n",
      "      17 of 20\n",
      "      18 of 20\n",
      "      19 of 20\n",
      "      20 of 20\n",
      "Computing ensemble means...\n",
      "Computing mean squared error...\n",
      "Iteration 156\n",
      "Train on 22332 samples, validate on 4764 samples\n",
      "Epoch 1/150\n",
      "22332/22332 [==============================] - 3s 131us/step - loss: 0.9107 - regression_loss: 0.2345 - handedness_loss: 0.6759 - val_loss: 0.8098 - val_regression_loss: 0.1154 - val_handedness_loss: 0.6946\n",
      "Epoch 2/150\n",
      "22332/22332 [==============================] - 3s 138us/step - loss: 0.8037 - regression_loss: 0.1092 - handedness_loss: 0.6944 - val_loss: 0.7974 - val_regression_loss: 0.1053 - val_handedness_loss: 0.6930\n",
      "Epoch 3/150\n",
      "22332/22332 [==============================] - 3s 137us/step - loss: 0.7943 - regression_loss: 0.0995 - handedness_loss: 0.6949 - val_loss: 0.7909 - val_regression_loss: 0.0974 - val_handedness_loss: 0.6937\n",
      "Epoch 4/150\n",
      "22332/22332 [==============================] - 3s 145us/step - loss: 0.7887 - regression_loss: 0.0948 - handedness_loss: 0.6939 - val_loss: 0.7871 - val_regression_loss: 0.0934 - val_handedness_loss: 0.6941\n",
      "Epoch 5/150\n",
      "22332/22332 [==============================] - 3s 146us/step - loss: 0.7855 - regression_loss: 0.0917 - handedness_loss: 0.6938 - val_loss: 0.7831 - val_regression_loss: 0.0903 - val_handedness_loss: 0.6935\n",
      "Epoch 6/150\n",
      "22332/22332 [==============================] - 3s 140us/step - loss: 0.7822 - regression_loss: 0.0889 - handedness_loss: 0.6933 - val_loss: 0.7821 - val_regression_loss: 0.0889 - val_handedness_loss: 0.6937\n",
      "Evaluating model with testing data...\n",
      "4764/4764 [==============================] - 0s 16us/step\n",
      "Getting distribution of predictions and covariance matrix...\n",
      "      1 of 20\n",
      "      2 of 20\n",
      "      3 of 20\n",
      "      4 of 20\n",
      "      5 of 20\n",
      "      6 of 20\n",
      "      7 of 20\n",
      "      8 of 20\n",
      "      9 of 20\n",
      "      10 of 20\n",
      "      11 of 20\n",
      "      12 of 20\n",
      "      13 of 20\n",
      "      14 of 20\n",
      "      15 of 20\n",
      "      16 of 20\n",
      "      17 of 20\n",
      "      18 of 20\n",
      "      19 of 20\n",
      "      20 of 20\n",
      "Computing ensemble means...\n",
      "Computing mean squared error...\n",
      "Iteration 157\n",
      "Train on 22472 samples, validate on 4794 samples\n",
      "Epoch 1/150\n",
      "22472/22472 [==============================] - 3s 137us/step - loss: 0.9260 - regression_loss: 0.2406 - handedness_loss: 0.6851 - val_loss: 0.7950 - val_regression_loss: 0.1009 - val_handedness_loss: 0.6939\n",
      "Epoch 2/150\n",
      "22472/22472 [==============================] - 3s 145us/step - loss: 0.7923 - regression_loss: 0.0977 - handedness_loss: 0.6946 - val_loss: 0.7904 - val_regression_loss: 0.0962 - val_handedness_loss: 0.6943\n",
      "Epoch 3/150\n",
      "22472/22472 [==============================] - 3s 142us/step - loss: 0.7896 - regression_loss: 0.0949 - handedness_loss: 0.6947 - val_loss: 0.7874 - val_regression_loss: 0.0933 - val_handedness_loss: 0.6942\n",
      "Epoch 4/150\n",
      "22472/22472 [==============================] - 3s 146us/step - loss: 0.7867 - regression_loss: 0.0926 - handedness_loss: 0.6940 - val_loss: 0.7852 - val_regression_loss: 0.0914 - val_handedness_loss: 0.6938\n",
      "Epoch 5/150\n",
      "22472/22472 [==============================] - 3s 144us/step - loss: 0.7846 - regression_loss: 0.0910 - handedness_loss: 0.6936 - val_loss: 0.7834 - val_regression_loss: 0.0899 - val_handedness_loss: 0.6936\n",
      "Epoch 6/150\n",
      "22472/22472 [==============================] - 3s 138us/step - loss: 0.7827 - regression_loss: 0.0893 - handedness_loss: 0.6934 - val_loss: 0.7828 - val_regression_loss: 0.0894 - val_handedness_loss: 0.6936\n",
      "Epoch 7/150\n",
      "22472/22472 [==============================] - 3s 141us/step - loss: 0.7815 - regression_loss: 0.0883 - handedness_loss: 0.6932 - val_loss: 0.7819 - val_regression_loss: 0.0881 - val_handedness_loss: 0.6938\n",
      "Epoch 8/150\n",
      "22472/22472 [==============================] - 3s 138us/step - loss: 0.7806 - regression_loss: 0.0874 - handedness_loss: 0.6932 - val_loss: 0.7817 - val_regression_loss: 0.0879 - val_handedness_loss: 0.6939\n",
      "Epoch 9/150\n",
      "22472/22472 [==============================] - 3s 137us/step - loss: 0.7800 - regression_loss: 0.0866 - handedness_loss: 0.6934 - val_loss: 0.7804 - val_regression_loss: 0.0869 - val_handedness_loss: 0.6935\n",
      "Epoch 10/150\n",
      "22472/22472 [==============================] - 3s 145us/step - loss: 0.7788 - regression_loss: 0.0858 - handedness_loss: 0.6930 - val_loss: 0.7792 - val_regression_loss: 0.0859 - val_handedness_loss: 0.6933\n",
      "Epoch 11/150\n",
      "22472/22472 [==============================] - 3s 131us/step - loss: 0.7787 - regression_loss: 0.0854 - handedness_loss: 0.6933 - val_loss: 0.7786 - val_regression_loss: 0.0853 - val_handedness_loss: 0.6933\n",
      "Epoch 12/150\n",
      "22472/22472 [==============================] - 3s 132us/step - loss: 0.7781 - regression_loss: 0.0850 - handedness_loss: 0.6931 - val_loss: 0.7785 - val_regression_loss: 0.0851 - val_handedness_loss: 0.6935\n",
      "Epoch 13/150\n",
      "22472/22472 [==============================] - 3s 139us/step - loss: 0.7776 - regression_loss: 0.0845 - handedness_loss: 0.6931 - val_loss: 0.7782 - val_regression_loss: 0.0849 - val_handedness_loss: 0.6932\n",
      "Epoch 14/150\n",
      "22472/22472 [==============================] - 3s 132us/step - loss: 0.7777 - regression_loss: 0.0845 - handedness_loss: 0.6932 - val_loss: 0.7779 - val_regression_loss: 0.0846 - val_handedness_loss: 0.6933\n",
      "Epoch 15/150\n",
      "22472/22472 [==============================] - 3s 144us/step - loss: 0.7773 - regression_loss: 0.0841 - handedness_loss: 0.6932 - val_loss: 0.7777 - val_regression_loss: 0.0845 - val_handedness_loss: 0.6933\n",
      "Epoch 16/150\n",
      "22472/22472 [==============================] - 3s 119us/step - loss: 0.7771 - regression_loss: 0.0840 - handedness_loss: 0.6931 - val_loss: 0.7774 - val_regression_loss: 0.0842 - val_handedness_loss: 0.6932\n",
      "Epoch 17/150\n",
      "22472/22472 [==============================] - 2s 105us/step - loss: 0.7770 - regression_loss: 0.0838 - handedness_loss: 0.6931 - val_loss: 0.7775 - val_regression_loss: 0.0843 - val_handedness_loss: 0.6933\n",
      "Epoch 18/150\n",
      "22472/22472 [==============================] - 3s 126us/step - loss: 0.7769 - regression_loss: 0.0838 - handedness_loss: 0.6931 - val_loss: 0.7774 - val_regression_loss: 0.0841 - val_handedness_loss: 0.6933\n",
      "Epoch 19/150\n",
      "22472/22472 [==============================] - 3s 140us/step - loss: 0.7768 - regression_loss: 0.0837 - handedness_loss: 0.6931 - val_loss: 0.7774 - val_regression_loss: 0.0842 - val_handedness_loss: 0.6933\n",
      "Epoch 20/150\n",
      "22472/22472 [==============================] - 3s 127us/step - loss: 0.7769 - regression_loss: 0.0837 - handedness_loss: 0.6932 - val_loss: 0.7774 - val_regression_loss: 0.0841 - val_handedness_loss: 0.6933\n",
      "Evaluating model with testing data...\n",
      "4794/4794 [==============================] - 0s 16us/step\n",
      "Getting distribution of predictions and covariance matrix...\n",
      "      1 of 20\n",
      "      2 of 20\n",
      "      3 of 20\n",
      "      4 of 20\n",
      "      5 of 20\n",
      "      6 of 20\n",
      "      7 of 20\n",
      "      8 of 20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      9 of 20\n",
      "      10 of 20\n",
      "      11 of 20\n",
      "      12 of 20\n",
      "      13 of 20\n",
      "      14 of 20\n",
      "      15 of 20\n",
      "      16 of 20\n",
      "      17 of 20\n",
      "      18 of 20\n",
      "      19 of 20\n",
      "      20 of 20\n",
      "Computing ensemble means...\n",
      "Computing mean squared error...\n",
      "Iteration 158\n",
      "Train on 22612 samples, validate on 4824 samples\n",
      "Epoch 1/150\n",
      "22612/22612 [==============================] - 3s 138us/step - loss: 0.9743 - regression_loss: 0.3025 - handedness_loss: 0.6715 - val_loss: 0.8138 - val_regression_loss: 0.1176 - val_handedness_loss: 0.6963\n",
      "Epoch 2/150\n",
      "22612/22612 [==============================] - 3s 144us/step - loss: 0.8017 - regression_loss: 0.1057 - handedness_loss: 0.6960 - val_loss: 0.7952 - val_regression_loss: 0.0997 - val_handedness_loss: 0.6954\n",
      "Epoch 3/150\n",
      "22612/22612 [==============================] - 3s 148us/step - loss: 0.7922 - regression_loss: 0.0979 - handedness_loss: 0.6943 - val_loss: 0.7906 - val_regression_loss: 0.0964 - val_handedness_loss: 0.6942\n",
      "Epoch 4/150\n",
      "22612/22612 [==============================] - 3s 148us/step - loss: 0.7879 - regression_loss: 0.0939 - handedness_loss: 0.6939 - val_loss: 0.7883 - val_regression_loss: 0.0940 - val_handedness_loss: 0.6942\n",
      "Epoch 5/150\n",
      "22612/22612 [==============================] - 3s 148us/step - loss: 0.7856 - regression_loss: 0.0918 - handedness_loss: 0.6938 - val_loss: 0.7835 - val_regression_loss: 0.0905 - val_handedness_loss: 0.6930\n",
      "Epoch 6/150\n",
      "22612/22612 [==============================] - 3s 148us/step - loss: 0.7830 - regression_loss: 0.0897 - handedness_loss: 0.6933 - val_loss: 0.7829 - val_regression_loss: 0.0890 - val_handedness_loss: 0.6938\n",
      "Epoch 7/150\n",
      "22612/22612 [==============================] - 3s 148us/step - loss: 0.7820 - regression_loss: 0.0885 - handedness_loss: 0.6935 - val_loss: 0.7813 - val_regression_loss: 0.0875 - val_handedness_loss: 0.6938\n",
      "Epoch 8/150\n",
      "22612/22612 [==============================] - 3s 144us/step - loss: 0.7803 - regression_loss: 0.0869 - handedness_loss: 0.6934 - val_loss: 0.7808 - val_regression_loss: 0.0868 - val_handedness_loss: 0.6939\n",
      "Epoch 9/150\n",
      "22612/22612 [==============================] - 3s 144us/step - loss: 0.7793 - regression_loss: 0.0860 - handedness_loss: 0.6932 - val_loss: 0.7795 - val_regression_loss: 0.0861 - val_handedness_loss: 0.6934\n",
      "Evaluating model with testing data...\n",
      "4824/4824 [==============================] - 0s 16us/step\n",
      "Getting distribution of predictions and covariance matrix...\n",
      "      1 of 20\n",
      "      2 of 20\n",
      "      3 of 20\n",
      "      4 of 20\n",
      "      5 of 20\n",
      "      6 of 20\n",
      "      7 of 20\n",
      "      8 of 20\n",
      "      9 of 20\n",
      "      10 of 20\n",
      "      11 of 20\n",
      "      12 of 20\n",
      "      13 of 20\n",
      "      14 of 20\n",
      "      15 of 20\n",
      "      16 of 20\n",
      "      17 of 20\n",
      "      18 of 20\n",
      "      19 of 20\n",
      "      20 of 20\n",
      "Computing ensemble means...\n",
      "Computing mean squared error...\n",
      "Iteration 159\n",
      "Train on 22752 samples, validate on 4854 samples\n",
      "Epoch 1/150\n",
      "22752/22752 [==============================] - 3s 139us/step - loss: 0.8857 - regression_loss: 0.2122 - handedness_loss: 0.6734 - val_loss: 0.8077 - val_regression_loss: 0.1140 - val_handedness_loss: 0.6938\n",
      "Epoch 2/150\n",
      "22752/22752 [==============================] - 3s 138us/step - loss: 0.8011 - regression_loss: 0.1071 - handedness_loss: 0.6940 - val_loss: 0.7983 - val_regression_loss: 0.1040 - val_handedness_loss: 0.6943\n",
      "Epoch 3/150\n",
      "22752/22752 [==============================] - 3s 146us/step - loss: 0.7936 - regression_loss: 0.1000 - handedness_loss: 0.6936 - val_loss: 0.7918 - val_regression_loss: 0.0985 - val_handedness_loss: 0.6933\n",
      "Epoch 4/150\n",
      "22752/22752 [==============================] - 3s 138us/step - loss: 0.7885 - regression_loss: 0.0953 - handedness_loss: 0.6932 - val_loss: 0.7879 - val_regression_loss: 0.0947 - val_handedness_loss: 0.6932\n",
      "Epoch 5/150\n",
      "22752/22752 [==============================] - 3s 147us/step - loss: 0.7853 - regression_loss: 0.0921 - handedness_loss: 0.6932 - val_loss: 0.7837 - val_regression_loss: 0.0905 - val_handedness_loss: 0.6931\n",
      "Epoch 6/150\n",
      "22752/22752 [==============================] - 3s 145us/step - loss: 0.7826 - regression_loss: 0.0893 - handedness_loss: 0.6933 - val_loss: 0.7819 - val_regression_loss: 0.0886 - val_handedness_loss: 0.6933\n",
      "Epoch 7/150\n",
      "22752/22752 [==============================] - 3s 147us/step - loss: 0.7809 - regression_loss: 0.0877 - handedness_loss: 0.6932 - val_loss: 0.7802 - val_regression_loss: 0.0871 - val_handedness_loss: 0.6931\n",
      "Epoch 8/150\n",
      "22752/22752 [==============================] - 3s 142us/step - loss: 0.7791 - regression_loss: 0.0860 - handedness_loss: 0.6932 - val_loss: 0.7793 - val_regression_loss: 0.0860 - val_handedness_loss: 0.6933\n",
      "Epoch 9/150\n",
      "22752/22752 [==============================] - 3s 147us/step - loss: 0.7784 - regression_loss: 0.0853 - handedness_loss: 0.6932 - val_loss: 0.7785 - val_regression_loss: 0.0853 - val_handedness_loss: 0.6932\n",
      "Evaluating model with testing data...\n",
      "4854/4854 [==============================] - 0s 17us/step\n",
      "Getting distribution of predictions and covariance matrix...\n",
      "      1 of 20\n",
      "      2 of 20\n",
      "      3 of 20\n",
      "      4 of 20\n",
      "      5 of 20\n",
      "      6 of 20\n",
      "      7 of 20\n",
      "      8 of 20\n",
      "      9 of 20\n",
      "      10 of 20\n",
      "      11 of 20\n",
      "      12 of 20\n",
      "      13 of 20\n",
      "      14 of 20\n",
      "      15 of 20\n",
      "      16 of 20\n",
      "      17 of 20\n",
      "      18 of 20\n",
      "      19 of 20\n",
      "      20 of 20\n",
      "Computing ensemble means...\n",
      "Computing mean squared error...\n",
      "Iteration 160\n",
      "Train on 22892 samples, validate on 4884 samples\n",
      "Epoch 1/150\n",
      "22892/22892 [==============================] - 3s 143us/step - loss: 0.8921 - regression_loss: 0.2416 - handedness_loss: 0.6504 - val_loss: 0.7980 - val_regression_loss: 0.1029 - val_handedness_loss: 0.6958\n",
      "Epoch 2/150\n",
      "22892/22892 [==============================] - 3s 147us/step - loss: 0.7939 - regression_loss: 0.0986 - handedness_loss: 0.6953 - val_loss: 0.7897 - val_regression_loss: 0.0957 - val_handedness_loss: 0.6939\n",
      "Epoch 3/150\n",
      "22892/22892 [==============================] - 3s 144us/step - loss: 0.7885 - regression_loss: 0.0938 - handedness_loss: 0.6948 - val_loss: 0.7868 - val_regression_loss: 0.0936 - val_handedness_loss: 0.6929\n",
      "Epoch 4/150\n",
      "22892/22892 [==============================] - 3s 130us/step - loss: 0.7858 - regression_loss: 0.0916 - handedness_loss: 0.6941 - val_loss: 0.7855 - val_regression_loss: 0.0921 - val_handedness_loss: 0.6935\n",
      "Epoch 5/150\n",
      "22892/22892 [==============================] - 3s 143us/step - loss: 0.7843 - regression_loss: 0.0906 - handedness_loss: 0.6937 - val_loss: 0.7846 - val_regression_loss: 0.0905 - val_handedness_loss: 0.6940\n",
      "Epoch 6/150\n",
      "22892/22892 [==============================] - 3s 140us/step - loss: 0.7830 - regression_loss: 0.0892 - handedness_loss: 0.6938 - val_loss: 0.7827 - val_regression_loss: 0.0891 - val_handedness_loss: 0.6934\n",
      "Epoch 7/150\n",
      "22892/22892 [==============================] - 3s 137us/step - loss: 0.7810 - regression_loss: 0.0877 - handedness_loss: 0.6933 - val_loss: 0.7805 - val_regression_loss: 0.0870 - val_handedness_loss: 0.6933\n",
      "Evaluating model with testing data...\n",
      "4884/4884 [==============================] - 0s 17us/step\n",
      "Getting distribution of predictions and covariance matrix...\n",
      "      1 of 20\n",
      "      2 of 20\n",
      "      3 of 20\n",
      "      4 of 20\n",
      "      5 of 20\n",
      "      6 of 20\n",
      "      7 of 20\n",
      "      8 of 20\n",
      "      9 of 20\n",
      "      10 of 20\n",
      "      11 of 20\n",
      "      12 of 20\n",
      "      13 of 20\n",
      "      14 of 20\n",
      "      15 of 20\n",
      "      16 of 20\n",
      "      17 of 20\n",
      "      18 of 20\n",
      "      19 of 20\n",
      "      20 of 20\n",
      "Computing ensemble means...\n",
      "Computing mean squared error...\n",
      "Iteration 161\n",
      "Train on 23032 samples, validate on 4914 samples\n",
      "Epoch 1/150\n",
      "23032/23032 [==============================] - 3s 127us/step - loss: 0.9738 - regression_loss: 0.2899 - handedness_loss: 0.6839 - val_loss: 0.8599 - val_regression_loss: 0.1665 - val_handedness_loss: 0.6939\n",
      "Epoch 2/150\n",
      "23032/23032 [==============================] - 3s 120us/step - loss: 0.8244 - regression_loss: 0.1309 - handedness_loss: 0.6935 - val_loss: 0.8121 - val_regression_loss: 0.1191 - val_handedness_loss: 0.6933\n",
      "Epoch 3/150\n",
      "23032/23032 [==============================] - 3s 132us/step - loss: 0.8036 - regression_loss: 0.1103 - handedness_loss: 0.6932 - val_loss: 0.7981 - val_regression_loss: 0.1051 - val_handedness_loss: 0.6932\n",
      "Epoch 4/150\n",
      "23032/23032 [==============================] - 3s 144us/step - loss: 0.7924 - regression_loss: 0.0993 - handedness_loss: 0.6931 - val_loss: 0.7889 - val_regression_loss: 0.0958 - val_handedness_loss: 0.6933\n",
      "Epoch 5/150\n",
      "23032/23032 [==============================] - 3s 128us/step - loss: 0.7855 - regression_loss: 0.0923 - handedness_loss: 0.6932 - val_loss: 0.7837 - val_regression_loss: 0.0906 - val_handedness_loss: 0.6932\n",
      "Epoch 6/150\n",
      "23032/23032 [==============================] - 2s 108us/step - loss: 0.7810 - regression_loss: 0.0878 - handedness_loss: 0.6932 - val_loss: 0.7801 - val_regression_loss: 0.0870 - val_handedness_loss: 0.6932\n",
      "Epoch 7/150\n",
      "23032/23032 [==============================] - 3s 139us/step - loss: 0.7786 - regression_loss: 0.0854 - handedness_loss: 0.6931 - val_loss: 0.7786 - val_regression_loss: 0.0854 - val_handedness_loss: 0.6932\n",
      "Epoch 8/150\n",
      "23032/23032 [==============================] - 3s 146us/step - loss: 0.7776 - regression_loss: 0.0845 - handedness_loss: 0.6932 - val_loss: 0.7779 - val_regression_loss: 0.0847 - val_handedness_loss: 0.6932\n",
      "Epoch 9/150\n",
      "23032/23032 [==============================] - 3s 142us/step - loss: 0.7771 - regression_loss: 0.0839 - handedness_loss: 0.6931 - val_loss: 0.7776 - val_regression_loss: 0.0845 - val_handedness_loss: 0.6932\n",
      "Epoch 10/150\n",
      "23032/23032 [==============================] - 3s 143us/step - loss: 0.7769 - regression_loss: 0.0837 - handedness_loss: 0.6931 - val_loss: 0.7775 - val_regression_loss: 0.0843 - val_handedness_loss: 0.6932\n",
      "Evaluating model with testing data...\n",
      "4914/4914 [==============================] - 0s 16us/step\n",
      "Getting distribution of predictions and covariance matrix...\n",
      "      1 of 20\n",
      "      2 of 20\n",
      "      3 of 20\n",
      "      4 of 20\n",
      "      5 of 20\n",
      "      6 of 20\n",
      "      7 of 20\n",
      "      8 of 20\n",
      "      9 of 20\n",
      "      10 of 20\n",
      "      11 of 20\n",
      "      12 of 20\n",
      "      13 of 20\n",
      "      14 of 20\n",
      "      15 of 20\n",
      "      16 of 20\n",
      "      17 of 20\n",
      "      18 of 20\n",
      "      19 of 20\n",
      "      20 of 20\n",
      "Computing ensemble means...\n",
      "Computing mean squared error...\n",
      "Iteration 162\n",
      "Train on 23172 samples, validate on 4944 samples\n",
      "Epoch 1/150\n",
      "23172/23172 [==============================] - 3s 140us/step - loss: 1.0393 - regression_loss: 0.3508 - handedness_loss: 0.6881 - val_loss: 0.9066 - val_regression_loss: 0.2132 - val_handedness_loss: 0.6933\n",
      "Epoch 2/150\n",
      "23172/23172 [==============================] - 3s 145us/step - loss: 0.8503 - regression_loss: 0.1561 - handedness_loss: 0.6937 - val_loss: 0.8140 - val_regression_loss: 0.1199 - val_handedness_loss: 0.6941\n",
      "Epoch 3/150\n",
      "23172/23172 [==============================] - 3s 144us/step - loss: 0.8013 - regression_loss: 0.1078 - handedness_loss: 0.6937 - val_loss: 0.7949 - val_regression_loss: 0.1011 - val_handedness_loss: 0.6936\n",
      "Epoch 4/150\n",
      "23172/23172 [==============================] - 3s 148us/step - loss: 0.7917 - regression_loss: 0.0982 - handedness_loss: 0.6934 - val_loss: 0.7898 - val_regression_loss: 0.0958 - val_handedness_loss: 0.6940\n",
      "Epoch 5/150\n",
      "23172/23172 [==============================] - 3s 148us/step - loss: 0.7859 - regression_loss: 0.0925 - handedness_loss: 0.6932 - val_loss: 0.7849 - val_regression_loss: 0.0912 - val_handedness_loss: 0.6935\n",
      "Evaluating model with testing data...\n",
      "4944/4944 [==============================] - 0s 17us/step\n",
      "Getting distribution of predictions and covariance matrix...\n",
      "      1 of 20\n",
      "      2 of 20\n",
      "      3 of 20\n",
      "      4 of 20\n",
      "      5 of 20\n",
      "      6 of 20\n",
      "      7 of 20\n",
      "      8 of 20\n",
      "      9 of 20\n",
      "      10 of 20\n",
      "      11 of 20\n",
      "      12 of 20\n",
      "      13 of 20\n",
      "      14 of 20\n",
      "      15 of 20\n",
      "      16 of 20\n",
      "      17 of 20\n",
      "      18 of 20\n",
      "      19 of 20\n",
      "      20 of 20\n",
      "Computing ensemble means...\n",
      "Computing mean squared error...\n",
      "Iteration 163\n",
      "Train on 23312 samples, validate on 4974 samples\n",
      "Epoch 1/150\n",
      "23312/23312 [==============================] - 3s 137us/step - loss: 0.9730 - regression_loss: 0.2862 - handedness_loss: 0.6861 - val_loss: 0.8667 - val_regression_loss: 0.1733 - val_handedness_loss: 0.6934\n",
      "Epoch 2/150\n",
      "23312/23312 [==============================] - 3s 147us/step - loss: 0.8178 - regression_loss: 0.1235 - handedness_loss: 0.6943 - val_loss: 0.7974 - val_regression_loss: 0.1032 - val_handedness_loss: 0.6942\n",
      "Epoch 3/150\n",
      "23312/23312 [==============================] - 3s 147us/step - loss: 0.7919 - regression_loss: 0.0979 - handedness_loss: 0.6940 - val_loss: 0.7896 - val_regression_loss: 0.0957 - val_handedness_loss: 0.6939\n",
      "Epoch 4/150\n",
      "23312/23312 [==============================] - 3s 139us/step - loss: 0.7873 - regression_loss: 0.0935 - handedness_loss: 0.6938 - val_loss: 0.7870 - val_regression_loss: 0.0930 - val_handedness_loss: 0.6940\n",
      "Epoch 5/150\n",
      "23312/23312 [==============================] - 3s 146us/step - loss: 0.7844 - regression_loss: 0.0911 - handedness_loss: 0.6932 - val_loss: 0.7841 - val_regression_loss: 0.0905 - val_handedness_loss: 0.6936\n",
      "Evaluating model with testing data...\n",
      "4974/4974 [==============================] - 0s 17us/step\n",
      "Getting distribution of predictions and covariance matrix...\n",
      "      1 of 20\n",
      "      2 of 20\n",
      "      3 of 20\n",
      "      4 of 20\n",
      "      5 of 20\n",
      "      6 of 20\n",
      "      7 of 20\n",
      "      8 of 20\n",
      "      9 of 20\n",
      "      10 of 20\n",
      "      11 of 20\n",
      "      12 of 20\n",
      "      13 of 20\n",
      "      14 of 20\n",
      "      15 of 20\n",
      "      16 of 20\n",
      "      17 of 20\n",
      "      18 of 20\n",
      "      19 of 20\n",
      "      20 of 20\n",
      "Computing ensemble means...\n",
      "Computing mean squared error...\n",
      "Iteration 164\n",
      "Train on 23452 samples, validate on 5004 samples\n",
      "Epoch 1/150\n",
      "23452/23452 [==============================] - 3s 135us/step - loss: 0.7935 - regression_loss: 0.1951 - handedness_loss: 0.5983 - val_loss: 0.8213 - val_regression_loss: 0.1230 - val_handedness_loss: 0.6990\n",
      "Epoch 2/150\n",
      "23452/23452 [==============================] - 3s 143us/step - loss: 0.8091 - regression_loss: 0.1117 - handedness_loss: 0.6974 - val_loss: 0.8002 - val_regression_loss: 0.1040 - val_handedness_loss: 0.6963\n",
      "Epoch 3/150\n",
      "23452/23452 [==============================] - 3s 137us/step - loss: 0.7950 - regression_loss: 0.1000 - handedness_loss: 0.6949 - val_loss: 0.7906 - val_regression_loss: 0.0963 - val_handedness_loss: 0.6942\n",
      "Epoch 4/150\n",
      "23452/23452 [==============================] - 3s 145us/step - loss: 0.7874 - regression_loss: 0.0932 - handedness_loss: 0.6943 - val_loss: 0.7856 - val_regression_loss: 0.0907 - val_handedness_loss: 0.6947\n",
      "Epoch 5/150\n",
      "23452/23452 [==============================] - 3s 143us/step - loss: 0.7830 - regression_loss: 0.0892 - handedness_loss: 0.6937 - val_loss: 0.7823 - val_regression_loss: 0.0880 - val_handedness_loss: 0.6938\n",
      "Epoch 6/150\n",
      "23452/23452 [==============================] - 3s 145us/step - loss: 0.7800 - regression_loss: 0.0867 - handedness_loss: 0.6932 - val_loss: 0.7788 - val_regression_loss: 0.0858 - val_handedness_loss: 0.6925\n",
      "Epoch 7/150\n",
      "23452/23452 [==============================] - 3s 138us/step - loss: 0.7784 - regression_loss: 0.0854 - handedness_loss: 0.6931 - val_loss: 0.7782 - val_regression_loss: 0.0847 - val_handedness_loss: 0.6933\n",
      "Epoch 8/150\n",
      "23452/23452 [==============================] - 3s 147us/step - loss: 0.7775 - regression_loss: 0.0843 - handedness_loss: 0.6933 - val_loss: 0.7773 - val_regression_loss: 0.0840 - val_handedness_loss: 0.6929\n",
      "Epoch 9/150\n",
      "23452/23452 [==============================] - 3s 136us/step - loss: 0.7771 - regression_loss: 0.0840 - handedness_loss: 0.6931 - val_loss: 0.7776 - val_regression_loss: 0.0840 - val_handedness_loss: 0.6931\n",
      "Epoch 10/150\n",
      "23452/23452 [==============================] - 3s 139us/step - loss: 0.7769 - regression_loss: 0.0837 - handedness_loss: 0.6932 - val_loss: 0.7772 - val_regression_loss: 0.0836 - val_handedness_loss: 0.6932\n",
      "Evaluating model with testing data...\n",
      "5004/5004 [==============================] - 0s 16us/step\n",
      "Getting distribution of predictions and covariance matrix...\n",
      "      1 of 20\n",
      "      2 of 20\n",
      "      3 of 20\n",
      "      4 of 20\n",
      "      5 of 20\n",
      "      6 of 20\n",
      "      7 of 20\n",
      "      8 of 20\n",
      "      9 of 20\n",
      "      10 of 20\n",
      "      11 of 20\n",
      "      12 of 20\n",
      "      13 of 20\n",
      "      14 of 20\n",
      "      15 of 20\n",
      "      16 of 20\n",
      "      17 of 20\n",
      "      18 of 20\n",
      "      19 of 20\n",
      "      20 of 20\n",
      "Computing ensemble means...\n",
      "Computing mean squared error...\n",
      "Iteration 165\n",
      "Train on 23592 samples, validate on 5034 samples\n",
      "Epoch 1/150\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23592/23592 [==============================] - 3s 144us/step - loss: 0.9043 - regression_loss: 0.2221 - handedness_loss: 0.6820 - val_loss: 0.8228 - val_regression_loss: 0.1254 - val_handedness_loss: 0.6973\n",
      "Epoch 2/150\n",
      "23592/23592 [==============================] - 3s 146us/step - loss: 0.8075 - regression_loss: 0.1137 - handedness_loss: 0.6937 - val_loss: 0.8027 - val_regression_loss: 0.1086 - val_handedness_loss: 0.6944\n",
      "Epoch 3/150\n",
      "23592/23592 [==============================] - 3s 147us/step - loss: 0.7975 - regression_loss: 0.1034 - handedness_loss: 0.6940 - val_loss: 0.7928 - val_regression_loss: 0.0995 - val_handedness_loss: 0.6935\n",
      "Epoch 4/150\n",
      "23592/23592 [==============================] - 3s 142us/step - loss: 0.7898 - regression_loss: 0.0962 - handedness_loss: 0.6936 - val_loss: 0.7875 - val_regression_loss: 0.0944 - val_handedness_loss: 0.6931\n",
      "Epoch 5/150\n",
      "23592/23592 [==============================] - 3s 141us/step - loss: 0.7848 - regression_loss: 0.0914 - handedness_loss: 0.6934 - val_loss: 0.7837 - val_regression_loss: 0.0903 - val_handedness_loss: 0.6934\n",
      "Epoch 6/150\n",
      "23592/23592 [==============================] - 3s 145us/step - loss: 0.7814 - regression_loss: 0.0881 - handedness_loss: 0.6933 - val_loss: 0.7802 - val_regression_loss: 0.0870 - val_handedness_loss: 0.6933\n",
      "Epoch 7/150\n",
      "23592/23592 [==============================] - 3s 147us/step - loss: 0.7791 - regression_loss: 0.0858 - handedness_loss: 0.6933 - val_loss: 0.7790 - val_regression_loss: 0.0858 - val_handedness_loss: 0.6932\n",
      "Epoch 8/150\n",
      "23592/23592 [==============================] - 2s 101us/step - loss: 0.7779 - regression_loss: 0.0847 - handedness_loss: 0.6932 - val_loss: 0.7784 - val_regression_loss: 0.0850 - val_handedness_loss: 0.6933\n",
      "Evaluating model with testing data...\n",
      "5034/5034 [==============================] - 0s 16us/step\n",
      "Getting distribution of predictions and covariance matrix...\n",
      "      1 of 20\n",
      "      2 of 20\n",
      "      3 of 20\n",
      "      4 of 20\n",
      "      5 of 20\n",
      "      6 of 20\n",
      "      7 of 20\n",
      "      8 of 20\n",
      "      9 of 20\n",
      "      10 of 20\n",
      "      11 of 20\n",
      "      12 of 20\n",
      "      13 of 20\n",
      "      14 of 20\n",
      "      15 of 20\n",
      "      16 of 20\n",
      "      17 of 20\n",
      "      18 of 20\n",
      "      19 of 20\n",
      "      20 of 20\n",
      "Computing ensemble means...\n",
      "Computing mean squared error...\n",
      "Iteration 166\n",
      "Train on 23732 samples, validate on 5064 samples\n",
      "Epoch 1/150\n",
      "23732/23732 [==============================] - 3s 143us/step - loss: 0.8120 - regression_loss: 0.2406 - handedness_loss: 0.5715 - val_loss: 0.8340 - val_regression_loss: 0.1343 - val_handedness_loss: 0.6993\n",
      "Epoch 2/150\n",
      "23732/23732 [==============================] - 4s 148us/step - loss: 0.8038 - regression_loss: 0.1077 - handedness_loss: 0.6960 - val_loss: 0.7949 - val_regression_loss: 0.1007 - val_handedness_loss: 0.6941\n",
      "Epoch 3/150\n",
      "23732/23732 [==============================] - 4s 148us/step - loss: 0.7923 - regression_loss: 0.0979 - handedness_loss: 0.6944 - val_loss: 0.7887 - val_regression_loss: 0.0945 - val_handedness_loss: 0.6941\n",
      "Epoch 4/150\n",
      "23732/23732 [==============================] - 4s 147us/step - loss: 0.7877 - regression_loss: 0.0935 - handedness_loss: 0.6941 - val_loss: 0.7855 - val_regression_loss: 0.0914 - val_handedness_loss: 0.6940\n",
      "Epoch 5/150\n",
      "23732/23732 [==============================] - 3s 142us/step - loss: 0.7836 - regression_loss: 0.0901 - handedness_loss: 0.6935 - val_loss: 0.7830 - val_regression_loss: 0.0894 - val_handedness_loss: 0.6935\n",
      "Epoch 6/150\n",
      "23732/23732 [==============================] - 3s 147us/step - loss: 0.7812 - regression_loss: 0.0880 - handedness_loss: 0.6932 - val_loss: 0.7802 - val_regression_loss: 0.0870 - val_handedness_loss: 0.6932\n",
      "Epoch 7/150\n",
      "23732/23732 [==============================] - 3s 141us/step - loss: 0.7802 - regression_loss: 0.0865 - handedness_loss: 0.6936 - val_loss: 0.7799 - val_regression_loss: 0.0860 - val_handedness_loss: 0.6939\n",
      "Epoch 8/150\n",
      "23732/23732 [==============================] - 3s 147us/step - loss: 0.7786 - regression_loss: 0.0854 - handedness_loss: 0.6932 - val_loss: 0.7787 - val_regression_loss: 0.0852 - val_handedness_loss: 0.6934\n",
      "Epoch 9/150\n",
      "23732/23732 [==============================] - 4s 148us/step - loss: 0.7780 - regression_loss: 0.0848 - handedness_loss: 0.6932 - val_loss: 0.7782 - val_regression_loss: 0.0849 - val_handedness_loss: 0.6931\n",
      "Epoch 10/150\n",
      "23732/23732 [==============================] - 4s 148us/step - loss: 0.7775 - regression_loss: 0.0844 - handedness_loss: 0.6931 - val_loss: 0.7776 - val_regression_loss: 0.0842 - val_handedness_loss: 0.6933\n",
      "Epoch 11/150\n",
      "23732/23732 [==============================] - 4s 148us/step - loss: 0.7773 - regression_loss: 0.0840 - handedness_loss: 0.6932 - val_loss: 0.7772 - val_regression_loss: 0.0841 - val_handedness_loss: 0.6931\n",
      "Epoch 12/150\n",
      "23732/23732 [==============================] - 3s 146us/step - loss: 0.7771 - regression_loss: 0.0839 - handedness_loss: 0.6932 - val_loss: 0.7774 - val_regression_loss: 0.0839 - val_handedness_loss: 0.6934\n",
      "Epoch 13/150\n",
      "23732/23732 [==============================] - 4s 148us/step - loss: 0.7769 - regression_loss: 0.0837 - handedness_loss: 0.6932 - val_loss: 0.7773 - val_regression_loss: 0.0839 - val_handedness_loss: 0.6933\n",
      "Epoch 14/150\n",
      "23732/23732 [==============================] - 3s 141us/step - loss: 0.7767 - regression_loss: 0.0836 - handedness_loss: 0.6932 - val_loss: 0.7769 - val_regression_loss: 0.0837 - val_handedness_loss: 0.6931\n",
      "Epoch 15/150\n",
      "23732/23732 [==============================] - 4s 148us/step - loss: 0.7767 - regression_loss: 0.0836 - handedness_loss: 0.6932 - val_loss: 0.7770 - val_regression_loss: 0.0837 - val_handedness_loss: 0.6932\n",
      "Evaluating model with testing data...\n",
      "5064/5064 [==============================] - 0s 16us/step\n",
      "Getting distribution of predictions and covariance matrix...\n",
      "      1 of 20\n",
      "      2 of 20\n",
      "      3 of 20\n",
      "      4 of 20\n",
      "      5 of 20\n",
      "      6 of 20\n",
      "      7 of 20\n",
      "      8 of 20\n",
      "      9 of 20\n",
      "      10 of 20\n",
      "      11 of 20\n",
      "      12 of 20\n",
      "      13 of 20\n",
      "      14 of 20\n",
      "      15 of 20\n",
      "      16 of 20\n",
      "      17 of 20\n",
      "      18 of 20\n",
      "      19 of 20\n",
      "      20 of 20\n",
      "Computing ensemble means...\n",
      "Computing mean squared error...\n",
      "Iteration 167\n",
      "Train on 23872 samples, validate on 5094 samples\n",
      "Epoch 1/150\n",
      "23872/23872 [==============================] - 3s 126us/step - loss: 0.9365 - regression_loss: 0.2760 - handedness_loss: 0.6605 - val_loss: 0.9193 - val_regression_loss: 0.2260 - val_handedness_loss: 0.6934\n",
      "Epoch 2/150\n",
      "23872/23872 [==============================] - 3s 137us/step - loss: 0.8233 - regression_loss: 0.1277 - handedness_loss: 0.6955 - val_loss: 0.8017 - val_regression_loss: 0.1072 - val_handedness_loss: 0.6945\n",
      "Epoch 3/150\n",
      "23872/23872 [==============================] - 3s 140us/step - loss: 0.7972 - regression_loss: 0.1029 - handedness_loss: 0.6942 - val_loss: 0.7940 - val_regression_loss: 0.0995 - val_handedness_loss: 0.6945\n",
      "Epoch 4/150\n",
      "23872/23872 [==============================] - 3s 142us/step - loss: 0.7896 - regression_loss: 0.0960 - handedness_loss: 0.6937 - val_loss: 0.7881 - val_regression_loss: 0.0940 - val_handedness_loss: 0.6940\n",
      "Epoch 5/150\n",
      "23872/23872 [==============================] - 3s 141us/step - loss: 0.7846 - regression_loss: 0.0910 - handedness_loss: 0.6935 - val_loss: 0.7831 - val_regression_loss: 0.0895 - val_handedness_loss: 0.6936\n",
      "Evaluating model with testing data...\n",
      "5094/5094 [==============================] - 0s 16us/step\n",
      "Getting distribution of predictions and covariance matrix...\n",
      "      1 of 20\n",
      "      2 of 20\n",
      "      3 of 20\n",
      "      4 of 20\n",
      "      5 of 20\n",
      "      6 of 20\n",
      "      7 of 20\n",
      "      8 of 20\n",
      "      9 of 20\n",
      "      10 of 20\n",
      "      11 of 20\n",
      "      12 of 20\n",
      "      13 of 20\n",
      "      14 of 20\n",
      "      15 of 20\n",
      "      16 of 20\n",
      "      17 of 20\n",
      "      18 of 20\n",
      "      19 of 20\n",
      "      20 of 20\n",
      "Computing ensemble means...\n",
      "Computing mean squared error...\n",
      "Iteration 168\n",
      "Train on 24012 samples, validate on 5124 samples\n",
      "Epoch 1/150\n",
      "24012/24012 [==============================] - 3s 125us/step - loss: 0.9100 - regression_loss: 0.2643 - handedness_loss: 0.6454 - val_loss: 0.7881 - val_regression_loss: 0.0952 - val_handedness_loss: 0.6948\n",
      "Epoch 2/150\n",
      "24012/24012 [==============================] - 3s 132us/step - loss: 0.7873 - regression_loss: 0.0927 - handedness_loss: 0.6946 - val_loss: 0.7880 - val_regression_loss: 0.0946 - val_handedness_loss: 0.6931\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3/150\n",
      "24012/24012 [==============================] - 3s 145us/step - loss: 0.7854 - regression_loss: 0.0912 - handedness_loss: 0.6942 - val_loss: 0.7852 - val_regression_loss: 0.0919 - val_handedness_loss: 0.6940\n",
      "Epoch 4/150\n",
      "24012/24012 [==============================] - 3s 143us/step - loss: 0.7836 - regression_loss: 0.0898 - handedness_loss: 0.6938 - val_loss: 0.7837 - val_regression_loss: 0.0890 - val_handedness_loss: 0.6939\n",
      "Epoch 5/150\n",
      "24012/24012 [==============================] - 4s 146us/step - loss: 0.7828 - regression_loss: 0.0889 - handedness_loss: 0.6939 - val_loss: 0.7828 - val_regression_loss: 0.0889 - val_handedness_loss: 0.6937\n",
      "Epoch 6/150\n",
      "24012/24012 [==============================] - 4s 147us/step - loss: 0.7815 - regression_loss: 0.0882 - handedness_loss: 0.6934 - val_loss: 0.7819 - val_regression_loss: 0.0881 - val_handedness_loss: 0.6941\n",
      "Evaluating model with testing data...\n",
      "5124/5124 [==============================] - 0s 17us/step\n",
      "Getting distribution of predictions and covariance matrix...\n",
      "      1 of 20\n",
      "      2 of 20\n",
      "      3 of 20\n",
      "      4 of 20\n",
      "      5 of 20\n",
      "      6 of 20\n",
      "      7 of 20\n",
      "      8 of 20\n",
      "      9 of 20\n",
      "      10 of 20\n",
      "      11 of 20\n",
      "      12 of 20\n",
      "      13 of 20\n",
      "      14 of 20\n",
      "      15 of 20\n",
      "      16 of 20\n",
      "      17 of 20\n",
      "      18 of 20\n",
      "      19 of 20\n",
      "      20 of 20\n",
      "Computing ensemble means...\n",
      "Computing mean squared error...\n",
      "Iteration 169\n",
      "Train on 24152 samples, validate on 5154 samples\n",
      "Epoch 1/150\n",
      "24152/24152 [==============================] - 3s 137us/step - loss: 0.7608 - regression_loss: 0.2057 - handedness_loss: 0.5552 - val_loss: 0.8017 - val_regression_loss: 0.1062 - val_handedness_loss: 0.6955\n",
      "Epoch 2/150\n",
      "24152/24152 [==============================] - 4s 146us/step - loss: 0.7927 - regression_loss: 0.0972 - handedness_loss: 0.6956 - val_loss: 0.7898 - val_regression_loss: 0.0951 - val_handedness_loss: 0.6946\n",
      "Epoch 3/150\n",
      "24152/24152 [==============================] - 4s 146us/step - loss: 0.7874 - regression_loss: 0.0929 - handedness_loss: 0.6944 - val_loss: 0.7865 - val_regression_loss: 0.0926 - val_handedness_loss: 0.6939\n",
      "Epoch 4/150\n",
      "24152/24152 [==============================] - 4s 148us/step - loss: 0.7847 - regression_loss: 0.0907 - handedness_loss: 0.6940 - val_loss: 0.7842 - val_regression_loss: 0.0908 - val_handedness_loss: 0.6934\n",
      "Epoch 5/150\n",
      "24152/24152 [==============================] - 4s 148us/step - loss: 0.7826 - regression_loss: 0.0890 - handedness_loss: 0.6937 - val_loss: 0.7843 - val_regression_loss: 0.0902 - val_handedness_loss: 0.6943\n",
      "Epoch 6/150\n",
      "24152/24152 [==============================] - 2s 94us/step - loss: 0.7813 - regression_loss: 0.0878 - handedness_loss: 0.6935 - val_loss: 0.7819 - val_regression_loss: 0.0886 - val_handedness_loss: 0.6934\n",
      "Epoch 7/150\n",
      "24152/24152 [==============================] - 4s 146us/step - loss: 0.7801 - regression_loss: 0.0870 - handedness_loss: 0.6932 - val_loss: 0.7811 - val_regression_loss: 0.0873 - val_handedness_loss: 0.6939\n",
      "Epoch 8/150\n",
      "24152/24152 [==============================] - 4s 148us/step - loss: 0.7796 - regression_loss: 0.0862 - handedness_loss: 0.6934 - val_loss: 0.7797 - val_regression_loss: 0.0867 - val_handedness_loss: 0.6931\n",
      "Epoch 9/150\n",
      "24152/24152 [==============================] - 3s 141us/step - loss: 0.7786 - regression_loss: 0.0852 - handedness_loss: 0.6934 - val_loss: 0.7795 - val_regression_loss: 0.0866 - val_handedness_loss: 0.6931\n",
      "Epoch 10/150\n",
      "24152/24152 [==============================] - 4s 148us/step - loss: 0.7785 - regression_loss: 0.0851 - handedness_loss: 0.6934 - val_loss: 0.7789 - val_regression_loss: 0.0859 - val_handedness_loss: 0.6932\n",
      "Epoch 11/150\n",
      "24152/24152 [==============================] - 4s 148us/step - loss: 0.7777 - regression_loss: 0.0845 - handedness_loss: 0.6933 - val_loss: 0.7784 - val_regression_loss: 0.0856 - val_handedness_loss: 0.6930\n",
      "Epoch 12/150\n",
      "24152/24152 [==============================] - 4s 146us/step - loss: 0.7775 - regression_loss: 0.0843 - handedness_loss: 0.6933 - val_loss: 0.7783 - val_regression_loss: 0.0853 - val_handedness_loss: 0.6932\n",
      "Epoch 13/150\n",
      "24152/24152 [==============================] - 4s 146us/step - loss: 0.7772 - regression_loss: 0.0841 - handedness_loss: 0.6931 - val_loss: 0.7780 - val_regression_loss: 0.0850 - val_handedness_loss: 0.6933\n",
      "Epoch 14/150\n",
      "24152/24152 [==============================] - 3s 139us/step - loss: 0.7771 - regression_loss: 0.0839 - handedness_loss: 0.6932 - val_loss: 0.7784 - val_regression_loss: 0.0853 - val_handedness_loss: 0.6932\n",
      "Epoch 15/150\n",
      "24152/24152 [==============================] - 4s 148us/step - loss: 0.7769 - regression_loss: 0.0838 - handedness_loss: 0.6931 - val_loss: 0.7782 - val_regression_loss: 0.0850 - val_handedness_loss: 0.6934\n",
      "Evaluating model with testing data...\n",
      "5154/5154 [==============================] - 0s 16us/step\n",
      "Getting distribution of predictions and covariance matrix...\n",
      "      1 of 20\n",
      "      2 of 20\n",
      "      3 of 20\n",
      "      4 of 20\n",
      "      5 of 20\n",
      "      6 of 20\n",
      "      7 of 20\n",
      "      8 of 20\n",
      "      9 of 20\n",
      "      10 of 20\n",
      "      11 of 20\n",
      "      12 of 20\n",
      "      13 of 20\n",
      "      14 of 20\n",
      "      15 of 20\n",
      "      16 of 20\n",
      "      17 of 20\n",
      "      18 of 20\n",
      "      19 of 20\n",
      "      20 of 20\n",
      "Computing ensemble means...\n",
      "Computing mean squared error...\n",
      "Iteration 170\n",
      "Train on 24292 samples, validate on 5184 samples\n",
      "Epoch 1/150\n",
      "24292/24292 [==============================] - 3s 135us/step - loss: 1.0078 - regression_loss: 0.3210 - handedness_loss: 0.6866 - val_loss: 0.8606 - val_regression_loss: 0.1650 - val_handedness_loss: 0.6958\n",
      "Epoch 2/150\n",
      "24292/24292 [==============================] - 3s 142us/step - loss: 0.8136 - regression_loss: 0.1190 - handedness_loss: 0.6946 - val_loss: 0.7982 - val_regression_loss: 0.1050 - val_handedness_loss: 0.6932\n",
      "Epoch 3/150\n",
      "24292/24292 [==============================] - 4s 148us/step - loss: 0.7947 - regression_loss: 0.1008 - handedness_loss: 0.6938 - val_loss: 0.7920 - val_regression_loss: 0.0982 - val_handedness_loss: 0.6938\n",
      "Epoch 4/150\n",
      "24292/24292 [==============================] - 3s 135us/step - loss: 0.7885 - regression_loss: 0.0951 - handedness_loss: 0.6934 - val_loss: 0.7870 - val_regression_loss: 0.0937 - val_handedness_loss: 0.6934\n",
      "Epoch 5/150\n",
      "24292/24292 [==============================] - 3s 136us/step - loss: 0.7855 - regression_loss: 0.0920 - handedness_loss: 0.6935 - val_loss: 0.7848 - val_regression_loss: 0.0912 - val_handedness_loss: 0.6936\n",
      "Epoch 6/150\n",
      "24292/24292 [==============================] - 4s 146us/step - loss: 0.7826 - regression_loss: 0.0894 - handedness_loss: 0.6933 - val_loss: 0.7825 - val_regression_loss: 0.0892 - val_handedness_loss: 0.6933\n",
      "Evaluating model with testing data...\n",
      "5184/5184 [==============================] - 0s 17us/step\n",
      "Getting distribution of predictions and covariance matrix...\n",
      "      1 of 20\n",
      "      2 of 20\n",
      "      3 of 20\n",
      "      4 of 20\n",
      "      5 of 20\n",
      "      6 of 20\n",
      "      7 of 20\n",
      "      8 of 20\n",
      "      9 of 20\n",
      "      10 of 20\n",
      "      11 of 20\n",
      "      12 of 20\n",
      "      13 of 20\n",
      "      14 of 20\n",
      "      15 of 20\n",
      "      16 of 20\n",
      "      17 of 20\n",
      "      18 of 20\n",
      "      19 of 20\n",
      "      20 of 20\n",
      "Computing ensemble means...\n",
      "Computing mean squared error...\n",
      "Iteration 171\n",
      "Train on 24432 samples, validate on 5214 samples\n",
      "Epoch 1/150\n",
      "24432/24432 [==============================] - 3s 126us/step - loss: 0.9158 - regression_loss: 0.2202 - handedness_loss: 0.6955 - val_loss: 0.7912 - val_regression_loss: 0.0974 - val_handedness_loss: 0.6937\n",
      "Epoch 2/150\n",
      "24432/24432 [==============================] - 3s 130us/step - loss: 0.7890 - regression_loss: 0.0942 - handedness_loss: 0.6948 - val_loss: 0.7880 - val_regression_loss: 0.0933 - val_handedness_loss: 0.6947\n",
      "Epoch 3/150\n",
      "24432/24432 [==============================] - 3s 129us/step - loss: 0.7861 - regression_loss: 0.0922 - handedness_loss: 0.6939 - val_loss: 0.7861 - val_regression_loss: 0.0921 - val_handedness_loss: 0.6940\n",
      "Epoch 4/150\n",
      "24432/24432 [==============================] - 3s 136us/step - loss: 0.7839 - regression_loss: 0.0907 - handedness_loss: 0.6933 - val_loss: 0.7858 - val_regression_loss: 0.0914 - val_handedness_loss: 0.6944\n",
      "Epoch 5/150\n",
      "24432/24432 [==============================] - 3s 141us/step - loss: 0.7833 - regression_loss: 0.0897 - handedness_loss: 0.6936 - val_loss: 0.7839 - val_regression_loss: 0.0904 - val_handedness_loss: 0.6935\n",
      "Epoch 6/150\n",
      "24432/24432 [==============================] - 3s 142us/step - loss: 0.7818 - regression_loss: 0.0886 - handedness_loss: 0.6933 - val_loss: 0.7822 - val_regression_loss: 0.0887 - val_handedness_loss: 0.6936\n",
      "Epoch 7/150\n",
      "24432/24432 [==============================] - 3s 140us/step - loss: 0.7811 - regression_loss: 0.0875 - handedness_loss: 0.6936 - val_loss: 0.7812 - val_regression_loss: 0.0880 - val_handedness_loss: 0.6932\n",
      "Epoch 8/150\n",
      "24432/24432 [==============================] - 4s 145us/step - loss: 0.7800 - regression_loss: 0.0867 - handedness_loss: 0.6933 - val_loss: 0.7812 - val_regression_loss: 0.0875 - val_handedness_loss: 0.6937\n",
      "Epoch 9/150\n",
      "24432/24432 [==============================] - 4s 147us/step - loss: 0.7795 - regression_loss: 0.0861 - handedness_loss: 0.6933 - val_loss: 0.7812 - val_regression_loss: 0.0879 - val_handedness_loss: 0.6933\n",
      "Epoch 10/150\n",
      "24432/24432 [==============================] - 4s 147us/step - loss: 0.7790 - regression_loss: 0.0857 - handedness_loss: 0.6933 - val_loss: 0.7795 - val_regression_loss: 0.0863 - val_handedness_loss: 0.6932\n",
      "Epoch 11/150\n",
      "24432/24432 [==============================] - 3s 127us/step - loss: 0.7783 - regression_loss: 0.0851 - handedness_loss: 0.6932 - val_loss: 0.7791 - val_regression_loss: 0.0859 - val_handedness_loss: 0.6933\n",
      "Evaluating model with testing data...\n",
      "5214/5214 [==============================] - 0s 16us/step\n",
      "Getting distribution of predictions and covariance matrix...\n",
      "      1 of 20\n",
      "      2 of 20\n",
      "      3 of 20\n",
      "      4 of 20\n",
      "      5 of 20\n",
      "      6 of 20\n",
      "      7 of 20\n",
      "      8 of 20\n",
      "      9 of 20\n",
      "      10 of 20\n",
      "      11 of 20\n",
      "      12 of 20\n",
      "      13 of 20\n",
      "      14 of 20\n",
      "      15 of 20\n",
      "      16 of 20\n",
      "      17 of 20\n",
      "      18 of 20\n",
      "      19 of 20\n",
      "      20 of 20\n",
      "Computing ensemble means...\n",
      "Computing mean squared error...\n",
      "Iteration 172\n",
      "Train on 24572 samples, validate on 5244 samples\n",
      "Epoch 1/150\n",
      "24572/24572 [==============================] - 3s 140us/step - loss: 0.9828 - regression_loss: 0.2900 - handedness_loss: 0.6928 - val_loss: 0.8842 - val_regression_loss: 0.1911 - val_handedness_loss: 0.6931\n",
      "Epoch 2/150\n",
      "24572/24572 [==============================] - 3s 135us/step - loss: 0.8347 - regression_loss: 0.1414 - handedness_loss: 0.6933 - val_loss: 0.8019 - val_regression_loss: 0.1087 - val_handedness_loss: 0.6932\n",
      "Epoch 3/150\n",
      "24572/24572 [==============================] - 3s 130us/step - loss: 0.7916 - regression_loss: 0.0985 - handedness_loss: 0.6931 - val_loss: 0.7887 - val_regression_loss: 0.0950 - val_handedness_loss: 0.6937\n",
      "Epoch 4/150\n",
      "24572/24572 [==============================] - 4s 144us/step - loss: 0.7853 - regression_loss: 0.0919 - handedness_loss: 0.6934 - val_loss: 0.7839 - val_regression_loss: 0.0909 - val_handedness_loss: 0.6930\n",
      "Epoch 5/150\n",
      "24572/24572 [==============================] - 3s 142us/step - loss: 0.7825 - regression_loss: 0.0892 - handedness_loss: 0.6933 - val_loss: 0.7820 - val_regression_loss: 0.0890 - val_handedness_loss: 0.6931\n",
      "Epoch 6/150\n",
      "24572/24572 [==============================] - 3s 120us/step - loss: 0.7803 - regression_loss: 0.0872 - handedness_loss: 0.6931 - val_loss: 0.7808 - val_regression_loss: 0.0875 - val_handedness_loss: 0.6933\n",
      "Epoch 7/150\n",
      "24572/24572 [==============================] - 3s 113us/step - loss: 0.7792 - regression_loss: 0.0860 - handedness_loss: 0.6932 - val_loss: 0.7793 - val_regression_loss: 0.0862 - val_handedness_loss: 0.6930\n",
      "Epoch 8/150\n",
      "24572/24572 [==============================] - 3s 136us/step - loss: 0.7781 - regression_loss: 0.0849 - handedness_loss: 0.6932 - val_loss: 0.7785 - val_regression_loss: 0.0853 - val_handedness_loss: 0.6931\n",
      "Evaluating model with testing data...\n",
      "5244/5244 [==============================] - 0s 16us/step\n",
      "Getting distribution of predictions and covariance matrix...\n",
      "      1 of 20\n",
      "      2 of 20\n",
      "      3 of 20\n",
      "      4 of 20\n",
      "      5 of 20\n",
      "      6 of 20\n",
      "      7 of 20\n",
      "      8 of 20\n",
      "      9 of 20\n",
      "      10 of 20\n",
      "      11 of 20\n",
      "      12 of 20\n",
      "      13 of 20\n",
      "      14 of 20\n",
      "      15 of 20\n",
      "      16 of 20\n",
      "      17 of 20\n",
      "      18 of 20\n",
      "      19 of 20\n",
      "      20 of 20\n",
      "Computing ensemble means...\n",
      "Computing mean squared error...\n",
      "Iteration 173\n",
      "Train on 24712 samples, validate on 5274 samples\n",
      "Epoch 1/150\n",
      "24712/24712 [==============================] - 3s 133us/step - loss: 0.9971 - regression_loss: 0.3090 - handedness_loss: 0.6875 - val_loss: 0.8575 - val_regression_loss: 0.1622 - val_handedness_loss: 0.6950\n",
      "Epoch 2/150\n",
      "24712/24712 [==============================] - 4s 145us/step - loss: 0.8150 - regression_loss: 0.1204 - handedness_loss: 0.6945 - val_loss: 0.8033 - val_regression_loss: 0.1075 - val_handedness_loss: 0.6959\n",
      "Epoch 3/150\n",
      "24712/24712 [==============================] - 4s 147us/step - loss: 0.7956 - regression_loss: 0.1015 - handedness_loss: 0.6941 - val_loss: 0.7928 - val_regression_loss: 0.0985 - val_handedness_loss: 0.6945\n",
      "Epoch 4/150\n",
      "24712/24712 [==============================] - 3s 138us/step - loss: 0.7898 - regression_loss: 0.0963 - handedness_loss: 0.6936 - val_loss: 0.7871 - val_regression_loss: 0.0936 - val_handedness_loss: 0.6932\n",
      "Epoch 5/150\n",
      "24712/24712 [==============================] - 4s 146us/step - loss: 0.7854 - regression_loss: 0.0920 - handedness_loss: 0.6932 - val_loss: 0.7839 - val_regression_loss: 0.0908 - val_handedness_loss: 0.6930\n",
      "Epoch 6/150\n",
      "24712/24712 [==============================] - 3s 141us/step - loss: 0.7824 - regression_loss: 0.0890 - handedness_loss: 0.6934 - val_loss: 0.7823 - val_regression_loss: 0.0889 - val_handedness_loss: 0.6935\n",
      "Epoch 7/150\n",
      "24712/24712 [==============================] - 3s 133us/step - loss: 0.7806 - regression_loss: 0.0873 - handedness_loss: 0.6933 - val_loss: 0.7801 - val_regression_loss: 0.0870 - val_handedness_loss: 0.6931\n",
      "Epoch 8/150\n",
      "24712/24712 [==============================] - 3s 136us/step - loss: 0.7792 - regression_loss: 0.0860 - handedness_loss: 0.6933 - val_loss: 0.7793 - val_regression_loss: 0.0861 - val_handedness_loss: 0.6932\n",
      "Epoch 9/150\n",
      "24712/24712 [==============================] - 3s 137us/step - loss: 0.7782 - regression_loss: 0.0850 - handedness_loss: 0.6933 - val_loss: 0.7786 - val_regression_loss: 0.0854 - val_handedness_loss: 0.6932\n",
      "Evaluating model with testing data...\n",
      "5274/5274 [==============================] - 0s 17us/step\n",
      "Getting distribution of predictions and covariance matrix...\n",
      "      1 of 20\n",
      "      2 of 20\n",
      "      3 of 20\n",
      "      4 of 20\n",
      "      5 of 20\n",
      "      6 of 20\n",
      "      7 of 20\n",
      "      8 of 20\n",
      "      9 of 20\n",
      "      10 of 20\n",
      "      11 of 20\n",
      "      12 of 20\n",
      "      13 of 20\n",
      "      14 of 20\n",
      "      15 of 20\n",
      "      16 of 20\n",
      "      17 of 20\n",
      "      18 of 20\n",
      "      19 of 20\n",
      "      20 of 20\n",
      "Computing ensemble means...\n",
      "Computing mean squared error...\n",
      "Iteration 174\n",
      "Train on 24852 samples, validate on 5304 samples\n",
      "Epoch 1/150\n",
      "24852/24852 [==============================] - 3s 135us/step - loss: 0.9193 - regression_loss: 0.2315 - handedness_loss: 0.6874 - val_loss: 0.7898 - val_regression_loss: 0.0963 - val_handedness_loss: 0.6934\n",
      "Epoch 2/150\n",
      "24852/24852 [==============================] - 3s 137us/step - loss: 0.7884 - regression_loss: 0.0947 - handedness_loss: 0.6936 - val_loss: 0.7877 - val_regression_loss: 0.0941 - val_handedness_loss: 0.6936\n",
      "Epoch 3/150\n",
      "24852/24852 [==============================] - 3s 134us/step - loss: 0.7862 - regression_loss: 0.0924 - handedness_loss: 0.6937 - val_loss: 0.7868 - val_regression_loss: 0.0932 - val_handedness_loss: 0.6936\n",
      "Epoch 4/150\n",
      "24852/24852 [==============================] - 3s 140us/step - loss: 0.7847 - regression_loss: 0.0913 - handedness_loss: 0.6934 - val_loss: 0.7848 - val_regression_loss: 0.0915 - val_handedness_loss: 0.6933\n",
      "Epoch 5/150\n",
      "24852/24852 [==============================] - 4s 148us/step - loss: 0.7831 - regression_loss: 0.0897 - handedness_loss: 0.6934 - val_loss: 0.7836 - val_regression_loss: 0.0904 - val_handedness_loss: 0.6931\n",
      "Epoch 6/150\n",
      "24852/24852 [==============================] - 4s 141us/step - loss: 0.7820 - regression_loss: 0.0887 - handedness_loss: 0.6933 - val_loss: 0.7823 - val_regression_loss: 0.0888 - val_handedness_loss: 0.6934\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7/150\n",
      "24852/24852 [==============================] - 4s 147us/step - loss: 0.7809 - regression_loss: 0.0877 - handedness_loss: 0.6932 - val_loss: 0.7815 - val_regression_loss: 0.0884 - val_handedness_loss: 0.6932\n",
      "Epoch 8/150\n",
      "24852/24852 [==============================] - 4s 148us/step - loss: 0.7802 - regression_loss: 0.0869 - handedness_loss: 0.6933 - val_loss: 0.7806 - val_regression_loss: 0.0875 - val_handedness_loss: 0.6931\n",
      "Epoch 9/150\n",
      "24852/24852 [==============================] - 4s 145us/step - loss: 0.7795 - regression_loss: 0.0863 - handedness_loss: 0.6932 - val_loss: 0.7802 - val_regression_loss: 0.0870 - val_handedness_loss: 0.6933\n",
      "Evaluating model with testing data...\n",
      "5304/5304 [==============================] - 0s 16us/step\n",
      "Getting distribution of predictions and covariance matrix...\n",
      "      1 of 20\n",
      "      2 of 20\n",
      "      3 of 20\n",
      "      4 of 20\n",
      "      5 of 20\n",
      "      6 of 20\n",
      "      7 of 20\n",
      "      8 of 20\n",
      "      9 of 20\n",
      "      10 of 20\n",
      "      11 of 20\n",
      "      12 of 20\n",
      "      13 of 20\n",
      "      14 of 20\n",
      "      15 of 20\n",
      "      16 of 20\n",
      "      17 of 20\n",
      "      18 of 20\n",
      "      19 of 20\n",
      "      20 of 20\n",
      "Computing ensemble means...\n",
      "Computing mean squared error...\n",
      "Iteration 175\n",
      "Train on 24992 samples, validate on 5334 samples\n",
      "Epoch 1/150\n",
      "24992/24992 [==============================] - 4s 146us/step - loss: 0.9199 - regression_loss: 0.2411 - handedness_loss: 0.6784 - val_loss: 0.8068 - val_regression_loss: 0.1115 - val_handedness_loss: 0.6953\n",
      "Epoch 2/150\n",
      "24992/24992 [==============================] - 4s 146us/step - loss: 0.8008 - regression_loss: 0.1057 - handedness_loss: 0.6952 - val_loss: 0.7968 - val_regression_loss: 0.1023 - val_handedness_loss: 0.6944\n",
      "Epoch 3/150\n",
      "24992/24992 [==============================] - 4s 145us/step - loss: 0.7930 - regression_loss: 0.0991 - handedness_loss: 0.6940 - val_loss: 0.7909 - val_regression_loss: 0.0971 - val_handedness_loss: 0.6938\n",
      "Epoch 4/150\n",
      "24992/24992 [==============================] - 4s 144us/step - loss: 0.7880 - regression_loss: 0.0946 - handedness_loss: 0.6934 - val_loss: 0.7870 - val_regression_loss: 0.0938 - val_handedness_loss: 0.6931\n",
      "Epoch 5/150\n",
      "24992/24992 [==============================] - 4s 147us/step - loss: 0.7844 - regression_loss: 0.0910 - handedness_loss: 0.6933 - val_loss: 0.7842 - val_regression_loss: 0.0909 - val_handedness_loss: 0.6933\n",
      "Epoch 6/150\n",
      "24992/24992 [==============================] - 4s 148us/step - loss: 0.7820 - regression_loss: 0.0886 - handedness_loss: 0.6934 - val_loss: 0.7820 - val_regression_loss: 0.0888 - val_handedness_loss: 0.6932\n",
      "Epoch 7/150\n",
      "24992/24992 [==============================] - 4s 148us/step - loss: 0.7800 - regression_loss: 0.0869 - handedness_loss: 0.6932 - val_loss: 0.7805 - val_regression_loss: 0.0871 - val_handedness_loss: 0.6933\n",
      "Epoch 8/150\n",
      "24992/24992 [==============================] - 4s 148us/step - loss: 0.7790 - regression_loss: 0.0857 - handedness_loss: 0.6933 - val_loss: 0.7792 - val_regression_loss: 0.0861 - val_handedness_loss: 0.6931\n",
      "Epoch 9/150\n",
      "24992/24992 [==============================] - 4s 143us/step - loss: 0.7780 - regression_loss: 0.0849 - handedness_loss: 0.6932 - val_loss: 0.7784 - val_regression_loss: 0.0851 - val_handedness_loss: 0.6933\n",
      "Epoch 10/150\n",
      "24992/24992 [==============================] - 4s 147us/step - loss: 0.7773 - regression_loss: 0.0842 - handedness_loss: 0.6932 - val_loss: 0.7781 - val_regression_loss: 0.0849 - val_handedness_loss: 0.6932\n",
      "Epoch 11/150\n",
      "24992/24992 [==============================] - 4s 141us/step - loss: 0.7770 - regression_loss: 0.0838 - handedness_loss: 0.6932 - val_loss: 0.7777 - val_regression_loss: 0.0845 - val_handedness_loss: 0.6932\n",
      "Epoch 12/150\n",
      "24992/24992 [==============================] - 2s 99us/step - loss: 0.7769 - regression_loss: 0.0838 - handedness_loss: 0.6932 - val_loss: 0.7777 - val_regression_loss: 0.0845 - val_handedness_loss: 0.6932\n",
      "Evaluating model with testing data...\n",
      "5334/5334 [==============================] - 0s 17us/step\n",
      "Getting distribution of predictions and covariance matrix...\n",
      "      1 of 20\n",
      "      2 of 20\n",
      "      3 of 20\n",
      "      4 of 20\n",
      "      5 of 20\n",
      "      6 of 20\n",
      "      7 of 20\n",
      "      8 of 20\n",
      "      9 of 20\n",
      "      10 of 20\n",
      "      11 of 20\n",
      "      12 of 20\n",
      "      13 of 20\n",
      "      14 of 20\n",
      "      15 of 20\n",
      "      16 of 20\n",
      "      17 of 20\n",
      "      18 of 20\n",
      "      19 of 20\n",
      "      20 of 20\n",
      "Computing ensemble means...\n",
      "Computing mean squared error...\n",
      "Iteration 176\n",
      "Train on 25132 samples, validate on 5364 samples\n",
      "Epoch 1/150\n",
      "25132/25132 [==============================] - 4s 141us/step - loss: 0.8621 - regression_loss: 0.2259 - handedness_loss: 0.6360 - val_loss: 0.7891 - val_regression_loss: 0.0935 - val_handedness_loss: 0.6955\n",
      "Epoch 2/150\n",
      "25132/25132 [==============================] - 3s 136us/step - loss: 0.7857 - regression_loss: 0.0911 - handedness_loss: 0.6946 - val_loss: 0.7855 - val_regression_loss: 0.0922 - val_handedness_loss: 0.6933\n",
      "Epoch 3/150\n",
      "25132/25132 [==============================] - 4s 147us/step - loss: 0.7846 - regression_loss: 0.0906 - handedness_loss: 0.6940 - val_loss: 0.7858 - val_regression_loss: 0.0916 - val_handedness_loss: 0.6942\n",
      "Epoch 4/150\n",
      "25132/25132 [==============================] - 4s 148us/step - loss: 0.7830 - regression_loss: 0.0892 - handedness_loss: 0.6939 - val_loss: 0.7839 - val_regression_loss: 0.0901 - val_handedness_loss: 0.6938\n",
      "Epoch 5/150\n",
      "25132/25132 [==============================] - 4s 147us/step - loss: 0.7822 - regression_loss: 0.0884 - handedness_loss: 0.6937 - val_loss: 0.7836 - val_regression_loss: 0.0892 - val_handedness_loss: 0.6943\n",
      "Epoch 6/150\n",
      "25132/25132 [==============================] - 4s 143us/step - loss: 0.7811 - regression_loss: 0.0874 - handedness_loss: 0.6937 - val_loss: 0.7823 - val_regression_loss: 0.0885 - val_handedness_loss: 0.6938\n",
      "Evaluating model with testing data...\n",
      "5364/5364 [==============================] - 0s 16us/step\n",
      "Getting distribution of predictions and covariance matrix...\n",
      "      1 of 20\n",
      "      2 of 20\n",
      "      3 of 20\n",
      "      4 of 20\n",
      "      5 of 20\n",
      "      6 of 20\n",
      "      7 of 20\n",
      "      8 of 20\n",
      "      9 of 20\n",
      "      10 of 20\n",
      "      11 of 20\n",
      "      12 of 20\n",
      "      13 of 20\n",
      "      14 of 20\n",
      "      15 of 20\n",
      "      16 of 20\n",
      "      17 of 20\n",
      "      18 of 20\n",
      "      19 of 20\n",
      "      20 of 20\n",
      "Computing ensemble means...\n",
      "Computing mean squared error...\n",
      "Iteration 177\n",
      "Train on 25272 samples, validate on 5394 samples\n",
      "Epoch 1/150\n",
      "25272/25272 [==============================] - 3s 130us/step - loss: 0.9848 - regression_loss: 0.2938 - handedness_loss: 0.6908 - val_loss: 0.8984 - val_regression_loss: 0.2052 - val_handedness_loss: 0.6932\n",
      "Epoch 2/150\n",
      "25272/25272 [==============================] - 3s 132us/step - loss: 0.8534 - regression_loss: 0.1602 - handedness_loss: 0.6932 - val_loss: 0.8223 - val_regression_loss: 0.1293 - val_handedness_loss: 0.6932\n",
      "Epoch 3/150\n",
      "25272/25272 [==============================] - 4s 142us/step - loss: 0.8023 - regression_loss: 0.1092 - handedness_loss: 0.6932 - val_loss: 0.7911 - val_regression_loss: 0.0983 - val_handedness_loss: 0.6932\n",
      "Epoch 4/150\n",
      "25272/25272 [==============================] - 3s 136us/step - loss: 0.7834 - regression_loss: 0.0903 - handedness_loss: 0.6931 - val_loss: 0.7810 - val_regression_loss: 0.0883 - val_handedness_loss: 0.6932\n",
      "Epoch 5/150\n",
      "25272/25272 [==============================] - 4s 144us/step - loss: 0.7781 - regression_loss: 0.0849 - handedness_loss: 0.6931 - val_loss: 0.7785 - val_regression_loss: 0.0859 - val_handedness_loss: 0.6932\n",
      "Evaluating model with testing data...\n",
      "5394/5394 [==============================] - 0s 16us/step\n",
      "Getting distribution of predictions and covariance matrix...\n",
      "      1 of 20\n",
      "      2 of 20\n",
      "      3 of 20\n",
      "      4 of 20\n",
      "      5 of 20\n",
      "      6 of 20\n",
      "      7 of 20\n",
      "      8 of 20\n",
      "      9 of 20\n",
      "      10 of 20\n",
      "      11 of 20\n",
      "      12 of 20\n",
      "      13 of 20\n",
      "      14 of 20\n",
      "      15 of 20\n",
      "      16 of 20\n",
      "      17 of 20\n",
      "      18 of 20\n",
      "      19 of 20\n",
      "      20 of 20\n",
      "Computing ensemble means...\n",
      "Computing mean squared error...\n",
      "Iteration 178\n",
      "Train on 25412 samples, validate on 5424 samples\n",
      "Epoch 1/150\n",
      "25412/25412 [==============================] - 3s 127us/step - loss: 0.9690 - regression_loss: 0.2763 - handedness_loss: 0.6924 - val_loss: 0.8517 - val_regression_loss: 0.1581 - val_handedness_loss: 0.6940\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/150\n",
      "25412/25412 [==============================] - 4s 142us/step - loss: 0.8130 - regression_loss: 0.1192 - handedness_loss: 0.6938 - val_loss: 0.8005 - val_regression_loss: 0.1073 - val_handedness_loss: 0.6933\n",
      "Epoch 3/150\n",
      "25412/25412 [==============================] - 4s 148us/step - loss: 0.7941 - regression_loss: 0.1008 - handedness_loss: 0.6933 - val_loss: 0.7915 - val_regression_loss: 0.0982 - val_handedness_loss: 0.6935\n",
      "Epoch 4/150\n",
      "25412/25412 [==============================] - 4s 148us/step - loss: 0.7871 - regression_loss: 0.0939 - handedness_loss: 0.6932 - val_loss: 0.7865 - val_regression_loss: 0.0924 - val_handedness_loss: 0.6940\n",
      "Epoch 5/150\n",
      "25412/25412 [==============================] - 4s 147us/step - loss: 0.7832 - regression_loss: 0.0900 - handedness_loss: 0.6932 - val_loss: 0.7839 - val_regression_loss: 0.0905 - val_handedness_loss: 0.6933\n",
      "Epoch 6/150\n",
      "25412/25412 [==============================] - 4s 145us/step - loss: 0.7810 - regression_loss: 0.0877 - handedness_loss: 0.6933 - val_loss: 0.7814 - val_regression_loss: 0.0880 - val_handedness_loss: 0.6934\n",
      "Epoch 7/150\n",
      "25412/25412 [==============================] - 4s 147us/step - loss: 0.7794 - regression_loss: 0.0862 - handedness_loss: 0.6932 - val_loss: 0.7801 - val_regression_loss: 0.0868 - val_handedness_loss: 0.6933\n",
      "Epoch 8/150\n",
      "25412/25412 [==============================] - 4s 147us/step - loss: 0.7783 - regression_loss: 0.0851 - handedness_loss: 0.6932 - val_loss: 0.7793 - val_regression_loss: 0.0861 - val_handedness_loss: 0.6932\n",
      "Epoch 9/150\n",
      "25412/25412 [==============================] - 4s 142us/step - loss: 0.7776 - regression_loss: 0.0845 - handedness_loss: 0.6932 - val_loss: 0.7788 - val_regression_loss: 0.0855 - val_handedness_loss: 0.6932\n",
      "Epoch 10/150\n",
      "25412/25412 [==============================] - 4s 144us/step - loss: 0.7773 - regression_loss: 0.0841 - handedness_loss: 0.6932 - val_loss: 0.7785 - val_regression_loss: 0.0852 - val_handedness_loss: 0.6932\n",
      "Epoch 11/150\n",
      "25412/25412 [==============================] - 4s 147us/step - loss: 0.7770 - regression_loss: 0.0839 - handedness_loss: 0.6932 - val_loss: 0.7783 - val_regression_loss: 0.0851 - val_handedness_loss: 0.6932\n",
      "Epoch 12/150\n",
      "25412/25412 [==============================] - 4s 147us/step - loss: 0.7768 - regression_loss: 0.0837 - handedness_loss: 0.6932 - val_loss: 0.7781 - val_regression_loss: 0.0849 - val_handedness_loss: 0.6932\n",
      "Evaluating model with testing data...\n",
      "5424/5424 [==============================] - 0s 17us/step\n",
      "Getting distribution of predictions and covariance matrix...\n",
      "      1 of 20\n",
      "      2 of 20\n",
      "      3 of 20\n",
      "      4 of 20\n",
      "      5 of 20\n",
      "      6 of 20\n",
      "      7 of 20\n",
      "      8 of 20\n",
      "      9 of 20\n",
      "      10 of 20\n",
      "      11 of 20\n",
      "      12 of 20\n",
      "      13 of 20\n",
      "      14 of 20\n",
      "      15 of 20\n",
      "      16 of 20\n",
      "      17 of 20\n",
      "      18 of 20\n",
      "      19 of 20\n",
      "      20 of 20\n",
      "Computing ensemble means...\n",
      "Computing mean squared error...\n",
      "Iteration 179\n",
      "Train on 25552 samples, validate on 5454 samples\n",
      "Epoch 1/150\n",
      "25552/25552 [==============================] - 4s 144us/step - loss: 0.8962 - regression_loss: 0.2194 - handedness_loss: 0.6766 - val_loss: 0.7938 - val_regression_loss: 0.0975 - val_handedness_loss: 0.6964\n",
      "Epoch 2/150\n",
      "25552/25552 [==============================] - 4s 147us/step - loss: 0.7902 - regression_loss: 0.0952 - handedness_loss: 0.6950 - val_loss: 0.7876 - val_regression_loss: 0.0936 - val_handedness_loss: 0.6940\n",
      "Epoch 3/150\n",
      "25552/25552 [==============================] - 4s 139us/step - loss: 0.7871 - regression_loss: 0.0930 - handedness_loss: 0.6942 - val_loss: 0.7865 - val_regression_loss: 0.0930 - val_handedness_loss: 0.6935\n",
      "Epoch 4/150\n",
      "25552/25552 [==============================] - 3s 131us/step - loss: 0.7842 - regression_loss: 0.0906 - handedness_loss: 0.6936 - val_loss: 0.7838 - val_regression_loss: 0.0902 - val_handedness_loss: 0.6935\n",
      "Epoch 5/150\n",
      "25552/25552 [==============================] - 4s 140us/step - loss: 0.7835 - regression_loss: 0.0897 - handedness_loss: 0.6938 - val_loss: 0.7834 - val_regression_loss: 0.0893 - val_handedness_loss: 0.6940\n",
      "Epoch 6/150\n",
      "25552/25552 [==============================] - 4s 147us/step - loss: 0.7816 - regression_loss: 0.0884 - handedness_loss: 0.6933 - val_loss: 0.7816 - val_regression_loss: 0.0884 - val_handedness_loss: 0.6932\n",
      "Epoch 7/150\n",
      "25552/25552 [==============================] - 3s 104us/step - loss: 0.7808 - regression_loss: 0.0872 - handedness_loss: 0.6936 - val_loss: 0.7820 - val_regression_loss: 0.0884 - val_handedness_loss: 0.6935\n",
      "Epoch 8/150\n",
      "25552/25552 [==============================] - 4s 145us/step - loss: 0.7798 - regression_loss: 0.0865 - handedness_loss: 0.6933 - val_loss: 0.7806 - val_regression_loss: 0.0872 - val_handedness_loss: 0.6934\n",
      "Epoch 9/150\n",
      "25552/25552 [==============================] - 4s 148us/step - loss: 0.7792 - regression_loss: 0.0860 - handedness_loss: 0.6932 - val_loss: 0.7802 - val_regression_loss: 0.0866 - val_handedness_loss: 0.6936\n",
      "Epoch 10/150\n",
      "25552/25552 [==============================] - 3s 135us/step - loss: 0.7786 - regression_loss: 0.0854 - handedness_loss: 0.6932 - val_loss: 0.7790 - val_regression_loss: 0.0855 - val_handedness_loss: 0.6934\n",
      "Evaluating model with testing data...\n",
      "5454/5454 [==============================] - 0s 16us/step\n",
      "Getting distribution of predictions and covariance matrix...\n",
      "      1 of 20\n",
      "      2 of 20\n",
      "      3 of 20\n",
      "      4 of 20\n",
      "      5 of 20\n",
      "      6 of 20\n",
      "      7 of 20\n",
      "      8 of 20\n",
      "      9 of 20\n",
      "      10 of 20\n",
      "      11 of 20\n",
      "      12 of 20\n",
      "      13 of 20\n",
      "      14 of 20\n",
      "      15 of 20\n",
      "      16 of 20\n",
      "      17 of 20\n",
      "      18 of 20\n",
      "      19 of 20\n",
      "      20 of 20\n",
      "Computing ensemble means...\n",
      "Computing mean squared error...\n",
      "Iteration 180\n",
      "Train on 25692 samples, validate on 5484 samples\n",
      "Epoch 1/150\n",
      "25692/25692 [==============================] - 3s 132us/step - loss: 0.9701 - regression_loss: 0.2738 - handedness_loss: 0.6961 - val_loss: 0.8584 - val_regression_loss: 0.1653 - val_handedness_loss: 0.6931\n",
      "Epoch 2/150\n",
      "25692/25692 [==============================] - 3s 132us/step - loss: 0.8177 - regression_loss: 0.1243 - handedness_loss: 0.6933 - val_loss: 0.8027 - val_regression_loss: 0.1093 - val_handedness_loss: 0.6934\n",
      "Epoch 3/150\n",
      "25692/25692 [==============================] - 4s 143us/step - loss: 0.7952 - regression_loss: 0.1019 - handedness_loss: 0.6933 - val_loss: 0.7918 - val_regression_loss: 0.0988 - val_handedness_loss: 0.6931\n",
      "Epoch 4/150\n",
      "25692/25692 [==============================] - 4s 138us/step - loss: 0.7874 - regression_loss: 0.0941 - handedness_loss: 0.6932 - val_loss: 0.7864 - val_regression_loss: 0.0931 - val_handedness_loss: 0.6934\n",
      "Epoch 5/150\n",
      "25692/25692 [==============================] - 4s 143us/step - loss: 0.7828 - regression_loss: 0.0895 - handedness_loss: 0.6933 - val_loss: 0.7829 - val_regression_loss: 0.0897 - val_handedness_loss: 0.6932\n",
      "Evaluating model with testing data...\n",
      "5484/5484 [==============================] - 0s 16us/step\n",
      "Getting distribution of predictions and covariance matrix...\n",
      "      1 of 20\n",
      "      2 of 20\n",
      "      3 of 20\n",
      "      4 of 20\n",
      "      5 of 20\n",
      "      6 of 20\n",
      "      7 of 20\n",
      "      8 of 20\n",
      "      9 of 20\n",
      "      10 of 20\n",
      "      11 of 20\n",
      "      12 of 20\n",
      "      13 of 20\n",
      "      14 of 20\n",
      "      15 of 20\n",
      "      16 of 20\n",
      "      17 of 20\n",
      "      18 of 20\n",
      "      19 of 20\n",
      "      20 of 20\n",
      "Computing ensemble means...\n",
      "Computing mean squared error...\n",
      "Iteration 181\n",
      "Train on 25832 samples, validate on 5514 samples\n",
      "Epoch 1/150\n",
      "25832/25832 [==============================] - 4s 136us/step - loss: 0.9138 - regression_loss: 0.2131 - handedness_loss: 0.7006 - val_loss: 0.7972 - val_regression_loss: 0.1040 - val_handedness_loss: 0.6934\n",
      "Epoch 2/150\n",
      "25832/25832 [==============================] - 4s 140us/step - loss: 0.7936 - regression_loss: 0.0996 - handedness_loss: 0.6940 - val_loss: 0.7922 - val_regression_loss: 0.0988 - val_handedness_loss: 0.6939\n",
      "Epoch 3/150\n",
      "25832/25832 [==============================] - 3s 130us/step - loss: 0.7888 - regression_loss: 0.0952 - handedness_loss: 0.6935 - val_loss: 0.7878 - val_regression_loss: 0.0943 - val_handedness_loss: 0.6932\n",
      "Epoch 4/150\n",
      "25832/25832 [==============================] - 4s 140us/step - loss: 0.7861 - regression_loss: 0.0927 - handedness_loss: 0.6934 - val_loss: 0.7867 - val_regression_loss: 0.0935 - val_handedness_loss: 0.6937\n",
      "Epoch 5/150\n",
      "25832/25832 [==============================] - 4s 146us/step - loss: 0.7842 - regression_loss: 0.0910 - handedness_loss: 0.6932 - val_loss: 0.7839 - val_regression_loss: 0.0906 - val_handedness_loss: 0.6932\n",
      "Epoch 6/150\n",
      "25832/25832 [==============================] - 4s 146us/step - loss: 0.7827 - regression_loss: 0.0893 - handedness_loss: 0.6934 - val_loss: 0.7830 - val_regression_loss: 0.0891 - val_handedness_loss: 0.6934\n",
      "Epoch 7/150\n",
      "25832/25832 [==============================] - 4s 146us/step - loss: 0.7810 - regression_loss: 0.0877 - handedness_loss: 0.6933 - val_loss: 0.7813 - val_regression_loss: 0.0877 - val_handedness_loss: 0.6934\n",
      "Epoch 8/150\n",
      "25832/25832 [==============================] - 4s 146us/step - loss: 0.7798 - regression_loss: 0.0866 - handedness_loss: 0.6932 - val_loss: 0.7806 - val_regression_loss: 0.0871 - val_handedness_loss: 0.6933\n",
      "Epoch 9/150\n",
      "25832/25832 [==============================] - 4s 146us/step - loss: 0.7790 - regression_loss: 0.0858 - handedness_loss: 0.6932 - val_loss: 0.7795 - val_regression_loss: 0.0863 - val_handedness_loss: 0.6931\n",
      "Epoch 10/150\n",
      "25832/25832 [==============================] - 4s 146us/step - loss: 0.7782 - regression_loss: 0.0850 - handedness_loss: 0.6932 - val_loss: 0.7793 - val_regression_loss: 0.0859 - val_handedness_loss: 0.6932\n",
      "Epoch 11/150\n",
      "25832/25832 [==============================] - 4s 138us/step - loss: 0.7777 - regression_loss: 0.0845 - handedness_loss: 0.6932 - val_loss: 0.7789 - val_regression_loss: 0.0855 - val_handedness_loss: 0.6931\n",
      "Epoch 12/150\n",
      "25832/25832 [==============================] - 4s 140us/step - loss: 0.7773 - regression_loss: 0.0842 - handedness_loss: 0.6932 - val_loss: 0.7784 - val_regression_loss: 0.0851 - val_handedness_loss: 0.6931\n",
      "Epoch 13/150\n",
      "25832/25832 [==============================] - 4s 137us/step - loss: 0.7772 - regression_loss: 0.0840 - handedness_loss: 0.6932 - val_loss: 0.7781 - val_regression_loss: 0.0847 - val_handedness_loss: 0.6932\n",
      "Evaluating model with testing data...\n",
      "5514/5514 [==============================] - 0s 16us/step\n",
      "Getting distribution of predictions and covariance matrix...\n",
      "      1 of 20\n",
      "      2 of 20\n",
      "      3 of 20\n",
      "      4 of 20\n",
      "      5 of 20\n",
      "      6 of 20\n",
      "      7 of 20\n",
      "      8 of 20\n",
      "      9 of 20\n",
      "      10 of 20\n",
      "      11 of 20\n",
      "      12 of 20\n",
      "      13 of 20\n",
      "      14 of 20\n",
      "      15 of 20\n",
      "      16 of 20\n",
      "      17 of 20\n",
      "      18 of 20\n",
      "      19 of 20\n",
      "      20 of 20\n",
      "Computing ensemble means...\n",
      "Computing mean squared error...\n",
      "Iteration 182\n",
      "Train on 25972 samples, validate on 5544 samples\n",
      "Epoch 1/150\n",
      "25972/25972 [==============================] - 4s 138us/step - loss: 0.9413 - regression_loss: 0.2574 - handedness_loss: 0.6839 - val_loss: 0.8558 - val_regression_loss: 0.1619 - val_handedness_loss: 0.6938\n",
      "Epoch 2/150\n",
      "25972/25972 [==============================] - 4s 146us/step - loss: 0.8086 - regression_loss: 0.1151 - handedness_loss: 0.6935 - val_loss: 0.7939 - val_regression_loss: 0.0997 - val_handedness_loss: 0.6942\n",
      "Epoch 3/150\n",
      "25972/25972 [==============================] - 4s 145us/step - loss: 0.7903 - regression_loss: 0.0963 - handedness_loss: 0.6940 - val_loss: 0.7886 - val_regression_loss: 0.0946 - val_handedness_loss: 0.6938\n",
      "Epoch 4/150\n",
      "25972/25972 [==============================] - 4s 146us/step - loss: 0.7861 - regression_loss: 0.0926 - handedness_loss: 0.6935 - val_loss: 0.7842 - val_regression_loss: 0.0910 - val_handedness_loss: 0.6933\n",
      "Epoch 5/150\n",
      "25972/25972 [==============================] - 3s 133us/step - loss: 0.7830 - regression_loss: 0.0897 - handedness_loss: 0.6933 - val_loss: 0.7827 - val_regression_loss: 0.0890 - val_handedness_loss: 0.6935\n",
      "Epoch 6/150\n",
      "25972/25972 [==============================] - 4s 146us/step - loss: 0.7810 - regression_loss: 0.0876 - handedness_loss: 0.6935 - val_loss: 0.7809 - val_regression_loss: 0.0877 - val_handedness_loss: 0.6932\n",
      "Epoch 7/150\n",
      "25972/25972 [==============================] - 4s 146us/step - loss: 0.7795 - regression_loss: 0.0862 - handedness_loss: 0.6933 - val_loss: 0.7799 - val_regression_loss: 0.0863 - val_handedness_loss: 0.6935\n",
      "Epoch 8/150\n",
      "25972/25972 [==============================] - 4s 143us/step - loss: 0.7783 - regression_loss: 0.0851 - handedness_loss: 0.6932 - val_loss: 0.7788 - val_regression_loss: 0.0856 - val_handedness_loss: 0.6931\n",
      "Epoch 9/150\n",
      "25972/25972 [==============================] - 3s 111us/step - loss: 0.7778 - regression_loss: 0.0847 - handedness_loss: 0.6932 - val_loss: 0.7784 - val_regression_loss: 0.0852 - val_handedness_loss: 0.6931\n",
      "Epoch 10/150\n",
      "25972/25972 [==============================] - 3s 124us/step - loss: 0.7775 - regression_loss: 0.0843 - handedness_loss: 0.6932 - val_loss: 0.7780 - val_regression_loss: 0.0848 - val_handedness_loss: 0.6930\n",
      "Epoch 11/150\n",
      "25972/25972 [==============================] - 4s 143us/step - loss: 0.7773 - regression_loss: 0.0841 - handedness_loss: 0.6932 - val_loss: 0.7777 - val_regression_loss: 0.0845 - val_handedness_loss: 0.6932\n",
      "Epoch 12/150\n",
      "25972/25972 [==============================] - 4s 145us/step - loss: 0.7771 - regression_loss: 0.0839 - handedness_loss: 0.6932 - val_loss: 0.7778 - val_regression_loss: 0.0844 - val_handedness_loss: 0.6933\n",
      "Epoch 13/150\n",
      "25972/25972 [==============================] - 4s 142us/step - loss: 0.7769 - regression_loss: 0.0838 - handedness_loss: 0.6932 - val_loss: 0.7776 - val_regression_loss: 0.0843 - val_handedness_loss: 0.6931\n",
      "Epoch 14/150\n",
      "25972/25972 [==============================] - 4s 139us/step - loss: 0.7768 - regression_loss: 0.0837 - handedness_loss: 0.6932 - val_loss: 0.7775 - val_regression_loss: 0.0843 - val_handedness_loss: 0.6931\n",
      "Evaluating model with testing data...\n",
      "5544/5544 [==============================] - 0s 16us/step\n",
      "Getting distribution of predictions and covariance matrix...\n",
      "      1 of 20\n",
      "      2 of 20\n",
      "      3 of 20\n",
      "      4 of 20\n",
      "      5 of 20\n",
      "      6 of 20\n",
      "      7 of 20\n",
      "      8 of 20\n",
      "      9 of 20\n",
      "      10 of 20\n",
      "      11 of 20\n",
      "      12 of 20\n",
      "      13 of 20\n",
      "      14 of 20\n",
      "      15 of 20\n",
      "      16 of 20\n",
      "      17 of 20\n",
      "      18 of 20\n",
      "      19 of 20\n",
      "      20 of 20\n",
      "Computing ensemble means...\n",
      "Computing mean squared error...\n",
      "Iteration 183\n",
      "Train on 26112 samples, validate on 5574 samples\n",
      "Epoch 1/150\n",
      "26112/26112 [==============================] - 4s 136us/step - loss: 0.8709 - regression_loss: 0.1761 - handedness_loss: 0.6948 - val_loss: 0.7939 - val_regression_loss: 0.0998 - val_handedness_loss: 0.6941\n",
      "Epoch 2/150\n",
      "26112/26112 [==============================] - 4s 140us/step - loss: 0.7907 - regression_loss: 0.0967 - handedness_loss: 0.6940 - val_loss: 0.7894 - val_regression_loss: 0.0955 - val_handedness_loss: 0.6940\n",
      "Epoch 3/150\n",
      "26112/26112 [==============================] - 3s 131us/step - loss: 0.7871 - regression_loss: 0.0935 - handedness_loss: 0.6935 - val_loss: 0.7872 - val_regression_loss: 0.0936 - val_handedness_loss: 0.6937\n",
      "Epoch 4/150\n",
      "26112/26112 [==============================] - 3s 123us/step - loss: 0.7854 - regression_loss: 0.0915 - handedness_loss: 0.6938 - val_loss: 0.7842 - val_regression_loss: 0.0907 - val_handedness_loss: 0.6935\n",
      "Epoch 5/150\n",
      "26112/26112 [==============================] - 4s 142us/step - loss: 0.7833 - regression_loss: 0.0899 - handedness_loss: 0.6934 - val_loss: 0.7837 - val_regression_loss: 0.0903 - val_handedness_loss: 0.6934\n",
      "Epoch 6/150\n",
      "26112/26112 [==============================] - 4s 140us/step - loss: 0.7820 - regression_loss: 0.0886 - handedness_loss: 0.6934 - val_loss: 0.7819 - val_regression_loss: 0.0884 - val_handedness_loss: 0.6935\n",
      "Epoch 7/150\n",
      "26112/26112 [==============================] - 4s 142us/step - loss: 0.7807 - regression_loss: 0.0873 - handedness_loss: 0.6934 - val_loss: 0.7803 - val_regression_loss: 0.0872 - val_handedness_loss: 0.6931\n",
      "Epoch 8/150\n",
      "26112/26112 [==============================] - 3s 128us/step - loss: 0.7797 - regression_loss: 0.0864 - handedness_loss: 0.6934 - val_loss: 0.7793 - val_regression_loss: 0.0862 - val_handedness_loss: 0.6931\n",
      "Epoch 9/150\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "26112/26112 [==============================] - 4s 145us/step - loss: 0.7788 - regression_loss: 0.0855 - handedness_loss: 0.6933 - val_loss: 0.7789 - val_regression_loss: 0.0858 - val_handedness_loss: 0.6931\n",
      "Epoch 10/150\n",
      "26112/26112 [==============================] - 4s 148us/step - loss: 0.7783 - regression_loss: 0.0851 - handedness_loss: 0.6932 - val_loss: 0.7788 - val_regression_loss: 0.0857 - val_handedness_loss: 0.6931\n",
      "Epoch 11/150\n",
      "26112/26112 [==============================] - 4s 140us/step - loss: 0.7778 - regression_loss: 0.0846 - handedness_loss: 0.6932 - val_loss: 0.7781 - val_regression_loss: 0.0851 - val_handedness_loss: 0.6931\n",
      "Epoch 12/150\n",
      "26112/26112 [==============================] - 4s 147us/step - loss: 0.7774 - regression_loss: 0.0842 - handedness_loss: 0.6932 - val_loss: 0.7781 - val_regression_loss: 0.0851 - val_handedness_loss: 0.6931\n",
      "Evaluating model with testing data...\n",
      "5574/5574 [==============================] - 0s 16us/step\n",
      "Getting distribution of predictions and covariance matrix...\n",
      "      1 of 20\n",
      "      2 of 20\n",
      "      3 of 20\n",
      "      4 of 20\n",
      "      5 of 20\n",
      "      6 of 20\n",
      "      7 of 20\n",
      "      8 of 20\n",
      "      9 of 20\n",
      "      10 of 20\n",
      "      11 of 20\n",
      "      12 of 20\n",
      "      13 of 20\n",
      "      14 of 20\n",
      "      15 of 20\n",
      "      16 of 20\n",
      "      17 of 20\n",
      "      18 of 20\n",
      "      19 of 20\n",
      "      20 of 20\n",
      "Computing ensemble means...\n",
      "Computing mean squared error...\n",
      "Iteration 184\n",
      "Train on 26252 samples, validate on 5604 samples\n",
      "Epoch 1/150\n",
      "26252/26252 [==============================] - 4s 139us/step - loss: 0.7987 - regression_loss: 0.2269 - handedness_loss: 0.5723 - val_loss: 0.8515 - val_regression_loss: 0.1514 - val_handedness_loss: 0.7001\n",
      "Epoch 2/150\n",
      "26252/26252 [==============================] - 4s 146us/step - loss: 0.8238 - regression_loss: 0.1272 - handedness_loss: 0.6964 - val_loss: 0.8054 - val_regression_loss: 0.1111 - val_handedness_loss: 0.6943\n",
      "Epoch 3/150\n",
      "26252/26252 [==============================] - 4s 146us/step - loss: 0.7966 - regression_loss: 0.1025 - handedness_loss: 0.6943 - val_loss: 0.7915 - val_regression_loss: 0.0971 - val_handedness_loss: 0.6944\n",
      "Epoch 4/150\n",
      "26252/26252 [==============================] - 4s 147us/step - loss: 0.7862 - regression_loss: 0.0925 - handedness_loss: 0.6935 - val_loss: 0.7833 - val_regression_loss: 0.0900 - val_handedness_loss: 0.6932\n",
      "Epoch 5/150\n",
      "26252/26252 [==============================] - 4s 147us/step - loss: 0.7805 - regression_loss: 0.0870 - handedness_loss: 0.6935 - val_loss: 0.7797 - val_regression_loss: 0.0864 - val_handedness_loss: 0.6933\n",
      "Epoch 6/150\n",
      "26252/26252 [==============================] - 4s 147us/step - loss: 0.7781 - regression_loss: 0.0849 - handedness_loss: 0.6933 - val_loss: 0.7782 - val_regression_loss: 0.0851 - val_handedness_loss: 0.6932\n",
      "Epoch 7/150\n",
      "26252/26252 [==============================] - 3s 121us/step - loss: 0.7773 - regression_loss: 0.0843 - handedness_loss: 0.6932 - val_loss: 0.7778 - val_regression_loss: 0.0846 - val_handedness_loss: 0.6932\n",
      "Epoch 8/150\n",
      "26252/26252 [==============================] - 4s 143us/step - loss: 0.7770 - regression_loss: 0.0839 - handedness_loss: 0.6931 - val_loss: 0.7777 - val_regression_loss: 0.0844 - val_handedness_loss: 0.6933\n",
      "Epoch 9/150\n",
      "26252/26252 [==============================] - 4s 137us/step - loss: 0.7769 - regression_loss: 0.0837 - handedness_loss: 0.6932 - val_loss: 0.7777 - val_regression_loss: 0.0845 - val_handedness_loss: 0.6932\n",
      "Epoch 10/150\n",
      "26252/26252 [==============================] - 4s 147us/step - loss: 0.7768 - regression_loss: 0.0836 - handedness_loss: 0.6932 - val_loss: 0.7776 - val_regression_loss: 0.0844 - val_handedness_loss: 0.6931\n",
      "Epoch 11/150\n",
      "26252/26252 [==============================] - 4s 143us/step - loss: 0.7768 - regression_loss: 0.0837 - handedness_loss: 0.6932 - val_loss: 0.7775 - val_regression_loss: 0.0844 - val_handedness_loss: 0.6931\n",
      "Epoch 12/150\n",
      "26252/26252 [==============================] - 4s 146us/step - loss: 0.7768 - regression_loss: 0.0838 - handedness_loss: 0.6932 - val_loss: 0.7775 - val_regression_loss: 0.0844 - val_handedness_loss: 0.6931\n",
      "Epoch 13/150\n",
      "26252/26252 [==============================] - 4s 147us/step - loss: 0.7768 - regression_loss: 0.0836 - handedness_loss: 0.6932 - val_loss: 0.7775 - val_regression_loss: 0.0844 - val_handedness_loss: 0.6932\n",
      "Epoch 14/150\n",
      "26252/26252 [==============================] - 3s 113us/step - loss: 0.7768 - regression_loss: 0.0838 - handedness_loss: 0.6932 - val_loss: 0.7775 - val_regression_loss: 0.0844 - val_handedness_loss: 0.6931\n",
      "Epoch 15/150\n",
      "26252/26252 [==============================] - 3s 121us/step - loss: 0.7768 - regression_loss: 0.0837 - handedness_loss: 0.6932 - val_loss: 0.7775 - val_regression_loss: 0.0844 - val_handedness_loss: 0.6932\n",
      "Epoch 16/150\n",
      "26252/26252 [==============================] - 4s 139us/step - loss: 0.7768 - regression_loss: 0.0837 - handedness_loss: 0.6932 - val_loss: 0.7775 - val_regression_loss: 0.0844 - val_handedness_loss: 0.6931\n",
      "Epoch 17/150\n",
      "26252/26252 [==============================] - 4s 146us/step - loss: 0.7768 - regression_loss: 0.0837 - handedness_loss: 0.6932 - val_loss: 0.7775 - val_regression_loss: 0.0844 - val_handedness_loss: 0.6932\n",
      "Epoch 18/150\n",
      "26252/26252 [==============================] - 4s 145us/step - loss: 0.7768 - regression_loss: 0.0836 - handedness_loss: 0.6932 - val_loss: 0.7775 - val_regression_loss: 0.0844 - val_handedness_loss: 0.6932\n",
      "Evaluating model with testing data...\n",
      "5604/5604 [==============================] - 0s 16us/step\n",
      "Getting distribution of predictions and covariance matrix...\n",
      "      1 of 20\n",
      "      2 of 20\n",
      "      3 of 20\n",
      "      4 of 20\n",
      "      5 of 20\n",
      "      6 of 20\n",
      "      7 of 20\n",
      "      8 of 20\n",
      "      9 of 20\n",
      "      10 of 20\n",
      "      11 of 20\n",
      "      12 of 20\n",
      "      13 of 20\n",
      "      14 of 20\n",
      "      15 of 20\n",
      "      16 of 20\n",
      "      17 of 20\n",
      "      18 of 20\n",
      "      19 of 20\n",
      "      20 of 20\n",
      "Computing ensemble means...\n",
      "Computing mean squared error...\n",
      "Iteration 185\n",
      "Train on 26392 samples, validate on 5634 samples\n",
      "Epoch 1/150\n",
      "26392/26392 [==============================] - 4s 142us/step - loss: 0.8181 - regression_loss: 0.1777 - handedness_loss: 0.6403 - val_loss: 0.7904 - val_regression_loss: 0.0953 - val_handedness_loss: 0.6950\n",
      "Epoch 2/150\n",
      "26392/26392 [==============================] - 4s 136us/step - loss: 0.7866 - regression_loss: 0.0926 - handedness_loss: 0.6940 - val_loss: 0.7866 - val_regression_loss: 0.0934 - val_handedness_loss: 0.6941\n",
      "Epoch 3/150\n",
      "26392/26392 [==============================] - 4s 144us/step - loss: 0.7848 - regression_loss: 0.0908 - handedness_loss: 0.6940 - val_loss: 0.7850 - val_regression_loss: 0.0921 - val_handedness_loss: 0.6931\n",
      "Epoch 4/150\n",
      "26392/26392 [==============================] - 4s 139us/step - loss: 0.7833 - regression_loss: 0.0894 - handedness_loss: 0.6940 - val_loss: 0.7825 - val_regression_loss: 0.0896 - val_handedness_loss: 0.6931\n",
      "Epoch 5/150\n",
      "26392/26392 [==============================] - 4s 140us/step - loss: 0.7818 - regression_loss: 0.0880 - handedness_loss: 0.6938 - val_loss: 0.7816 - val_regression_loss: 0.0888 - val_handedness_loss: 0.6934\n",
      "Epoch 6/150\n",
      "26392/26392 [==============================] - 4s 140us/step - loss: 0.7806 - regression_loss: 0.0870 - handedness_loss: 0.6935 - val_loss: 0.7798 - val_regression_loss: 0.0873 - val_handedness_loss: 0.6924\n",
      "Epoch 7/150\n",
      "26392/26392 [==============================] - 3s 130us/step - loss: 0.7795 - regression_loss: 0.0862 - handedness_loss: 0.6933 - val_loss: 0.7798 - val_regression_loss: 0.0870 - val_handedness_loss: 0.6932\n",
      "Epoch 8/150\n",
      "26392/26392 [==============================] - 4s 140us/step - loss: 0.7788 - regression_loss: 0.0855 - handedness_loss: 0.6932 - val_loss: 0.7794 - val_regression_loss: 0.0865 - val_handedness_loss: 0.6938\n",
      "Epoch 9/150\n",
      "26392/26392 [==============================] - 3s 128us/step - loss: 0.7786 - regression_loss: 0.0852 - handedness_loss: 0.6933 - val_loss: 0.7792 - val_regression_loss: 0.0864 - val_handedness_loss: 0.6928\n",
      "Epoch 10/150\n",
      "26392/26392 [==============================] - 3s 126us/step - loss: 0.7780 - regression_loss: 0.0848 - handedness_loss: 0.6932 - val_loss: 0.7787 - val_regression_loss: 0.0862 - val_handedness_loss: 0.6929\n",
      "Evaluating model with testing data...\n",
      "5634/5634 [==============================] - 0s 16us/step\n",
      "Getting distribution of predictions and covariance matrix...\n",
      "      1 of 20\n",
      "      2 of 20\n",
      "      3 of 20\n",
      "      4 of 20\n",
      "      5 of 20\n",
      "      6 of 20\n",
      "      7 of 20\n",
      "      8 of 20\n",
      "      9 of 20\n",
      "      10 of 20\n",
      "      11 of 20\n",
      "      12 of 20\n",
      "      13 of 20\n",
      "      14 of 20\n",
      "      15 of 20\n",
      "      16 of 20\n",
      "      17 of 20\n",
      "      18 of 20\n",
      "      19 of 20\n",
      "      20 of 20\n",
      "Computing ensemble means...\n",
      "Computing mean squared error...\n",
      "Iteration 186\n",
      "Train on 26532 samples, validate on 5664 samples\n",
      "Epoch 1/150\n",
      "26532/26532 [==============================] - 4s 141us/step - loss: 0.9182 - regression_loss: 0.2272 - handedness_loss: 0.6906 - val_loss: 0.8000 - val_regression_loss: 0.1064 - val_handedness_loss: 0.6941\n",
      "Epoch 2/150\n",
      "26532/26532 [==============================] - 4s 144us/step - loss: 0.7965 - regression_loss: 0.1025 - handedness_loss: 0.6941 - val_loss: 0.7935 - val_regression_loss: 0.0996 - val_handedness_loss: 0.6942\n",
      "Epoch 3/150\n",
      "26532/26532 [==============================] - 4s 147us/step - loss: 0.7909 - regression_loss: 0.0971 - handedness_loss: 0.6938 - val_loss: 0.7898 - val_regression_loss: 0.0957 - val_handedness_loss: 0.6940\n",
      "Epoch 4/150\n",
      "26532/26532 [==============================] - 4s 147us/step - loss: 0.7872 - regression_loss: 0.0935 - handedness_loss: 0.6938 - val_loss: 0.7862 - val_regression_loss: 0.0928 - val_handedness_loss: 0.6934\n",
      "Epoch 5/150\n",
      "26532/26532 [==============================] - 4s 147us/step - loss: 0.7844 - regression_loss: 0.0908 - handedness_loss: 0.6936 - val_loss: 0.7834 - val_regression_loss: 0.0901 - val_handedness_loss: 0.6934\n",
      "Epoch 6/150\n",
      "26532/26532 [==============================] - 4s 147us/step - loss: 0.7820 - regression_loss: 0.0886 - handedness_loss: 0.6934 - val_loss: 0.7817 - val_regression_loss: 0.0881 - val_handedness_loss: 0.6935\n",
      "Epoch 7/150\n",
      "26532/26532 [==============================] - 4s 147us/step - loss: 0.7805 - regression_loss: 0.0871 - handedness_loss: 0.6934 - val_loss: 0.7797 - val_regression_loss: 0.0868 - val_handedness_loss: 0.6931\n",
      "Epoch 8/150\n",
      "26532/26532 [==============================] - 4s 147us/step - loss: 0.7789 - regression_loss: 0.0857 - handedness_loss: 0.6932 - val_loss: 0.7792 - val_regression_loss: 0.0859 - val_handedness_loss: 0.6933\n",
      "Epoch 9/150\n",
      "26532/26532 [==============================] - 4s 135us/step - loss: 0.7782 - regression_loss: 0.0850 - handedness_loss: 0.6932 - val_loss: 0.7786 - val_regression_loss: 0.0855 - val_handedness_loss: 0.6931\n",
      "Epoch 10/150\n",
      "26532/26532 [==============================] - 4s 136us/step - loss: 0.7778 - regression_loss: 0.0846 - handedness_loss: 0.6932 - val_loss: 0.7781 - val_regression_loss: 0.0849 - val_handedness_loss: 0.6932\n",
      "Epoch 11/150\n",
      "26532/26532 [==============================] - 4s 145us/step - loss: 0.7774 - regression_loss: 0.0842 - handedness_loss: 0.6932 - val_loss: 0.7780 - val_regression_loss: 0.0848 - val_handedness_loss: 0.6932\n",
      "Epoch 12/150\n",
      "26532/26532 [==============================] - 4s 147us/step - loss: 0.7771 - regression_loss: 0.0840 - handedness_loss: 0.6931 - val_loss: 0.7776 - val_regression_loss: 0.0844 - val_handedness_loss: 0.6932\n",
      "Epoch 13/150\n",
      "26532/26532 [==============================] - 4s 147us/step - loss: 0.7770 - regression_loss: 0.0838 - handedness_loss: 0.6932 - val_loss: 0.7776 - val_regression_loss: 0.0844 - val_handedness_loss: 0.6932\n",
      "Evaluating model with testing data...\n",
      "5664/5664 [==============================] - 0s 17us/step\n",
      "Getting distribution of predictions and covariance matrix...\n",
      "      1 of 20\n",
      "      2 of 20\n",
      "      3 of 20\n",
      "      4 of 20\n",
      "      5 of 20\n",
      "      6 of 20\n",
      "      7 of 20\n",
      "      8 of 20\n",
      "      9 of 20\n",
      "      10 of 20\n",
      "      11 of 20\n",
      "      12 of 20\n",
      "      13 of 20\n",
      "      14 of 20\n",
      "      15 of 20\n",
      "      16 of 20\n",
      "      17 of 20\n",
      "      18 of 20\n",
      "      19 of 20\n",
      "      20 of 20\n",
      "Computing ensemble means...\n",
      "Computing mean squared error...\n",
      "Iteration 187\n",
      "Train on 26672 samples, validate on 5694 samples\n",
      "Epoch 1/150\n",
      "26672/26672 [==============================] - 4s 133us/step - loss: 0.9093 - regression_loss: 0.2157 - handedness_loss: 0.6932 - val_loss: 0.8081 - val_regression_loss: 0.1126 - val_handedness_loss: 0.6956\n",
      "Epoch 2/150\n",
      "26672/26672 [==============================] - 4s 139us/step - loss: 0.8000 - regression_loss: 0.1054 - handedness_loss: 0.6945 - val_loss: 0.7964 - val_regression_loss: 0.1026 - val_handedness_loss: 0.6939\n",
      "Epoch 3/150\n",
      "26672/26672 [==============================] - 3s 105us/step - loss: 0.7922 - regression_loss: 0.0982 - handedness_loss: 0.6940 - val_loss: 0.7908 - val_regression_loss: 0.0968 - val_handedness_loss: 0.6941\n",
      "Epoch 4/150\n",
      "26672/26672 [==============================] - 4s 141us/step - loss: 0.7876 - regression_loss: 0.0939 - handedness_loss: 0.6937 - val_loss: 0.7854 - val_regression_loss: 0.0922 - val_handedness_loss: 0.6933\n",
      "Epoch 5/150\n",
      "26672/26672 [==============================] - 4s 145us/step - loss: 0.7840 - regression_loss: 0.0905 - handedness_loss: 0.6935 - val_loss: 0.7834 - val_regression_loss: 0.0900 - val_handedness_loss: 0.6935\n",
      "Epoch 6/150\n",
      "26672/26672 [==============================] - 4s 146us/step - loss: 0.7815 - regression_loss: 0.0881 - handedness_loss: 0.6934 - val_loss: 0.7812 - val_regression_loss: 0.0879 - val_handedness_loss: 0.6933\n",
      "Epoch 7/150\n",
      "26672/26672 [==============================] - 4s 142us/step - loss: 0.7797 - regression_loss: 0.0863 - handedness_loss: 0.6933 - val_loss: 0.7796 - val_regression_loss: 0.0864 - val_handedness_loss: 0.6932\n",
      "Epoch 8/150\n",
      "26672/26672 [==============================] - 4s 139us/step - loss: 0.7784 - regression_loss: 0.0853 - handedness_loss: 0.6932 - val_loss: 0.7785 - val_regression_loss: 0.0855 - val_handedness_loss: 0.6930\n",
      "Epoch 9/150\n",
      "26672/26672 [==============================] - 4s 144us/step - loss: 0.7777 - regression_loss: 0.0846 - handedness_loss: 0.6932 - val_loss: 0.7779 - val_regression_loss: 0.0847 - val_handedness_loss: 0.6932\n",
      "Epoch 10/150\n",
      "26672/26672 [==============================] - 4s 145us/step - loss: 0.7772 - regression_loss: 0.0840 - handedness_loss: 0.6932 - val_loss: 0.7777 - val_regression_loss: 0.0846 - val_handedness_loss: 0.6932\n",
      "Epoch 11/150\n",
      "26672/26672 [==============================] - 4s 146us/step - loss: 0.7770 - regression_loss: 0.0838 - handedness_loss: 0.6932 - val_loss: 0.7774 - val_regression_loss: 0.0843 - val_handedness_loss: 0.6931\n",
      "Epoch 12/150\n",
      "26672/26672 [==============================] - 4s 142us/step - loss: 0.7769 - regression_loss: 0.0837 - handedness_loss: 0.6932 - val_loss: 0.7774 - val_regression_loss: 0.0843 - val_handedness_loss: 0.6932\n",
      "Evaluating model with testing data...\n",
      "5694/5694 [==============================] - 0s 16us/step\n",
      "Getting distribution of predictions and covariance matrix...\n",
      "      1 of 20\n",
      "      2 of 20\n",
      "      3 of 20\n",
      "      4 of 20\n",
      "      5 of 20\n",
      "      6 of 20\n",
      "      7 of 20\n",
      "      8 of 20\n",
      "      9 of 20\n",
      "      10 of 20\n",
      "      11 of 20\n",
      "      12 of 20\n",
      "      13 of 20\n",
      "      14 of 20\n",
      "      15 of 20\n",
      "      16 of 20\n",
      "      17 of 20\n",
      "      18 of 20\n",
      "      19 of 20\n",
      "      20 of 20\n",
      "Computing ensemble means...\n",
      "Computing mean squared error...\n",
      "Iteration 188\n",
      "Train on 26812 samples, validate on 5724 samples\n",
      "Epoch 1/150\n",
      "26812/26812 [==============================] - 3s 130us/step - loss: 0.9227 - regression_loss: 0.2618 - handedness_loss: 0.6606 - val_loss: 0.8147 - val_regression_loss: 0.1203 - val_handedness_loss: 0.6944\n",
      "Epoch 2/150\n",
      "26812/26812 [==============================] - 4s 138us/step - loss: 0.8022 - regression_loss: 0.1075 - handedness_loss: 0.6946 - val_loss: 0.7951 - val_regression_loss: 0.1005 - val_handedness_loss: 0.6945\n",
      "Epoch 3/150\n",
      "26812/26812 [==============================] - 3s 130us/step - loss: 0.7915 - regression_loss: 0.0975 - handedness_loss: 0.6939 - val_loss: 0.7896 - val_regression_loss: 0.0959 - val_handedness_loss: 0.6936\n",
      "Epoch 4/150\n",
      "26812/26812 [==============================] - 3s 129us/step - loss: 0.7869 - regression_loss: 0.0932 - handedness_loss: 0.6937 - val_loss: 0.7869 - val_regression_loss: 0.0929 - val_handedness_loss: 0.6940\n",
      "Epoch 5/150\n",
      "26812/26812 [==============================] - 4s 131us/step - loss: 0.7835 - regression_loss: 0.0900 - handedness_loss: 0.6935 - val_loss: 0.7824 - val_regression_loss: 0.0892 - val_handedness_loss: 0.6932\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6/150\n",
      "26812/26812 [==============================] - 4s 144us/step - loss: 0.7808 - regression_loss: 0.0875 - handedness_loss: 0.6932 - val_loss: 0.7808 - val_regression_loss: 0.0876 - val_handedness_loss: 0.6931\n",
      "Epoch 7/150\n",
      "26812/26812 [==============================] - 4s 144us/step - loss: 0.7793 - regression_loss: 0.0860 - handedness_loss: 0.6933 - val_loss: 0.7790 - val_regression_loss: 0.0859 - val_handedness_loss: 0.6931\n",
      "Epoch 8/150\n",
      "26812/26812 [==============================] - 4s 147us/step - loss: 0.7782 - regression_loss: 0.0850 - handedness_loss: 0.6932 - val_loss: 0.7783 - val_regression_loss: 0.0851 - val_handedness_loss: 0.6932\n",
      "Epoch 9/150\n",
      "26812/26812 [==============================] - 4s 148us/step - loss: 0.7775 - regression_loss: 0.0844 - handedness_loss: 0.6932 - val_loss: 0.7776 - val_regression_loss: 0.0845 - val_handedness_loss: 0.6931\n",
      "Epoch 10/150\n",
      "26812/26812 [==============================] - 4s 147us/step - loss: 0.7771 - regression_loss: 0.0840 - handedness_loss: 0.6931 - val_loss: 0.7775 - val_regression_loss: 0.0843 - val_handedness_loss: 0.6931\n",
      "Epoch 11/150\n",
      "26812/26812 [==============================] - 4s 148us/step - loss: 0.7770 - regression_loss: 0.0838 - handedness_loss: 0.6932 - val_loss: 0.7772 - val_regression_loss: 0.0841 - val_handedness_loss: 0.6931\n",
      "Evaluating model with testing data...\n",
      "5724/5724 [==============================] - 0s 16us/step\n",
      "Getting distribution of predictions and covariance matrix...\n",
      "      1 of 20\n",
      "      2 of 20\n",
      "      3 of 20\n",
      "      4 of 20\n",
      "      5 of 20\n",
      "      6 of 20\n",
      "      7 of 20\n",
      "      8 of 20\n",
      "      9 of 20\n",
      "      10 of 20\n",
      "      11 of 20\n",
      "      12 of 20\n",
      "      13 of 20\n",
      "      14 of 20\n",
      "      15 of 20\n",
      "      16 of 20\n",
      "      17 of 20\n",
      "      18 of 20\n",
      "      19 of 20\n",
      "      20 of 20\n",
      "Computing ensemble means...\n",
      "Computing mean squared error...\n",
      "Iteration 189\n",
      "Train on 26952 samples, validate on 5754 samples\n",
      "Epoch 1/150\n",
      "26952/26952 [==============================] - 4s 138us/step - loss: 0.9721 - regression_loss: 0.2781 - handedness_loss: 0.6936 - val_loss: 0.8503 - val_regression_loss: 0.1563 - val_handedness_loss: 0.6940\n",
      "Epoch 2/150\n",
      "26952/26952 [==============================] - 4s 141us/step - loss: 0.8099 - regression_loss: 0.1164 - handedness_loss: 0.6935 - val_loss: 0.7968 - val_regression_loss: 0.1033 - val_handedness_loss: 0.6935\n",
      "Epoch 3/150\n",
      "26952/26952 [==============================] - 4s 146us/step - loss: 0.7910 - regression_loss: 0.0976 - handedness_loss: 0.6934 - val_loss: 0.7897 - val_regression_loss: 0.0953 - val_handedness_loss: 0.6944\n",
      "Epoch 4/150\n",
      "26952/26952 [==============================] - 4s 141us/step - loss: 0.7856 - regression_loss: 0.0922 - handedness_loss: 0.6935 - val_loss: 0.7845 - val_regression_loss: 0.0909 - val_handedness_loss: 0.6936\n",
      "Epoch 5/150\n",
      "26952/26952 [==============================] - 4s 145us/step - loss: 0.7823 - regression_loss: 0.0890 - handedness_loss: 0.6933 - val_loss: 0.7817 - val_regression_loss: 0.0887 - val_handedness_loss: 0.6930\n",
      "Epoch 6/150\n",
      "26952/26952 [==============================] - 4s 137us/step - loss: 0.7809 - regression_loss: 0.0876 - handedness_loss: 0.6932 - val_loss: 0.7800 - val_regression_loss: 0.0868 - val_handedness_loss: 0.6932\n",
      "Epoch 7/150\n",
      "26952/26952 [==============================] - 4s 136us/step - loss: 0.7792 - regression_loss: 0.0860 - handedness_loss: 0.6932 - val_loss: 0.7788 - val_regression_loss: 0.0856 - val_handedness_loss: 0.6932\n",
      "Epoch 8/150\n",
      "26952/26952 [==============================] - 4s 142us/step - loss: 0.7782 - regression_loss: 0.0850 - handedness_loss: 0.6932 - val_loss: 0.7782 - val_regression_loss: 0.0849 - val_handedness_loss: 0.6932\n",
      "Epoch 9/150\n",
      "26952/26952 [==============================] - 4s 146us/step - loss: 0.7777 - regression_loss: 0.0844 - handedness_loss: 0.6932 - val_loss: 0.7779 - val_regression_loss: 0.0847 - val_handedness_loss: 0.6933\n",
      "Evaluating model with testing data...\n",
      "5754/5754 [==============================] - 0s 17us/step\n",
      "Getting distribution of predictions and covariance matrix...\n",
      "      1 of 20\n",
      "      2 of 20\n",
      "      3 of 20\n",
      "      4 of 20\n",
      "      5 of 20\n",
      "      6 of 20\n",
      "      7 of 20\n",
      "      8 of 20\n",
      "      9 of 20\n",
      "      10 of 20\n",
      "      11 of 20\n",
      "      12 of 20\n",
      "      13 of 20\n",
      "      14 of 20\n",
      "      15 of 20\n",
      "      16 of 20\n",
      "      17 of 20\n",
      "      18 of 20\n",
      "      19 of 20\n",
      "      20 of 20\n",
      "Computing ensemble means...\n",
      "Computing mean squared error...\n",
      "Iteration 190\n",
      "Train on 27092 samples, validate on 5784 samples\n",
      "Epoch 1/150\n",
      "27092/27092 [==============================] - 3s 121us/step - loss: 0.9988 - regression_loss: 0.3045 - handedness_loss: 0.6941 - val_loss: 0.9062 - val_regression_loss: 0.2127 - val_handedness_loss: 0.6932\n",
      "Epoch 2/150\n",
      "27092/27092 [==============================] - 4s 130us/step - loss: 0.8426 - regression_loss: 0.1494 - handedness_loss: 0.6932 - val_loss: 0.8104 - val_regression_loss: 0.1171 - val_handedness_loss: 0.6931\n",
      "Epoch 3/150\n",
      "27092/27092 [==============================] - 4s 142us/step - loss: 0.7985 - regression_loss: 0.1052 - handedness_loss: 0.6932 - val_loss: 0.7912 - val_regression_loss: 0.0981 - val_handedness_loss: 0.6933\n",
      "Epoch 4/150\n",
      "27092/27092 [==============================] - 4s 131us/step - loss: 0.7865 - regression_loss: 0.0933 - handedness_loss: 0.6932 - val_loss: 0.7830 - val_regression_loss: 0.0902 - val_handedness_loss: 0.6930\n",
      "Epoch 5/150\n",
      "27092/27092 [==============================] - 4s 146us/step - loss: 0.7811 - regression_loss: 0.0878 - handedness_loss: 0.6932 - val_loss: 0.7794 - val_regression_loss: 0.0864 - val_handedness_loss: 0.6931\n",
      "Epoch 6/150\n",
      "27092/27092 [==============================] - 4s 144us/step - loss: 0.7786 - regression_loss: 0.0854 - handedness_loss: 0.6932 - val_loss: 0.7782 - val_regression_loss: 0.0852 - val_handedness_loss: 0.6931\n",
      "Epoch 7/150\n",
      "27092/27092 [==============================] - 4s 130us/step - loss: 0.7775 - regression_loss: 0.0844 - handedness_loss: 0.6932 - val_loss: 0.7772 - val_regression_loss: 0.0843 - val_handedness_loss: 0.6931\n",
      "Epoch 8/150\n",
      "27092/27092 [==============================] - 4s 134us/step - loss: 0.7771 - regression_loss: 0.0840 - handedness_loss: 0.6932 - val_loss: 0.7771 - val_regression_loss: 0.0841 - val_handedness_loss: 0.6931\n",
      "Evaluating model with testing data...\n",
      "5784/5784 [==============================] - 0s 16us/step\n",
      "Getting distribution of predictions and covariance matrix...\n",
      "      1 of 20\n",
      "      2 of 20\n",
      "      3 of 20\n",
      "      4 of 20\n",
      "      5 of 20\n",
      "      6 of 20\n",
      "      7 of 20\n",
      "      8 of 20\n",
      "      9 of 20\n",
      "      10 of 20\n",
      "      11 of 20\n",
      "      12 of 20\n",
      "      13 of 20\n",
      "      14 of 20\n",
      "      15 of 20\n",
      "      16 of 20\n",
      "      17 of 20\n",
      "      18 of 20\n",
      "      19 of 20\n",
      "      20 of 20\n",
      "Computing ensemble means...\n",
      "Computing mean squared error...\n",
      "Iteration 191\n",
      "Train on 27232 samples, validate on 5814 samples\n",
      "Epoch 1/150\n",
      "27232/27232 [==============================] - 4s 134us/step - loss: 0.9783 - regression_loss: 0.2834 - handedness_loss: 0.6947 - val_loss: 0.8342 - val_regression_loss: 0.1412 - val_handedness_loss: 0.6930\n",
      "Epoch 2/150\n",
      "27232/27232 [==============================] - 4s 133us/step - loss: 0.8085 - regression_loss: 0.1151 - handedness_loss: 0.6935 - val_loss: 0.7998 - val_regression_loss: 0.1065 - val_handedness_loss: 0.6934\n",
      "Epoch 3/150\n",
      "27232/27232 [==============================] - 4s 135us/step - loss: 0.7941 - regression_loss: 0.1008 - handedness_loss: 0.6933 - val_loss: 0.7915 - val_regression_loss: 0.0982 - val_handedness_loss: 0.6935\n",
      "Epoch 4/150\n",
      "27232/27232 [==============================] - 4s 139us/step - loss: 0.7879 - regression_loss: 0.0946 - handedness_loss: 0.6932 - val_loss: 0.7872 - val_regression_loss: 0.0936 - val_handedness_loss: 0.6937\n",
      "Epoch 5/150\n",
      "27232/27232 [==============================] - 3s 126us/step - loss: 0.7837 - regression_loss: 0.0905 - handedness_loss: 0.6932 - val_loss: 0.7823 - val_regression_loss: 0.0893 - val_handedness_loss: 0.6931\n",
      "Evaluating model with testing data...\n",
      "5814/5814 [==============================] - 0s 16us/step\n",
      "Getting distribution of predictions and covariance matrix...\n",
      "      1 of 20\n",
      "      2 of 20\n",
      "      3 of 20\n",
      "      4 of 20\n",
      "      5 of 20\n",
      "      6 of 20\n",
      "      7 of 20\n",
      "      8 of 20\n",
      "      9 of 20\n",
      "      10 of 20\n",
      "      11 of 20\n",
      "      12 of 20\n",
      "      13 of 20\n",
      "      14 of 20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      15 of 20\n",
      "      16 of 20\n",
      "      17 of 20\n",
      "      18 of 20\n",
      "      19 of 20\n",
      "      20 of 20\n",
      "Computing ensemble means...\n",
      "Computing mean squared error...\n",
      "Iteration 192\n",
      "Train on 27372 samples, validate on 5844 samples\n",
      "Epoch 1/150\n",
      "27372/27372 [==============================] - 4s 137us/step - loss: 0.9281 - regression_loss: 0.2469 - handedness_loss: 0.6810 - val_loss: 0.7941 - val_regression_loss: 0.0998 - val_handedness_loss: 0.6943\n",
      "Epoch 2/150\n",
      "27372/27372 [==============================] - 4s 140us/step - loss: 0.7893 - regression_loss: 0.0950 - handedness_loss: 0.6943 - val_loss: 0.7864 - val_regression_loss: 0.0928 - val_handedness_loss: 0.6937\n",
      "Epoch 3/150\n",
      "27372/27372 [==============================] - 4s 142us/step - loss: 0.7859 - regression_loss: 0.0922 - handedness_loss: 0.6936 - val_loss: 0.7859 - val_regression_loss: 0.0919 - val_handedness_loss: 0.6942\n",
      "Epoch 4/150\n",
      "27372/27372 [==============================] - 4s 146us/step - loss: 0.7839 - regression_loss: 0.0906 - handedness_loss: 0.6933 - val_loss: 0.7830 - val_regression_loss: 0.0902 - val_handedness_loss: 0.6929\n",
      "Epoch 5/150\n",
      "27372/27372 [==============================] - 4s 146us/step - loss: 0.7827 - regression_loss: 0.0892 - handedness_loss: 0.6934 - val_loss: 0.7821 - val_regression_loss: 0.0888 - val_handedness_loss: 0.6934\n",
      "Epoch 6/150\n",
      "27372/27372 [==============================] - 4s 146us/step - loss: 0.7813 - regression_loss: 0.0880 - handedness_loss: 0.6934 - val_loss: 0.7818 - val_regression_loss: 0.0882 - val_handedness_loss: 0.6936\n",
      "Epoch 7/150\n",
      "27372/27372 [==============================] - 4s 146us/step - loss: 0.7805 - regression_loss: 0.0871 - handedness_loss: 0.6934 - val_loss: 0.7802 - val_regression_loss: 0.0873 - val_handedness_loss: 0.6930\n",
      "Epoch 8/150\n",
      "27372/27372 [==============================] - 4s 141us/step - loss: 0.7795 - regression_loss: 0.0862 - handedness_loss: 0.6933 - val_loss: 0.7801 - val_regression_loss: 0.0868 - val_handedness_loss: 0.6933\n",
      "Evaluating model with testing data...\n",
      "5844/5844 [==============================] - 0s 16us/step\n",
      "Getting distribution of predictions and covariance matrix...\n",
      "      1 of 20\n",
      "      2 of 20\n",
      "      3 of 20\n",
      "      4 of 20\n",
      "      5 of 20\n",
      "      6 of 20\n",
      "      7 of 20\n",
      "      8 of 20\n",
      "      9 of 20\n",
      "      10 of 20\n",
      "      11 of 20\n",
      "      12 of 20\n",
      "      13 of 20\n",
      "      14 of 20\n",
      "      15 of 20\n",
      "      16 of 20\n",
      "      17 of 20\n",
      "      18 of 20\n",
      "      19 of 20\n",
      "      20 of 20\n",
      "Computing ensemble means...\n",
      "Computing mean squared error...\n",
      "Iteration 193\n",
      "Train on 27512 samples, validate on 5874 samples\n",
      "Epoch 1/150\n",
      "27512/27512 [==============================] - 4s 143us/step - loss: 0.9689 - regression_loss: 0.2750 - handedness_loss: 0.6938 - val_loss: 0.8630 - val_regression_loss: 0.1697 - val_handedness_loss: 0.6932\n",
      "Epoch 2/150\n",
      "27512/27512 [==============================] - 4s 147us/step - loss: 0.8192 - regression_loss: 0.1257 - handedness_loss: 0.6935 - val_loss: 0.7981 - val_regression_loss: 0.1048 - val_handedness_loss: 0.6933\n",
      "Epoch 3/150\n",
      "27512/27512 [==============================] - 4s 145us/step - loss: 0.7907 - regression_loss: 0.0974 - handedness_loss: 0.6933 - val_loss: 0.7882 - val_regression_loss: 0.0951 - val_handedness_loss: 0.6932\n",
      "Epoch 4/150\n",
      "27512/27512 [==============================] - 4s 146us/step - loss: 0.7849 - regression_loss: 0.0916 - handedness_loss: 0.6932 - val_loss: 0.7830 - val_regression_loss: 0.0900 - val_handedness_loss: 0.6929\n",
      "Epoch 5/150\n",
      "27512/27512 [==============================] - 4s 138us/step - loss: 0.7816 - regression_loss: 0.0884 - handedness_loss: 0.6932 - val_loss: 0.7812 - val_regression_loss: 0.0880 - val_handedness_loss: 0.6932\n",
      "Epoch 6/150\n",
      "27512/27512 [==============================] - 4s 139us/step - loss: 0.7797 - regression_loss: 0.0865 - handedness_loss: 0.6932 - val_loss: 0.7791 - val_regression_loss: 0.0860 - val_handedness_loss: 0.6932\n",
      "Epoch 7/150\n",
      "27512/27512 [==============================] - 4s 147us/step - loss: 0.7786 - regression_loss: 0.0854 - handedness_loss: 0.6932 - val_loss: 0.7785 - val_regression_loss: 0.0853 - val_handedness_loss: 0.6931\n",
      "Epoch 8/150\n",
      "27512/27512 [==============================] - 3s 106us/step - loss: 0.7777 - regression_loss: 0.0846 - handedness_loss: 0.6931 - val_loss: 0.7780 - val_regression_loss: 0.0849 - val_handedness_loss: 0.6931\n",
      "Evaluating model with testing data...\n",
      "5874/5874 [==============================] - 0s 16us/step\n",
      "Getting distribution of predictions and covariance matrix...\n",
      "      1 of 20\n",
      "      2 of 20\n",
      "      3 of 20\n",
      "      4 of 20\n",
      "      5 of 20\n",
      "      6 of 20\n",
      "      7 of 20\n",
      "      8 of 20\n",
      "      9 of 20\n",
      "      10 of 20\n",
      "      11 of 20\n",
      "      12 of 20\n",
      "      13 of 20\n",
      "      14 of 20\n",
      "      15 of 20\n",
      "      16 of 20\n",
      "      17 of 20\n",
      "      18 of 20\n",
      "      19 of 20\n",
      "      20 of 20\n",
      "Computing ensemble means...\n",
      "Computing mean squared error...\n",
      "Iteration 194\n",
      "Train on 27652 samples, validate on 5904 samples\n",
      "Epoch 1/150\n",
      "27652/27652 [==============================] - 4s 139us/step - loss: 1.0046 - regression_loss: 0.3228 - handedness_loss: 0.6809 - val_loss: 0.9013 - val_regression_loss: 0.2074 - val_handedness_loss: 0.6931\n",
      "Epoch 2/150\n",
      "27652/27652 [==============================] - 4s 140us/step - loss: 0.8531 - regression_loss: 0.1596 - handedness_loss: 0.6932 - val_loss: 0.8205 - val_regression_loss: 0.1268 - val_handedness_loss: 0.6931\n",
      "Epoch 3/150\n",
      "27652/27652 [==============================] - 4s 146us/step - loss: 0.8005 - regression_loss: 0.1073 - handedness_loss: 0.6932 - val_loss: 0.7892 - val_regression_loss: 0.0957 - val_handedness_loss: 0.6931\n",
      "Epoch 4/150\n",
      "27652/27652 [==============================] - 4s 143us/step - loss: 0.7825 - regression_loss: 0.0894 - handedness_loss: 0.6932 - val_loss: 0.7799 - val_regression_loss: 0.0865 - val_handedness_loss: 0.6931\n",
      "Epoch 5/150\n",
      "27652/27652 [==============================] - 4s 146us/step - loss: 0.7779 - regression_loss: 0.0846 - handedness_loss: 0.6932 - val_loss: 0.7778 - val_regression_loss: 0.0845 - val_handedness_loss: 0.6931\n",
      "Evaluating model with testing data...\n",
      "5904/5904 [==============================] - 0s 16us/step\n",
      "Getting distribution of predictions and covariance matrix...\n",
      "      1 of 20\n",
      "      2 of 20\n",
      "      3 of 20\n",
      "      4 of 20\n",
      "      5 of 20\n",
      "      6 of 20\n",
      "      7 of 20\n",
      "      8 of 20\n",
      "      9 of 20\n",
      "      10 of 20\n",
      "      11 of 20\n",
      "      12 of 20\n",
      "      13 of 20\n",
      "      14 of 20\n",
      "      15 of 20\n",
      "      16 of 20\n",
      "      17 of 20\n",
      "      18 of 20\n",
      "      19 of 20\n",
      "      20 of 20\n",
      "Computing ensemble means...\n",
      "Computing mean squared error...\n",
      "Iteration 195\n",
      "Train on 27792 samples, validate on 5934 samples\n",
      "Epoch 1/150\n",
      "27792/27792 [==============================] - 4s 135us/step - loss: 0.9171 - regression_loss: 0.2352 - handedness_loss: 0.6814 - val_loss: 0.7997 - val_regression_loss: 0.1052 - val_handedness_loss: 0.6945\n",
      "Epoch 2/150\n",
      "27792/27792 [==============================] - 4s 145us/step - loss: 0.7956 - regression_loss: 0.1015 - handedness_loss: 0.6942 - val_loss: 0.7925 - val_regression_loss: 0.0984 - val_handedness_loss: 0.6939\n",
      "Epoch 3/150\n",
      "27792/27792 [==============================] - 4s 138us/step - loss: 0.7900 - regression_loss: 0.0959 - handedness_loss: 0.6942 - val_loss: 0.7882 - val_regression_loss: 0.0944 - val_handedness_loss: 0.6936\n",
      "Epoch 4/150\n",
      "27792/27792 [==============================] - 4s 146us/step - loss: 0.7859 - regression_loss: 0.0925 - handedness_loss: 0.6934 - val_loss: 0.7860 - val_regression_loss: 0.0922 - val_handedness_loss: 0.6937\n",
      "Epoch 5/150\n",
      "27792/27792 [==============================] - 4s 140us/step - loss: 0.7838 - regression_loss: 0.0902 - handedness_loss: 0.6935 - val_loss: 0.7832 - val_regression_loss: 0.0896 - val_handedness_loss: 0.6933\n",
      "Epoch 6/150\n",
      "27792/27792 [==============================] - 4s 136us/step - loss: 0.7818 - regression_loss: 0.0884 - handedness_loss: 0.6934 - val_loss: 0.7818 - val_regression_loss: 0.0880 - val_handedness_loss: 0.6935\n",
      "Epoch 7/150\n",
      "27792/27792 [==============================] - 4s 132us/step - loss: 0.7806 - regression_loss: 0.0872 - handedness_loss: 0.6934 - val_loss: 0.7808 - val_regression_loss: 0.0874 - val_handedness_loss: 0.6932\n",
      "Epoch 8/150\n",
      "27792/27792 [==============================] - 4s 129us/step - loss: 0.7791 - regression_loss: 0.0858 - handedness_loss: 0.6933 - val_loss: 0.7791 - val_regression_loss: 0.0857 - val_handedness_loss: 0.6932\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9/150\n",
      "27792/27792 [==============================] - 4s 142us/step - loss: 0.7782 - regression_loss: 0.0850 - handedness_loss: 0.6931 - val_loss: 0.7783 - val_regression_loss: 0.0850 - val_handedness_loss: 0.6931\n",
      "Epoch 10/150\n",
      "27792/27792 [==============================] - 4s 148us/step - loss: 0.7778 - regression_loss: 0.0846 - handedness_loss: 0.6932 - val_loss: 0.7783 - val_regression_loss: 0.0850 - val_handedness_loss: 0.6931\n",
      "Epoch 11/150\n",
      "27792/27792 [==============================] - 4s 147us/step - loss: 0.7774 - regression_loss: 0.0842 - handedness_loss: 0.6932 - val_loss: 0.7779 - val_regression_loss: 0.0845 - val_handedness_loss: 0.6932\n",
      "Epoch 12/150\n",
      "27792/27792 [==============================] - 4s 141us/step - loss: 0.7772 - regression_loss: 0.0840 - handedness_loss: 0.6932 - val_loss: 0.7776 - val_regression_loss: 0.0843 - val_handedness_loss: 0.6932\n",
      "Epoch 13/150\n",
      "27792/27792 [==============================] - 4s 147us/step - loss: 0.7770 - regression_loss: 0.0839 - handedness_loss: 0.6932 - val_loss: 0.7776 - val_regression_loss: 0.0842 - val_handedness_loss: 0.6932\n",
      "Epoch 14/150\n",
      "27792/27792 [==============================] - 4s 147us/step - loss: 0.7770 - regression_loss: 0.0838 - handedness_loss: 0.6932 - val_loss: 0.7774 - val_regression_loss: 0.0842 - val_handedness_loss: 0.6931\n",
      "Epoch 15/150\n",
      "27792/27792 [==============================] - 4s 147us/step - loss: 0.7769 - regression_loss: 0.0837 - handedness_loss: 0.6932 - val_loss: 0.7775 - val_regression_loss: 0.0842 - val_handedness_loss: 0.6931\n",
      "Epoch 16/150\n",
      "27792/27792 [==============================] - 4s 147us/step - loss: 0.7769 - regression_loss: 0.0837 - handedness_loss: 0.6932 - val_loss: 0.7773 - val_regression_loss: 0.0841 - val_handedness_loss: 0.6931\n",
      "Epoch 17/150\n",
      "27792/27792 [==============================] - 4s 145us/step - loss: 0.7769 - regression_loss: 0.0837 - handedness_loss: 0.6932 - val_loss: 0.7773 - val_regression_loss: 0.0841 - val_handedness_loss: 0.6931\n",
      "Epoch 18/150\n",
      "27792/27792 [==============================] - 4s 146us/step - loss: 0.7769 - regression_loss: 0.0837 - handedness_loss: 0.6932 - val_loss: 0.7773 - val_regression_loss: 0.0841 - val_handedness_loss: 0.6931\n",
      "Epoch 19/150\n",
      "27792/27792 [==============================] - 4s 140us/step - loss: 0.7769 - regression_loss: 0.0837 - handedness_loss: 0.6932 - val_loss: 0.7774 - val_regression_loss: 0.0841 - val_handedness_loss: 0.6931\n",
      "Epoch 20/150\n",
      "27792/27792 [==============================] - 4s 148us/step - loss: 0.7769 - regression_loss: 0.0837 - handedness_loss: 0.6932 - val_loss: 0.7773 - val_regression_loss: 0.0841 - val_handedness_loss: 0.6931\n",
      "Evaluating model with testing data...\n",
      "5934/5934 [==============================] - 0s 17us/step\n",
      "Getting distribution of predictions and covariance matrix...\n",
      "      1 of 20\n",
      "      2 of 20\n",
      "      3 of 20\n",
      "      4 of 20\n",
      "      5 of 20\n",
      "      6 of 20\n",
      "      7 of 20\n",
      "      8 of 20\n",
      "      9 of 20\n",
      "      10 of 20\n",
      "      11 of 20\n",
      "      12 of 20\n",
      "      13 of 20\n",
      "      14 of 20\n",
      "      15 of 20\n",
      "      16 of 20\n",
      "      17 of 20\n",
      "      18 of 20\n",
      "      19 of 20\n",
      "      20 of 20\n",
      "Computing ensemble means...\n",
      "Computing mean squared error...\n",
      "Iteration 196\n",
      "Train on 27932 samples, validate on 5964 samples\n",
      "Epoch 1/150\n",
      "27932/27932 [==============================] - 4s 138us/step - loss: 0.8652 - regression_loss: 0.2019 - handedness_loss: 0.6630 - val_loss: 0.7921 - val_regression_loss: 0.0983 - val_handedness_loss: 0.6939\n",
      "Epoch 2/150\n",
      "27932/27932 [==============================] - 4s 144us/step - loss: 0.7879 - regression_loss: 0.0940 - handedness_loss: 0.6939 - val_loss: 0.7873 - val_regression_loss: 0.0935 - val_handedness_loss: 0.6939\n",
      "Epoch 3/150\n",
      "27932/27932 [==============================] - 3s 109us/step - loss: 0.7856 - regression_loss: 0.0919 - handedness_loss: 0.6938 - val_loss: 0.7858 - val_regression_loss: 0.0915 - val_handedness_loss: 0.6943\n",
      "Epoch 4/150\n",
      "27932/27932 [==============================] - 4s 137us/step - loss: 0.7835 - regression_loss: 0.0898 - handedness_loss: 0.6937 - val_loss: 0.7830 - val_regression_loss: 0.0896 - val_handedness_loss: 0.6935\n",
      "Epoch 5/150\n",
      "27932/27932 [==============================] - 4s 146us/step - loss: 0.7819 - regression_loss: 0.0885 - handedness_loss: 0.6935 - val_loss: 0.7818 - val_regression_loss: 0.0883 - val_handedness_loss: 0.6935\n",
      "Epoch 6/150\n",
      "27932/27932 [==============================] - 4s 146us/step - loss: 0.7808 - regression_loss: 0.0874 - handedness_loss: 0.6933 - val_loss: 0.7808 - val_regression_loss: 0.0877 - val_handedness_loss: 0.6932\n",
      "Epoch 7/150\n",
      "27932/27932 [==============================] - 4s 137us/step - loss: 0.7797 - regression_loss: 0.0865 - handedness_loss: 0.6932 - val_loss: 0.7800 - val_regression_loss: 0.0868 - val_handedness_loss: 0.6931\n",
      "Epoch 8/150\n",
      "27932/27932 [==============================] - 4s 144us/step - loss: 0.7789 - regression_loss: 0.0859 - handedness_loss: 0.6931 - val_loss: 0.7792 - val_regression_loss: 0.0859 - val_handedness_loss: 0.6933\n",
      "Epoch 9/150\n",
      "27932/27932 [==============================] - 4s 146us/step - loss: 0.7786 - regression_loss: 0.0852 - handedness_loss: 0.6934 - val_loss: 0.7783 - val_regression_loss: 0.0852 - val_handedness_loss: 0.6930\n",
      "Epoch 10/150\n",
      "27932/27932 [==============================] - 4s 138us/step - loss: 0.7778 - regression_loss: 0.0847 - handedness_loss: 0.6931 - val_loss: 0.7784 - val_regression_loss: 0.0854 - val_handedness_loss: 0.6931\n",
      "Epoch 11/150\n",
      "27932/27932 [==============================] - 4s 145us/step - loss: 0.7776 - regression_loss: 0.0843 - handedness_loss: 0.6932 - val_loss: 0.7782 - val_regression_loss: 0.0849 - val_handedness_loss: 0.6933\n",
      "Epoch 12/150\n",
      "27932/27932 [==============================] - 4s 141us/step - loss: 0.7773 - regression_loss: 0.0841 - handedness_loss: 0.6932 - val_loss: 0.7778 - val_regression_loss: 0.0847 - val_handedness_loss: 0.6931\n",
      "Epoch 13/150\n",
      "27932/27932 [==============================] - 4s 146us/step - loss: 0.7772 - regression_loss: 0.0839 - handedness_loss: 0.6932 - val_loss: 0.7778 - val_regression_loss: 0.0846 - val_handedness_loss: 0.6932\n",
      "Evaluating model with testing data...\n",
      "5964/5964 [==============================] - 0s 16us/step\n",
      "Getting distribution of predictions and covariance matrix...\n",
      "      1 of 20\n",
      "      2 of 20\n",
      "      3 of 20\n",
      "      4 of 20\n",
      "      5 of 20\n",
      "      6 of 20\n",
      "      7 of 20\n",
      "      8 of 20\n",
      "      9 of 20\n",
      "      10 of 20\n",
      "      11 of 20\n",
      "      12 of 20\n",
      "      13 of 20\n",
      "      14 of 20\n",
      "      15 of 20\n",
      "      16 of 20\n",
      "      17 of 20\n",
      "      18 of 20\n",
      "      19 of 20\n",
      "      20 of 20\n",
      "Computing ensemble means...\n",
      "Computing mean squared error...\n",
      "Iteration 197\n",
      "Train on 28072 samples, validate on 5994 samples\n",
      "Epoch 1/150\n",
      "28072/28072 [==============================] - 4s 133us/step - loss: 0.9836 - regression_loss: 0.3022 - handedness_loss: 0.6810 - val_loss: 0.8570 - val_regression_loss: 0.1627 - val_handedness_loss: 0.6943\n",
      "Epoch 2/150\n",
      "28072/28072 [==============================] - 4s 137us/step - loss: 0.8133 - regression_loss: 0.1189 - handedness_loss: 0.6944 - val_loss: 0.7981 - val_regression_loss: 0.1037 - val_handedness_loss: 0.6944\n",
      "Epoch 3/150\n",
      "28072/28072 [==============================] - 4s 141us/step - loss: 0.7926 - regression_loss: 0.0983 - handedness_loss: 0.6944 - val_loss: 0.7900 - val_regression_loss: 0.0965 - val_handedness_loss: 0.6935\n",
      "Epoch 4/150\n",
      "28072/28072 [==============================] - 4s 130us/step - loss: 0.7870 - regression_loss: 0.0932 - handedness_loss: 0.6939 - val_loss: 0.7860 - val_regression_loss: 0.0924 - val_handedness_loss: 0.6936\n",
      "Epoch 5/150\n",
      "28072/28072 [==============================] - 4s 140us/step - loss: 0.7829 - regression_loss: 0.0897 - handedness_loss: 0.6932 - val_loss: 0.7824 - val_regression_loss: 0.0893 - val_handedness_loss: 0.6931\n",
      "Epoch 6/150\n",
      "28072/28072 [==============================] - 4s 144us/step - loss: 0.7808 - regression_loss: 0.0874 - handedness_loss: 0.6934 - val_loss: 0.7806 - val_regression_loss: 0.0875 - val_handedness_loss: 0.6930\n",
      "Epoch 7/150\n",
      "28072/28072 [==============================] - 4s 128us/step - loss: 0.7793 - regression_loss: 0.0860 - handedness_loss: 0.6933 - val_loss: 0.7790 - val_regression_loss: 0.0859 - val_handedness_loss: 0.6931\n",
      "Epoch 8/150\n",
      "28072/28072 [==============================] - 4s 141us/step - loss: 0.7783 - regression_loss: 0.0850 - handedness_loss: 0.6933 - val_loss: 0.7789 - val_regression_loss: 0.0855 - val_handedness_loss: 0.6934\n",
      "Epoch 9/150\n",
      "28072/28072 [==============================] - 4s 146us/step - loss: 0.7778 - regression_loss: 0.0846 - handedness_loss: 0.6932 - val_loss: 0.7782 - val_regression_loss: 0.0851 - val_handedness_loss: 0.6930\n",
      "Epoch 10/150\n",
      "28072/28072 [==============================] - 4s 144us/step - loss: 0.7774 - regression_loss: 0.0841 - handedness_loss: 0.6932 - val_loss: 0.7780 - val_regression_loss: 0.0847 - val_handedness_loss: 0.6932\n",
      "Evaluating model with testing data...\n",
      "5994/5994 [==============================] - 0s 16us/step\n",
      "Getting distribution of predictions and covariance matrix...\n",
      "      1 of 20\n",
      "      2 of 20\n",
      "      3 of 20\n",
      "      4 of 20\n",
      "      5 of 20\n",
      "      6 of 20\n",
      "      7 of 20\n",
      "      8 of 20\n",
      "      9 of 20\n",
      "      10 of 20\n",
      "      11 of 20\n",
      "      12 of 20\n",
      "      13 of 20\n",
      "      14 of 20\n",
      "      15 of 20\n",
      "      16 of 20\n",
      "      17 of 20\n",
      "      18 of 20\n",
      "      19 of 20\n",
      "      20 of 20\n",
      "Computing ensemble means...\n",
      "Computing mean squared error...\n",
      "Iteration 198\n",
      "Train on 28212 samples, validate on 6024 samples\n",
      "Epoch 1/150\n",
      "28212/28212 [==============================] - 4s 133us/step - loss: 0.8957 - regression_loss: 0.2295 - handedness_loss: 0.6660 - val_loss: 0.7865 - val_regression_loss: 0.0927 - val_handedness_loss: 0.6938\n",
      "Epoch 2/150\n",
      "28212/28212 [==============================] - 4s 144us/step - loss: 0.7855 - regression_loss: 0.0916 - handedness_loss: 0.6939 - val_loss: 0.7851 - val_regression_loss: 0.0925 - val_handedness_loss: 0.6932\n",
      "Epoch 3/150\n",
      "28212/28212 [==============================] - 4s 147us/step - loss: 0.7842 - regression_loss: 0.0905 - handedness_loss: 0.6938 - val_loss: 0.7850 - val_regression_loss: 0.0912 - val_handedness_loss: 0.6942\n",
      "Epoch 4/150\n",
      "28212/28212 [==============================] - 4s 147us/step - loss: 0.7832 - regression_loss: 0.0895 - handedness_loss: 0.6936 - val_loss: 0.7836 - val_regression_loss: 0.0908 - val_handedness_loss: 0.6933\n",
      "Epoch 5/150\n",
      "28212/28212 [==============================] - 4s 147us/step - loss: 0.7821 - regression_loss: 0.0885 - handedness_loss: 0.6936 - val_loss: 0.7822 - val_regression_loss: 0.0890 - val_handedness_loss: 0.6934\n",
      "Epoch 6/150\n",
      "28212/28212 [==============================] - 4s 145us/step - loss: 0.7813 - regression_loss: 0.0879 - handedness_loss: 0.6934 - val_loss: 0.7823 - val_regression_loss: 0.0887 - val_handedness_loss: 0.6941\n",
      "Evaluating model with testing data...\n",
      "6024/6024 [==============================] - 0s 16us/step\n",
      "Getting distribution of predictions and covariance matrix...\n",
      "      1 of 20\n",
      "      2 of 20\n",
      "      3 of 20\n",
      "      4 of 20\n",
      "      5 of 20\n",
      "      6 of 20\n",
      "      7 of 20\n",
      "      8 of 20\n",
      "      9 of 20\n",
      "      10 of 20\n",
      "      11 of 20\n",
      "      12 of 20\n",
      "      13 of 20\n",
      "      14 of 20\n",
      "      15 of 20\n",
      "      16 of 20\n",
      "      17 of 20\n",
      "      18 of 20\n",
      "      19 of 20\n",
      "      20 of 20\n",
      "Computing ensemble means...\n",
      "Computing mean squared error...\n",
      "Iteration 199\n",
      "Train on 28352 samples, validate on 6054 samples\n",
      "Epoch 1/150\n",
      "28352/28352 [==============================] - 4s 142us/step - loss: 1.0001 - regression_loss: 0.3096 - handedness_loss: 0.6902 - val_loss: 0.8592 - val_regression_loss: 0.1653 - val_handedness_loss: 0.6936\n",
      "Epoch 2/150\n",
      "28352/28352 [==============================] - 3s 106us/step - loss: 0.8169 - regression_loss: 0.1229 - handedness_loss: 0.6940 - val_loss: 0.8036 - val_regression_loss: 0.1098 - val_handedness_loss: 0.6937\n",
      "Epoch 3/150\n",
      "28352/28352 [==============================] - 4s 136us/step - loss: 0.7959 - regression_loss: 0.1022 - handedness_loss: 0.6936 - val_loss: 0.7929 - val_regression_loss: 0.0994 - val_handedness_loss: 0.6935\n",
      "Epoch 4/150\n",
      "28352/28352 [==============================] - 4s 136us/step - loss: 0.7881 - regression_loss: 0.0948 - handedness_loss: 0.6933 - val_loss: 0.7864 - val_regression_loss: 0.0930 - val_handedness_loss: 0.6935\n",
      "Epoch 5/150\n",
      "28352/28352 [==============================] - 4s 144us/step - loss: 0.7831 - regression_loss: 0.0898 - handedness_loss: 0.6933 - val_loss: 0.7823 - val_regression_loss: 0.0891 - val_handedness_loss: 0.6933\n",
      "Epoch 6/150\n",
      "28352/28352 [==============================] - 4s 146us/step - loss: 0.7800 - regression_loss: 0.0867 - handedness_loss: 0.6933 - val_loss: 0.7801 - val_regression_loss: 0.0871 - val_handedness_loss: 0.6932\n",
      "Epoch 7/150\n",
      "28352/28352 [==============================] - 4s 147us/step - loss: 0.7784 - regression_loss: 0.0852 - handedness_loss: 0.6932 - val_loss: 0.7787 - val_regression_loss: 0.0857 - val_handedness_loss: 0.6931\n",
      "Epoch 8/150\n",
      "28352/28352 [==============================] - 4s 134us/step - loss: 0.7776 - regression_loss: 0.0844 - handedness_loss: 0.6932 - val_loss: 0.7783 - val_regression_loss: 0.0852 - val_handedness_loss: 0.6932\n",
      "Epoch 9/150\n",
      "28352/28352 [==============================] - 4s 127us/step - loss: 0.7772 - regression_loss: 0.0840 - handedness_loss: 0.6932 - val_loss: 0.7778 - val_regression_loss: 0.0848 - val_handedness_loss: 0.6931\n",
      "Epoch 10/150\n",
      "28352/28352 [==============================] - 4s 133us/step - loss: 0.7770 - regression_loss: 0.0838 - handedness_loss: 0.6932 - val_loss: 0.7777 - val_regression_loss: 0.0847 - val_handedness_loss: 0.6932\n",
      "Epoch 11/150\n",
      "28352/28352 [==============================] - 4s 136us/step - loss: 0.7770 - regression_loss: 0.0838 - handedness_loss: 0.6932 - val_loss: 0.7776 - val_regression_loss: 0.0846 - val_handedness_loss: 0.6932\n",
      "Epoch 12/150\n",
      "28352/28352 [==============================] - 4s 137us/step - loss: 0.7769 - regression_loss: 0.0837 - handedness_loss: 0.6932 - val_loss: 0.7775 - val_regression_loss: 0.0846 - val_handedness_loss: 0.6931\n",
      "Epoch 13/150\n",
      "28352/28352 [==============================] - 4s 141us/step - loss: 0.7769 - regression_loss: 0.0837 - handedness_loss: 0.6932 - val_loss: 0.7776 - val_regression_loss: 0.0846 - val_handedness_loss: 0.6931\n",
      "Evaluating model with testing data...\n",
      "6054/6054 [==============================] - 0s 16us/step\n",
      "Getting distribution of predictions and covariance matrix...\n",
      "      1 of 20\n",
      "      2 of 20\n",
      "      3 of 20\n",
      "      4 of 20\n",
      "      5 of 20\n",
      "      6 of 20\n",
      "      7 of 20\n",
      "      8 of 20\n",
      "      9 of 20\n",
      "      10 of 20\n",
      "      11 of 20\n",
      "      12 of 20\n",
      "      13 of 20\n",
      "      14 of 20\n",
      "      15 of 20\n",
      "      16 of 20\n",
      "      17 of 20\n",
      "      18 of 20\n",
      "      19 of 20\n",
      "      20 of 20\n",
      "Computing ensemble means...\n",
      "Computing mean squared error...\n"
     ]
    }
   ],
   "source": [
    "# how well does the first go generalize?\n",
    "#loss, ensemble_loss = modelPredictionsGeneral(mc_model, testFiles)\n",
    "#print(\"MSE: {:.3}\".format(loss))\n",
    "#print(\"MC-ensemble MSE: {:.3}\".format(ensemble_loss))\n",
    "\n",
    "# keep track of the losses in our three lists\n",
    "#mses.append(loss)\n",
    "#ensemble_mses.append(ensemble_loss)\n",
    "\n",
    "# number of iterations\n",
    "n = 200\n",
    "\n",
    "# when to check how well we generalize\n",
    "check = np.arange(0,n,5)\n",
    "check = np.append(check,n)\n",
    "\n",
    "# exploration vs. exploitation probability\n",
    "x = np.linspace(0,1,num=n)\n",
    "p = np.exp(-2.75*x)\n",
    "\n",
    "for i in range(n):\n",
    "\n",
    "    print(\"Iteration\", i)\n",
    "    \n",
    "    # how many instances to get in our next batch\n",
    "    batchSize = 100\n",
    "    phiStepSize = 1.\n",
    "    thetaStepSize = 1.\n",
    "    y0RStepSize = 1.\n",
    "    \n",
    "    #####################\n",
    "    ### Random\n",
    "    #####################\n",
    "        \n",
    "    startTime = time.time()\n",
    "    \n",
    "    # clear the previous model and session\n",
    "    keras.backend.clear_session()\n",
    "    gc.collect()\n",
    "    del h_mc\n",
    "    del mc_model\n",
    "    \n",
    "    # randomly select the next set of data \n",
    "    batch = np.zeros(shape=(batchSize,4))\n",
    "    phiIndicies = np.arange(0., 360, phiStepSize)\n",
    "    thetaIndicies = np.arange(-90., 90, thetaStepSize)\n",
    "    y0RIndicies = np.arange(-100., 100, y0RStepSize)\n",
    "    \n",
    "    batch[:,0] = np.random.choice( phiIndicies, batchSize, replace=True )\n",
    "    batch[:,1] = np.random.choice( thetaIndicies, batchSize, replace=True )\n",
    "    batch[:,2] = np.random.choice( y0RIndicies, batchSize, replace=True )\n",
    "    batch[:,3] = np.random.choice([0, 1], batchSize, replace=True )\n",
    "    \n",
    "    # also check model limitations - model doesn't work for (phi,theta) (0,0) and (180,0)\n",
    "    ix = np.where( (batch[:,0] == 0) & (batch[:,1] == 0) )\n",
    "    if ( len(ix[0]) > 0 ):\n",
    "        batch[ix,0] == 5.\n",
    "        batch[ix,1] == 5.\n",
    "    ix = np.where( (batch[:,0] == 180) & (batch[:,1] == 0) )\n",
    "    if ( len(ix[0]) > 0 ):\n",
    "        batch[ix,0] == 170\n",
    "        batch[ix,1] == 5.\n",
    "    \n",
    "    newX, newY = getMoreFluxRopes( batch )\n",
    "    \n",
    "    # train the next batch\n",
    "    mc_model = get_model(act=\"relu\")\n",
    "    xTrain, yTrain, xTest, yTest, xVal, yVal = trainTestValidationSplit( dataX,dataY )\n",
    "    xTrain = np.concatenate( (xTrain, newX) )\n",
    "    yTrain = np.concatenate( (yTrain, newY) )\n",
    "    #h_mc = mc_model.fit(xTrain, yTrain, \n",
    "    #                epochs=150, batch_size=128, verbose=1, \n",
    "    #                callbacks=callbacks_list,\n",
    "    #                validation_data=(xVal, yVal))\n",
    "    \n",
    "    ################\n",
    "    from sklearn.preprocessing import LabelEncoder\n",
    "    le = LabelEncoder()\n",
    "    le.fit(yTrain[:,3])\n",
    "    y_train_enc = le.transform(yTrain[:,3])\n",
    "    y_val_enc = le.transform(yVal[:,3])\n",
    "    ################\n",
    "\n",
    "    h_mc = mc_model.fit(xTrain, {\"regression\": yTrain[:,0:3], \"handedness\": y_train_enc}, #yTrain[:,3]}, \n",
    "                    epochs=150, batch_size=128, verbose=1, \n",
    "                    callbacks=callbacks_list,\n",
    "                    validation_data=(xVal,{\"regression\": yVal[:,0:3], \"handedness\": y_val_enc}) )#yVal[:,3]}) )\n",
    "    \n",
    "    dataX = np.concatenate( (xTrain, xTest, xVal, newX) )\n",
    "    dataY = np.concatenate( (yTrain, yTest, yVal, newY) )\n",
    "    \n",
    "    stopTime = time.time()\n",
    "\n",
    "    duration = stopTime-startTime\n",
    "    training_times.append(duration)\n",
    "    \n",
    "    # how well did we do?\n",
    "    duration, mseLoss, bceLoss, ensemble_loss, bce, mc_ensemble_pred = modelPredictionsActiveLearning(mc_model, \n",
    "                                                                                                 xTest, \n",
    "                                                                                                 yTest,\n",
    "                                                                                                 batch_size=3072)\n",
    "\n",
    "    temp1.append(mseLoss)\n",
    "    temp2.append(bceLoss)\n",
    "    temp3.append(ensemble_loss)\n",
    "    training_times.append(duration)\n",
    "    \n",
    "    # are we generalizing better?\n",
    "    #if ( i in check ):\n",
    "    #    loss, ensemble_loss = modelPredictionsGeneral(mc_model, testFiles, batch_size=64)\n",
    "    #    mses.append(loss)\n",
    "    #    ensemble_mses.append(ensemble_loss)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 724,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    }
   ],
   "source": [
    "a = np.zeros(shape=(5,2))\n",
    "ix = np.where( (a[:,0] == 1) & (a[:,1] == 1) )\n",
    "print( len(ix[0]) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 700,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "168.98399999999998\n",
      "21.000600000000006\n",
      "24.0\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n"
     ]
    }
   ],
   "source": [
    "b = np.var(bce, axis=0)\n",
    "b.shape\n",
    "i = np.where(b > 0.75)\n",
    "yTest[5385,:]\n",
    "print( unscale(.4694,0,360) )\n",
    "print( unscale(.61667,-90,90) )\n",
    "print( unscale(.62,-100,100) )\n",
    "#print( np.isnan(bce[]).any() )\n",
    "for i in range(bce.shape[0]):\n",
    "    print( np.isnan(bce[i,:]).any() )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 641,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7fe5f9fedbe0>]"
      ]
     },
     "execution_count": 641,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(temp1)\n",
    "plt.plot(temp2)\n",
    "plt.plot(temp3, color='red')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 616,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/narock/.local/lib/python3.6/site-packages/numpy/lib/histograms.py:824: RuntimeWarning: invalid value encountered in greater_equal\n",
      "  keep = (tmp_a >= first_edge)\n",
      "/home/narock/.local/lib/python3.6/site-packages/numpy/lib/histograms.py:825: RuntimeWarning: invalid value encountered in less_equal\n",
      "  keep &= (tmp_a <= last_edge)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(array([869., 562.,   9.,   6.,   3.,   1.,   1.,   2.,   1.,   2.]),\n",
       " array([0.        , 0.12154324, 0.24308648, 0.36462972, 0.48617296,\n",
       "        0.6077162 , 0.72925944, 0.85080268, 0.97234592, 1.09388916,\n",
       "        1.21543239]),\n",
       " <a list of 10 Patch objects>)"
      ]
     },
     "execution_count": 616,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "var = np.var(bce, axis=0)\n",
    "var.shape\n",
    "plt.hist(var)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 629,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYgAAAEWCAYAAAB8LwAVAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy8li6FKAAAgAElEQVR4nOzdd3zU9f3A8df7kktCSC4EElYCCXuDTAVBwAEu0LZurVurVqu1rtrW1dpatVb7q9u692yRpajsHVbYM4yEFQjZO/f5/fG5QAiX5EJyuZC8n49HHrn7rntzXO79/WwxxqCUUkpV5gh0AEoppRonTRBKKaW80gShlFLKK00QSimlvNIEoZRSyitNEEoppbzSBKFUAxKRcSKSGug4lPKFJgilABHZKSIFIpIrIvtF5F0RiQh0XEoFkiYIpY6ZZIyJAE4DBgO/D3A8SgWUJgilKjHG7Ae+wyYKROQiEVklItkiskdEnig/VkQSRcSIyA0isltEDonIHyrsb+EpjRwRkQ3A8IqvJSJ9RGSOiGSKyHoRmVxh37si8oqIzPCUbBaKSHsRedFzvU0iMtjf74dqvjRBKFWJiMQDFwDbPJvygOuBVsBFwJ0icmml00YDvYBzgMdEpI9n++NAN8/PROCGCq/jBL4FvgfaAvcAH4lIrwrXvQL4IxADFAGLgZWe518CL9T9X6yUd5oglDrmvyKSA+wBDmK/3DHGzDHGrDXGuI0xycAnwNhK5z5pjCkwxqwB1gCDPNuvAJ42xmQYY/YA/6pwzhlABPCMMabYGPMTMBW4usIx3xhjVhhjCoFvgEJjzPvGmDLgM2xVmFJ+oQlCqWMuNcZEAuOA3ti7dETkdBGZLSLpIpIF3FG+r4L9FR7nY7/4ATpiE065XRUedwT2GGPclfbHVXh+oMLjAi/PtSFd+Y0mCKUqMcbMBd4Fnvds+hiYAnQyxkQBrwHi4+X2AZ0qPO9c4fFeoJOIOCrtTzuJsJWqd5oglPLuReA8ERkERAIZxphCERkBXFOL63wO/F5Eoj1tG/dU2LcUW9p4SEScIjIOmAR8Wi//AqXqSBOEUl4YY9KB94HHgLuApzztE49hv/R99SS22igF2xj9QYXXKMYmhAuAQ8ArwPXGmE318W9Qqq5EFwxSSinljZYglFJKeaUJQimllFeaIJRSSnmlCUIppZRXwYEOoL7ExMSYxMTEQIehlFKnlBUrVhwyxsR629dkEkRiYiJJSUmBDkMppU4pIrKrqn1axaSUUsorTRBKKaW80gShlFLKK00QSimlvNIEoZRSyitNEEoppbzSBKGUUsorTRA1WJeWxcx1+wIdhlJKNbgmM1Cuvu3LKuC57zbzzao0jIH1T06kZai+XUqp5kO/8SrJLSrl9bnbeXP+DtwGTuvUilW7M8kuLNEEoZRqVvQbz6O0zM3nSam8MGsLh3KLmDyoIw9O7EXyjh38encm2QWldIgKdJRKKdVwmn2CMMYwZ0s6f5u+kS0HchmWEM2b1w9lcOdoSP2WnWueAx4mKzcXuzSxUko1D80+QaQcyuPmd5fTuXU4r147hPP7t0dMKax6CDY+R5SjHwDZudlAh8AGq5RSDajZJ4iusRG8c+NwRnWLISTYAXl7YOFVcGgR9LgTl2M4bIasvNxAh6qUUg1Ku7kC43q1tclh7wyYORgyk2HUJzD8FaJcrQHIzs8LcJRKKdWwNEEAuEth9aMw50JoEQfnr4DEqwCIjLDtDtn5hYGMUCmlGlyzr2Ki4AAsvAIOzoNut8HQlyC4xdHdwSEuWjoOk5UfFsAglVKq4WmCCAqBogwY+QF0ue7E/U4XUUG5ZBcENXxsSikVQJogQqLhgtXgqCIBOCNxBeWRXRTRsHEppVSAaRsEVJ0cAJwuXEF5ZBWahotHKaUaAU0QNQkK95QgAh2IUko1LE0QNRHBFVxEdrG+VUqp5kW/9XwQFVJKdrE21yilmhdNED5whZSRU+qkzK3tEEqp5kMThA9cITYx5BSWBDgSpZRqOJogfBAVan9nF5QGNhCllGpAmiB84Aqz3WCztQShlGpGNEH4wNXCNlBnFWiCUEo1H5ogfBAV5gQgWxOEUqoZ0QThA1e4nahPE4RSqjnRBOEDV3g4AFl5uiaEUqr50AThg4jwljgoI1sThFKqGdEE4QMJ8UzYp4sGKaWaEU0Qvji6JoQmCKVU86EJwhfBnjUhtJFaKdWMaILwxdE1IXQktVKq+fBrghCR80Vks4hsE5FHvOy/X0Q2iEiyiPwoIgkV9pWJyGrPzxR/xlkjZ6StYip0BzQMpZRqSH6bw1pEgoCXgfOAVGC5iEwxxmyocNgqYJgxJl9E7gSeBa707Cswxpzmr/hqxVOCyC4IdCBKKdVw/FmCGAFsM8bsMMYUA58Cl1Q8wBgz2xiT73m6BIj3Yzwnz+nC5cglSxcNUko1I/78xosD9lR4nurZVpVbgBkVnoeJSJKILBGRS/0RoM8coUQFF1BU5qCwpCygoSilVENpFMukich1wDBgbIXNCcaYNBHpCvwkImuNMdsrnXc7cDtA586d/RkgrhCbGHIKSwlzBvnvtZRSqpHwZwkiDehU4Xm8Z9txRORc4A/AZGNMUfl2Y0ya5/cOYA4wuPK5xpg3jDHDjDHDYmNj6zf6SlyhNkHojK5KqebCnwliOdBDRLqISAhwFXBcbyQRGQy8jk0OBytsjxaRUM/jGOBMoGLjdoNzhQqga0IopZoPv1UxGWNKReRu4DsgCHjbGLNeRJ4CkowxU4DngAjgCxEB2G2MmQz0AV4XETc2iT1TqfdTgytfNEhLEEqp5sKvbRDGmOnA9ErbHqvw+NwqzlsEDPBnbLUVFWoLWzqaWinVXGi/TR+5WoQAkK2jqZVSzYQmCB+5wkMBLUEopZoPTRA+CguNIFSKNUEopZoNTRC+crpwBeWSXVAc6EiUUqpBaILwlTPSs2iQTsiklGoeNEH4qnzRoPyimo9VSqkmQBOErzyLBmVpFZNSqpnQBOGr8hKEdnNVSjUTmiB8Vd5IrYsGKaWaCU0QvvI0UmcXGYwxgY5GKaX8ThOErzxVTGVGyCvWNSGUUk2fJghfBUficuQBOppaKdU8aILwlaeKCXRGV6VU86AJwldBoUQ57RgILUEopZoDTRC14Aq1jdPa1VUp1RxogqiFqDD7dmkVk1KqOdAEUQuuULuqnFYxKaWaA00QtRDpWTRISxBKqeZAE0QtBIVEEhlUSHahJgilVNOnCaI2nJG4gvLJLtBGaqVU06cJojacLiKD8rSKSSnVLGiCqI3gSKKCsrWKSSnVLGiCqA2nC5cjW5cdVUo1C5ogaqN8TQhNEEqpZkATRG2UT/mtjdRKqWZAE0RtOF24gvLILXZTWqYLBymlmjZNELURHElUUC4AOTofk1KqidMEURueEgSgPZmUUk2eJojacLpwOWwJQsdCKKWaOk0QteGMJCq4fFU5rWJSSjVtmiBqo0IJQquYlFJNnSaI2gjWZUeVUs2HJojacAQTFVIG6JoQSqmmTxNELYWHhhAkbq1iUko1eX5NECJyvohsFpFtIvKIl/33i8gGEUkWkR9FJKHCvhtEZKvn5wZ/xlkb4owkylmsVUxKqSbPbwlCRIKAl4ELgL7A1SLSt9Jhq4BhxpiBwJfAs55zWwOPA6cDI4DHRSTaX7HWitOFK7hQezEppZo8f5YgRgDbjDE7jDHFwKfAJRUPMMbMNsbke54uAeI9jycCs4wxGcaYI8As4Hw/xuo7pwtXUIGWIJRSTZ4/E0QcsKfC81TPtqrcAsyozbkicruIJIlIUnp6eh3D9ZFnLIS2QSilmrpG0UgtItcBw4DnanOeMeYNY8wwY8yw2NhY/wRXmdOFy5GjvZiUUk2ePxNEGtCpwvN4z7bjiMi5wB+AycaYotqcGxDBkbgcWWRpG4RSqonzZ4JYDvQQkS4iEgJcBUypeICIDAZexyaHgxV2fQdMEJFoT+P0BM+2wHO6cMkRrWJSSjV5wf66sDGmVETuxn6xBwFvG2PWi8hTQJIxZgq2SikC+EJEAHYbYyYbYzJE5M/YJAPwlDEmw1+x1orThcuRQnGpm8KSMsKcQYGOSCml/MJvCQLAGDMdmF5p22MVHp9bzblvA2/7L7qT5Dy2JkR2QYkmCKVUk9UoGqlPKbomhFKqmdAEUVvBkbiCdE0IpVTTpwmitpyuClVM2pNJKdV0aYKoLacLl0OrmJRSTZ8miNpy6poQSqnmQRNEbTldR9sgdDS1Uqop0wRRW8GRhDpKCQtyk12obRBKqaZLE0RtBUcAEBVSSla+liCUUk2XJojacgRBcAQuZ7E2UiulmjRNECfDGYkruEgThFKqSdMEcTKcLqKCddEgpVTTVm2C8KzTUP74zEr77vZXUI1esO3qqgPllFJNWU0liPsrPP6/SvturudYTh2erq5aglBKNWU1JQip4rG3582H00WUI4ucwhLcbhPoaJRSyi9qShCmisfenjcfwZG4JBO3gbxirWZSSjVNNa0H0VtEkrGlhW6ex3ied/VrZI2Z04XLswJqVkEJkWHOAAeklFL1r6YE0adBojjVOCOJ4hDgmdE1OsDxKKWUH1SbIIwxuyo+F5E2wFnYpUFX+DOwRs3pwhWUDeiMrkqppqumbq5TRaS/53EHYB2299IHInJfA8TXOFWYsE97MimlmqqaGqm7GGPWeR7fBMwyxkwCTqc5d3MNjiSqfNlRTRBKqSaqpgRR8dvvHGA6gDEmB3D7K6hGz+nC5dAShFKqaaupkXqPiNwDpAJDgJkAItICaL5dd5yRRAblI6BTfiulmqyaShC3AP2AG4ErjTGZnu1nAO/4Ma7GzenCIYaIEKNVTEqpJqumXkwHgTu8bJ8NzPZXUI2e0wWASxOEUqoJqzZBiMiU6vYbYybXbziniOBIwC4apN1clVJNVU1tECOBPcAnwFKa8/xLFZWXIJwlOqOrUqrJqilBtAfOA64GrgGmAZ8YY9b7O7BGLbglIEQ5i9ipVUxKqSaq2kZqY0yZMWamMeYGbMP0NmBOs14LAkDEs6pcgVYxKaWarJpKEIhIKHARthSRCPwL+Ma/YZ0CnC5cQfnaSK2UarJqaqR+H+iPHSD3ZIVR1So4kqigHPKKyygpc+MM0tVblVJNS03fatcBPYB7gUUiku35yRGRbP+H14g5Xbgc9i3I0cFySqkmqKZxEHpbXBWnC5dkAXa6jdYtQwIckFJK1S9NACfLGUmUZAA6YZ9Sqmnya4IQkfNFZLOIbBORR7zsP0tEVopIqYhcVmlfmYis9vxUO2AvIJwuXBwGdE0IpVTTVGMvppMlIkHAy9hxFKnAchGZYozZUOGw3dh5nh7wcokCY8xp/oqvzoIjcXlWldMZXZVSTZHfEgQwAthmjNkBICKfApcARxOEMWanZ9+pN3W400UU+wF0NLVSqknyZxVTHHaajnKpnm2+ChORJBFZIiKXejtARG73HJOUnp5el1hrz+nC5cgBtIpJKdU0NeZG6gRjzDDsFB8viki3ygcYY94wxgwzxgyLjY1t2OickbSQIpwO0SompVST5M8EkQZ0qvA83rPNJ8aYNM/vHcAcYHB9BldnwS5EwBXm0F5MSqkmyZ8JYjnQQ0S6iEgIcBXgU28kEYn2TPGBiMQAZ1Kh7aJRcNopvztECjvS8wIcjFJK1T+/JQhjTClwN/AdsBH43BizXkSeEpHJACIyXERSgcuB10WkfJbYPkCSiKzBLkz0TKXeT4HnmfJ7VDys2HWEguKyAAeklFL1y5+9mDDGTMfO41Rx22MVHi/HVj1VPm8RMMCfsdWZJ0GMjivijRVBLE05zLhebQMclFJK1Z/G3EjduHlWlRsRm01IsIMFWw8FOCCllKpfmiBOlqcEEWayGZ4YzYJtmiCUUk2LJoiT5WmkpjSH0d1j2bQ/h4M5hYGNSSml6pEmiJMV1AIkCEqyGdMjBoCFWopQSjUhmiBOloitZirJpm8HF9HhTuZrO4RSqgnRBFEXwZFQkoPDIYzqHsOCrYcwxgQ6KqWUqheaIOrCU4IAGNM9hoM5RWw9mBvgoJRSqn5ogqgLZySU2gn7RnvaIbS7q1KqqdAEURcVShDx0eF0iWmp3V2VUk2GJoi6qJAgAEZ3j2HJjsMUl556y1sopVRlmiDqwtNIXW50jxjyi8tYtftIAINSSqn6oQmiLiqVIEZ2a0OQQ7SaSSnVJGiCqAtnJJTmgrFVSq4wJ4Pio3Q8hFKqSdAEURdOF2Cg9Nh6EKN7xJKcmklWvi4ipJQ6tWmCqAvPhH0Vq5nG9IjBbWDxDi1FKKVObZog6sIz5XfFhurTOrWiZUiQVjMppU55miDqwksJwhnk4IyubbShWil1ytMEURcVpvyuaHSPGHYdzmdPRn4AglJKqfqhCaIuvJQggKPTf2s1k1LqVKYJoi6qSBDdYiNo7wpjwbb0AASllFL1QxNEXXhppAYQEUb3iGHhtsOUuXX6b6XUqUkTRF2UlyBKs0/YNaZHDFkFJaxLy2rgoJRSqn5ogqiLoFBwhJxQggA4s7tn+m/tzXTKc7sNr87ZTnpOUaBDUapBaYKoK2fkCW0QADERofTp4GL+Vm2HONWt2pPJ32du4oPFOwMdilINKjjQAZzyQtpA3m6vu8b0iOGdhSl8tnw3GXklZOQVcTivmMO5xWTk2Z8+HVy8ef1QRKSBA1e+Wr4zA4A5W9K5f0KvAEejVMPRBFFXHc6Hba9DcRaERB23a3yvtrwxbwcPf7UWgDCngzYtQ2kTEUKbiBCiW4bww8YDzFi3nwsHdAhE9MoHy1NsgkhOzeJQbhExEaEBjkiphqEJoq4SroIt/4LU/0HX64/bNbJbG364fyyhwQ7aRIQQHnL8213mNlzw0jyenbmJc/u0IyRYa/waG7fbsHxnBgPioliblsW8Len8fEh8oMNSqkHoN1JdxZwBLRNg16ded3dvG0Gn1uEnJAeAIIfw+wv6sPNwPp8s815NpXz3RdIeNu0/sT2oLjYfyCG7sJTrI98nJlyYvVnblFTzoQmirkRsKWL/LCisfY+lcb1iGdm1DS/9uJWcQp0i/GTlFZXy8FfJ/G36pnq9bnn7w+lmCmPb7mX+1nQd26KaDU0Q9SHhKjClsOerWp8qIvz+wt5k5BXz+twdfgiueViXloXb2G7FGXnF9XbdZSkZtGtRQqeQA4xvuYTM/BJW78mst+sr1ZhpgqgPrQaBqzfs+uSkTh8Y34rJgzry1oId7M8qrOfgmofkVDsgscxtmL52X71c0xjb/jC81R5EYIx8g0Ng7uaD9XJ9pRo7TRD1obya6eA8yE87qUs8OLEXZW7DP2dtqefgmoc1qZnEtWpB97YRTFmzt16uuSejgAPZRYwIWw7OKKIcGQzpGMycLdoOoZoHTRD1JeEqwMDuz0/q9E6tw7l+ZCJfrNjD5v0njsxW1UtOzWJgfBSTB3Vk+c4M9mUV1PmayzztD8OD50PXmwEY1/YAyalZOqpaNQt+TRAicr6IbBaRbSLyiJf9Z4nIShEpFZHLKu27QUS2en5u8Gec9cLVC6IHV9mbyRd3j+9Oy9BgnpmxsR4Da/qO5BWzOyOfAXEuJg/sgDEwdU3dq5mWp2TgCoVeYbsgfjKExzMuYikA87QUoWohM7+YHzceYNXuI6QeyaewpCzQIfnEb+MgRCQIeBk4D0gFlovIFGPMhgqH7QZuBB6odG5r4HFgGGCAFZ5zj/gr3nqRcDWsfghytkNkt1qfHt0yhF+P784zMzaxaNshRnnmc1LVS/ZMiDhoz70kth3NwPiz+DZ5L7ed1bVO112+M4NhMVk4xEDrIRAzkr6HphMT8TPmbEnnF0N1PITyzR++Wce0Sm1jrrBgYiNDPT9h3HRmIkM6RwcoQu/8WYIYAWwzxuwwxhQDnwKXVDzAGLPTGJMMuCudOxGYZYzJ8CSFWcD5foy1fiRcYX/v/uykL3HjqETiWrXgbzM24T4Fu1O63YZdh/Ma9DWTPb2K+ss82PU5kwZ2JDk1i5RDJx9Hek4ROw7lMTxisy0dOl0QMxJH/k7Gdmup3V2Vz7an5zJ93T6uPb0zb984jL//YgAPTOjJzwbH0at9JGVuw08bD/CP7zcHOtQT+DNBxAF7KjxP9Wyrt3NF5HYRSRKRpPT0RlDkb5kAMaPqVM0U5gzidxN6sjYti2+T66extSG9Nm8745+fw8Z99TtgrTprUrPo2soQFZQHmWu4uFcwIvBtHRqrkzztDyOC50DrYXZjmzMAGN/ugHZ3VT57bc52QoMd/Pa8npzdux1XDu/M3Wf34MlL+vPKtUP54o5R3Dy6C4u3H+ZgTuPqxXhKN1IbY94wxgwzxgyLjY0NdDhWwtWQuRYy15/0JS49LY4+HVw8991mikpPjbpKsG0Br87ejtvAuwt3NtjrJqdmMrDVsdrHDnlzGJ7Ymilr9mLMyd3lL9uZQWiwMEAWQeuhdmPrIeAIYUzLZdrdVfkkLbOAb1alcdXwztXO4TV5UEfcBqYl108X7frizwSRBnSq8Dzes83f5wZW58tBHHUqRTgcwqMX9ib1SAH3frKaQ7mnRo+ZV+duJ7e4lDO7t+G/q9PqdcBaVfZnFXIwp4iB4VshoiuEtYV93zF5UEe2Hcxl476T6xG2fGcGp7UzhDhKj5UggkIheghR2fMZ0jlap91QNXpznh38ensN7WE92kXSu31kvXXRri/+TBDLgR4i0kVEQoCrgCk+nvsdMEFEokUkGpjg2db4tWgH7c62g+ZO8u4VYEyPWB46vxc/bjrAuS/M5euVqSd9N9wQ9mUV8O6infx8cDyPT+pHUam7QeaXWpNqq3kGORbbXmTtz4P9s7igX1uCHHJS1XQ5hSVs2JvNiOh9gNjrlosZCRlJjOvRmrVp2t01EE6VHkCHcov4ZNlufj4kjo6tWtR4/OTTOrJqdyZ7MvIbIDrf+C1BGGNKgbuxX+wbgc+NMetF5CkRmQwgIsNFJBW4HHhdRNZ7zs0A/oxNMsuBpzzbTg0JV0HudshYUafL3DWuO9N/M4auMS25//M13PDOclKPNJ4PT0Uv/bAVDNx3bg96totkdPcYPli8i5Kyyv0P6ldyaiZBDujLAjuivf0EKEqnTclGRneP4duTqGZauTsTt4HhYSshqg84I47tjDkDygoZ19FWaWl314a1fGcGg578no+W7gp0KDV6Z2EKxWVufjXWtx6NkwZ2BGhUbY9+bYMwxkw3xvQ0xnQzxjzt2faYMWaK5/FyY0y8MaalMaaNMaZfhXPfNsZ09/y84884612nn4PDedJTb1TUo10kX9wxiscn9SVpZwYT/jmPdxemNKoeTtsO5vJ50h6uPaMznVqHA7Y31v7sQmau2+/X105OzaJnmyBaOAohehB0mGB3eKqZUo8UsHJ37RqTl6dk4BAYwgyIHnr8zpiRAPR1JBETEaqjqhuQMYanp22kqNTNE1PWs2JX4+31nl1YwvuLdnFh/w50i42Agv2w82NIXwyF6V5rFzq1Dmdw51ZMWd1MEkSzFRJtFxLa9RmYut9BBzmEm87swnf3ncWwxNY88e0GLn99MdsONo4R1//4fjMtnEHcPb770W1n925LQptw3l2002+va4xhbVoWg6LtOAiiB0GL9rYkse97JvSza2zUtjfTsp0Z9GvfgojindBm2PE7W3aCFnE4Di9mbM9Y5m3R7q4NZca6/azek8kfL+pDx1YtuPPDFRzM9r3XT5nb8Nb8HXy7Zi/Fpf4t2X6weBc5RaXcOc5Telh5Pyy6FmaNgq/bwpetYMZQWHAlrPkDbH8HijKYPKgjm/bnsPVA4/jb1gThLwlXQUEapC+ot0t2ah3OezcN54UrBrE9PZdJ/7ewwcccVLZmTyYz1u3ntrO60qZCLw2HQ7h+ZCIrdh0hOdU/3UF3Z+STmV/CwJbbwdkKwjvbHR0mwqGFRAYVcXavtkxN3kepj1VdRaVlrN6TyfC2nve19bATD4o5Aw4tZnzvWLIKSli9p/HeyTYVJWVunvtuMz3bRXDTmV14/ZdDySks5a6PVvr0ZV9c6uY3n6ziL9M2cs8nqxj5tx/524yN7KzDWJmqFBSX8faCFMb1iqV/XJRdsz71G0i8DsZOgyEvQpfrbYeKjJWw4e+w9GZY9SAXDeyAo45dtOuTJgh/iZsMQS3q1JvJGxHh50PimfabMYjAn6cGdlqOZ7/bROuWIdw65sReGpcPi6dlSJDfuryu8czgOjBomS09lK/r3WEiuEvgwGwmn9aRQ7lFLE3xrQlrbWoWxaVuRri2295o0aedeFDMSMjbyZh4Nw6BOTX0Ztq0P5vMfP/36GrKPl2+h5RDeTw0sTdBDqF3exd/v2wgSbuO8PS0DdWem19cyi3vLWfa2n08emFv3r1pOMMSo3lrfgrjnp/DdW8tZVryvnorVXy2fDeH84r5dXmJeveXUFYIPe+GuAuh970w7P9g/AyYvBWuLIBOl0Hat7Rt6WRktzZ16qJdnzRB+IszAuImwe4vIGuTrXd0l9bb5eNateCes3vww8YDzAlQf/z5W9NZuO0wd4/vTkToibO2uMKcXD6sE98m7/XLAKDkPZmEBjvoVTbbViuViz0TgsJh33ec3bstEaHBPtfrlk/QNyx4Abj6QnD4iQd52iGi8pIY0jm6ygSxJyOfX3+0kvNfnM/tH6xoFH/wp6K8olJe+mErIxJbc06ftke3Tx7UkdvGdOG9xbv4akWq13Mz84u57q2lLNx2iGcvG8jtZ3VjXK+2vP7LYSx65Gx+d15PUg7l8euPVzLqmZ946YetdWrfKy5188a8HYxIbM3wxNZ2Y8r7ENkT2ozwfpLDCZ1+AUXpcHgpkwZ2ZOfhfNZ6ppAJJE0Q/pR4LRQdgml9bL3jp0743AX/S4QZg+HHcyDpXsg7uR4ZN49OpEtMS56ausHvdaqVud2GZ2duJq5VC649o3OVx10/MoGSMsPHS+u/y2tyahZ924XgLMu2JYhyQaHQbhzs/54wZxAT+rZjxrp9Pg06XJ6SQdfYlsTkzT+x/aFc6yH2j/rQYsb1ij2hu2tuUSnPfbeJc16Yy4+bDnBO77YsS8lghjfM1osAACAASURBVJ8b7H2VXVjC/K3pvDpnOyt3N/7qsTfn7+BQbhGPXNgbKS8lejx8fm9Gdm3Do9+sZV2lL9SD2YVc+foS1qVl88q1Q7liWKfj9rdzhXHPOT2Y99B43rlxOP3jXPzzhy3M2njgpGP93+o09mYVctd4T9tD7k44ONdWKVWK/TgdzwcJhrRvuaB/B5xB0igaqzVB+FPcJDjnJxj1EQz9PxjwJHS7BdqOhRbxtti57VWY0h2W3go522p1+dDgIB67uC870vN4z4+Nwd7MWLeftWlZ3H9eT0KDg47tKM6ElI+O9tLoGhvB+F6xfLhkd72OCi9zG9btzWJQ61y7oWKCAFvNlLMVclOYNKgj2YWlzNtS/ZKwZW5D0q4jjIgPhcKD3tsfAILC7NiIw0sY18ve0c7bko7bbfg8aQ/jn5/Dy7O3c2H/9sx+YBxvXD+M3u0jeXraxgbvw19a5mb93iw+XLKLB75Yw7kvzGXQk9/zy/8s4+8zN3H1G0tYtK32S+U2lPScIt6Yt4ML+rf3OpFdcJCDf18zmDYtQ/jVBys44hmcuetwHr94bRGpR/J556bhnN+/fZWvEeQQxvduy1vXDyOuVQv+Mz/lpGItcxtenbudfh1djO3pmdlh54f2d+K11Z8c0grangVpU4gKdzK2ZyxTk/cFvLeiJgh/EoF24yHxGuh1Nwx4DIb+E0a+B+O+hQkLYdJ26HEHpHwIU3vBol/aKikfje/dlrN7t+WlH7fWqkdHXZSUuXn++830ahfJpYMrTZG15lFYfB2kTT266cYzu3Aot6jeVnoD27U2v7iMgS1TQIIgqt/xB3SYaH/v+47RPWKIDnfWOEp18/4ccgpLGd7aU2VXVYIAW810eDl927UgJiKUj5ftZvLLC3joy2TiWrXg67tG8eJVg+kQ1YIgh/DYpL6kZRbw1vzaLStbXOpmT0Z+raqn9mTk8/7indz4zjIGPPE9F/1rAX/87zp+2nSQhNbh3H9uTz64ZQRzHxxHQptwbn0/iRW7Gucwo3/9uJWiUjcPTuxV5TFtIkJ59bqhpOcW8ZtPV7F+bxaXvbaY3MJSPr7tDM70cVbk4CAHN52ZyLKdGaxNrX31znfr97MjPY+7xnW3JR1jIOUDe0MYkVjzBeImQ9YGyNnOpEEd2Z9deHRN9EDRBBFoLTvZBqtLUqDXb2HP1zCtr+3+lrnWp0s8dnFfikvd/H1mw8wG+UVSKimH8nhwYi+CHBWKzXm7Yftb9vGGvx0tRZzVI4ZusS15Z+HOequHLx9BPTB4hV3uNSjs+AMie9peTfu+wxnk4IIBHfhhw4FqR6mW/zGOCE+2xf1WA6sOIGYklBXgyF7L2J6xrNh1hEM5xbx45Wl8feeoE+52R3WLYWK/drwyZ7vPy8rmFJYw+d8LGPPsbAY9+T3XvrWEZ2ZsYvrafccljdIyN0t3HOZvMzYy4Z9zGfPsbB7733p2HsrjimHxvHTVacx7cDwr/ngu/7lxOPec04MxPWJJaNOSD289nXauMG58e/lJfSn6U8qhPD5ZtpurR3Sia2xEtccO6tSKv1zSn/lbDzH53wsJEuHzX41kUKdWtXrNK4Z3omVIEP9ZULtEbozh5dnb6BrT8lhp5fAyyNliq5d8ET/J/k77lvP6tqOFMyjgU29ogmgsWnSAIc/DJTuh7yOwdwZMH2jbKNwl1Z6aGNOSW8Z04auVqX6vU84qKOHFH7YwNCH6uAZDANb/1f7u8xAcWgzp8wHb8+rGUYkkp2bVetBaVZJTM4kMDaZrybzjG6jLidhSxIGfwF3CdacnEOSQagcaLtuZQYeoMOKLFtoSSXA10yN4GqpJX8x95/bgL5f256cHxnLp4DgcDu91zX+4sC+lZYZnZ9ZcQixzG+79dDVbD+byu/N6cvGgjmQXlPKfBTu466OVjHl2NoP/PIsrXl/MkD/P4so3lvCf+SnERITyx4v68NPvxjLnwfE8eUl/Ljktjs5twk+ovwdoGxnGR7eejquFk1++vdSn1QyNMczacKBeS4TePPfdJkKCHdx7Tk+fjr9ieCduHd2FXu0i+fLOkfRoF1nr13SFOblyeGemJu+r1frwM9btZ/3ebO4Y1+3YTVPK+/bGpfNl1Z9cLqKr/dylTSE8JJhz+7Zj+tp9fp+NoDqaIBqbsFg47a82UfS8G7b8C34619aJV+Pu8d1p5wrliSnr/Vpv+cSU9RzOK+bxSX2P/8LJ2wU73oZut8KAxyE0Ftb/7ejunw+JJzIsmHcWnlz9bmXJqVn07xiOo2D3ie0P5TpMtH3QDy2lb0cX3//2LE7vagcaXvH6Yran5x491BjD8pQMhidGI0eSqm6gLhfeySb1w0vo1Dqc685IIDyk+vW3OrcJ55YxXfh6VRqrakjkz8zYyE+bDvLE5H7cc04P/vqzAXx7z2jWPTmRb+8ezdM/68/5/dpTXOpmQr/2vHrtEFY9dh4f33YGt47pWuMdd0UdW7Xgk9vOIDTYwbVvLWVHhfelImMMczYf5JKXF3Lb+0nc9dFKv/XXX7X7CNPX7ue2MV2JjawwC2ruTtu5I2Ol1/P+eHFfpt87hvhoL73PfHTTmYm4jeH9xTt9Or6wpIynp22kTwcXvxjiWUSqrNh2cY+/1K4l4qu4yXZt++IjTBrYgSP5JSwMYBuRJojGKrS1rXoa+SEcXg4zh9rfVWgZGsyjF/YhOTWLL1bsqfK4upi+dh/frErjnrO7MzC+UtF93dOAQL9HbdfQ3vfBvpmQsepofFcO68SMdfvrvF50UWkZG/dlM7CN5zreShAA7c+xYxn22XkeO7ZqwTs32oGGWw/mcsFL83l1znZKy9zszsjnYE4RwzsCRYerb38AW0KJGWlLSrXw6/HdiY0M5clvN1SZyD9fvoc356dww8gEfnlGwnH7QoODGBAfxbWnJ/DMLwby31+fyfOXD+KCAR2IDHPWKpaKOrcJ56Nbz8AYw7VvLT2hKm7x9sNc/tpibnxnORl5xTz7i4EMT4zmgS/W1JjsassYwzMzNhETEXLiqoBrfm9LhUturrFkfbI6tQ5nQt/2fLxsNwXFNXcqeH3uDtIyC3hiUt9jpYe906E4w/fqpXLxk8GUwd6ZjO0ViyssOKDVTJogGrsu18J5C21D7Kwxdkh+FSYP6siwhGienbmZrIL6/eM5mF3Io9+sZVB81LEBQOVyU2DHO9DtNgj33EH1uAuCI+0oUY8bRiVijOHNeXUrRWzal0NJmWFQhKfrbFUliJBW0Ob0owkCjg00nHX/WYzvFcvfZ27iZ68s4mPPzLMjXJ7YakoQYBNE7o4aS3cVRYQG8+DEXqzek8n/1pw4g/3SHYf5w3/XMqZHDH+6uK/P160P3dtG8MEtp5NfXMY1by1hf1YhK3cf4dq3lnD1m0vYcyTfVqX9bhxXDO/E678cRltXKLe9v4K0zLol/Ypmbz7I0pQMfnNOj+PH1xxebu/KY8dA5hrY9GK9vWZlt4zpQmZ+CV+t9D6+olxaZgGvzt3GRQM7cHrXNsd2pLwPYe3s7MK10WaEHWGdNoXQ4CDO79+e79cfCNgMtpogTgWtB8PEJGg7xg7JX/5rW4StRER4YnI/MvKLefGHLfX28sYYHvoqmYLiMv5xxWk4gyp9bNY/bRNYv98f2xbSCnrcCXu+ONp9t1PrcH4xJJ63F6bw9LSq76BrUj51x8CQVfaPsEXVXRjpMBEykmypoIK2kWG8dt1QXr5mCHszC3h97g6iWjjpQZId49BqQM2BeFaY49CSWsV/2ZB4BsRF8cyMTeQVHRs8uftwPnd8uIJOrcP59zVDCK78PjeAvh1dvHfzCI7klTDhn3P5+SuL2LQvhz9d3Je5D47nujMSCAm2cbVuGcLbNwynqKSMW95dTm5R7QeCZheWsGTHYd6av4P7Pl3FuS/M5Zb3kkhsE87VIyqMrzEGVj1kqy7HTbVVMWsftzcnvnKX2RuW5Mdh70worrrkMywhmoHxUbxdw8SYf51uZzJ49MI+xzYWHYa9UyHhGnBUX+14AnFAx4ttG2RZMZMHxZFbVMrsTYEZDKsJ4lQRFgPjZkCfB2HrK/DT2XaGyEr6x0VxzYjOvL94F1vqacKvT5btYc7mdH5/QW+6t61Ut527A3a8C91vh/BKXV57/xbECRufO7rpbz8fwPUjE3hzfgp3fbTSpyJ8ZWtSs2jTMoS4wsVVVy+V6zARMLD/hxN2iQgXDezArPvHcvWITtx+VlccR5IgaoAdbFeT1kNtb6daVjM5HMLjk/pyILuI1+ZuB2yPpVveW47bwH9uGE5Ui5OvLqqr0zq14u0bhxMXHc5D5/di3kPjuWV0F8KcQScc26NdJP++dghbD+Zy36erfJq4cMHWQ9z98UrGPTebgU98z1VvLOEv0zayZEcGiW1acu85PXjv5hHH34jsnQEH50D/x2yd/rB/25uS5Xf5vu7Kqgdg9SOw7s8w5wL4sjVM7WOrq7a9aXsNuu3nUUS4ZXQXdqTnMbeKGXsXbz/MtOR93Dm2O3EV13vY9Zmt/upay+qlcnGToCQL0uczslsbYiJCA1bNJE1l+P+wYcNMUlJSoMNoGLs+sx/q0NZwwWoIbXPc7oy8YsY/P4dW4U5evmaInTDsZF/qcB4XvGRXUHv/5hEn9tBZcrOd1nzSdgjveOIFlt1pG68npxzdb4zh7YU7+cu0DQyMb8Vb1w87viGyBhP+OZe4VmG80+Is6HUvDH626oPdZfBVDHT6GZzxdvUXNsZ+aSRcASNe9y2YmSNsm8u5c6o+piTX9mapdDd5zyer+H79fmb9diyPTVnHgq2HeP+WEYzq5lu//cbkg8U7+dP/1nPbmC784SLvVWPr0rL4+8xNzN96iJiIUIYlRDMgPop+HV306xhV9WfAXQYzBkFZEVy0HoJC7PZNL8HK+2DUJ5B4VfUBbnkZku6GXvfBwKdsddWhxfbn8JJjJczwzjBxKbRoT0mZmzF/n023ti356NYzjrtcaZmbi/9vATmFpfz4u7HHJ8/vRkJZHlywpvrR01UpzYMv29jxUUNf5Ikp6/l42W6uOz2Bjq3CiI9uQcdW9qdNyxCvvdNqQ0RWGGO81qnWsvyjGoWEK6FlF5g1EtY+BcNeOm5365Yh/OeGYdz98Sp+/soi/nhxH355RkKtP0hlbsP9n68h2CE8d/nAE5NDzjZb19rzbu/JAaDPA7D9Ddj8TxhsSxLld2fx0S2499NVXPryQt69abhP3RLzikrZdjCXC7oHQU5xzSUIRxC0Pxf2fW8TQHXvQe4OKMn0rf2hXMxIO/bDXXpidUJZMWx+EdY9BR0vgtGfHbf7kQt6M2vDfi59ZSEZecU8/bP+DZccjNv2PAuPt1VqdfTLkYlsT8/jzfkpdI2NOK56aNfhPJ7/fgvfrtlLdLiTP13cl+vO6Hz8CPzqpLwHWeth9BfHkgPYz93OD2HlvdBxop1m35u06bDiN7ZaavDzns/E2fYH7OciZ5stoSz7FWx9FQY+iTPIwfWjEnh25mY27sumT4djvZE+Wb6HTftzeOXaIccnh+wtNuEMfu7kkgNAcEv7mU2dAkP+yTWnd2bJjsN8unw3+ZVK3KHBDjq2asHwxGievayGv4WToFVMp6qYEbZReOsrXkdeD0tszfR7xzC6RwyP/W89d364stYN16/N3c6KXUf486X96RDlZUzAur/YL5e+D1d9kchu0PlK2PraCXW+E/u15/NfjaSo1M3PX13kU3e+dWlZuA0MivQ0HnqbbbWyDhPt1OtZ1c/6SYanBNp6aPXHVRRzBpTlnziocf8P9q539cP2rnT357Dnm+MOiWvVgl+d1Y2MvGJuHJXItacf32Op3pQV295k29+GpHtg1mj4IgqmdIXvToeS+qmK/ONFfRjbM5Y//Xcdi7Yd4lBuEY//bx3n/GMuszbs5+7x3Znrqa7yOTmU5kPyn2xng06/OH6fIwhGvGHv/ldV8Rk8sgYWXgmtToMzP7bnVCYCrh7Q/TboeCFse82WVoBrRnSmhTOItxcca+vIzC/mH99vZmTXNlxQeQqPlA9sO0LCNb79+6oSNwnyUiBrPT3bRTLzvrNY/+REVj92HtN+M5o3rx/Gk5P7ccOoRPp2dNHSy2SZ9cIY0yR+hg4dapqdggPGfO4yZvZFVR5SVuY2b8zdbrr9fpo585kfzcpdGT5del1apun+6DRz10crjNvtPvGArC3GfOwwJum3NV8sY40xH2HM2j973b0nI8+c98Ic0+3308xny3ZXe6k35m43CQ9PNemLfm/MJ6HGlJXU/Pq5u+3rb/hH9cetfNCYT0KMKS2q+ZrlclLstTe/bJ/n7TFm/hV22/+6GZM6zZiyYmOmn2bM1x2MKTpy3OnFpWVmzuaDpqS0zPfX9EVZiTGb/21f9xOnjecjjPmspTHfn2nMsl8bk/yUMR8HGfPT+b69jz7IKig2570wx/R/bKbp+6cZpuvvp5lHv042B7IKTu6C6/5q4z4wr+pjVvzO+zF5qcZ8HWfMN/HG5KX59np7v7fX2v7u0U1/+CbZ9Hh0ujmYXWiMMeZP/11rujwy1Wzcl3X8ue4yY/6bYMyPE3x7rerkpdo41v217teqAZBkqvhe1RLEqSysLfT7A+ydBvtmeT3E4RBuO6srX9wxEmPg8tcW88a87dX2zCgsKeO3n60mOjyEpy/t771qat2fwRFafemhXPRAW8Wy+SV7R1hJfHQ4X945ipHd2vDQV8n8+qOV7D7sfUqMNamZxLVqQUxBkh116ksvkZadwNXnuO6uXmUk2SqritUYNV47AcLa28FNG56Fqb0hbQoMeAouWmfn/3c44fT/2O6wqx487nRnkIOxPWPrt8fSvlkw4zRb5+4Ihd73w5mfwsWb4fJsOG8BDP83DPgTDH/FjlepTWNvNVxhTv5zw3BaR4RwVs9Yvv/tWTz9swG0dYXVfHJlhel2sGX8JbYHX1UGPmn/H5b96uidPyW5MNfT2Dt2WtVVoJW1Pxei+trPquf9uOnMLhSXuflwyS427c/mwyW7uO6MBHq3rzQALn2Brbar7dgHb8LjbFVn6pS6X6sOtA3iVNfrXlt9s/J+uGBVlV+YgztHM/03Y3j4q2T+Ot02FPZsF0luYSk5RSXkFJaSXVhKTmEJmfklZOQV8+5Nw2kV7uXLMnsz7PrIzh3Vop1vcfZ9BH4YA9v/A73uOWG3K8zJ2zcO598/beP1eduZteEAN4xK4O7xPYgKP1ZHnpyaxcD4KDiyGuIu9u21wVYzbXsNsjZCVJ8T9xs3ZKyoedbNykRsNdPuz+xP3GQY+iJEdDn+uNZDoPfvYOOzdvLGduNrvrYxsPZJOLLSXjf+EjvSvirZW2HV7yDtWzttw5iv7Uje6urCu99uRydv+JuNuWJX5aqU5NhEV5QOIz84Yc2MTq3DmfugD/++mqz7i62+G/RM9ccFt4Rhr8Dci2yS7vcoLLrGjpUYO9XeoPhKBHr+BpbfYb/w246hW2wEZ/duy4dLdrF4+2FcLZzcf56X6T9S3ofgCOh0ae3+nVWJmwRrn4CCA77/ndUzLUGc6oJCbYNY1jr75VuNqHAnr143hKcu6cfKXUf4ZNlu5mw5eHQWU1dYMH3au5jQtx0vXDHo6FTWJ1j3Z3CEQd+HfI+z7WiIHQ0bn69yBKwzyMFvz+vJnAfGc8lpHXlrQQpjn5/NOwtTKClzcySvmN0Z+Qxs57BfTjU1UFdU/sU/rS/8NMHONltxvfCcbXZajtq0P1S8duthMPZbGPu/E5NDuQGPQ0Q3WHqb15LUcYyBFffBuidtT5tlt8E37eGHcbb3Tl6F9TWKs2DlAzC9HxyYDac9AxdtsD23fGkoHfQXW2e+5lHY+XH1xx5aYtcy2f6mbVNZcLnXMTl1lrPNtq91uwWietd8fNyF0PkKWP8Xz2zC39qusB0vqP1rd/mlbfDefKzzxy2ju3A4r5hlOzP43YReJ944lebZxcE6/cImrPoQPxkwtoYgUKqqezrVfpplG0Q5t9uYWWcZ82WsMUWZPp7ipV3BF3u/s3WjKx+q/bmp006o363OurRMc82bi03Cw1PNuOdmm79O22ASHp5qFi6Zbq+zf07tXr/ggDFr/2LrpcvbCDa+YNsFUj6y2zJW1/7fVRv7f6r5/XOXGbPsTnvcivvt/2/GKmPW/MmYqf2PtSfMGGr3fxlrzEdizOKbjcnfd3JxlRYaM2usbYPx9r6WlRiT/KRts/hvgq3v3/q6jWPBVcaUlZ7c61Zl/hXGfBpuTP5e38/J32fM51E2Jl/axqqz8iHbxpaTYoyxfy8X/WueueDFeaa0zMvfzvLf2Nc9uKhur1uR223MN52MmXtJ/V3TC6ppgwj4F3t9/TTrBGGMMYeT7JfEyXxx+yp/nzFftTVmaj9jSvJqf77bbcz0wbZhfd8PPp7iNj9u3G/Ofn62SXh4qkl4eKrJWvWs/WMs8q3B/QRlxcbs/Mw21pY33H7by5hPw+w+f1tyq/2iPbzixH3uMmOW3HYsiXjtILDZmPXPGDPzdHvc96O9X6u2ijKM+baPMZ+3MiZzw7HtOduN+W6Ufa2F1x5/E7L+Gbt96R3eYz0Z6UvtNdc8VvtzU6cas+qRuies3F32/2jlA0c3ZRUUm+wCL5+P8qS//Dd1e01vlt1lzKctjCnJr/9re2iCaC4W3WDvAHO21/+13WXG/Hiu/bAeWXfy18ndbcy0AcZ8HOxzScIYY0pKy8yHS3aaV2ZvM2bB1cZ80/nkY6jo8ApjFt9o37cfzq6fa9ak6Ijt0TT9tOMTUlmpMYtvsl82q//g2xduSW79fTEbY++Yv2pnSwn5++z/0WeR9s485WPv56x62BPzoyf/ukUZxuz60pilv7LvzVdtjSnOPvnr1Yf5l9tkWZJb9THFWfa9mtLj5G6aapI20763qd/W/7U9NEE0F3lptlg+77L6v3Z5d8Otb9T9WkWZNtl8hDHJT9T+C25qX2PmTKp7HMfFlGH/2BvK7q893Rj/Zp+XlRqz8JeeO+fH6/dLv7YOJ9nP0RfRNp5ZZxmTu7Pq491uY5be7ulK/Jxvr1FaaO+8Vz9qzIzhtjrnI4z5LML+3x6YWz//lro4uMDGtOWVqo9ZcquNvT6rlioqLbTvydLb/XN9U32C0EbqpiS8o+0ttOdL2+2yvqQvsoOVOl9p13uoq5Ao2/Wwyw22l8bSm31v6CwtgOxNtWug9imm6NrN219XnX4GnX5u//1ZG2Hx9bDzAxj4Zxj4xMmPwq0PrYfC6M/tPFOD/gpn/2S7kVZFxPYi6nyl7d207S3vx+WmwJZXYM7FdkqTH8+2k+cFhUC/P9nut5dlwNgpdn3mQIsZZd+Lzf86vkNDubTpdhR9n4cgdqR/YggKtT3w0r49YcLJhqBzMTU1pfl2beuwdjBxmR3VWRfFR2D6abb77Pkr7Zd7fTHGTkOx9gnb/3z0lzVf/3ASfDfcHtv5F9Uf29gV7IOpfcGU2F4wg/4G/R4JdFTHmBqmJqmsrBjmXQL7v4czPV1+0+fbtRH2zoBsO/MpEV3tiOX2E6Dd2IZNzLWV8oFN3uNm2uk8yhVlwPT+ENIGzk/ybXLHk47hI9szC+wiVVH97WzDrQbYx1F9T+hqXBs6F1NzEhxu+40vvg6SH4OuN9k/yJO5IzUGlt4KBXthwqL6TQ5gYxrwOLRMtK/zwxgYN/3YmhLeZK6xv6taA+JU0qIDDP0nLLnJdlXu80CgIzpebT8zQSEw5iuYPcGOQ3CEQmkuOEKg7Tg75qLjhRDZI7AlpNrofIUtFW1+6fgEkXSPHcg3dpp/kwNA4tV2HMSR1ZC5zk7rsvUVKCtfElWgwwQYP7PeX1oTRFOUeLWd4Gz90/YnPN7+gbYbZ3/7mjC2vgp7vrYTnLUZ7r94u95gR47O/4WdG2jUx/bO0psja+xgpIiu3vefarreaAfAVTXR3KkmONwOTlt6G4TG2ITQbjw4fV8CtVEJCrXrmqx9wg4QdfWC3V/Cro/taPnWg/0fgzhsCbv9uce2ucsgd7sd/5S5tv7GXlR+aa1iaqKMsXX1B+fAgTn2d/nKZy3ioO1YOwK4zXA74V1QpakQjqyxX9btzrYLtNS1qsoXmWth3qV2VtVut9lpvEMqLW36w1g70G7CIv/HoxTYkcz/62w/k/3/ZKuWWibaz2A9zIQbaFrF1ByJ2CklovrYO6DKCePAT/YuCGxjZKsBNlm09iSMxdfZ9SZGvtcwyQFsDBeutXdrm17wjIb9Pzs6VcT+G46sgYSrGyYepcBW7yRcBSnvQu42O9XIyPeaRHKoiZYgmitj7BTYh5fbn4zltgG4JNNzgMA5P/o2Z5A/ZKy07RJHVtnGzuEv2zUXpnSB4a9Bj18FJi7VPGWshJmeaVgGPw99fhfYeOqRliDUiURs20R4vO1yCccWTslYDs6owCUHsJPbTVxmF9xJfsz29ombZPc1hQZqdWppPcTeqLiL7Kp0zYSWIFTjl7sDlt0B+2cBAlfk+K1RTqkqGTcgp04PLB9VV4Lwa+WyiJwvIptFZJuInNDBW0RCReQzz/6lIpLo2Z4oIgUistrz85o/41SNXERXGP8djPwQhrygyUEFhjiaXHKoid+qmEQkCHgZOA9IBZaLyBRjTMV1H28BjhhjuovIVcDfgSs9+7YbY3xYT1I1CyLQpZZrNSil6sSfJYgRwDZjzA5jTDHwKXBJpWMuAd7zPP4SOEe8Ll+mlFKqofkzQcQBeyo8T/Vs83qMMaYUyALaePZ1EZFVIjJXRLyuNygit4tIkogkpaen12/0SinVzDXWyfr2AZ2NMYOB+4GPReSECVuMMW8YY4YZY4bFxlazFKNSSqla82eCSAM6VXge79nm9RgRCQaigMPGmCJjzGEAY8wKYDvgZRFYpZRS/uLPBLEc6CEiript6AAABwlJREFUXUQkBLgKmFLpmCnADZ7HlwE/GWOMiMR6GrkRka5AD2CHH2NVSilVid96MRljSkXkbuA7IAh42xizXkSewi5QMQX4D/CBiGwDMrBJBOAs4CkRKQHcwB3GmAx/xaqUUupEOlBOKaWasYANlFNKKXXqajIlCBFJB3bV4RIxwKF6Cqc+aVy1o3HVjsZVO00xrgRjjNduoE0mQdSViCRVVcwKJI2rdjSu2tG4aqe5xaVVTEoppbzSBKGUUsorTRDHvBHoAKqgcdWOxlU7GlftNKu4tA1CKaWUV1qCUEop5ZUmCKWUUl41+wRR06p3DRhHJxGZLSIbRGS9iNzr2f6EiKRVWF3vwgDEtlNE1npeP8mzrbWIzBKRrZ7f0Q0cU68K78lqEckWkfsC9X6JyNsiclBE1lXY5vU9Eutfns9csogMacCYnhORTZ7X/UZEWnm2N+gqjlXEVuX/nYj83vN+bRaRiQ0c12cVYtopIqs92xvkPavmu8H/ny9jTLP9wc4RtR3oCoQAa4C+AYqlAzDE8zgS2AL0BZ4AHgjw+7QTiKm07VngEc/jR4C/B/j/cT+QEKj3Czt/2BBgXU3vEXAhMAMQ4AxgaQPGNAEI9jz+e4WYEiseF6D3y+v/nefvYA0QCnTx/M0GNVRclfb/A3isId+zar4b/P75au4lCF9WvWsQxph9xpiVnsc5wEZOXGCpMam4GuB7wKUBjOUc7BK1dRlJXyfGmHnYCScrquo9ugR431hLgFYi0qEhYjLGfG/s4lwAS7DT8De4Kt6vqlwCfGrsMgApwDbs326DxiUiAlwBfOKP164mpqq+G/z++WruCcKXVe8anIgkAoOBpZ5Nd3uKim83dFWOhwG+F5EVInK7Z1s7Y8w+z+P9QLsAxFXuKo7/ow30+1WuqveosXzubsbeaZbrIjWs4tgAvP3fNZb3awxwwBiztcK2Bn3PKn03+P3z1dwTRKMjIhHAV8B9xphs4FWgG3AadqW9fwQgrNHGmCHABcCvReSsijuNLdcGpL+02LVGJgNfeDY1hvfrBIF8j7wRkT8ApcBHnk0+reLoZ43y/66Cqzn+RqRB3zMv3w1H+evz1dwThC+r3jUYEXFiPwAfGWO+BjDGHDDGlBlj3MD/t3c/r1KVcRzH3x9amEgIWYsWgbaIoKAfJGQZuJDQsCBbGAkVtaiggjYi+Q+4CloEUgSCSASFdVcZBZYZoXC5Xq/Zr6X9uEaFVEKIfFs831PnDs+cunTnHOF+XjDMzHPPnHnuM2fOd85zZr7f15nQoXWXiPgur88Bh7IP881ha16f67tfaSswHRHz2cfBx6tl3BgNut1JegLYBuzMHQtxGVRx7HjtBn+fqlS83A681bT1OWa1fQM9bF/LPUD8l6p3vcj5zTeAMxHxcqu9PXf4EDA3+tgJ92uVpKua25STnHMsrAb4OPBen/1qWfCpbujxGjFujKaAx/LbJncB51tTBRMlaQuwC3gwIi602gev4tjx2k0Bj0haIWld9u14n30DNgNfRsTZpqGvMRu3b6CP7WvSZ+Av9wvljP/XlOi/Z8B+bKQcIs4CM3m5HzgAnMr2KeC6nvt1A+UbJCeB080YAWuAj4BvgA+BqwcYs1XAz8DqVtsg40UJUj8AFylzvk+NGyPKt0tezW3uFHBnj336ljI/3Wxj+3LZh/P1nQGmgQcGGK+xrx2wJ8frK2Brn/3K9v2UypbtZXsZs459w8S3L6faMDOzquU+xWRmZmM4QJiZWZUDhJmZVTlAmJlZlQOEmZlVOUCYVUj6Pa/XSnp0idf90sj9z5Zy/WZLxQHCrNtaYFEBIn9122VBgIiIuxfZJ7NeOECYddsL3Jv5/l+UdIVKTYUTmVTuaQBJmyQdlTQFfJFt72aCw9NNkkNJe4GVub6D2dYcrSjXPadSf2NHa91HJL2tUsvhYP661myi/u2Tjtlyt5tSo2AbQO7oz0fEekkrgGOSPshl7wBuiZKSGuDJiPhF0krghKR3ImK3pOci4rbKc22nJKq7FbgmH/NJ/u124Gbge+AYcA/w6dL/u2b/8BGE2eLcR8lzM0NJubyGkoMH4HgrOAC8IOkkpe7C9a3lxtkIvBklYd088DGwvrXus1ES2c1Qpr7MJspHEGaLI+D5iDi8oFHaBPwxcn8zsCEiLkg6Alz5P573z9btS/i9az3wEYRZt98oZR4bh4FnM/0ykm7MLLejVgO/ZnC4iVL6sXGxefyIo8COPM9xLaX8Zd9ZS83+5k8hZt1mgUs5VbQfeIUyvTOdJ4p/ol5u9X3gGUlnKBlIP2/97TVgVtJ0ROxstR8CNlAy5wawKyJ+zABj1jtnczUzsypPMZmZWZUDhJmZVTlAmJlZlQOEmZlVOUCYmVmVA4SZmVU5QJiZWdVf5N4MX7RTagcAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# write results to a file\n",
    "xa = np.arange(41)\n",
    "plt.plot(xa*5, ensemble_mses, color='orange')\n",
    "plt.plot(xa*5, mses)\n",
    "plt.ylabel('MSE')\n",
    "plt.xlabel('Iteration')\n",
    "plt.title('Random')\n",
    "\n",
    "file = open(\"/home/narock/data/fluxropes_results/random_100_2_outputs.txt\", \"w\")\n",
    "for i in range( len(mses) ):\n",
    "    line = str(mses[i]) + ',' + str(ensemble_mses[i]) + '\\n'\n",
    "    file.write(line)\n",
    "file.close()\n",
    "\n",
    "file = open(\"/home/narock/data/fluxropes_results/random_times_100_2_outputs.txt\", \"w\")\n",
    "for i in range( len(training_times) ):\n",
    "    line =  str(training_times[i]) + '\\n'\n",
    "    file.write(line)\n",
    "file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 458,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9016511679100696\n",
      "0.13194313833133792\n"
     ]
    }
   ],
   "source": [
    "print(ensemble_mses[-1])\n",
    "print(np.min(ensemble_mses))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 459,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.collections.PathCollection at 0x7fe5e046c780>"
      ]
     },
     "execution_count": 459,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.scatter(dataY[:,0],dataY[:,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 465,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.        , 0.        , 0.47627284, 0.        , 0.38301203,\n",
       "       0.        , 0.57649304, 0.3642352 , 0.58023069, 0.        ])"
      ]
     },
     "execution_count": 465,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mc_ensemble_pred[0:10,3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 504,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5, 1.0, 'Random')"
      ]
     },
     "execution_count": 504,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "ts = []\n",
    "for i in range(len(temp1)):\n",
    "    ts.append( temp1[i][2] )\n",
    "plt.plot(ts, color='orange')\n",
    "#plt.plot(xa*5, mses)\n",
    "plt.ylabel('MSE')\n",
    "plt.xlabel('Iteration')\n",
    "plt.title('Random')\n",
    "#plt.xlim(0,50)\n",
    "#plt.ylim(-10,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 438,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-46.30219268798828"
      ]
     },
     "execution_count": 438,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "temp1[100][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 260,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5, 1.0, 'Trace')"
      ]
     },
     "execution_count": 260,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "mses = []\n",
    "ensemble_mses = []\n",
    "file = open(\"/home/narock/data/fluxropes_results/trace_100_-1.txt\", \"r\")\n",
    "for line in file:\n",
    "    parts = line.split(\",\")\n",
    "    mses.append( float(parts[0].strip()) )\n",
    "    ensemble_mses.append( float(parts[1].strip()) )\n",
    "xa = np.arange(41)\n",
    "plt.plot(xa*5, ensemble_mses, color='orange')\n",
    "plt.plot(xa*5, mses)\n",
    "plt.ylabel('MSE')\n",
    "plt.xlabel('Iteration')\n",
    "plt.title('Trace')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Obsolete"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PredictGenerator(Sequence):\n",
    "    \n",
    "    def __init__(self, files, batch_size=32, shuffle=True):\n",
    "        \n",
    "        self.batch_size = batch_size\n",
    "        self.files = files\n",
    "        self.shuffle = shuffle\n",
    "        self.on_epoch_end()\n",
    "\n",
    "    def __len__(self):\n",
    "        \n",
    "        'Denotes the number of batches per epoch'\n",
    "\n",
    "        'If the batch size doesnt divide evenly then add 1'\n",
    "        diff = (len(self.files) / self.batch_size) - np.floor((len(self.files) / self.batch_size))\n",
    "        if ( diff > 0 ):\n",
    "            return int(np.floor(len(self.files) / self.batch_size))+1\n",
    "        else:\n",
    "            return int(np.floor(len(self.files) / self.batch_size))\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        \n",
    "        'Generate one batch of data'\n",
    "        # Generate indexes of the batch\n",
    "        indexes = self.indexes[index*self.batch_size:(index+1)*self.batch_size]\n",
    "\n",
    "        # get list of files\n",
    "        fileList = [self.files[k] for k in indexes]\n",
    "\n",
    "        # Generate data\n",
    "        batch_x, batch_y = readCSV(fileList)\n",
    "\n",
    "        return batch_x\n",
    "\n",
    "    def on_epoch_end(self):\n",
    "        \n",
    "        'Updates indexes after each epoch'\n",
    "        self.indexes = np.arange(len(self.files))\n",
    "        if self.shuffle == True:\n",
    "            np.random.shuffle(self.indexes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [],
   "source": [
    "#def modelPredictionsGeneral(model, evaluateGen, predictGen, n, qs):\n",
    "    \n",
    "#    T = 20\n",
    "#    d = 4\n",
    "\n",
    "#    mc_predictions = np.zeros(shape=(T,n,d))\n",
    "#    mc_ensemble_pred = np.zeros(shape=(n,d))\n",
    "    \n",
    "#    print(\"Evaluating model with testing data...\")\n",
    "#    loss = model.evaluate_generator(evaluateGen, verbose=1, workers=8, max_queue_size=qs, \n",
    "#                                    use_multiprocessing=True)\n",
    "    \n",
    "#    count = 1\n",
    "#    print(\"Getting distribution of predictions...\")\n",
    "#    for i in range(T):\n",
    "#        print(\"     \",count,\"of\",T)\n",
    "#        predictions = model.predict_generator(predictGen, verbose=1, workers=8, \n",
    "#                                              max_queue_size=qs, use_multiprocessing=True)\n",
    "#        mc_predictions[i,:,:] = predictions\n",
    "#        count += 1\n",
    "        \n",
    "#    print(\"Computing ensemble means...\")\n",
    "#    mc_ensemble_pred = np.mean( mc_predictions, axis=0 )\n",
    "    \n",
    "#    # Evaluate the ensemble model\n",
    "#    print(\"Computing mean squared error...\")\n",
    "#    ensemble_loss = mean_squared_error(mc_ensemble_pred, yTest)\n",
    "\n",
    "#    return loss, ensemble_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7fea8d0032e8>]"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(ensemble_mses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'indicies' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-78-b2f72755d989>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mindicies\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'indicies' is not defined"
     ]
    }
   ],
   "source": [
    "indicies.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7f7659edaeb8>]"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(mses)\n",
    "plt.plot(ensemble_mses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "20"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(trace)\n",
    "len(trace)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7f0cf1957f60>]"
      ]
     },
     "execution_count": 199,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# batch size 1000, 25 iterations, random selection\n",
    "plt.plot(mses)\n",
    "plt.plot(ensemble_mses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6234.101770877838"
      ]
     },
     "execution_count": 200,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(prediction_times)\n",
    "np.sum(prediction_times)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# batch size 1000, 25 iterations, rehearsal method, changing weights\n",
    "plt.plot(mses)\n",
    "plt.plot(ensemble_mses)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
