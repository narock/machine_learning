{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "import shutil\n",
    "import random\n",
    "import numpy as np\n",
    "\n",
    "import keras\n",
    "from keras import backend as K\n",
    "from keras.utils import Sequence\n",
    "from keras.callbacks.callbacks import History\n",
    "from keras.models import Sequential, Model, Input\n",
    "from keras.layers import Dense, Dropout, Flatten \n",
    "from keras.layers import Conv1D, Conv2D, MaxPooling2D\n",
    "from keras.layers.convolutional import MaxPooling1D\n",
    "\n",
    "from pathlib import Path\n",
    "from os import listdir\n",
    "from os.path import isfile, join\n",
    "from scipy.spatial import distance\n",
    "\n",
    "import tensorflow as tf\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Path setup and configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {},
   "outputs": [],
   "source": [
    "nhours = 27 # how many time series points (hours) used in fluxrope simulations\n",
    "d1 = 0.25 # dropout percentage - first dropout layer\n",
    "d2 = 0.25 # dropout percentage - second dropout layer\n",
    "csvPath = \"/data/pool/fluxropes/\"\n",
    "npzPath = \"/data/pool/npz/\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Functions to read data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {},
   "outputs": [],
   "source": [
    "def readNPZ(file):\n",
    "    \n",
    "    npzfile = np.load(file)\n",
    "    return npzfile['x'], npzfile['y']\n",
    "\n",
    "    return dataX, dataY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {},
   "outputs": [],
   "source": [
    "def readCSV(dir, files):\n",
    "    \n",
    "    count = len(files)\n",
    "    dataX = np.zeros(shape=(count, nhours, 3))\n",
    "    dataY = np.zeros(shape=(count, 5))\n",
    "\n",
    "    index = 0\n",
    "    for f in files:\n",
    "        \n",
    "        # extract the output value from the file name\n",
    "        parts = f.split(\"_\")\n",
    "        bmag = float(parts[1])\n",
    "        phi = float(parts[2])\n",
    "        theta = float(parts[3])\n",
    "        y0R = float(parts[4])\n",
    "        HH = parts[5].split(\".\")\n",
    "        HH = float(HH[0])\n",
    "        \n",
    "        # change handedness from -1 or 1 to 0 or 1 to align with \n",
    "        # neural network sigmoid function\n",
    "        if (HH == -1):\n",
    "            HH = 0\n",
    "                    \n",
    "        # normalize the output value\n",
    "        dataY[index, 0] = bmag\n",
    "        dataY[index, 1] = phi\n",
    "        dataY[index, 2] = theta\n",
    "        dataY[index, 3] = y0R\n",
    "        dataY[index, 4] = HH\n",
    "                    \n",
    "        # read the data\n",
    "        bx = []\n",
    "        by = []\n",
    "        bz = []\n",
    "        openFile = open(join(dir,f), \"r\")\n",
    "        for line in openFile:\n",
    "            parts = line.split(\",\")\n",
    "            bx.append(float(parts[0]))\n",
    "            by.append(float(parts[1]))\n",
    "            bz.append(float(parts[2]))\n",
    "        openFile.close()\n",
    "        \n",
    "        dataX[index, :, 0] = bx\n",
    "        dataX[index, :, 1] = by\n",
    "        dataX[index, :, 2] = bz\n",
    "        \n",
    "        index += 1\n",
    "\n",
    "    return dataX, dataY"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read fluxrope files and split data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 259,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training files: 544118\n",
      "Test files: 181373\n",
      "Validation files: 181373\n",
      "\n",
      "Total number of files: 906864\n"
     ]
    }
   ],
   "source": [
    "allFiles = [f for f in listdir(csvPath) if isfile(join(csvPath, f))]\n",
    "random.shuffle(allFiles)\n",
    "\n",
    "# Distribution is - 60% Training, 20% Testing, 20% Validation\n",
    "train = allFiles[ : int(len(allFiles) * 0.6)]\n",
    "test = allFiles[int(len(allFiles) * 0.6) : int(len(allFiles) * 0.8)]\n",
    "validation = allFiles[int(len(allFiles) * 0.8) : ]\n",
    "\n",
    "print(\"Training files:\", len(train))\n",
    "print(\"Test files:\", len(test))\n",
    "print(\"Validation files:\", len(validation))\n",
    "print()\n",
    "print(\"Total number of files:\", len(allFiles))\n",
    "\n",
    "total = len(test) + len(train) + len(validation)\n",
    "assert total == len(allFiles)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Make npz files - this makes evaluation much faster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 260,
   "metadata": {},
   "outputs": [],
   "source": [
    "def makeNpzFiles(text, csvP, npzP, fileList, stepSize):\n",
    "    \n",
    "    # make sure there are no npz files left over from a previous run\n",
    "    c = 0\n",
    "    for filename in os.listdir(npzP):\n",
    "        file_path = os.path.join(npzP, filename)\n",
    "        try:\n",
    "            if os.path.isfile(file_path) or os.path.islink(file_path):\n",
    "                os.unlink(file_path)\n",
    "                c += 1\n",
    "        except Exception as e:\n",
    "            print('Failed to delete %s. Reason: %s' % (file_path, e))\n",
    "\n",
    "    print(\"Deleted\", c, \"npz files in\", npzP)\n",
    "        \n",
    "    loops = int(np.ceil(len(fileList)/stepSize))\n",
    "    index1 = 0\n",
    "    index2 = stepSize\n",
    "    numFiles = 0\n",
    "    for l in range(loops):\n",
    "        files = fileList[index1:index2]\n",
    "        x, y = readCSV(csvP, files)\n",
    "        if (l < 10):\n",
    "            counter = '00' + str(l)\n",
    "        elif ( (l >= 10) and (l < 100) ):\n",
    "            counter = '0' + str(l)\n",
    "        else:\n",
    "            counter = str(l)\n",
    "        outfile = npzP + 'fluxropes_' + text + '_' + counter + '.npz'\n",
    "        np.savez(outfile, x=x, y=y)\n",
    "        index1 = index2\n",
    "        index2 += stepSize\n",
    "        numFiles += 1\n",
    "    print(\"Created\", numFiles, \"npz files in\", npzP)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 261,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Deleted 128 npz files in /data/pool/npz/baseline_test/\n",
      "Created 114 npz files in /data/pool/npz/baseline_test/\n",
      "Deleted 0 npz files in /data/pool/npz/baseline_train/\n",
      "Created 2126 npz files in /data/pool/npz/baseline_train/\n",
      "Deleted 0 npz files in /data/pool/npz/baseline_validation/\n",
      "Created 114 npz files in /data/pool/npz/baseline_validation/\n",
      "\n",
      "Data generation: 39.59 seconds\n"
     ]
    }
   ],
   "source": [
    "startTime = time.time()\n",
    "\n",
    "makeNpzFiles('test', csvPath, npzPath+'baseline_test/', test, 1600)\n",
    "makeNpzFiles('train', csvPath, npzPath+'baseline_train/', train, 256)\n",
    "makeNpzFiles('val', csvPath, npzPath+'baseline_validation/', validation, 1600)\n",
    "\n",
    "# arrays now points to npz files\n",
    "test = [f for f in listdir(npzPath+'baseline_test/') if isfile(join(npzPath+'baseline_test/', f))]\n",
    "train = [f for f in listdir(npzPath+'baseline_train/') if isfile(join(npzPath+'baseline_train/', f))]\n",
    "validation = [f for f in listdir(npzPath+'baseline_validation/') if isfile(join(npzPath+'baseline_validation/', f))]\n",
    "\n",
    "random.shuffle(test)\n",
    "random.shuffle(train)\n",
    "random.shuffle(validation)\n",
    "\n",
    "# convert from lists to numpy arrays\n",
    "test = np.array(test)\n",
    "train = np.array(train)\n",
    "validation = np.array(validation)\n",
    "\n",
    "stopTime = time.time()\n",
    "duration = stopTime-startTime\n",
    "print()\n",
    "print(\"Data generation:\", round(duration, 2), \"seconds\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Helper functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "def addNoise(vector):\n",
    "    noise = np.random.normal(0.25, 1, len(vector))\n",
    "    return vector+noise"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Keras data generators for csv and npz files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CsvDataGenerator(Sequence):\n",
    "    \n",
    "    def __init__(self, d, files, batch_size=256, shuffle=True):\n",
    "        \n",
    "        self.batch_size = batch_size\n",
    "        self.files = files\n",
    "        self.dir = d\n",
    "        self.shuffle = shuffle\n",
    "        self.on_epoch_end()\n",
    "\n",
    "    def __len__(self):\n",
    "        \n",
    "        'Denotes the number of batches per epoch'\n",
    "\n",
    "        'If the batch size doesnt divide evenly then add 1'\n",
    "        diff = (len(self.files) / self.batch_size) - np.floor((len(self.files) / self.batch_size))\n",
    "        if ( diff > 0 ):\n",
    "            return int(np.floor(len(self.files) / self.batch_size))+1\n",
    "        else:\n",
    "            return int(np.floor(len(self.files) / self.batch_size))\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        \n",
    "        'Generate one batch of data'\n",
    "        # Generate indexes of the batch\n",
    "        indexes = self.indexes[index*self.batch_size:(index+1)*self.batch_size]\n",
    "\n",
    "        # get list of files\n",
    "        files = [self.files[k] for k in indexes]\n",
    "        \n",
    "        # Generate data\n",
    "        data_x, data_y = readCSV(self.dir, files)\n",
    "        \n",
    "        p = np.zeros( shape=(data_y.shape[0],2) )\n",
    "        p[:,0] = np.sin( np.radians(data_y[:,1]) )\n",
    "        p[:,1] = np.cos( np.radians(data_y[:,1]) )\n",
    "        \n",
    "        t = np.zeros( shape=(data_y.shape[0],2) )\n",
    "        t[:,0] = np.sin( np.radians(data_y[:,2]) )\n",
    "        t[:,1] = np.cos( np.radians(data_y[:,2]) )\n",
    "        \n",
    "        le = LabelEncoder()\n",
    "        le.fit(data_y[:,4])\n",
    "        y_enc = le.transform(data_y[:,4])\n",
    "\n",
    "        batch_y = {\"bmag\": data_y[:,0], \"phi\": p, \"theta\": t, \"y0r\": data_y[:,3], \"handedness\": y_enc}\n",
    "                \n",
    "        return data_x, batch_y\n",
    "\n",
    "    def on_epoch_end(self):\n",
    "        \n",
    "        'Updates indexes after each epoch'\n",
    "        self.indexes = np.arange(len(self.files))\n",
    "        if self.shuffle == True:\n",
    "            np.random.shuffle(self.indexes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NpzDataGenerator(Sequence):\n",
    "    \n",
    "    def __init__(self, d, files, batch_size=1, shuffle=True):\n",
    "        \n",
    "        self.batch_size = batch_size\n",
    "        self.files = files\n",
    "        self.dir = d\n",
    "        self.shuffle = shuffle\n",
    "        self.on_epoch_end()\n",
    "\n",
    "    def __len__(self):\n",
    "        \n",
    "        'Denotes the number of batches per epoch'\n",
    "\n",
    "        'If the batch size doesnt divide evenly then add 1'\n",
    "        diff = (len(self.files) / self.batch_size) - np.floor((len(self.files) / self.batch_size))\n",
    "        if ( diff > 0 ):\n",
    "            return int(np.floor(len(self.files) / self.batch_size))+1\n",
    "        else:\n",
    "            return int(np.floor(len(self.files) / self.batch_size))\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        \n",
    "        'Generate one batch of data'\n",
    "        # Generate indexes of the batch\n",
    "        indexes = self.indexes[index*self.batch_size:(index+1)*self.batch_size]\n",
    "\n",
    "        # get list of files\n",
    "        #files = [self.files[k] for k in indexes]\n",
    "        file = self.files[indexes[0]]\n",
    "        \n",
    "        # Generate data\n",
    "        npzfile = np.load(self.dir + file)\n",
    "        data_x = npzfile['x']\n",
    "        data_y = npzfile['y']\n",
    "            \n",
    "        p = np.zeros( shape=(data_y.shape[0],2) )\n",
    "        p[:,0] = np.sin( np.radians(data_y[:,1]) )\n",
    "        p[:,1] = np.cos( np.radians(data_y[:,1]) )\n",
    "        \n",
    "        t = np.zeros( shape=(data_y.shape[0],2) )\n",
    "        t[:,0] = np.sin( np.radians(data_y[:,2]) )\n",
    "        t[:,1] = np.cos( np.radians(data_y[:,2]) )\n",
    "        \n",
    "        le = LabelEncoder()\n",
    "        le.fit(data_y[:,4])\n",
    "        y_enc = le.transform(data_y[:,4])\n",
    "\n",
    "        batch_y = {\"bmag\": data_y[:,0], \"phi\": p, \"theta\": t, \"y0r\": data_y[:,3], \"handedness\": y_enc}\n",
    "        \n",
    "        return data_x, batch_y\n",
    "\n",
    "    def on_epoch_end(self):\n",
    "        \n",
    "        'Updates indexes after each epoch'\n",
    "        self.indexes = np.arange(len(self.files))\n",
    "        if self.shuffle == True:\n",
    "            np.random.shuffle(self.indexes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1-D CNN Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Custom loss function - angles\n",
    "\n",
    "def angle_loss(y_true, y_pred):\n",
    "    return K.sum(K.square(y_pred - y_true), axis=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define model\n",
    "    \n",
    "input_shape = (nhours, 3)\n",
    "\n",
    "def get_model(d1=0.25, d2=0.5, act=\"relu\", dropoutTraining=True):\n",
    "    \n",
    "    kernel_size = 5\n",
    "    inp = Input(input_shape, name=\"input\")\n",
    "    x = Conv1D(32, kernel_size=kernel_size, activation=act, padding=\"same\")(inp)\n",
    "    x = Conv1D(64, kernel_size=kernel_size, activation=act, padding=\"same\")(x)\n",
    "    x = MaxPooling1D(pool_size=2)(x)\n",
    "    x = Dropout(d1, name=\"dropout_1\")(x, training=dropoutTraining)\n",
    "    x = Flatten(name=\"flatten\")(x)    \n",
    "    x = Dense(128, activation=act)(x) \n",
    "    x = Dropout(d2, name=\"dropout_2\")(x, training=dropoutTraining)\n",
    "    out1 = Dense(1, name=\"bmag\")(x)\n",
    "    out2 = Dense(2, name=\"phi\", activation=\"tanh\")(x)\n",
    "    out3 = Dense(2, name=\"theta\", activation=\"tanh\")(x)\n",
    "    out4 = Dense(1, name=\"y0r\")(x)\n",
    "    out5 = Dense(1, name=\"handedness\", activation='sigmoid')(x)\n",
    "\n",
    "    losses = {'bmag': 'mean_absolute_error',\n",
    "              'phi': 'mean_absolute_error',\n",
    "              'theta': 'mean_absolute_error',\n",
    "              'y0r': 'mean_absolute_error',\n",
    "              'handedness': 'binary_crossentropy'}\n",
    "    \n",
    "    lossWeights = {\"bmag\": 1.0, \"phi\": 1.0, \"theta\": 1.0, \"y0r\": 1.0, \"handedness\": 1.0}\n",
    "    \n",
    "    model = Model(inputs=inp, outputs=[out1,out2,out3,out4,out5])\n",
    "\n",
    "    model.compile(loss=losses, loss_weights=lossWeights, optimizer='adam')\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_2\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input (InputLayer)              (None, 27, 3)        0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_3 (Conv1D)               (None, 27, 32)       512         input[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_4 (Conv1D)               (None, 27, 64)       10304       conv1d_3[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_2 (MaxPooling1D)  (None, 13, 64)       0           conv1d_4[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dropout_1 (Dropout)             (None, 13, 64)       0           max_pooling1d_2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "flatten (Flatten)               (None, 832)          0           dropout_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_2 (Dense)                 (None, 128)          106624      flatten[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dropout_2 (Dropout)             (None, 128)          0           dense_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "bmag (Dense)                    (None, 1)            129         dropout_2[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "phi (Dense)                     (None, 2)            258         dropout_2[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "theta (Dense)                   (None, 2)            258         dropout_2[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "y0r (Dense)                     (None, 1)            129         dropout_2[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "handedness (Dense)              (None, 1)            129         dropout_2[0][0]                  \n",
      "==================================================================================================\n",
      "Total params: 118,343\n",
      "Trainable params: 118,343\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "mc_model = get_model(d1, d2, act=\"relu\")\n",
    "mc_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is required for my GPU: GeForce RTX 2060\n",
    "# Without this config, tensorflow cannot properly allocate GPU memory\n",
    "config = tf.ConfigProto()\n",
    "config.gpu_options.allow_growth = True\n",
    "session = tf.Session(config=config)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "metadata": {},
   "outputs": [],
   "source": [
    "def handedness_error(p, y):\n",
    "\n",
    "    # binary cross entropy\n",
    "    \n",
    "    # p = predicted handedness\n",
    "    # y = actual handedness\n",
    "    \n",
    "    ## binary cross entropy is not defined at 0 or 1\n",
    "    p[ p == 0. ] = 0.00001\n",
    "    p[ p == 1. ] = 0.99999\n",
    "    b = -(y*np.log(p)+(1-y)*np.log(1-p))\n",
    "        \n",
    "    return np.sum(b)/len(b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "metadata": {},
   "outputs": [],
   "source": [
    "def angle_error(phiPred, thetaPred, phiActual, thetaActual):\n",
    "    \n",
    "    pPred = np.zeros( shape=(phiPred.shape[0],2) )\n",
    "    tPred = np.zeros( shape=(thetaPred.shape[0],2) )\n",
    "    pActu = np.zeros( shape=(phiActual.shape[0],2) )\n",
    "    tActu = np.zeros( shape=(thetaActual.shape[0],2) )\n",
    "    \n",
    "    pPred[:,0] = np.sin( np.radians(phiPred) )\n",
    "    pPred[:,1] = np.cos( np.radians(phiPred) )\n",
    "        \n",
    "    tPred[:,0] = np.sin( np.radians(thetaPred) )\n",
    "    tPred[:,1] = np.cos( np.radians(thetaPred) )\n",
    "    \n",
    "    pActu[:,0] = np.sin( np.radians(phiActual) )\n",
    "    pActu[:,1] = np.cos( np.radians(phiActual) )\n",
    "        \n",
    "    tActu[:,0] = np.sin( np.radians(thetaActual) )\n",
    "    tActu[:,1] = np.cos( np.radians(thetaActual) )\n",
    "    \n",
    "    ePhi = mean_absolute_error( pActu, pPred )\n",
    "    eTheta = mean_absolute_error( tActu, tPred )\n",
    "    \n",
    "    return ePhi, eTheta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "metadata": {},
   "outputs": [],
   "source": [
    "def modelEvaluations(model, dir, testFiles, T=25):\n",
    "    \n",
    "    print()\n",
    "    print(\"Evaluating model on test set...\")\n",
    "    \n",
    "    for i in range(T):\n",
    "        \n",
    "        counter = 0\n",
    "        #print(\"     \",i+1,\"of\",T)\n",
    "        \n",
    "        for file in testFiles:\n",
    "            \n",
    "            xTest, yTest = readNPZ(dir+file)\n",
    "            \n",
    "            predictions = model.predict(xTest, verbose=0, batch_size=1600)  \n",
    "            \n",
    "            phi = predictions[1]\n",
    "            sin = phi[:,0]\n",
    "            cos = phi[:,1]\n",
    "            phi = np.degrees( np.arctan2(sin,cos) )\n",
    "            \n",
    "            # check the quadrant\n",
    "            ix = np.where( phi < 0. )\n",
    "            if ( len(ix[0]) > 0 ):\n",
    "                phi[ix] += 360.\n",
    "            \n",
    "            theta = predictions[2]\n",
    "            sin = theta[:,0]\n",
    "            cos = theta[:,1]\n",
    "            theta = np.degrees( np.arctan2(sin,cos) )\n",
    "\n",
    "            n = yTest.shape[0]\n",
    "            p = np.zeros(shape=(n,5))\n",
    "            p[:,0] = np.reshape(predictions[0], (n) )\n",
    "            p[:,1] = phi\n",
    "            p[:,2] = theta\n",
    "            p[:,3] = np.reshape(predictions[3], (n) )\n",
    "            p[:,4] = np.reshape(predictions[4], (n) )\n",
    "            \n",
    "            if (counter == 0):\n",
    "                yAll = yTest\n",
    "                allPredictions = p\n",
    "            else:\n",
    "                yAll = np.concatenate( (yAll, yTest) )\n",
    "                allPredictions = np.concatenate( (allPredictions, p) )\n",
    "                \n",
    "            counter += 1\n",
    "\n",
    "        if (i == 0):\n",
    "            ensemblePredictions = np.reshape(allPredictions, (1, allPredictions.shape[0], allPredictions.shape[1]))    \n",
    "        else:\n",
    "            t = np.reshape( allPredictions, (1,allPredictions.shape[0], allPredictions.shape[1]))\n",
    "            ensemblePredictions = np.vstack( (ensemblePredictions,t) )\n",
    "                                                  \n",
    "    # Evaluate the ensemble model\n",
    "    #print(\"Computing ensemble predictions...\")\n",
    "    ensemble_pred = np.mean( ensemblePredictions, axis=0 )\n",
    "    \n",
    "    # Need directional statistics for angles\n",
    "    #print(\"Computing directional statistics...\")\n",
    "    \n",
    "    ## phi\n",
    "    y = np.sum( np.sin( np.radians(ensemblePredictions[:,:,1]) ), axis=0 ) / T\n",
    "    x = np.sum( np.cos( np.radians(ensemblePredictions[:,:,1]) ), axis=0 ) / T\n",
    "    rr = np.sqrt( x**2 + y**2 )\n",
    "    avg_cos = x/rr\n",
    "    avg_sin = y/rr\n",
    "    avg_phi = np.degrees( np.arctan2( avg_sin, avg_cos ) )\n",
    "    \n",
    "    ix = np.where( avg_phi < 0 )\n",
    "    if ( len(ix[0]) > 0 ):\n",
    "        avg_phi[ix] += 360\n",
    "    ensemble_pred[:,1] = avg_phi\n",
    "    \n",
    "    ## theta\n",
    "    y = np.sum( np.sin( np.radians(ensemblePredictions[:,:,2]) ), axis=0 ) / T\n",
    "    x = np.sum( np.cos( np.radians(ensemblePredictions[:,:,2]) ), axis=0 ) / T\n",
    "    rr = np.sqrt( x**2 + y**2 )\n",
    "    avg_cos = x/rr\n",
    "    avg_sin = y/rr\n",
    "    avg_theta = np.degrees( np.arctan2( avg_sin, avg_cos ) )\n",
    "          \n",
    "    #print(\"Computing errors...\")\n",
    "    errorB = mean_absolute_error( ensemble_pred[:,0], yAll[:,0] )\n",
    "    errorPhi, errorTheta = angle_error( ensemble_pred[:,1], ensemble_pred[:,2], yAll[:,1], yAll[:,2] )\n",
    "    errorY0r = mean_absolute_error( ensemble_pred[:,3], yAll[:,3] ) \n",
    "    errorH = handedness_error( ensemble_pred[:,4], yAll[:,4] )\n",
    "    overall = mean_absolute_error( ensemble_pred, yAll )\n",
    "    \n",
    "    # handedness is a likelihood in the range [0,1]\n",
    "    # make it either 0 or 1 for comparison to actual values\n",
    "    ix = np.where( ensemble_pred[:,4] < 0.5 )\n",
    "    ensemble_pred[ix,4] = 0.\n",
    "    ix = np.where( ensemble_pred[:,4] >= 0.5 )\n",
    "    ensemble_pred[ix,4] = 1.\n",
    "\n",
    "    ensembleErrors = [ round(errorB, 3), round(errorPhi, 3), round(errorTheta, 3), \n",
    "                      round(errorY0r, 3), round(errorH, 3), round(overall, 3) ]\n",
    "    \n",
    "    return ensemble_pred, yAll, ensembleErrors "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "metadata": {},
   "outputs": [],
   "source": [
    "def modelPredictions(model, npzPath, fileList, T=25, det=False):\n",
    "    \n",
    "    tra = NpzDataGenerator(npzPath, fileList)\n",
    "    \n",
    "    print()\n",
    "    print(\"Making predictions on pool...\")\n",
    "    \n",
    "    for i in range(T):\n",
    "        \n",
    "        #print(\"     \",i+1,\"of\",T)\n",
    "                \n",
    "        predictions = model.predict_generator(tra, verbose=0)  \n",
    "            \n",
    "        phi = predictions[1]\n",
    "        sin = phi[:,0]\n",
    "        cos = phi[:,1]\n",
    "        phi = np.degrees( np.arctan2(sin,cos) )\n",
    "            \n",
    "        # check the quadrant\n",
    "        ix = np.where( phi < 0. )\n",
    "        if ( len(ix[0]) > 0 ):\n",
    "            phi[ix] += 360.\n",
    "            \n",
    "        theta = predictions[2]\n",
    "        sin = theta[:,0]\n",
    "        cos = theta[:,1]\n",
    "        theta = np.degrees( np.arctan2(sin,cos) )\n",
    "    \n",
    "        if ( i == 0 ):\n",
    "            n = predictions[0].shape[0]\n",
    "            ensemblePredictions = np.zeros( shape=(T,n,5) )\n",
    "\n",
    "        ensemblePredictions[i,:,0] = np.reshape(predictions[0],(n))\n",
    "        ensemblePredictions[i,:,1] = phi\n",
    "        ensemblePredictions[i,:,2] = theta\n",
    "        ensemblePredictions[i,:,3] = np.reshape(predictions[3],(n))\n",
    "        ensemblePredictions[i,:,4] = np.reshape(predictions[4],(n))\n",
    "    \n",
    "    # Evaluate the ensemble model     \n",
    "    #print(\"Computing ensemble predictions...\")\n",
    "    ensemble_pred = np.mean( ensemblePredictions, axis=0 )\n",
    "    ensemble_var = np.var( ensemblePredictions, axis=0 )\n",
    "    \n",
    "    # Need directional statistics for angles\n",
    "    #print(\"Computing directional statistics...\")\n",
    "    \n",
    "    ## phi\n",
    "    y = np.sum( np.sin( np.radians(ensemblePredictions[:,:,1]) ), axis=0 ) / T\n",
    "    x = np.sum( np.cos( np.radians(ensemblePredictions[:,:,1]) ), axis=0 ) / T\n",
    "    rr = np.sqrt( x**2 + y**2 )\n",
    "    avg_cos = x/rr\n",
    "    avg_sin = y/rr\n",
    "    avg_phi = np.degrees( np.arctan2( avg_sin, avg_cos ) )\n",
    "    \n",
    "    ix = np.where( avg_phi < 0 )\n",
    "    if ( len(ix[0]) > 0 ):\n",
    "        avg_phi[ix] += 360\n",
    "    ensemble_pred[:,1] = avg_phi\n",
    "    \n",
    "    # circular variance\n",
    "    ensemble_var[:,1] = 1. - rr\n",
    "    \n",
    "    ## theta\n",
    "    y = np.sum( np.sin( np.radians(ensemblePredictions[:,:,2]) ), axis=0 ) / T\n",
    "    x = np.sum( np.cos( np.radians(ensemblePredictions[:,:,2]) ), axis=0 ) / T\n",
    "    rr = np.sqrt( x**2 + y**2 )\n",
    "    avg_cos = x/rr\n",
    "    avg_sin = y/rr\n",
    "    avg_theta = np.degrees( np.arctan2( avg_sin, avg_cos ) )\n",
    "    \n",
    "    # circular variance   \n",
    "    ensemble_var[:,2] = 1. - rr\n",
    "    \n",
    "    # handedness is a likelihood in the range [0,1]\n",
    "    # make it either 0 or 1 for comparison to actual values\n",
    "    ix = np.where( ensemble_pred[:,4] < 0.5 )\n",
    "    ensemble_pred[ix,4] = 0.\n",
    "    ix = np.where( ensemble_pred[:,4] >= 0.5 )\n",
    "    ensemble_pred[ix,4] = 1.\n",
    "    \n",
    "    if ( det == True ):\n",
    "    \n",
    "        determinant = np.zeros( shape=(n) )\n",
    "            \n",
    "        for i in range(n):\n",
    "            a = ensemblePredictions[:,i,0]\n",
    "            b = ensemblePredictions[:,i,1]\n",
    "            c = ensemblePredictions[:,i,2]\n",
    "            d = ensemblePredictions[:,i,3]\n",
    "            e = ensemblePredictions[:,i,4]\n",
    "            m = np.array( [a,b,c,d,e] )\n",
    "            c = np.cov( m )\n",
    "            determinant[i] = np.linalg.det(c)\n",
    "    \n",
    "    if ( det == False ):\n",
    "        return ensemble_pred, ensemble_var\n",
    "    else:\n",
    "        return ensemble_pred, determinant"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 262,
   "metadata": {},
   "outputs": [],
   "source": [
    "def combineTrainValidation(npzPath, trainDir, trainFiles, valDir, valFiles):\n",
    "    \n",
    "    dest = npzPath + 'baseline_train_2/'\n",
    "    \n",
    "    # delete any files left over from a previous session\n",
    "    for filename in os.listdir(dest):\n",
    "        file_path = os.path.join(dest, filename)\n",
    "        try:\n",
    "            if os.path.isfile(file_path) or os.path.islink(file_path):\n",
    "                os.unlink(file_path)\n",
    "        except Exception as e:\n",
    "            print('Failed to delete %s. Reason: %s' % (file_path, e))\n",
    "    \n",
    "    # move the current training files\n",
    "    for f in trainFiles:\n",
    "        shutil.move(npzPath + trainDir + f, dest)\n",
    "        \n",
    "    # move the current validation files\n",
    "    for f in valFiles:\n",
    "        shutil.move(npzPath + valDir + f, dest)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 263,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/500\n",
      "2126/2126 [==============================] - 9s 4ms/step - loss: 18.5889 - bmag_loss: 2.8193 - phi_loss: 0.4696 - theta_loss: 0.3492 - y0r_loss: 14.6815 - handedness_loss: 0.2693 - val_loss: 12.6631 - val_bmag_loss: 2.3270 - val_phi_loss: 0.3454 - val_theta_loss: 0.2034 - val_y0r_loss: 9.6699 - val_handedness_loss: 0.1833\n",
      "Epoch 2/500\n",
      "2126/2126 [==============================] - 9s 4ms/step - loss: 11.4254 - bmag_loss: 2.2625 - phi_loss: 0.3223 - theta_loss: 0.1881 - y0r_loss: 8.4896 - handedness_loss: 0.1629 - val_loss: 10.0022 - val_bmag_loss: 2.2328 - val_phi_loss: 0.3192 - val_theta_loss: 0.1860 - val_y0r_loss: 7.4757 - val_handedness_loss: 0.1574\n",
      "Epoch 3/500\n",
      "2126/2126 [==============================] - 9s 4ms/step - loss: 9.8961 - bmag_loss: 2.1488 - phi_loss: 0.3067 - theta_loss: 0.1748 - y0r_loss: 7.1218 - handedness_loss: 0.1439 - val_loss: 9.5367 - val_bmag_loss: 2.1440 - val_phi_loss: 0.3049 - val_theta_loss: 0.1781 - val_y0r_loss: 6.8493 - val_handedness_loss: 0.1378\n",
      "Epoch 4/500\n",
      "2126/2126 [==============================] - 10s 5ms/step - loss: 9.2506 - bmag_loss: 2.0760 - phi_loss: 0.3030 - theta_loss: 0.1725 - y0r_loss: 6.5692 - handedness_loss: 0.1299 - val_loss: 8.7109 - val_bmag_loss: 2.0281 - val_phi_loss: 0.3018 - val_theta_loss: 0.1679 - val_y0r_loss: 6.2750 - val_handedness_loss: 0.1269\n",
      "Epoch 5/500\n",
      "2126/2126 [==============================] - 9s 4ms/step - loss: 8.8305 - bmag_loss: 2.0186 - phi_loss: 0.2934 - theta_loss: 0.1640 - y0r_loss: 6.2292 - handedness_loss: 0.1254 - val_loss: 8.6036 - val_bmag_loss: 2.0163 - val_phi_loss: 0.2929 - val_theta_loss: 0.1671 - val_y0r_loss: 5.9633 - val_handedness_loss: 0.1249\n",
      "Epoch 6/500\n",
      "2126/2126 [==============================] - 12s 5ms/step - loss: 8.5165 - bmag_loss: 1.9669 - phi_loss: 0.2783 - theta_loss: 0.1644 - y0r_loss: 5.9868 - handedness_loss: 0.1200 - val_loss: 8.5577 - val_bmag_loss: 1.9215 - val_phi_loss: 0.2731 - val_theta_loss: 0.1661 - val_y0r_loss: 5.8981 - val_handedness_loss: 0.1196\n",
      "Epoch 7/500\n",
      "2126/2126 [==============================] - 9s 4ms/step - loss: 8.2646 - bmag_loss: 1.9220 - phi_loss: 0.2726 - theta_loss: 0.1652 - y0r_loss: 5.7880 - handedness_loss: 0.1168 - val_loss: 8.4183 - val_bmag_loss: 1.8932 - val_phi_loss: 0.2712 - val_theta_loss: 0.1636 - val_y0r_loss: 5.8436 - val_handedness_loss: 0.1190\n",
      "Epoch 8/500\n",
      "2126/2126 [==============================] - 15s 7ms/step - loss: 8.1100 - bmag_loss: 1.8869 - phi_loss: 0.2714 - theta_loss: 0.1659 - y0r_loss: 5.6713 - handedness_loss: 0.1145 - val_loss: 7.9652 - val_bmag_loss: 1.8377 - val_phi_loss: 0.2713 - val_theta_loss: 0.1652 - val_y0r_loss: 5.6260 - val_handedness_loss: 0.1170\n",
      "Epoch 9/500\n",
      "2126/2126 [==============================] - 13s 6ms/step - loss: 7.9454 - bmag_loss: 1.8543 - phi_loss: 0.2714 - theta_loss: 0.1644 - y0r_loss: 5.5401 - handedness_loss: 0.1152 - val_loss: 7.5703 - val_bmag_loss: 1.7995 - val_phi_loss: 0.2704 - val_theta_loss: 0.1653 - val_y0r_loss: 5.4158 - val_handedness_loss: 0.1225\n",
      "Epoch 10/500\n",
      "2126/2126 [==============================] - 11s 5ms/step - loss: 7.8347 - bmag_loss: 1.8398 - phi_loss: 0.2714 - theta_loss: 0.1638 - y0r_loss: 5.4469 - handedness_loss: 0.1128 - val_loss: 7.7466 - val_bmag_loss: 1.8338 - val_phi_loss: 0.2691 - val_theta_loss: 0.1610 - val_y0r_loss: 5.3365 - val_handedness_loss: 0.1134\n",
      "Epoch 11/500\n",
      "2126/2126 [==============================] - 12s 6ms/step - loss: 7.7188 - bmag_loss: 1.8192 - phi_loss: 0.2699 - theta_loss: 0.1623 - y0r_loss: 5.3563 - handedness_loss: 0.1111 - val_loss: 7.9930 - val_bmag_loss: 1.8422 - val_phi_loss: 0.2695 - val_theta_loss: 0.1612 - val_y0r_loss: 5.3143 - val_handedness_loss: 0.1160\n",
      "Epoch 12/500\n",
      "2126/2126 [==============================] - 10s 5ms/step - loss: 7.6249 - bmag_loss: 1.8030 - phi_loss: 0.2695 - theta_loss: 0.1615 - y0r_loss: 5.2806 - handedness_loss: 0.1103 - val_loss: 7.3829 - val_bmag_loss: 1.7563 - val_phi_loss: 0.2686 - val_theta_loss: 0.1581 - val_y0r_loss: 5.2303 - val_handedness_loss: 0.1110\n",
      "Epoch 13/500\n",
      "2126/2126 [==============================] - 15s 7ms/step - loss: 7.5306 - bmag_loss: 1.7843 - phi_loss: 0.2700 - theta_loss: 0.1604 - y0r_loss: 5.2057 - handedness_loss: 0.1101 - val_loss: 7.4719 - val_bmag_loss: 1.7759 - val_phi_loss: 0.2701 - val_theta_loss: 0.1572 - val_y0r_loss: 5.1162 - val_handedness_loss: 0.1093\n",
      "Epoch 14/500\n",
      "2126/2126 [==============================] - 10s 5ms/step - loss: 7.4290 - bmag_loss: 1.7698 - phi_loss: 0.2693 - theta_loss: 0.1606 - y0r_loss: 5.1201 - handedness_loss: 0.1091 - val_loss: 7.3610 - val_bmag_loss: 1.7385 - val_phi_loss: 0.2733 - val_theta_loss: 0.1628 - val_y0r_loss: 5.1745 - val_handedness_loss: 0.1107\n",
      "Epoch 15/500\n",
      "2126/2126 [==============================] - 10s 5ms/step - loss: 7.3541 - bmag_loss: 1.7575 - phi_loss: 0.2688 - theta_loss: 0.1608 - y0r_loss: 5.0602 - handedness_loss: 0.1067 - val_loss: 7.2207 - val_bmag_loss: 1.7450 - val_phi_loss: 0.2662 - val_theta_loss: 0.1588 - val_y0r_loss: 4.8771 - val_handedness_loss: 0.1054\n",
      "Epoch 16/500\n",
      "2126/2126 [==============================] - 9s 4ms/step - loss: 7.2645 - bmag_loss: 1.7420 - phi_loss: 0.2678 - theta_loss: 0.1595 - y0r_loss: 4.9883 - handedness_loss: 0.1069 - val_loss: 7.1568 - val_bmag_loss: 1.7161 - val_phi_loss: 0.2654 - val_theta_loss: 0.1585 - val_y0r_loss: 4.9360 - val_handedness_loss: 0.1110\n",
      "Epoch 17/500\n",
      "2126/2126 [==============================] - 12s 6ms/step - loss: 7.1692 - bmag_loss: 1.7267 - phi_loss: 0.2681 - theta_loss: 0.1591 - y0r_loss: 4.9103 - handedness_loss: 0.1050 - val_loss: 7.2836 - val_bmag_loss: 1.7252 - val_phi_loss: 0.2730 - val_theta_loss: 0.1620 - val_y0r_loss: 4.9031 - val_handedness_loss: 0.1110\n",
      "Epoch 18/500\n",
      "2126/2126 [==============================] - 12s 5ms/step - loss: 7.1266 - bmag_loss: 1.7179 - phi_loss: 0.2664 - theta_loss: 0.1594 - y0r_loss: 4.8794 - handedness_loss: 0.1035 - val_loss: 7.1562 - val_bmag_loss: 1.7174 - val_phi_loss: 0.2647 - val_theta_loss: 0.1623 - val_y0r_loss: 4.8671 - val_handedness_loss: 0.1041\n",
      "Epoch 19/500\n",
      "2126/2126 [==============================] - 11s 5ms/step - loss: 7.0527 - bmag_loss: 1.7045 - phi_loss: 0.2666 - theta_loss: 0.1584 - y0r_loss: 4.8200 - handedness_loss: 0.1033 - val_loss: 6.9520 - val_bmag_loss: 1.6720 - val_phi_loss: 0.2670 - val_theta_loss: 0.1595 - val_y0r_loss: 4.8334 - val_handedness_loss: 0.1083\n",
      "Epoch 20/500\n",
      "2126/2126 [==============================] - 9s 4ms/step - loss: 6.9953 - bmag_loss: 1.6980 - phi_loss: 0.2656 - theta_loss: 0.1579 - y0r_loss: 4.7722 - handedness_loss: 0.1016 - val_loss: 7.0829 - val_bmag_loss: 1.6673 - val_phi_loss: 0.2673 - val_theta_loss: 0.1560 - val_y0r_loss: 4.8267 - val_handedness_loss: 0.0983\n",
      "Epoch 21/500\n",
      "2126/2126 [==============================] - 11s 5ms/step - loss: 6.9209 - bmag_loss: 1.6873 - phi_loss: 0.2653 - theta_loss: 0.1580 - y0r_loss: 4.7103 - handedness_loss: 0.0999 - val_loss: 7.0960 - val_bmag_loss: 1.6587 - val_phi_loss: 0.2633 - val_theta_loss: 0.1560 - val_y0r_loss: 4.7887 - val_handedness_loss: 0.0980\n",
      "Epoch 22/500\n",
      "2126/2126 [==============================] - 12s 6ms/step - loss: 6.8672 - bmag_loss: 1.6750 - phi_loss: 0.2641 - theta_loss: 0.1575 - y0r_loss: 4.6714 - handedness_loss: 0.0992 - val_loss: 6.8062 - val_bmag_loss: 1.6773 - val_phi_loss: 0.2687 - val_theta_loss: 0.1564 - val_y0r_loss: 4.6554 - val_handedness_loss: 0.0956\n",
      "Epoch 23/500\n",
      "2126/2126 [==============================] - 9s 4ms/step - loss: 6.8226 - bmag_loss: 1.6735 - phi_loss: 0.2646 - theta_loss: 0.1561 - y0r_loss: 4.6315 - handedness_loss: 0.0969 - val_loss: 6.8816 - val_bmag_loss: 1.6490 - val_phi_loss: 0.2638 - val_theta_loss: 0.1529 - val_y0r_loss: 4.6044 - val_handedness_loss: 0.0994\n",
      "Epoch 24/500\n",
      "2126/2126 [==============================] - 10s 5ms/step - loss: 6.7432 - bmag_loss: 1.6625 - phi_loss: 0.2635 - theta_loss: 0.1523 - y0r_loss: 4.5690 - handedness_loss: 0.0959 - val_loss: 6.9469 - val_bmag_loss: 1.6532 - val_phi_loss: 0.2753 - val_theta_loss: 0.1541 - val_y0r_loss: 4.6491 - val_handedness_loss: 0.0994\n",
      "Epoch 25/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2126/2126 [==============================] - 10s 4ms/step - loss: 6.7092 - bmag_loss: 1.6551 - phi_loss: 0.2626 - theta_loss: 0.1496 - y0r_loss: 4.5475 - handedness_loss: 0.0944 - val_loss: 6.8007 - val_bmag_loss: 1.6991 - val_phi_loss: 0.2619 - val_theta_loss: 0.1448 - val_y0r_loss: 4.5146 - val_handedness_loss: 0.0942\n",
      "Epoch 26/500\n",
      "2126/2126 [==============================] - 9s 4ms/step - loss: 6.6567 - bmag_loss: 1.6453 - phi_loss: 0.2632 - theta_loss: 0.1455 - y0r_loss: 4.5075 - handedness_loss: 0.0951 - val_loss: 6.5620 - val_bmag_loss: 1.6456 - val_phi_loss: 0.2643 - val_theta_loss: 0.1440 - val_y0r_loss: 4.4211 - val_handedness_loss: 0.0977\n",
      "Epoch 27/500\n",
      "2126/2126 [==============================] - 9s 4ms/step - loss: 6.6257 - bmag_loss: 1.6439 - phi_loss: 0.2623 - theta_loss: 0.1455 - y0r_loss: 4.4790 - handedness_loss: 0.0950 - val_loss: 6.5907 - val_bmag_loss: 1.6663 - val_phi_loss: 0.2633 - val_theta_loss: 0.1432 - val_y0r_loss: 4.4154 - val_handedness_loss: 0.0958\n",
      "Epoch 28/500\n",
      "2126/2126 [==============================] - 9s 4ms/step - loss: 6.5720 - bmag_loss: 1.6309 - phi_loss: 0.2632 - theta_loss: 0.1456 - y0r_loss: 4.4351 - handedness_loss: 0.0972 - val_loss: 6.4628 - val_bmag_loss: 1.6087 - val_phi_loss: 0.2607 - val_theta_loss: 0.1457 - val_y0r_loss: 4.4973 - val_handedness_loss: 0.0996\n",
      "Epoch 29/500\n",
      "2126/2126 [==============================] - 13s 6ms/step - loss: 6.5502 - bmag_loss: 1.6298 - phi_loss: 0.2623 - theta_loss: 0.1451 - y0r_loss: 4.4167 - handedness_loss: 0.0963 - val_loss: 6.4779 - val_bmag_loss: 1.6056 - val_phi_loss: 0.2662 - val_theta_loss: 0.1450 - val_y0r_loss: 4.3943 - val_handedness_loss: 0.0950\n",
      "Epoch 30/500\n",
      "2126/2126 [==============================] - 14s 6ms/step - loss: 6.5144 - bmag_loss: 1.6211 - phi_loss: 0.2613 - theta_loss: 0.1454 - y0r_loss: 4.3919 - handedness_loss: 0.0946 - val_loss: 6.4875 - val_bmag_loss: 1.5966 - val_phi_loss: 0.2616 - val_theta_loss: 0.1443 - val_y0r_loss: 4.4084 - val_handedness_loss: 0.0936\n",
      "Epoch 31/500\n",
      "2126/2126 [==============================] - 13s 6ms/step - loss: 6.4767 - bmag_loss: 1.6189 - phi_loss: 0.2612 - theta_loss: 0.1455 - y0r_loss: 4.3576 - handedness_loss: 0.0935 - val_loss: 6.6442 - val_bmag_loss: 1.6414 - val_phi_loss: 0.2626 - val_theta_loss: 0.1460 - val_y0r_loss: 4.4111 - val_handedness_loss: 0.0976\n",
      "Epoch 32/500\n",
      "2126/2126 [==============================] - 17s 8ms/step - loss: 6.4233 - bmag_loss: 1.6018 - phi_loss: 0.2595 - theta_loss: 0.1455 - y0r_loss: 4.3240 - handedness_loss: 0.0924 - val_loss: 6.5216 - val_bmag_loss: 1.6415 - val_phi_loss: 0.2593 - val_theta_loss: 0.1450 - val_y0r_loss: 4.3020 - val_handedness_loss: 0.0966\n",
      "Epoch 33/500\n",
      "2126/2126 [==============================] - 10s 5ms/step - loss: 6.3851 - bmag_loss: 1.5966 - phi_loss: 0.2585 - theta_loss: 0.1460 - y0r_loss: 4.2916 - handedness_loss: 0.0924 - val_loss: 6.2234 - val_bmag_loss: 1.5715 - val_phi_loss: 0.2582 - val_theta_loss: 0.1465 - val_y0r_loss: 4.2219 - val_handedness_loss: 0.0930\n",
      "Epoch 34/500\n",
      "2126/2126 [==============================] - 9s 4ms/step - loss: 6.3566 - bmag_loss: 1.5935 - phi_loss: 0.2587 - theta_loss: 0.1458 - y0r_loss: 4.2667 - handedness_loss: 0.0919 - val_loss: 6.4965 - val_bmag_loss: 1.6340 - val_phi_loss: 0.2590 - val_theta_loss: 0.1461 - val_y0r_loss: 4.2466 - val_handedness_loss: 0.0943\n",
      "Epoch 35/500\n",
      "2126/2126 [==============================] - 9s 4ms/step - loss: 6.3301 - bmag_loss: 1.5938 - phi_loss: 0.2588 - theta_loss: 0.1456 - y0r_loss: 4.2398 - handedness_loss: 0.0922 - val_loss: 6.2328 - val_bmag_loss: 1.5621 - val_phi_loss: 0.2614 - val_theta_loss: 0.1483 - val_y0r_loss: 4.1882 - val_handedness_loss: 0.0903\n",
      "Epoch 36/500\n",
      "2126/2126 [==============================] - 9s 4ms/step - loss: 6.3045 - bmag_loss: 1.5895 - phi_loss: 0.2580 - theta_loss: 0.1456 - y0r_loss: 4.2197 - handedness_loss: 0.0918 - val_loss: 6.0515 - val_bmag_loss: 1.5629 - val_phi_loss: 0.2544 - val_theta_loss: 0.1482 - val_y0r_loss: 4.1634 - val_handedness_loss: 0.0920\n",
      "Epoch 37/500\n",
      "2126/2126 [==============================] - 9s 4ms/step - loss: 6.2773 - bmag_loss: 1.5836 - phi_loss: 0.2578 - theta_loss: 0.1459 - y0r_loss: 4.1978 - handedness_loss: 0.0923 - val_loss: 6.4003 - val_bmag_loss: 1.5570 - val_phi_loss: 0.2543 - val_theta_loss: 0.1466 - val_y0r_loss: 4.1970 - val_handedness_loss: 0.0949\n",
      "Epoch 38/500\n",
      "2126/2126 [==============================] - 9s 4ms/step - loss: 6.2636 - bmag_loss: 1.5796 - phi_loss: 0.2576 - theta_loss: 0.1463 - y0r_loss: 4.1876 - handedness_loss: 0.0924 - val_loss: 6.3075 - val_bmag_loss: 1.5599 - val_phi_loss: 0.2580 - val_theta_loss: 0.1443 - val_y0r_loss: 4.1209 - val_handedness_loss: 0.0941\n",
      "Epoch 39/500\n",
      "2126/2126 [==============================] - 8s 4ms/step - loss: 6.2281 - bmag_loss: 1.5786 - phi_loss: 0.2574 - theta_loss: 0.1458 - y0r_loss: 4.1553 - handedness_loss: 0.0910 - val_loss: 6.1547 - val_bmag_loss: 1.5551 - val_phi_loss: 0.2602 - val_theta_loss: 0.1486 - val_y0r_loss: 4.2319 - val_handedness_loss: 0.0921\n",
      "Epoch 40/500\n",
      "2126/2126 [==============================] - 10s 5ms/step - loss: 6.2240 - bmag_loss: 1.5776 - phi_loss: 0.2565 - theta_loss: 0.1452 - y0r_loss: 4.1539 - handedness_loss: 0.0908 - val_loss: 6.2443 - val_bmag_loss: 1.5727 - val_phi_loss: 0.2527 - val_theta_loss: 0.1452 - val_y0r_loss: 4.2309 - val_handedness_loss: 0.0929\n",
      "Epoch 41/500\n",
      "2126/2126 [==============================] - 11s 5ms/step - loss: 6.1911 - bmag_loss: 1.5702 - phi_loss: 0.2555 - theta_loss: 0.1451 - y0r_loss: 4.1288 - handedness_loss: 0.0915 - val_loss: 6.1633 - val_bmag_loss: 1.5665 - val_phi_loss: 0.2571 - val_theta_loss: 0.1505 - val_y0r_loss: 4.1118 - val_handedness_loss: 0.0947\n",
      "Epoch 42/500\n",
      "2126/2126 [==============================] - 10s 5ms/step - loss: 6.1713 - bmag_loss: 1.5701 - phi_loss: 0.2558 - theta_loss: 0.1464 - y0r_loss: 4.1082 - handedness_loss: 0.0908 - val_loss: 6.2866 - val_bmag_loss: 1.5646 - val_phi_loss: 0.2575 - val_theta_loss: 0.1472 - val_y0r_loss: 4.2577 - val_handedness_loss: 0.0914\n",
      "Epoch 1/42\n",
      "2240/2240 [==============================] - 10s 4ms/step - loss: 18.1882 - bmag_loss: 2.8313 - phi_loss: 0.4492 - theta_loss: 0.3200 - y0r_loss: 14.3280 - handedness_loss: 0.2597\n",
      "Epoch 2/42\n",
      "2240/2240 [==============================] - 11s 5ms/step - loss: 11.3688 - bmag_loss: 2.3277 - phi_loss: 0.3191 - theta_loss: 0.1882 - y0r_loss: 8.3679 - handedness_loss: 0.1659\n",
      "Epoch 3/42\n",
      "2240/2240 [==============================] - 12s 5ms/step - loss: 10.1172 - bmag_loss: 2.2182 - phi_loss: 0.3088 - theta_loss: 0.1749 - y0r_loss: 7.2666 - handedness_loss: 0.1489\n",
      "Epoch 4/42\n",
      "2240/2240 [==============================] - 18s 8ms/step - loss: 9.5010 - bmag_loss: 2.1397 - phi_loss: 0.3062 - theta_loss: 0.1711 - y0r_loss: 6.7444 - handedness_loss: 0.1397\n",
      "Epoch 5/42\n",
      "2240/2240 [==============================] - 12s 5ms/step - loss: 9.1318 - bmag_loss: 2.0865 - phi_loss: 0.3043 - theta_loss: 0.1740 - y0r_loss: 6.4338 - handedness_loss: 0.1331\n",
      "Epoch 6/42\n",
      "2240/2240 [==============================] - 10s 4ms/step - loss: 8.8629 - bmag_loss: 2.0530 - phi_loss: 0.3031 - theta_loss: 0.1766 - y0r_loss: 6.2020 - handedness_loss: 0.1282\n",
      "Epoch 7/42\n",
      "2240/2240 [==============================] - 12s 5ms/step - loss: 8.6420 - bmag_loss: 2.0050 - phi_loss: 0.3036 - theta_loss: 0.1762 - y0r_loss: 6.0345 - handedness_loss: 0.1226\n",
      "Epoch 8/42\n",
      "2240/2240 [==============================] - 20s 9ms/step - loss: 8.4380 - bmag_loss: 1.9739 - phi_loss: 0.3030 - theta_loss: 0.1690 - y0r_loss: 5.8737 - handedness_loss: 0.1184\n",
      "Epoch 9/42\n",
      "2240/2240 [==============================] - 16s 7ms/step - loss: 8.2745 - bmag_loss: 1.9442 - phi_loss: 0.3031 - theta_loss: 0.1690 - y0r_loss: 5.7415 - handedness_loss: 0.1166\n",
      "Epoch 10/42\n",
      "2240/2240 [==============================] - 10s 4ms/step - loss: 8.1590 - bmag_loss: 1.9282 - phi_loss: 0.3014 - theta_loss: 0.1710 - y0r_loss: 5.6424 - handedness_loss: 0.1160\n",
      "Epoch 11/42\n",
      "2240/2240 [==============================] - 12s 5ms/step - loss: 8.0075 - bmag_loss: 1.8979 - phi_loss: 0.2998 - theta_loss: 0.1734 - y0r_loss: 5.5228 - handedness_loss: 0.1136\n",
      "Epoch 12/42\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2240/2240 [==============================] - 13s 6ms/step - loss: 7.8958 - bmag_loss: 1.8788 - phi_loss: 0.2990 - theta_loss: 0.1740 - y0r_loss: 5.4322 - handedness_loss: 0.1117\n",
      "Epoch 13/42\n",
      "2240/2240 [==============================] - 10s 5ms/step - loss: 7.7491 - bmag_loss: 1.8583 - phi_loss: 0.2984 - theta_loss: 0.1715 - y0r_loss: 5.3110 - handedness_loss: 0.1100\n",
      "Epoch 14/42\n",
      "2240/2240 [==============================] - 15s 7ms/step - loss: 7.6648 - bmag_loss: 1.8490 - phi_loss: 0.2983 - theta_loss: 0.1654 - y0r_loss: 5.2445 - handedness_loss: 0.1076\n",
      "Epoch 15/42\n",
      "2240/2240 [==============================] - 11s 5ms/step - loss: 7.5702 - bmag_loss: 1.8248 - phi_loss: 0.2980 - theta_loss: 0.1654 - y0r_loss: 5.1757 - handedness_loss: 0.1062\n",
      "Epoch 16/42\n",
      "2240/2240 [==============================] - 12s 5ms/step - loss: 7.4698 - bmag_loss: 1.8124 - phi_loss: 0.2959 - theta_loss: 0.1646 - y0r_loss: 5.0928 - handedness_loss: 0.1041\n",
      "Epoch 17/42\n",
      "2240/2240 [==============================] - 14s 6ms/step - loss: 7.3786 - bmag_loss: 1.7930 - phi_loss: 0.2959 - theta_loss: 0.1647 - y0r_loss: 5.0215 - handedness_loss: 0.1036\n",
      "Epoch 18/42\n",
      "2240/2240 [==============================] - 17s 8ms/step - loss: 7.2947 - bmag_loss: 1.7843 - phi_loss: 0.2958 - theta_loss: 0.1642 - y0r_loss: 4.9477 - handedness_loss: 0.1026\n",
      "Epoch 19/42\n",
      "2240/2240 [==============================] - 11s 5ms/step - loss: 7.2276 - bmag_loss: 1.7728 - phi_loss: 0.2954 - theta_loss: 0.1640 - y0r_loss: 4.8928 - handedness_loss: 0.1025\n",
      "Epoch 20/42\n",
      "2240/2240 [==============================] - 11s 5ms/step - loss: 7.1492 - bmag_loss: 1.7594 - phi_loss: 0.2937 - theta_loss: 0.1639 - y0r_loss: 4.8303 - handedness_loss: 0.1019\n",
      "Epoch 21/42\n",
      "2240/2240 [==============================] - 11s 5ms/step - loss: 7.0855 - bmag_loss: 1.7481 - phi_loss: 0.2925 - theta_loss: 0.1635 - y0r_loss: 4.7805 - handedness_loss: 0.1009\n",
      "Epoch 22/42\n",
      "2240/2240 [==============================] - 10s 4ms/step - loss: 7.0184 - bmag_loss: 1.7431 - phi_loss: 0.2884 - theta_loss: 0.1638 - y0r_loss: 4.7225 - handedness_loss: 0.1005\n",
      "Epoch 23/42\n",
      "2240/2240 [==============================] - 12s 5ms/step - loss: 6.9491 - bmag_loss: 1.7337 - phi_loss: 0.2848 - theta_loss: 0.1638 - y0r_loss: 4.6664 - handedness_loss: 0.1005\n",
      "Epoch 24/42\n",
      "2240/2240 [==============================] - 11s 5ms/step - loss: 6.8966 - bmag_loss: 1.7181 - phi_loss: 0.2824 - theta_loss: 0.1638 - y0r_loss: 4.6329 - handedness_loss: 0.0993\n",
      "Epoch 25/42\n",
      "2240/2240 [==============================] - 12s 5ms/step - loss: 6.8316 - bmag_loss: 1.7153 - phi_loss: 0.2801 - theta_loss: 0.1632 - y0r_loss: 4.5745 - handedness_loss: 0.0984\n",
      "Epoch 26/42\n",
      "2240/2240 [==============================] - 14s 6ms/step - loss: 6.8038 - bmag_loss: 1.7175 - phi_loss: 0.2785 - theta_loss: 0.1636 - y0r_loss: 4.5475 - handedness_loss: 0.0966\n",
      "Epoch 27/42\n",
      "2240/2240 [==============================] - 25s 11ms/step - loss: 6.7616 - bmag_loss: 1.7098 - phi_loss: 0.2775 - theta_loss: 0.1631 - y0r_loss: 4.5153 - handedness_loss: 0.0960\n",
      "Epoch 28/42\n",
      "2240/2240 [==============================] - 14s 6ms/step - loss: 6.7296 - bmag_loss: 1.7040 - phi_loss: 0.2777 - theta_loss: 0.1644 - y0r_loss: 4.4865 - handedness_loss: 0.0970\n",
      "Epoch 29/42\n",
      "2240/2240 [==============================] - 10s 4ms/step - loss: 6.6866 - bmag_loss: 1.7024 - phi_loss: 0.2772 - theta_loss: 0.1643 - y0r_loss: 4.4463 - handedness_loss: 0.0964\n",
      "Epoch 30/42\n",
      "2240/2240 [==============================] - 11s 5ms/step - loss: 6.6508 - bmag_loss: 1.6993 - phi_loss: 0.2754 - theta_loss: 0.1640 - y0r_loss: 4.4169 - handedness_loss: 0.0952\n",
      "Epoch 31/42\n",
      "2240/2240 [==============================] - 12s 5ms/step - loss: 6.6302 - bmag_loss: 1.6975 - phi_loss: 0.2750 - theta_loss: 0.1637 - y0r_loss: 4.3995 - handedness_loss: 0.0945\n",
      "Epoch 32/42\n",
      "2240/2240 [==============================] - 10s 4ms/step - loss: 6.5920 - bmag_loss: 1.6926 - phi_loss: 0.2724 - theta_loss: 0.1650 - y0r_loss: 4.3683 - handedness_loss: 0.0937\n",
      "Epoch 33/42\n",
      "2240/2240 [==============================] - 25s 11ms/step - loss: 6.5639 - bmag_loss: 1.6855 - phi_loss: 0.2704 - theta_loss: 0.1650 - y0r_loss: 4.3503 - handedness_loss: 0.0928\n",
      "Epoch 34/42\n",
      "2240/2240 [==============================] - 31s 14ms/step - loss: 6.5524 - bmag_loss: 1.6880 - phi_loss: 0.2679 - theta_loss: 0.1651 - y0r_loss: 4.3382 - handedness_loss: 0.0933\n",
      "Epoch 35/42\n",
      "2240/2240 [==============================] - 11s 5ms/step - loss: 6.5146 - bmag_loss: 1.6881 - phi_loss: 0.2661 - theta_loss: 0.1650 - y0r_loss: 4.3036 - handedness_loss: 0.0918\n",
      "Epoch 36/42\n",
      "2240/2240 [==============================] - 12s 5ms/step - loss: 6.4750 - bmag_loss: 1.6824 - phi_loss: 0.2651 - theta_loss: 0.1654 - y0r_loss: 4.2701 - handedness_loss: 0.0920\n",
      "Epoch 37/42\n",
      "2240/2240 [==============================] - 10s 5ms/step - loss: 6.4597 - bmag_loss: 1.6808 - phi_loss: 0.2642 - theta_loss: 0.1648 - y0r_loss: 4.2584 - handedness_loss: 0.0914\n",
      "Epoch 38/42\n",
      "2240/2240 [==============================] - 13s 6ms/step - loss: 6.4480 - bmag_loss: 1.6830 - phi_loss: 0.2629 - theta_loss: 0.1658 - y0r_loss: 4.2452 - handedness_loss: 0.0910\n",
      "Epoch 39/42\n",
      "2240/2240 [==============================] - 19s 9ms/step - loss: 6.4260 - bmag_loss: 1.6790 - phi_loss: 0.2626 - theta_loss: 0.1657 - y0r_loss: 4.2285 - handedness_loss: 0.0903\n",
      "Epoch 40/42\n",
      "2240/2240 [==============================] - 12s 5ms/step - loss: 6.3956 - bmag_loss: 1.6736 - phi_loss: 0.2610 - theta_loss: 0.1661 - y0r_loss: 4.2040 - handedness_loss: 0.0908\n",
      "Epoch 41/42\n",
      "2240/2240 [==============================] - 11s 5ms/step - loss: 6.3729 - bmag_loss: 1.6674 - phi_loss: 0.2615 - theta_loss: 0.1662 - y0r_loss: 4.1881 - handedness_loss: 0.0897\n",
      "Epoch 42/42\n",
      "2240/2240 [==============================] - 10s 5ms/step - loss: 6.3488 - bmag_loss: 1.6649 - phi_loss: 0.2608 - theta_loss: 0.1664 - y0r_loss: 4.1668 - handedness_loss: 0.0898\n",
      "\n",
      "Evaluating model on test set...\n",
      "[0.969, 0.145, 0.101, 2.187, 0.069, 7.222]\n"
     ]
    }
   ],
   "source": [
    "durations = []\n",
    "\n",
    "# 1. Train a model with the current training set\n",
    "keras.backend.clear_session()\n",
    "mc_model = get_model(d1, d2, act=\"relu\")\n",
    "startTime = time.time()\n",
    "\n",
    "callbacks_list = [\n",
    "    keras.callbacks.EarlyStopping(monitor='val_loss', patience=6)\n",
    "]\n",
    "\n",
    "tra = NpzDataGenerator(npzPath+'baseline_train/', train) \n",
    "val = NpzDataGenerator(npzPath+'baseline_validation/', validation)\n",
    "\n",
    "h_mc = mc_model.fit_generator(tra, epochs=500, verbose=1, callbacks=callbacks_list, validation_data=(val) )\n",
    "\n",
    "epochs = len(h_mc.history['loss'])\n",
    "\n",
    "stopTime = time.time()\n",
    "durations.append( stopTime-startTime )\n",
    "    \n",
    "# 2. Retrain with training + validation\n",
    "x = np.concatenate( (train,validation) )\n",
    "keras.backend.clear_session()\n",
    "mc_model = get_model(d1, d2, act=\"relu\")\n",
    "startTime = time.time()\n",
    "combineTrainValidation(npzPath, 'baseline_train/', train, 'baseline_validation/', validation)\n",
    "tra = NpzDataGenerator(npzPath+'baseline_train_2/', x) \n",
    "h_mc = mc_model.fit_generator( tra, epochs=epochs, verbose=1 )\n",
    "stopTime = time.time()\n",
    "durations.append( stopTime-startTime )\n",
    "\n",
    "# 3. Compute the error on the test set\n",
    "startTime = time.time()\n",
    "test_pred, yTest, errors = modelEvaluations(mc_model, npzPath+'baseline_test/', test)\n",
    "stopTime = time.time()\n",
    "durations.append( stopTime-startTime )\n",
    "print(errors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 264,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Duration: 17.17 minutes\n"
     ]
    }
   ],
   "source": [
    "print(\"Duration:\", round(np.sum(durations)/60.,2), \"minutes\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 268,
   "metadata": {},
   "outputs": [],
   "source": [
    "file = '/data/pool/results/baseline_01.txt'\n",
    "f = open(file, 'w')\n",
    "f.write('duration, b, phi, theta, y0, h, overall')\n",
    "line = str(round(np.sum(durations)/60.,2)).strip() + ',' + \\\n",
    "        str(errors[0]).strip() + ',' + str(errors[1]).strip() + ',' + str(errors[2]).strip() + ',' + \\\n",
    "        str(errors[3]).strip() + ',' + str(errors[4]).strip() + ',' + str(errors[5]).strip()\n",
    "f.write( line )\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### END"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
